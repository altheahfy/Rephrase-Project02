"""
ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³
è¤‡æ–‡å†…éƒ¨æ§‹é€ ï¼ˆé–¢ä¿‚è©ç¯€ãƒ»å‰¯è©ç¯€ï¼‰ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«åˆ†è§£
"""
import spacy
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class SubSlotResult:
    """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœ"""
    clause_type: str  # "relative_clause", "adverbial_clause"
    original_text: str
    sub_slots: Dict[str, str]
    confidence: float

class SubSlotDecomposer:
    """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        print("ğŸ”§ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...")
        self.nlp = spacy.load('en_core_web_sm')
        print("âœ… ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº†")
    
    def decompose_complex_slots(self, main_slots: Dict[str, str]) -> Dict[str, List[SubSlotResult]]:
        """ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆã‹ã‚‰è¤‡æ–‡ç®‡æ‰€ã‚’æ¤œå‡ºã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£"""
        sub_slot_results = {}
        
        print("\nğŸ” è¤‡æ–‡ç®‡æ‰€æ¤œå‡ºãƒ»ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£é–‹å§‹")
        
        # 1. ä¸»èª(S)å†…ã®é–¢ä¿‚è©ç¯€
        if 'S' in main_slots and ('who' in main_slots['S'] or 'which' in main_slots['S']):
            print(f"\n1ï¸âƒ£ ä¸»èª(S)å†…é–¢ä¿‚è©ç¯€åˆ†æ: {main_slots['S']}")
            relative_result = self._decompose_relative_clause(main_slots['S'])
            if relative_result:
                sub_slot_results['S'] = [relative_result]
        
        # 2. ä¿®é£¾èª(M2)å†…ã®å‰¯è©ç¯€
        if 'M2' in main_slots:
            print(f"\n2ï¸âƒ£ ä¿®é£¾èª(M2)å†…å‰¯è©ç¯€åˆ†æ: {main_slots['M2']}")
            adverbial_result = self._decompose_adverbial_clause(main_slots['M2'])
            if adverbial_result:
                sub_slot_results['M2'] = [adverbial_result]
        
        # 3. ä¿®é£¾èª(M3)å†…ã®å‰¯è©ç¯€
        if 'M3' in main_slots:
            print(f"\n3ï¸âƒ£ ä¿®é£¾èª(M3)å†…å‰¯è©ç¯€åˆ†æ: {main_slots['M3']}")
            adverbial_result = self._decompose_adverbial_clause(main_slots['M3'])
            if adverbial_result:
                sub_slot_results['M3'] = [adverbial_result]
        
        # 4. è£œèª(C2)å†…ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
        if 'C2' in main_slots:
            print(f"\n4ï¸âƒ£ è£œèª(C2)å†…ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†æ: {main_slots['C2']}")
            complement_result = self._decompose_complement_phrase(main_slots['C2'])
            if complement_result:
                sub_slot_results['C2'] = [complement_result]
        
        print("\nâœ… ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£å®Œäº†")
        return sub_slot_results
    
    def _decompose_relative_clause(self, text: str) -> SubSlotResult:
        """é–¢ä¿‚è©ç¯€ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£"""
        doc = self.nlp(text)
        
        # é–¢ä¿‚è©ç¯€éƒ¨åˆ†ã‚’æŠ½å‡º
        relative_clause = self._extract_relative_clause_text(text)
        if not relative_clause:
            return None
        
        print(f"   ğŸ¯ é–¢ä¿‚è©ç¯€æŠ½å‡º: {relative_clause}")
        
        # é–¢ä¿‚è©ç¯€ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
        sub_slots = {}
        rel_doc = self.nlp(relative_clause)
        
        # ã‚µãƒ–S (é–¢ä¿‚ä»£åè© + å…ˆè¡Œè©)
        # å®Œå…¨ãªä¸»èªå¥ã‚’å–å¾—ï¼ˆå…ˆè¡Œè© + é–¢ä¿‚ä»£åè©ï¼‰
        main_text = text  # "the manager who had recently taken charge..."
        relative_clause = self._extract_relative_clause_text(text)  # "who had recently taken charge..."
        
        # å…ˆè¡Œè©éƒ¨åˆ†ã‚’æŠ½å‡º
        if relative_clause:
            antecedent_end_idx = text.find(relative_clause)
            antecedent = text[:antecedent_end_idx].strip()  # "the manager"
            relative_pronoun = relative_clause.split()[0]  # "who"
            sub_slots['sub_S'] = f"{antecedent} {relative_pronoun}"  # "the manager who"
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é–¢ä¿‚ä»£åè©ã®ã¿
            for token in rel_doc:
                if token.dep_ == 'nsubj' and token.pos_ == 'PRON':
                    sub_slots['sub_S'] = token.text
                    break
        
        # ã‚µãƒ–Aux (åŠ©å‹•è©)
        aux_parts = []
        for token in rel_doc:
            if token.dep_ == 'aux':
                aux_parts.append(token.text)
        if aux_parts:
            sub_slots['sub_Aux'] = ' '.join(aux_parts)
        
        # ã‚µãƒ–V (å‹•è©)
        for token in rel_doc:
            if token.dep_ == 'ROOT':
                sub_slots['sub_V'] = token.text
                break
        
        # ã‚µãƒ–M2 (å‰¯è©)
        for token in rel_doc:
            if token.dep_ == 'advmod':
                sub_slots['sub_M2'] = token.text
                break
        
        # ã‚µãƒ–O1 (ç›®çš„èª) - å‰ç½®è©å¥ã‚‚å«ã‚€å®Œå…¨ãªç›®çš„èª
        for token in rel_doc:
            if token.dep_ == 'dobj':
                # ç›®çš„èªã®å®Œå…¨ãªå¥ã‚’æŠ½å‡ºï¼ˆå‰ç½®è©å¥å«ã‚€ï¼‰
                obj_phrase = self._extract_complete_object_phrase(token, rel_doc)
                sub_slots['sub_O1'] = obj_phrase
                break
        
        return SubSlotResult(
            clause_type="relative_clause",
            original_text=relative_clause,
            sub_slots=sub_slots,
            confidence=0.95
        )
    
    def _decompose_adverbial_clause(self, text: str) -> SubSlotResult:
        """å‰¯è©ç¯€ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£"""
        doc = self.nlp(text)
        sub_slots = {}
        
        # æ¥ç¶šè©ã‚’æ¤œå‡º
        conjunction = self._extract_conjunction(text)
        if conjunction:
            sub_slots['sub_M1'] = conjunction
        
        # ä¸»èªã‚’æ¤œå‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                # å®Œå…¨ãªä¸»èªå¥ã‚’æŠ½å‡º
                subject_phrase = self._extract_noun_phrase(token, doc)
                sub_slots['sub_S'] = subject_phrase
                break
        
        # åŠ©å‹•è©ã‚’æ¤œå‡º
        aux_parts = []
        for token in doc:
            if token.dep_ == 'aux':
                aux_parts.append(token.text)
        if aux_parts:
            sub_slots['sub_Aux'] = ' '.join(aux_parts)
        
        # å‹•è©ã‚’æ¤œå‡º
        main_verb = None
        for token in doc:
            if token.pos_ == 'VERB' and token.dep_ != 'aux':
                main_verb = token.text
                break
        if not main_verb:
            for token in doc:
                if token.pos_ == 'AUX' and token.dep_ == 'ROOT':
                    main_verb = token.text
                    break
        if main_verb:
            sub_slots['sub_V'] = main_verb
        
        # ç›®çš„èªã‚’æ¤œå‡º
        for token in doc:
            if token.dep_ == 'dobj':
                obj_phrase = self._extract_noun_phrase(token, doc)
                sub_slots['sub_O1'] = obj_phrase
                break
        
        # å‰ç½®è©å¥ã‚’æ¤œå‡º
        prep_phrases = []
        for token in doc:
            if token.dep_ == 'prep':
                prep_phrase = self._extract_prep_phrase(token, doc)
                if prep_phrase and conjunction not in prep_phrase:
                    prep_phrases.append(prep_phrase)
        if prep_phrases:
            # M2ã‚¹ãƒ­ãƒƒãƒˆã®å ´åˆã¯ sub_M2 ã«è¨­å®š (M3ã§ã¯ãªã)
            sub_slots['sub_M2'] = ' '.join(prep_phrases)
        
        return SubSlotResult(
            clause_type="adverbial_clause",
            original_text=text,
            sub_slots=sub_slots,
            confidence=0.90
        )
    
    def _decompose_complement_phrase(self, text: str) -> SubSlotResult:
        """è£œèªå¥ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ (deliver the final proposal flawlessly)"""
        doc = self.nlp(text)
        sub_slots = {}
        
        # å‹•è©ã‚’æ¤œå‡º (sub_V)
        main_verb = None
        for token in doc:
            if token.pos_ == 'VERB':
                main_verb = token
                sub_slots['sub_V'] = token.text
                break
        
        # ç›®çš„èªã‚’æ¤œå‡º (sub_O1)
        if main_verb:
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    obj_phrase = self._extract_noun_phrase(child, doc)
                    sub_slots['sub_O1'] = obj_phrase
                    break
        
        # ä¿®é£¾èªã‚’æ¤œå‡º (sub_M3)
        for token in doc:
            if token.dep_ == 'advmod':
                sub_slots['sub_M3'] = token.text
                break
        
        return SubSlotResult(
            clause_type="complement_phrase",
            original_text=text,
            sub_slots=sub_slots,
            confidence=0.95
        )
    
    def _extract_relative_clause_text(self, text: str) -> str:
        """é–¢ä¿‚è©ç¯€éƒ¨åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        if 'who' in text:
            who_index = text.find('who')
            return text[who_index:].strip()
        elif 'which' in text:
            which_index = text.find('which')
            return text[which_index:].strip()
        return ""
    
    def _extract_conjunction(self, text: str) -> str:
        """æ¥ç¶šè©ã‚’æŠ½å‡º"""
        conjunctions = ['even though', 'though', 'although', 'so', 'because', 'since', 'while', 'when']
        
        for conj in conjunctions:
            if text.lower().startswith(conj):
                return conj
        
        # å˜ä¸€èªã®æ¥ç¶šè©
        words = text.split()
        if words and words[0].lower() in ['so', 'because', 'since', 'while', 'when']:
            return words[0]
        
        return ""
    
    def _extract_noun_phrase(self, head_token, doc) -> str:
        """åè©å¥ã‚’æŠ½å‡º"""
        phrase_tokens = []
        
        # ä¿®é£¾èªã‚’åé›†
        for child in head_token.children:
            if child.dep_ in ['det', 'amod', 'poss']:
                phrase_tokens.append((child.i, child.text))
        
        # ãƒ˜ãƒƒãƒ‰èª
        phrase_tokens.append((head_token.i, head_token.text))
        
        # å¾Œç½®ä¿®é£¾èª
        for child in head_token.children:
            if child.dep_ in ['nmod', 'amod'] and child.i > head_token.i:
                phrase_tokens.append((child.i, child.text))
        
        # ä½ç½®ã§ã‚½ãƒ¼ãƒˆ
        phrase_tokens.sort()
        return ' '.join([text for _, text in phrase_tokens])
    
    def _extract_prep_phrase(self, prep_token, doc) -> str:
        """å‰ç½®è©å¥ã‚’æŠ½å‡º"""
        phrase_parts = [prep_token.text]
        
        # å‰ç½®è©ã®ç›®çš„èªã‚’å–å¾—
        for child in prep_token.children:
            if child.dep_ == 'pobj':
                obj_phrase = self._extract_noun_phrase(child, doc)
                phrase_parts.append(obj_phrase)
        
        return ' '.join(phrase_parts)
    
    def _extract_complete_object_phrase(self, obj_token, doc) -> str:
        """ç›®çš„èªã®å®Œå…¨ãªå¥ã‚’æŠ½å‡ºï¼ˆå‰ç½®è©å¥å«ã‚€ï¼‰"""
        phrase_parts = [obj_token.text]
        
        # ç›®çš„èªã«ä»˜éšã™ã‚‹å‰ç½®è©å¥ã‚’åé›†
        for child in obj_token.children:
            if child.dep_ == 'prep':
                prep_phrase = self._extract_prep_phrase(child, doc)
                phrase_parts.append(prep_phrase)
        
        return ' '.join(phrase_parts)
    
    def print_sub_slot_analysis(self, main_slots: Dict[str, str], sub_slot_results: Dict[str, List[SubSlotResult]]):
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†æçµæœã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ” ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœè©³ç´°")
        print("="*60)
        
        for main_slot, sub_results in sub_slot_results.items():
            print(f"\nğŸ“Œ ã€{main_slot}ã‚¹ãƒ­ãƒƒãƒˆã€‘: {main_slots[main_slot]}")
            
            for i, sub_result in enumerate(sub_results, 1):
                print(f"\n   {i}. {sub_result.clause_type} (ä¿¡é ¼åº¦: {sub_result.confidence:.1%})")
                print(f"      åŸæ–‡: {sub_result.original_text}")
                print(f"      ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£:")
                
                for sub_slot, value in sub_result.sub_slots.items():
                    print(f"        {sub_slot}: {value}")
