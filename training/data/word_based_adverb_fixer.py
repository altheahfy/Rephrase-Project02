#!/usr/bin/env python3
"""
å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ç‰ˆï¼‰
Mè¦ç´ ã‚’ã‚¹ãƒ­ãƒƒãƒˆIDã§ã¯ãªãå˜èªãã®ã‚‚ã®ã§ãƒ¡ã‚¿ã‚»ãƒ«é…ç½®
"""

import json
from pathlib import Path

class WordBasedAdverbFixer:
    def __init__(self):
        # actionã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚¹ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢çŸ¥ï¼‰
        self.action_data = [
            {
                "sentence": "She sings beautifully.",
                "slots": {"S": "She", "V": "sings", "M2": "beautifully"}
            },
            {
                "sentence": "We always eat breakfast together.",
                "slots": {"S": "We", "V": "eat", "O1": "breakfast", "M1": "always", "M2": "together"}
            },
            {
                "sentence": "The cat quietly sat on the mat.",
                "slots": {"S": "The cat", "V": "sat", "M1": "quietly", "M2": "on the mat"}
            },
            {
                "sentence": "She carefully reads books.",
                "slots": {"S": "She", "V": "reads", "O1": "books", "M2": "carefully"}
            },
            {
                "sentence": "They run fast.",
                "slots": {"S": "They", "V": "run", "M2": "fast"}
            },
            {
                "sentence": "Actually, she works very hard.",
                "slots": {"S": "she", "V": "works", "M1": "Actually", "M2": "very hard"}
            },
            {
                "sentence": "Every morning, he jogs slowly in the park.",
                "slots": {"S": "he", "V": "jogs", "M1": "Every morning", "M2": "slowly", "M3": "in the park"}
            }
        ]
    
    def analyze_word_positions(self):
        """å˜èªã®å®Ÿéš›ã®æ–‡ä¸­ä½ç½®ã‚’åˆ†æ"""
        print("ğŸš€ å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®åˆ†æé–‹å§‹")
        
        word_positions = {}  # å‰¯è©å˜èªåˆ¥ã®ä½ç½®æƒ…å ±
        non_adverb_elements = {}  # éå‰¯è©è¦ç´ ã®ä½ç½®æƒ…å ±
        
        for data in self.action_data:
            sentence = data["sentence"]
            slots = data["slots"]
            
            print(f"\nğŸ“ åˆ†æ: {sentence}")
            
            # å˜èªã®å®Ÿéš›ã®ä½ç½®ã‚’å–å¾—
            words = sentence.replace(',', '').replace('.', '').split()
            print(f"   å˜èªãƒªã‚¹ãƒˆ: {words}")
            
            for slot_type, slot_value in slots.items():
                # æ–‡ä¸­ã§ã®å®Ÿéš›ã®ä½ç½®ã‚’è¨ˆç®—
                slot_words = slot_value.split()
                try:
                    # æœ€åˆã®å˜èªã®ä½ç½®ã‚’å–å¾—
                    first_word = slot_words[0]
                    word_position = words.index(first_word) + 1
                    
                    if slot_type.startswith('M'):
                        # Mè¦ç´ ã¯å˜èªãƒ™ãƒ¼ã‚¹ã§è¨˜éŒ²
                        if slot_value not in word_positions:
                            word_positions[slot_value] = []
                        
                        # æ–‡æ³•çš„ä½ç½®ã®åˆ¤å®š
                        if word_position == 1:
                            grammar_role = "sentence_initial"
                        elif word_position == len(words) - len(slot_words) + 1:
                            grammar_role = "sentence_final"
                        else:
                            # S, V, Oã¨ã®ç›¸å¯¾ä½ç½®ã§åˆ¤å®š
                            s_pos = self._get_element_position(slots.get('S', ''), words)
                            v_pos = self._get_element_position(slots.get('V', ''), words)
                            
                            if word_position < v_pos:
                                if word_position < s_pos or word_position == s_pos + 1:
                                    grammar_role = "pre_subject_or_after_subject"
                                else:
                                    grammar_role = "pre_verb"
                            else:
                                grammar_role = "post_verb"
                        
                        word_positions[slot_value].append({
                            'sentence': sentence,
                            'position': word_position,
                            'grammar_role': grammar_role,
                            'context': f"{slot_type} in '{sentence}'"
                        })
                        
                        print(f"   ğŸ¯ '{slot_value}' â†’ ä½ç½®{word_position} ({grammar_role})")
                        
                    else:
                        # éMè¦ç´ 
                        element_key = f"{slot_type}_normal"
                        if element_key not in non_adverb_elements:
                            non_adverb_elements[element_key] = []
                        
                        non_adverb_elements[element_key].append({
                            'value': slot_value,
                            'sentence': sentence,
                            'position': word_position
                        })
                        
                        print(f"   ğŸ“ {slot_type}='{slot_value}' â†’ ä½ç½®{word_position}")
                        
                except (ValueError, IndexError) as e:
                    print(f"   âŒ ä½ç½®ç‰¹å®šã‚¨ãƒ©ãƒ¼: {slot_value} - {e}")
        
        return word_positions, non_adverb_elements
    
    def _get_element_position(self, element_value, words):
        """è¦ç´ ã®æ–‡ä¸­ä½ç½®ã‚’å–å¾—"""
        if not element_value:
            return 0
        try:
            first_word = element_value.split()[0]
            return words.index(first_word) + 1
        except (ValueError, IndexError):
            return 0
    
    def determine_adverb_order_positions(self, word_positions):
        """å‰¯è©ã®é †åºä½ç½®ã‚’æ±ºå®š"""
        print(f"\nğŸ” å‰¯è©ã®æ–‡æ³•çš„é †åºä½ç½®æ±ºå®š:")
        
        adverb_order = {}
        
        for word, positions in word_positions.items():
            # å„å‰¯è©ã®æ–‡æ³•çš„å½¹å‰²ã‚’åˆ†æ
            roles = [pos['grammar_role'] for pos in positions]
            most_common_role = max(set(roles), key=roles.count)
            
            # é †åºä½ç½®ã‚’æ±ºå®š
            if most_common_role == "sentence_initial":
                order_pos = 1
            elif most_common_role == "pre_subject_or_after_subject":
                order_pos = 3
            elif most_common_role == "pre_verb":
                order_pos = 3
            elif most_common_role == "post_verb":
                # ã•ã‚‰ã«ç´°åˆ†åŒ–ï¼šç›´å¾Œ vs æ–‡æœ«
                avg_pos = sum(pos['position'] for pos in positions) / len(positions)
                if avg_pos < 5:  # ç›¸å¯¾çš„ã«æ—©ã„ä½ç½®
                    order_pos = 5
                else:  # æ–‡æœ«å¯„ã‚Š
                    order_pos = 7
            elif most_common_role == "sentence_final":
                order_pos = 8
            else:
                order_pos = 5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
            adverb_order[word] = {
                'order_position': order_pos,
                'grammar_role': most_common_role,
                'positions': positions
            }
            
            print(f"  ğŸ¯ '{word}' â†’ é †åº{order_pos} ({most_common_role})")
        
        return adverb_order
    
    def build_final_order_mapping(self, non_adverb_elements, adverb_order):
        """æœ€çµ‚çš„ãªé †åºãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ§‹ç¯‰"""
        print(f"\nğŸ“Š æœ€çµ‚é †åºãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰:")
        
        # éå‰¯è©è¦ç´ ã®å¹³å‡ä½ç½®
        element_positions = {}
        for element_type, elements in non_adverb_elements.items():
            positions = [elem['position'] for elem in elements]
            avg_pos = sum(positions) / len(positions)
            element_positions[element_type] = avg_pos
            print(f"  ğŸ“ {element_type}: å¹³å‡ä½ç½®={avg_pos:.2f}")
        
        # å…¨è¦ç´ ã‚’çµ±åˆ
        all_elements = {}
        
        # éå‰¯è©è¦ç´ ã‚’è¿½åŠ 
        for element_type, avg_pos in element_positions.items():
            all_elements[element_type] = avg_pos
        
        # å‰¯è©ã‚’å˜èªãƒ™ãƒ¼ã‚¹ã§è¿½åŠ 
        for word, info in adverb_order.items():
            all_elements[f"word_{word}"] = info['order_position']
        
        # ã‚½ãƒ¼ãƒˆã—ã¦ç•ªå·ã‚’ä»˜ä¸
        sorted_elements = sorted(all_elements.items(), key=lambda x: x[1])
        
        order_mapping = {}
        for i, (element, position) in enumerate(sorted_elements, 1):
            order_mapping[element] = i
            print(f"  {i}. {element} (ä½ç½®: {position})")
        
        return order_mapping
    
    def apply_corrected_ordering(self, order_mapping, adverb_order):
        """ä¿®æ­£ã•ã‚ŒãŸé †åºã‚’é©ç”¨"""
        print(f"\nâœ… ä¿®æ­£ç‰ˆé †åºé©ç”¨:")
        
        results = []
        
        for data in self.action_data:
            sentence = data["sentence"]
            slots = data["slots"]
            
            ordered_slots = {}
            
            for slot_type, slot_value in slots.items():
                if slot_type.startswith('M'):
                    # Mè¦ç´ ã¯å˜èªãƒ™ãƒ¼ã‚¹ã§å‡¦ç†
                    word_key = f"word_{slot_value}"
                    if word_key in order_mapping:
                        order_num = order_mapping[word_key]
                        ordered_slots[str(order_num)] = slot_value
                else:
                    # éMè¦ç´ 
                    element_key = f"{slot_type}_normal"
                    if element_key in order_mapping:
                        order_num = order_mapping[element_key]
                        ordered_slots[str(order_num)] = slot_value
            
            results.append({
                'sentence': sentence,
                'original_slots': slots,
                'ordered_slots': ordered_slots
            })
            
            print(f"  ğŸ“ {sentence}")
            print(f"     ä¿®æ­£å¾Œ: {ordered_slots}")
        
        return results

def test_word_based_fix():
    """å˜èªãƒ™ãƒ¼ã‚¹ä¿®æ­£ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®ä¿®æ­£ãƒ†ã‚¹ãƒˆ")
    
    fixer = WordBasedAdverbFixer()
    
    # 1. å˜èªä½ç½®åˆ†æ
    word_positions, non_adverb_elements = fixer.analyze_word_positions()
    
    # 2. å‰¯è©é †åºä½ç½®æ±ºå®š
    adverb_order = fixer.determine_adverb_order_positions(word_positions)
    
    # 3. æœ€çµ‚é †åºãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰
    order_mapping = fixer.build_final_order_mapping(non_adverb_elements, adverb_order)
    
    # 4. ä¿®æ­£ç‰ˆé©ç”¨
    results = fixer.apply_corrected_ordering(order_mapping, adverb_order)
    
    # 5. çµæœä¿å­˜
    output_file = "word_based_corrected_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ä¿®æ­£ç‰ˆçµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # 6. å•é¡Œã®ã‚ã‚‹ä¾‹æ–‡ã®ç¢ºèª
    print(f"\nğŸ” å•é¡Œä¾‹æ–‡ã®ä¿®æ­£ç¢ºèª:")
    for result in results:
        if "together" in result['sentence'] or "carefully" in result['sentence']:
            print(f"  ğŸ“ {result['sentence']}")
            print(f"     ä¿®æ­£å¾Œé †åº: {result['ordered_slots']}")
            # ä¿®æ­£ã•ã‚ŒãŸèªé †ã‚’æ§‹ç¯‰
            ordered_words = {}
            for pos, word in result['ordered_slots'].items():
                ordered_words[int(pos)] = word
            reconstructed = " ".join([ordered_words[i] for i in sorted(ordered_words.keys())])
            print(f"     ä¿®æ­£ã•ã‚ŒãŸèªé †: {reconstructed}")
    
    return results

if __name__ == "__main__":
    test_word_based_fix()
