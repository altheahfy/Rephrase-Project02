#!/usr/bin/env python3
"""
Phase 3: spaCyå¢ƒç•Œç²¾å¯†åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
Step18ã®å¢ƒç•Œæ¤œå‡ºæŠ€è¡“ã‚’é¸æŠç§»æ¤ã—ã¦Phase 2çµæœã‚’ç²¾å¯†åŒ–

è¨­è¨ˆåŸå‰‡:
1. Phase 2çµæœã‚’åŸºç›¤ã¨ã—ã¦å¢ƒç•Œã®ã¿ã‚’ç²¾å¯†åŒ–
2. Step18ã‹ã‚‰å®Ÿè¨¼æ¸ˆã¿ã®å¢ƒç•Œæ¤œå‡ºæŠ€è¡“ã‚’é¸æŠç§»æ¤
3. v3+Phase2ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç ´å£Šã—ãªã„çµ±åˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from hierarchical_clause_engine import HierarchicalClauseEngine
import spacy
from typing import Dict, List, Optional, Any, Tuple

class SpacyBoundaryRefiner:
    """spaCyå¢ƒç•Œç²¾å¯†åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆPhase 3ï¼‰"""
    
    def __init__(self):
        """å¢ƒç•Œèª¿æ•´ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–"""
        print("ğŸ¯ Phase 3: spaCyå¢ƒç•Œç²¾å¯†åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...")
        
        try:
            self.spacy_nlp = spacy.load("en_core_web_sm")
            print("âœ… spaCyæº–å‚™å®Œäº†")
        except Exception as e:
            print(f"âŒ spaCyåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        
        # Step18ã‹ã‚‰ç§»æ¤ã™ã‚‹å¢ƒç•Œæ‹¡å¼µè¦å‰‡
        self.expand_deps = ['det', 'poss', 'compound', 'amod', 'case']
        self.connector_deps = ['mark']  # æ¥ç¶šè©ã‚’å«ã‚ã‚‹
        
        print("ğŸ—ï¸ å¢ƒç•Œç²¾å¯†åŒ–ãƒ«ãƒ¼ãƒ«æº–å‚™å®Œäº†")
    
    def refine_complex_result(self, text: str, phase2_result: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 2çµæœã®å¢ƒç•Œç²¾å¯†åŒ–ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰"""
        print(f"\nğŸ¯ Phase 3: å¢ƒç•Œç²¾å¯†åŒ–é–‹å§‹ '{text}'")
        
        # spaCyè§£æ
        spacy_doc = self.spacy_nlp(text)
        
        # Phase 2çµæœã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ç²¾å¯†åŒ–
        refined_result = phase2_result.copy()
        
        # ä¸»ç¯€ã®å¢ƒç•Œç²¾å¯†åŒ–
        if 'main_clause' in refined_result and refined_result['main_clause']:
            refined_result['main_clause'] = self._refine_clause_boundaries(
                refined_result['main_clause'], spacy_doc, "main"
            )
        
        # å¾“å±ç¯€ã®å¢ƒç•Œç²¾å¯†åŒ–
        if 'subordinate_clauses' in refined_result:
            refined_subordinate = []
            for i, sub_clause in enumerate(refined_result['subordinate_clauses']):
                refined_sub = self._refine_clause_boundaries(sub_clause, spacy_doc, f"sub_{i}")
                refined_subordinate.append(refined_sub)
            refined_result['subordinate_clauses'] = refined_subordinate
        
        return refined_result
    
    def _refine_clause_boundaries(self, clause_result: Dict[str, Any], spacy_doc, clause_type: str) -> Dict[str, Any]:
        """å€‹åˆ¥clauseå†…ã®ã‚¹ãƒ­ãƒƒãƒˆå¢ƒç•Œç²¾å¯†åŒ–"""
        print(f"\nğŸ“‹ {clause_type}ç¯€ã®å¢ƒç•Œç²¾å¯†åŒ–:")
        
        refined_clause = clause_result.copy()
        
        if 'slots' not in clause_result or not clause_result['slots']:
            print("  âš ï¸ ã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ãªã— - ã‚¹ã‚­ãƒƒãƒ—")
            return refined_clause
        
        # å„ã‚¹ãƒ­ãƒƒãƒˆã®å¢ƒç•Œç²¾å¯†åŒ–
        refined_slots = {}
        for slot_name, slot_data in clause_result['slots'].items():
            if isinstance(slot_data, dict) and 'main' in slot_data:
                slot_text = slot_data['main']
                refined_text = self._refine_slot_boundary(slot_text, slot_name, spacy_doc)
                refined_slots[slot_name] = {'main': refined_text}
                
                if refined_text != slot_text:
                    print(f"  ğŸ”§ {slot_name}: '{slot_text}' â†’ '{refined_text}'")
                else:
                    print(f"  âœ… {slot_name}: '{slot_text}' (å¤‰æ›´ãªã—)")
            else:
                refined_slots[slot_name] = slot_data
        
        refined_clause['slots'] = refined_slots
        return refined_clause
    
    def _refine_slot_boundary(self, slot_text: str, slot_name: str, spacy_doc) -> str:
        """å€‹åˆ¥ã‚¹ãƒ­ãƒƒãƒˆã®å¢ƒç•Œç²¾å¯†åŒ–"""
        
        # ã‚¹ãƒ­ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆã«å¯¾å¿œã™ã‚‹spaCyãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®š
        target_tokens = self._find_matching_tokens(slot_text, spacy_doc)
        if not target_tokens:
            print(f"    âš ï¸ '{slot_text}' ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„")
            return slot_text
        
        # Step18ã®å¢ƒç•Œæ‹¡å¼µæŠ€è¡“ã‚’é©ç”¨
        expanded_tokens = self._expand_token_span(target_tokens, spacy_doc, slot_name)
        
        # é€£ç¶šãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²ã§ãƒ†ã‚­ã‚¹ãƒˆå†æ§‹æˆ
        if expanded_tokens:
            start_i = min(token.i for token in expanded_tokens)
            end_i = max(token.i for token in expanded_tokens)
            refined_text = " ".join([spacy_doc[i].text for i in range(start_i, end_i + 1)])
            return refined_text
        
        return slot_text
    
    def _find_matching_tokens(self, slot_text: str, spacy_doc) -> List[Any]:
        """ã‚¹ãƒ­ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆã«å¯¾å¿œã™ã‚‹spaCyãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®š"""
        slot_words = slot_text.lower().split()
        if not slot_words:
            return []
        
        # æœ€åˆã®å˜èªã‚’æ¢ã™
        matching_tokens = []
        for token in spacy_doc:
            if token.text.lower() == slot_words[0]:
                # é€£ç¶šã™ã‚‹å˜èªãŒä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                consecutive_match = True
                token_sequence = []
                
                for i, word in enumerate(slot_words):
                    if token.i + i < len(spacy_doc):
                        current_token = spacy_doc[token.i + i]
                        if current_token.text.lower() == word:
                            token_sequence.append(current_token)
                        else:
                            consecutive_match = False
                            break
                    else:
                        consecutive_match = False
                        break
                
                if consecutive_match and len(token_sequence) == len(slot_words):
                    matching_tokens = token_sequence
                    break
        
        return matching_tokens
    
    def _expand_token_span(self, target_tokens: List[Any], spacy_doc, slot_name: str) -> List[Any]:
        """Step18å¢ƒç•Œæ‹¡å¼µæŠ€è¡“ã®é¸æŠé©ç”¨"""
        
        if not target_tokens:
            return target_tokens
        
        expanded_tokens = set(target_tokens)
        
        # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰å¢ƒç•Œæ‹¡å¼µ
        for token in target_tokens:
            # Step18ã®åŸºæœ¬æ‹¡å¼µè¦å‰‡
            for child in token.children:
                if child.dep_ in self.expand_deps:
                    expanded_tokens.add(child)
                    print(f"    ğŸ”§ åŸºæœ¬æ‹¡å¼µ: '{child.text}' ({child.dep_})")
            
            # æ¥ç¶šè©ã®ç‰¹åˆ¥å‡¦ç†ï¼ˆPhase 2ã§æ¶ˆå¤±ã—ãŸã€Œthoughã€ç­‰ã‚’å›å¾©ï¼‰
            for child in token.children:
                if child.dep_ in self.connector_deps:
                    expanded_tokens.add(child)
                    print(f"    ğŸ”§ æ¥ç¶šè©å›å¾©: '{child.text}' ({child.dep_})")
            
            # å‰ç½®è©å¥ã®å®Œå…¨å‡¦ç†
            if token.pos_ == 'NOUN':
                for child in token.children:
                    if child.dep_ == 'case':  # å‰ç½®è©
                        expanded_tokens.add(child)
                        print(f"    ğŸ”§ å‰ç½®è©è¿½åŠ : '{child.text}'")
        
        return list(expanded_tokens)

class CompleteBoundaryEngine(HierarchicalClauseEngine):
    """Phase 2 + Phase 3çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        super().__init__()
        self.boundary_refiner = SpacyBoundaryRefiner()
    
    def analyze_with_refined_boundaries(self, text: str) -> Dict[str, Any]:
        """å¢ƒç•Œç²¾å¯†åŒ–ä»˜ãå®Œå…¨åˆ†æ"""
        print(f"\nğŸ¯ Phase2+3çµ±åˆåˆ†æ: '{text}'")
        
        # Phase 2: éšå±¤çš„clauseåˆ†è§£
        phase2_result = super().analyze_complex_sentence(text)
        
        # Phase 3: å¢ƒç•Œç²¾å¯†åŒ–
        refined_result = self.boundary_refiner.refine_complex_result(text, phase2_result)
        
        return refined_result

def test_boundary_refinement():
    """Phase 3å¢ƒç•Œç²¾å¯†åŒ–ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ¯ Phase 3: spaCyå¢ƒç•Œç²¾å¯†åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ ãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    
    try:
        engine = CompleteBoundaryEngine()
        print("âœ… Phase 2+3çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†\n")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
        return
    
    # Phase 2ã§å•é¡ŒãŒè¦‹ã¤ã‹ã£ãŸæ–‡ã‚’é‡ç‚¹ãƒ†ã‚¹ãƒˆ
    test_sentences = [
        "He succeeded even though he was under intense pressure.",
        "She passed the test because she is very intelligent.",
        "The man who is tall walks quickly.",
    ]
    
    for sentence in test_sentences:
        print(f"\n{'='*80}")
        print(f"ãƒ†ã‚¹ãƒˆæ–‡: {sentence}")
        print('='*80)
        
        result = engine.analyze_with_refined_boundaries(sentence)
        
        print(f"\nğŸ“Š Phase3 å¢ƒç•Œç²¾å¯†åŒ–çµæœ:")
        print(f"ğŸ“‹ æ–‡å‹: {result.get('sentence_type', 'unknown')}")
        print(f"ğŸ“‹ ç¯€æ•°: {result.get('total_clauses', 0)}")
        
        # ä¸»ç¯€çµæœ
        main_clause = result.get('main_clause', {})
        print(f"\nğŸ›ï¸ ä¸»ç¯€ï¼ˆå¢ƒç•Œç²¾å¯†åŒ–å¾Œï¼‰:")
        print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: '{main_clause.get('text', 'N/A')}'")
        print(f"  ã‚¹ãƒ­ãƒƒãƒˆ:")
        for slot_name, slot_data in main_clause.get('slots', {}).items():
            if isinstance(slot_data, dict) and 'main' in slot_data:
                print(f"    {slot_name}: '{slot_data['main']}'")
        
        # å¾“å±ç¯€çµæœ
        for i, sub_clause in enumerate(result.get('subordinate_clauses', [])):
            print(f"\nğŸ”— å¾“å±ç¯€ {i+1}ï¼ˆå¢ƒç•Œç²¾å¯†åŒ–å¾Œï¼‰:")
            print(f"  æ¥ç¶š: '{sub_clause.get('connector', '')}' ({sub_clause.get('relation', 'N/A')})")
            print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: '{sub_clause.get('text', 'N/A')}'")
            print(f"  ã‚¹ãƒ­ãƒƒãƒˆ:")
            for slot_name, slot_data in sub_clause.get('slots', {}).items():
                if isinstance(slot_data, dict) and 'main' in slot_data:
                    print(f"    {slot_name}: '{slot_data['main']}'")

if __name__ == "__main__":
    test_boundary_refinement()
