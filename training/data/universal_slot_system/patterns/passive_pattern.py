"""
Passive Pattern Implementation
å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±ä¸€ä¿®æ­£å®Ÿè£…

æ—¢å­˜ã®å€‹åˆ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œå®Ÿè£…
"""

from typing import Dict, List, Any, Tuple
from ..base_patterns import GrammarPattern


class PassivePattern(GrammarPattern):
    """
    å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±ä¸€ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 
    
    beå‹•è© + éå»åˆ†è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å—å‹•æ…‹åˆ¤å®šãƒ»ä¿®æ­£
    
    äººé–“ã®èªè­˜: "was unexpected" â†’ be + pp â†’ å—å‹•æ…‹
    stanzaèª¤åˆ¤å®š: unexpected(root) + was(cop) â†’ è£œèªæ§‹æ–‡
    äººé–“ä¿®æ­£: was(aux) + unexpected(root, passive) â†’ å—å‹•æ…‹æ§‹é€ 
    """
    
    def __init__(self):
        super().__init__(
            pattern_name="passive_voice",
            confidence_threshold=0.85
        )
        
        # beå‹•è©ãƒªã‚¹ãƒˆ
        self.be_verbs = ['be', 'am', 'is', 'are', 'was', 'were', 'been', 'being']
        
        # éå»åˆ†è©èªå°¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.past_participle_endings = [
            'ed',      # è¦å‰‡å‹•è©
            'en',      # broken, chosen
            'ated',    # created, related
            'ized',    # realized, organized  
            'ified',   # classified, verified
            'ected',   # connected, expected
            'ested'    # interested, invested
        ]
        
        # ç´”ç²‹å½¢å®¹è©ï¼ˆéå»åˆ†è©ã§ã¯ãªã„ï¼‰èªå°¾
        self.pure_adjective_patterns = ['red', 'ded', 'eed', 'ted']
        
        self.description = "beå‹•è© + éå»åˆ†è©ã®å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±ä¸€ä¿®æ­£"
        
    def detect(self, words: List, sentence: str) -> Dict[str, Any]:
        """
        å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã®çµ±ä¸€å®Ÿè£…
        
        Args:
            words: Stanzaè§£æå¾Œã®å˜èªãƒªã‚¹ãƒˆ  
            sentence: åŸæ–‡
            
        Returns:
            æ¤œå‡ºçµæœè¾æ›¸
        """
        result = {
            'found': False,
            'be_verb': None,
            'past_participle': None,
            'confidence': 0.0,
            'target_words': [],
            'correction_data': {},
            'pattern_matches': [],
            'keywords_matched': 0,
            'total_keywords': 2  # beå‹•è© + éå»åˆ†è©
        }
        
        # å„å˜èªã«æ–‡è„ˆæƒ…å ±ã‚’è¿½åŠ ï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹åˆ¤å®šç”¨ï¼‰
        for word in words:
            word._sentence_words = words
            
        # æ§‹é€ çš„ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜å®Ÿè¡Œ
        passive_detection = self._detect_passive_voice_structural_pattern(words)
        
        if passive_detection['found']:
            be_verb = passive_detection['be_verb']
            past_participle = passive_detection['past_participle']
            
            # stanzaèª¤åˆ¤å®šãƒã‚§ãƒƒã‚¯ï¼šéå»åˆ†è©ãŒrootã§ã€beå‹•è©ãŒcop
            is_stanza_misanalysis = (
                past_participle.deprel == 'root' and 
                be_verb.deprel == 'cop'
            )
            
            if is_stanza_misanalysis:
                result.update({
                    'found': True,
                    'be_verb': be_verb,
                    'past_participle': past_participle,
                    'confidence': passive_detection['confidence'],
                    'target_words': [be_verb, past_participle],
                    'correction_data': {
                        'be_verb_original_deprel': be_verb.deprel,
                        'be_verb_target_deprel': 'aux',
                        'past_participle_original_deprel': past_participle.deprel,
                        'past_participle_target_deprel': 'root',
                        'correction_type': 'passive_voice_restructure'
                    },
                    'pattern_matches': ['be_verb_cop_past_participle_root'],
                    'keywords_matched': 2,
                    'structure_match_score': 0.9,
                    'pos_consistency_score': 0.85,
                    'semantic_score': 0.8
                })
                
        return result
        
    def correct(self, doc, detection_result: Dict) -> Tuple[Any, Dict]:
        """
        å—å‹•æ…‹ä¿®æ­£ã®çµ±ä¸€å®Ÿè£…
        
        Args:
            doc: Stanza document
            detection_result: detect()ã®çµæœ
            
        Returns:
            (ä¿®æ­£å¾Œdoc, ä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)
        """
        if not detection_result.get('found', False):
            return doc, {}
            
        be_verb = detection_result['be_verb']
        past_participle = detection_result['past_participle']
        correction_data = detection_result['correction_data']
        
        # ä¿®æ­£æƒ…å ±ã‚’è¨˜éŒ²
        if not hasattr(doc, 'human_grammar_corrections'):
            doc.human_grammar_corrections = {}
            
        # beå‹•è©ã®ä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        be_verb_metadata = self.create_correction_metadata(
            be_verb,
            {'deprel': correction_data['be_verb_original_deprel']},
            {
                'deprel': correction_data['be_verb_target_deprel'],
                'confidence': detection_result['confidence']
            }
        )
        
        # éå»åˆ†è©ã®ä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        past_participle_metadata = self.create_correction_metadata(
            past_participle,
            {'deprel': correction_data['past_participle_original_deprel']},
            {
                'deprel': correction_data['past_participle_target_deprel'],
                'confidence': detection_result['confidence']
            }
        )
        
        # human_grammar_correctionsã«è¿½åŠ 
        doc.human_grammar_corrections[be_verb.id] = be_verb_metadata
        doc.human_grammar_corrections[past_participle.id] = past_participle_metadata
        
        # çµ±åˆä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        combined_metadata = {
            'correction_type': 'passive_voice',
            'be_verb': be_verb_metadata,
            'past_participle': past_participle_metadata,
            'correction_description': f"Convert '{be_verb.text} {past_participle.text}' to passive voice",
            'confidence': detection_result['confidence'],
            'original_structure': f"{past_participle.text}(root) + {be_verb.text}(cop)",
            'corrected_structure': f"{be_verb.text}(aux) + {past_participle.text}(root, passive)"
        }
        
        self.logger.debug(
            f"ğŸ”„ å—å‹•æ…‹ä¿®æ­£: '{be_verb.text} {past_participle.text}' "
            f"â†’ å—å‹•æ…‹ (stanza: {past_participle.text}=root, {be_verb.text}=cop)"
        )
        
        return doc, combined_metadata
        
    def is_applicable(self, sentence: str) -> bool:
        """
        å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        
        Args:
            sentence: å¯¾è±¡æ–‡
            
        Returns:
            é©ç”¨å¯èƒ½ãƒ•ãƒ©ã‚°
        """
        sentence_lower = sentence.lower()
        
        # beå‹•è©å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        has_be_verb = any(be_verb in sentence_lower for be_verb in self.be_verbs)
        
        # éå»åˆ†è©ã‚‰ã—ãèªå°¾å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        has_past_participle_ending = any(
            ending in sentence_lower for ending in self.past_participle_endings
        )
        
        return has_be_verb and has_past_participle_ending
        
    def _detect_passive_voice_structural_pattern(self, words):
        """æ§‹é€ çš„å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã®çµ±ä¸€å®Ÿè£…"""
        result = {'found': False, 'be_verb': None, 'past_participle': None, 'confidence': 0.0}
        
        for i in range(len(words) - 1):
            current = words[i]
            next_word = words[i + 1]
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: beå‹•è© + ç›´å¾Œã®èª
            if self._is_be_verb(current):
                confidence = 0.0
                
                # ç›´å¾ŒãŒæ˜ç¢ºãªéå»åˆ†è©
                if self._is_past_participle(next_word):
                    confidence = 0.9
                    
                    # é«˜ä¿¡é ¼åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³
                    if next_word.xpos == 'VBN':
                        confidence = 0.95
                    elif next_word.upos == 'ADJ' and self._has_past_participle_morphology(next_word):
                        confidence = 0.8
                    
                    if confidence > result['confidence']:
                        result.update({
                            'found': True,
                            'be_verb': current,
                            'past_participle': next_word,
                            'confidence': confidence
                        })
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: beå‹•è© + å‰¯è© + éå»åˆ†è©
            if (i < len(words) - 2 and 
                self._is_be_verb(current) and 
                words[i + 1].upos == 'ADV' and
                self._is_past_participle(words[i + 2])):
                
                confidence = 0.85
                if confidence > result['confidence']:
                    result.update({
                        'found': True,
                        'be_verb': current,
                        'past_participle': words[i + 2],
                        'confidence': confidence
                    })
        
        return result
        
    def _is_be_verb(self, word):
        """beå‹•è©åˆ¤å®šï¼ˆæ±ç”¨çš„ãƒ»lemmaãƒ™ãƒ¼ã‚¹ï¼‰"""
        return (word.upos == 'AUX' and word.lemma.lower() == 'be')
        
    def _is_past_participle(self, word):
        """éå»åˆ†è©åˆ¤å®šï¼ˆæ±ç”¨çš„ãƒ»å½¢æ…‹è«–çš„åˆ†æé‡è¦–ï¼‰"""
        # 1. stanzaã®å½¢æ…‹è«–çš„åˆ¤å®šã‚’æœ€å„ªå…ˆ
        if word.xpos == 'VBN':  # Past participle
            return True
            
        # 2. beå‹•è©ç›´å¾Œã®å½¢å®¹è©çš„èªã®æ–‡è„ˆçš„åˆ¤å®š
        if word.upos == 'ADJ':
            return self._contextual_past_participle_check(word)
        
        return False
        
    def _contextual_past_participle_check(self, word):
        """æ–‡è„ˆçš„éå»åˆ†è©åˆ¤å®šï¼ˆbeå‹•è©ç›´å¾Œã®å½¢å®¹è©ï¼‰"""
        # beå‹•è©ç›´å¾Œã§å½¢å®¹è©ã‚¿ã‚° â†’ å—å‹•æ…‹ã®å¯èƒ½æ€§
        if self._follows_be_verb_directly(word):
            # å½¢æ…‹è«–çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            return self._has_past_participle_morphology(word)
        return False
        
    def _follows_be_verb_directly(self, word):
        """ç›´å‰ã«beå‹•è©ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if hasattr(word, '_sentence_words'):
            words = word._sentence_words
            word_pos = next((i for i, w in enumerate(words) if w.id == word.id), -1)
            if word_pos > 0:
                prev_word = words[word_pos - 1]
                return self._is_be_verb(prev_word)
        return False
        
    def _has_past_participle_morphology(self, word):
        """å½¢æ…‹è«–çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆèªå°¾åˆ†æï¼‰"""
        text = word.text.lower()
        
        # è¦å‰‡å‹•è©ã®-edèªå°¾ï¼ˆæœ€ä½4æ–‡å­—ä»¥ä¸Šï¼‰
        if text.endswith('ed') and len(text) > 3:
            # ãŸã ã—ç´”ç²‹ãªå½¢å®¹è©ï¼ˆkindred, sacredç­‰ï¼‰ã‚’é™¤å¤–
            if not self._is_pure_adjective_ending(text):
                return True
        
        # -enèªå°¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆbroken, chosenç­‰ï¼‰
        if text.endswith('en') and len(text) > 3:
            # listen, kittenç­‰ã®åè©ãƒ»å‹•è©ã‚’é™¤å¤–
            if not text.endswith(('tten', 'sten', 'chen', 'len')):
                return True
        
        # ç‰¹å¾´çš„ãªéå»åˆ†è©èªå°¾
        if any(text.endswith(ending) for ending in self.past_participle_endings):
            return True
        
        return False
        
    def _is_pure_adjective_ending(self, text):
        """ç´”ç²‹ãªå½¢å®¹è©èªå°¾ï¼ˆéå»åˆ†è©ã§ã¯ãªã„ï¼‰"""
        return any(text.endswith(pattern) for pattern in self.pure_adjective_patterns)
        
    def calculate_confidence(self, detection_result: Dict) -> float:
        """
        å—å‹•æ…‹å°‚ç”¨ã®ä¿¡é ¼åº¦è¨ˆç®—
        
        Args:
            detection_result: æ¤œå‡ºçµæœ
            
        Returns:
            è¨ˆç®—ã•ã‚ŒãŸä¿¡é ¼åº¦
        """
        if not detection_result.get('found', False):
            return 0.0
            
        base_confidence = detection_result.get('confidence', 0.85)
        
        # XPOSã‚¿ã‚°ã®ä¿¡é ¼æ€§ã«ã‚ˆã‚‹èª¿æ•´
        past_participle = detection_result.get('past_participle')
        if past_participle:
            if past_participle.xpos == 'VBN':
                # æ˜ç¢ºãªéå»åˆ†è©ã‚¿ã‚°
                pos_bonus = 0.1
            elif past_participle.upos == 'ADJ':
                # å½¢å®¹è©ã‚¿ã‚°ã ãŒå½¢æ…‹è«–çš„ã«éå»åˆ†è©
                pos_bonus = 0.05
            else:
                pos_bonus = 0.0
        else:
            pos_bonus = 0.0
            
        # æ§‹é€ çš„ä¸€è‡´åº¦
        structure_score = detection_result.get('structure_match_score', 0.9)
        structure_bonus = (structure_score - 0.9) * 0.1
        
        # æœ€çµ‚ä¿¡é ¼åº¦è¨ˆç®—
        final_confidence = min(1.0, base_confidence + pos_bonus + structure_bonus)
        
        self.logger.debug(
            f"ğŸ“Š å—å‹•æ…‹ä¿¡é ¼åº¦è¨ˆç®—: base={base_confidence:.3f}, "
            f"pos_bonus={pos_bonus:.3f}, "
            f"structure_bonus={structure_bonus:.3f}, "
            f"final={final_confidence:.3f}"
        )
        
        return final_confidence
