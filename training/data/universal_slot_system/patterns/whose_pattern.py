"""
Whose Pattern Implementation
whoseæ§‹æ–‡ã§ã®å‹•è©/åè©åŒå½¢èªä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³

æ—¢å­˜ã®å€‹åˆ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç§»è¡Œå®Ÿè£…
"""

import re
from typing import Dict, List, Any, Tuple
from ..base_patterns import GrammarPattern


class WhosePattern(GrammarPattern):
    """
    whoseæ§‹æ–‡ã§ã®å‹•è©/åè©åŒå½¢èªã®çµ±ä¸€ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
    
    äººé–“ã®èªè­˜: "whose car is red lives here" 
    â†’ whose [åè©] [beå‹•è©] [å½¢å®¹è©] [å‹•è©] [å ´æ‰€] 
    â†’ [å‹•è©]ã¯ç¢ºå®Ÿã«å‹•è©ã¨ã—ã¦æ‰±ã†
    
    stanzaèª¤åˆ¤å®š: lives(NOUN, acl:relcl) â†’ åè©ã¨ã—ã¦é–¢ä¿‚ç¯€ä¿®é£¾
    äººé–“ä¿®æ­£: lives(VERB, root) â†’ å‹•è©ã¨ã—ã¦ãƒ¡ã‚¤ãƒ³å‹•è©
    """
    
    def __init__(self):
        super().__init__(
            pattern_name="whose_ambiguous_verb",
            confidence_threshold=0.90
        )
        
        # å‹•è©/åè©åŒå½¢èªãƒªã‚¹ãƒˆ
        self.ambiguous_verbs = [
            'lives', 'works', 'runs', 'goes', 'comes', 
            'stays', 'plays', 'looks', 'sounds', 'seems'
        ]
        
        # whoseæ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ­£è¦è¡¨ç¾ï¼‰
        self.whose_patterns = [
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: whose [åè©] is [å½¢å®¹è©] [å‹•è©] (here|there|in...)
            r'whose\s+\w+\s+is\s+\w+\s+{verb}\s+(here|there|in\s+\w+)',
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: whose [åè©] [ä¿®é£¾èª]* [å‹•è©] (å ´æ‰€è¡¨ç¾)
            r'whose\s+\w+.*?\s+{verb}\s+(here|there|in|at|on)\s+\w+',
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: whose [åè©] [å‹•è©] (å‰¯è©) (å ´æ‰€)
            r'whose\s+\w+\s+{verb}\s+\w+\s+(here|there|in|at|on)'
        ]
        
        self.description = "whoseæ§‹æ–‡ã§ã®å‹•è©/åè©åŒå½¢èªã®äººé–“æ–‡æ³•çš„åˆ¤å®š"
        
    def detect(self, words: List, sentence: str) -> Dict[str, Any]:
        """
        whoseæ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã®çµ±ä¸€å®Ÿè£…
        
        Args:
            words: Stanzaè§£æå¾Œã®å˜èªãƒªã‚¹ãƒˆ
            sentence: åŸæ–‡
            
        Returns:
            æ¤œå‡ºçµæœè¾æ›¸
        """
        result = {
            'found': False,
            'ambiguous_verb': None,
            'confidence': 0.0,
            'target_words': [],
            'correction_data': {},
            'pattern_matches': [],
            'keywords_matched': 0,
            'total_keywords': 1
        }
        
        # whoseæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        if 'whose' not in sentence.lower():
            return result
            
        # å„åŒå½¢èªã«ã¤ã„ã¦æ¤œè¨¼
        for verb_text in self.ambiguous_verbs:
            if verb_text not in sentence.lower():
                continue
                
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
            pattern_matches = self._check_whose_patterns(sentence, verb_text)
            
            if pattern_matches:
                # è©²å½“ã™ã‚‹èªã‚’æ¢ã™
                target_word = self._find_target_word(words, verb_text)
                
                if target_word:
                    result.update({
                        'found': True,
                        'ambiguous_verb': target_word,
                        'confidence': 0.95,
                        'target_words': [target_word],
                        'correction_data': {
                            'verb_text': verb_text,
                            'original_upos': target_word.upos,
                            'target_upos': 'VERB',
                            'original_deprel': target_word.deprel,
                            'target_deprel': 'root'
                        },
                        'pattern_matches': pattern_matches,
                        'keywords_matched': 1,
                        'total_keywords': 1,
                        'structure_match_score': 0.9,
                        'pos_consistency_score': 0.8,
                        'semantic_score': 0.85
                    })
                    break
                    
        return result
        
    def correct(self, doc, detection_result: Dict) -> Tuple[Any, Dict]:
        """
        whoseæ§‹æ–‡ä¿®æ­£ã®çµ±ä¸€å®Ÿè£…
        
        Args:
            doc: Stanza document
            detection_result: detect()ã®çµæœ
            
        Returns:
            (ä¿®æ­£å¾Œdoc, ä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)
        """
        if not detection_result.get('found', False):
            return doc, {}
            
        ambiguous_word = detection_result['ambiguous_verb']
        correction_data = detection_result['correction_data']
        
        # ä¿®æ­£æƒ…å ±ã‚’è¨˜éŒ²ï¼ˆstanzaãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¯ä¸å¤‰ã®ãŸã‚ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ç®¡ç†ï¼‰
        if not hasattr(doc, 'human_grammar_corrections'):
            doc.human_grammar_corrections = {}
            
        # çµ±ä¸€ä¿®æ­£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        correction_metadata = self.create_correction_metadata(
            ambiguous_word,
            {
                'upos': correction_data['original_upos'],
                'deprel': correction_data['original_deprel']
            },
            {
                'upos': correction_data['target_upos'],
                'deprel': correction_data['target_deprel'],
                'confidence': detection_result['confidence']
            }
        )
        
        # human_grammar_correctionsã«è¿½åŠ 
        doc.human_grammar_corrections[ambiguous_word.id] = correction_metadata
        
        self.logger.debug(
            f"ğŸ§  whoseæ§‹æ–‡å‹•è©ä¿®æ­£: {ambiguous_word.text} "
            f"{correction_data['original_upos']}â†’{correction_data['target_upos']} "
            f"(äººé–“æ–‡æ³•èªè­˜)"
        )
        
        return doc, correction_metadata
        
    def is_applicable(self, sentence: str) -> bool:
        """
        whoseæ§‹æ–‡é©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        
        Args:
            sentence: å¯¾è±¡æ–‡
            
        Returns:
            é©ç”¨å¯èƒ½ãƒ•ãƒ©ã‚°
        """
        # whoseå¿…é ˆ + åŒå½¢èªå­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if 'whose' not in sentence.lower():
            return False
            
        # å°‘ãªãã¨ã‚‚ä¸€ã¤ã®åŒå½¢èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
        sentence_lower = sentence.lower()
        return any(verb in sentence_lower for verb in self.ambiguous_verbs)
        
    def _check_whose_patterns(self, sentence: str, verb_text: str) -> List[str]:
        """
        whoseæ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒãƒƒãƒãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
        
        Args:
            sentence: å¯¾è±¡æ–‡
            verb_text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡å‹•è©
            
        Returns:
            ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
        """
        matches = []
        sentence_lower = sentence.lower()
        
        for pattern_template in self.whose_patterns:
            # å‹•è©ã‚’å…·ä½“çš„ã«åŸ‹ã‚è¾¼ã‚“ã ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆ
            pattern = pattern_template.format(verb=verb_text)
            
            if re.search(pattern, sentence_lower):
                matches.append(pattern)
                self.logger.debug(f"ğŸ¯ whoseãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: {pattern}")
                
        return matches
        
    def _find_target_word(self, words: List, verb_text: str):
        """
        ä¿®æ­£å¯¾è±¡èªã‚’ç‰¹å®š
        
        Args:
            words: å˜èªãƒªã‚¹ãƒˆ
            verb_text: å¯¾è±¡å‹•è©ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            å¯¾è±¡èªï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        for word in words:
            if (word.text.lower() == verb_text and 
                word.upos == 'NOUN' and 
                word.deprel == 'acl:relcl'):
                
                self.logger.debug(
                    f"ğŸ” ä¿®æ­£å¯¾è±¡èªç™ºè¦‹: {word.text} "
                    f"(UPOS:{word.upos}, DEPREL:{word.deprel})"
                )
                return word
                
        return None
        
    def calculate_confidence(self, detection_result: Dict) -> float:
        """
        whoseæ§‹æ–‡å°‚ç”¨ã®ä¿¡é ¼åº¦è¨ˆç®—
        
        Args:
            detection_result: æ¤œå‡ºçµæœ
            
        Returns:
            è¨ˆç®—ã•ã‚ŒãŸä¿¡é ¼åº¦
        """
        if not detection_result.get('found', False):
            return 0.0
            
        base_confidence = detection_result.get('confidence', 0.95)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæ•°ã«ã‚ˆã‚‹èª¿æ•´
        pattern_matches = detection_result.get('pattern_matches', [])
        pattern_bonus = min(0.05, len(pattern_matches) * 0.02)
        
        # æ§‹é€ ãƒãƒƒãƒã‚¹ã‚³ã‚¢
        structure_score = detection_result.get('structure_match_score', 0.9)
        
        # æœ€çµ‚ä¿¡é ¼åº¦è¨ˆç®—
        final_confidence = min(1.0, base_confidence + pattern_bonus + (structure_score - 0.9) * 0.1)
        
        self.logger.debug(
            f"ğŸ“Š whoseä¿¡é ¼åº¦è¨ˆç®—: base={base_confidence:.3f}, "
            f"pattern_bonus={pattern_bonus:.3f}, "
            f"structure={structure_score:.3f}, "
            f"final={final_confidence:.3f}"
        )
        
        return final_confidence
