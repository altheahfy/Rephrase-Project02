"""
Modal Handler - åŠ©å‹•è©å‡¦ç†å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
Phase 6: ModalHandlerå®Ÿè£…

è¨­è¨ˆæ–¹é‡:
- Modalå‹•è©: can, could, will, would, shall, should, may, might, must
- åŠ©å‹•è©: do, does, did, have, has, had
- åŠåŠ©å‹•è©: be going to, used to, ought to
- å®Œäº†å½¢ãƒ»é€²è¡Œå½¢ã®è¤‡åˆæ§‹é€ å‡¦ç†
- Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ å®Œå…¨æº–æ‹ 
- Human Grammar Pattern: spaCy POSè§£æã‚’æ´»ç”¨ã—ãŸåŠ©å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
"""

import spacy
from typing import Dict, List, Any, Optional


class ModalHandler:
    """
    åŠ©å‹•è©å‡¦ç†å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    è²¬ä»»:
    - åŠ©å‹•è©ãƒ»æ³•åŠ©å‹•è©ã®æ¤œå‡ºã¨åˆ†é¡
    - è¤‡åˆåŠ©å‹•è©ï¼ˆshould have, will beç­‰ï¼‰ã®å‡¦ç†
    - ç–‘å•æ–‡ã§ã®åŠ©å‹•è©å€’ç½®å‡¦ç†
    - å®Œäº†å½¢ãƒ»é€²è¡Œå½¢ã®åŠ©å‹•è©å‡¦ç†
    - å¦å®šå½¢åŠ©å‹•è©ã®å‡¦ç†
    
    å¯¾è±¡ç¯„å›²:
    - Modal verbs: can/could/will/would/shall/should/may/might/must
    - Auxiliary verbs: do/does/did/have/has/had/be/am/is/are/was/were
    - Semi-modals: be going to/used to/ought to
    - Complex modals: should have/will be/might haveç­‰
    """
    
    def __init__(self, nlp=None):
        """åˆæœŸåŒ–: spaCy POSè§£æå™¨ã¨åŠ©å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨­å®š"""
        self.nlp = nlp if nlp else spacy.load('en_core_web_sm')
        
        # åŠ©å‹•è©åˆ†é¡ãƒãƒƒãƒ”ãƒ³ã‚°
        self._initialize_modal_patterns()
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤æ¸ˆã¿
    
    def _initialize_modal_patterns(self):
        """åŠ©å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–"""
        
        # åŸºæœ¬æ³•åŠ©å‹•è©
        self.modal_verbs = {
            'can', 'could', 'will', 'would', 'shall', 'should', 
            'may', 'might', 'must'
        }
        
        # åŠ©å‹•è©doç³»
        self.do_auxiliaries = {'do', 'does', 'did', "don't", "doesn't", "didn't"}
        
        # åŠ©å‹•è©haveç³»ï¼ˆå®Œäº†å½¢ï¼‰
        self.have_auxiliaries = {'have', 'has', 'had', "haven't", "hasn't", "hadn't"}
        
        # åŠ©å‹•è©beç³»
        self.be_auxiliaries = {
            'be', 'am', 'is', 'are', 'was', 'were', 'been', 'being',
            "isn't", "aren't", "wasn't", "weren't"
        }
        
        # è¤‡åˆåŠ©å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.complex_modals = {
            'be going to': r'\b(is|am|are|was|were)\s+going\s+to\b',
            'used to': r'\bused\s+to\b',
            'ought to': r'\bought\s+to\b',
            'have to': r'\b(have|has|had)\s+to\b',
            'will be': r'\bwill\s+be\b',
            'would be': r'\bwould\s+be\b',
            'should be': r'\bshould\s+be\b',
            'could be': r'\bcould\s+be\b',
            'might be': r'\bmight\s+be\b',
            'must be': r'\bmust\s+be\b',
            'should have': r'\bshould\s+have\b',
            'could have': r'\bcould\s+have\b',
            'would have': r'\bwould\s+have\b',
            'might have': r'\bmight\s+have\b',
            'must have': r'\bmust\s+have\b',
            'will have': r'\bwill\s+have\b',
            'have been': r'\b(have|has|had)\s+been\b',
            'will be': r'\bwill\s+be\b'
        }
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤æ¸ˆã¿
    
    def detect_modal_structure(self, text: str) -> Dict[str, Any]:
        """
        åŠ©å‹•è©æ§‹é€ ã®æ¤œå‡º
        
        Args:
            text: åˆ†æå¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: æ¤œå‡ºã•ã‚ŒãŸåŠ©å‹•è©æƒ…å ±
        """
        doc = self.nlp(text)
        
        result = {
            'has_modal': False,
            'modal_type': None,
            'auxiliary': None,
            'main_verb': None,
            'is_question': False,
            'is_negative': False,
            'structure_type': 'simple'
        }
        
        # è¤‡åˆåŠ©å‹•è©ã®æ¤œå‡ºï¼ˆå„ªå…ˆï¼‰
        complex_modal = self._detect_complex_modal(text)
        if complex_modal:
            result.update(complex_modal)
            return result
        
        # åŸºæœ¬åŠ©å‹•è©ã®æ¤œå‡º
        modal_info = self._detect_basic_modal(doc)
        if modal_info:
            result.update(modal_info)
            return result
        
        return result
    
    def _detect_complex_modal(self, text: str) -> Optional[Dict[str, Any]]:
        """è¤‡åˆåŠ©å‹•è©ã®æ¤œå‡ºï¼ˆå®Ÿéš›ã®å‹•è©å½¢ã‚’è¿”ã™ï¼‰"""
        import re
        
        text_lower = text.lower()
        
        for modal_phrase, pattern in self.complex_modals.items():
            match = re.search(pattern, text_lower)
            if match:
                # å®Ÿéš›ã«ãƒãƒƒãƒã—ãŸéƒ¨åˆ†ã‚’å–å¾—
                actual_auxiliary = match.group(0)
                
                return {
                    'has_modal': True,
                    'modal_type': 'complex',
                    'auxiliary': actual_auxiliary,
                    'structure_type': 'complex_modal'
                }
        
        return None
    
    def _detect_basic_modal(self, doc) -> Optional[Dict[str, Any]]:
        """åŸºæœ¬åŠ©å‹•è©ã®æ¤œå‡ºï¼ˆå¦å®šå½¢å¯¾å¿œï¼‰"""
        
        for i, token in enumerate(doc):
            token_lower = token.text.lower()
            
            # æ³•åŠ©å‹•è©
            if token_lower in self.modal_verbs:
                return {
                    'has_modal': True,
                    'modal_type': 'modal_verb',
                    'auxiliary': token.text,
                    'structure_type': 'modal'
                }
            
            # doç³»åŠ©å‹•è©ï¼ˆå¦å®šå½¢ãƒã‚§ãƒƒã‚¯ï¼‰
            if token_lower in {'do', 'does', 'did'}:
                # æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒ"n't"ã‹ãƒã‚§ãƒƒã‚¯
                auxiliary_text = token.text
                is_negative = False
                
                if (i + 1 < len(doc) and 
                    doc[i + 1].text.lower() in {"n't", "not"}):
                    auxiliary_text = token.text + "n't"
                    is_negative = True
                
                return {
                    'has_modal': True,
                    'modal_type': 'do_auxiliary',
                    'auxiliary': auxiliary_text,
                    'is_question': self._is_question_structure(doc),
                    'is_negative': is_negative,
                    'structure_type': 'auxiliary'
                }
            
            # haveç³»åŠ©å‹•è©ï¼ˆå®Œäº†å½¢ï¼‰
            if token_lower in self.have_auxiliaries and self._is_perfect_tense(doc, token):
                return {
                    'has_modal': True,
                    'modal_type': 'perfect_auxiliary',
                    'auxiliary': token.text,
                    'structure_type': 'perfect'
                }
        
        return None
    
    def _is_question_structure(self, doc) -> bool:
        """ç–‘å•æ–‡æ§‹é€ ã®åˆ¤å®š"""
        text = doc.text
        return (text.strip().endswith('?') or 
                any(token.text.lower() in ['what', 'where', 'when', 'why', 'how', 'who', 'which'] 
                    for token in doc[:2]))
    
    def _is_perfect_tense(self, doc, have_token) -> bool:
        """å®Œäº†å½¢ã®åˆ¤å®šï¼ˆhave/has/had + éå»åˆ†è©ï¼‰å‰¯è©ä»‹åœ¨å¯¾å¿œ"""
        have_idx = have_token.i
        
        # have/has/hadã®å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é †ç•ªã«ç¢ºèªï¼ˆå‰¯è©ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        for i in range(have_idx + 1, len(doc)):
            token = doc[i]
            
            # å¥èª­ç‚¹ã‚„æ¥ç¶šè©ã§åŒºåˆ‡ã‚‰ã‚ŒãŸã‚‰åœæ­¢
            if token.pos_ in ['PUNCT', 'CCONJ']:
                break
                
            # å‰¯è©ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶™ç¶š
            if token.pos_ == 'ADV':
                continue
                
            # éå»åˆ†è©ã‚’ç™ºè¦‹
            if token.tag_ in ['VBN']:  # past participle
                return True
                
            # beenã®å ´åˆï¼ˆå®Œäº†é€²è¡Œå½¢ï¼‰
            if token.text.lower() == 'been':
                return True
                
            # å‹•è©ä»¥å¤–ã®å“è©ãŒæ¥ãŸã‚‰å®Œäº†å½¢ã§ã¯ãªã„
            if token.pos_ not in ['VERB', 'AUX']:
                break
        
        return False
    
    def process(self, text: str, collaborators: Optional[Dict] = None) -> Dict[str, Any]:
        """
        åŠ©å‹•è©åˆ†è§£å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
        
        Args:
            text: åˆ†æå¯¾è±¡ã®è‹±èªæ–‡
            collaborators: ä»–ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨ã®å”åŠ›è€…ï¼ˆæœªä½¿ç”¨ã€å°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
            
        Returns:
            Dict: Rephraseã‚¹ãƒ­ãƒƒãƒˆå½¢å¼ã®åˆ†è§£çµæœ
        """
        print(f"ğŸ”„ ModalHandlerå‡¦ç†é–‹å§‹: '{text}'")
        
        try:
            # åŠ©å‹•è©æ§‹é€ ã®æ¤œå‡º
            modal_info = self.detect_modal_structure(text)
            
            if not modal_info.get('has_modal', False):
                return {
                    'success': False,
                    'reason': 'no_modal_detected',
                    'text': text
                }
            
            # Rephraseã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£å®Ÿè¡Œ
            result = self._decompose_to_rephrase_slots(text, modal_info)
            
            print(f"âœ… ModalHandlerå‡¦ç†å®Œäº†: {result.get('success', False)}")
            return result
            
        except Exception as e:
            print(f"âŒ ModalHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'text': text
            }
    
    def _decompose_to_rephrase_slots(self, text: str, modal_info: Dict) -> Dict[str, Any]:
        """Rephraseã‚¹ãƒ­ãƒƒãƒˆå½¢å¼ã¸ã®åˆ†è§£"""
        
        doc = self.nlp(text)
        
        # åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ 
        main_slots = {}
        sub_slots = {}
        
        # åŠ©å‹•è©ã®é…ç½®
        auxiliary = modal_info.get('auxiliary', '')
        if auxiliary:
            main_slots['Aux'] = auxiliary
        
        # ä¸»èªãƒ»å‹•è©ãƒ»ç›®çš„èªç­‰ã®æŠ½å‡º
        self._extract_basic_elements(doc, main_slots, modal_info)
        
        # ä¿®é£¾èªã®å‡¦ç†
        self._extract_modifiers(doc, main_slots, modal_info)
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'modal_info': modal_info,
            'text': text
        }
    
    def _extract_basic_elements(self, doc, main_slots: Dict, modal_info: Dict):
        """åŸºæœ¬è¦ç´ ï¼ˆä¸»èªãƒ»å‹•è©ãƒ»ç›®çš„èªãƒ»è£œèªï¼‰ã®æŠ½å‡º"""
        
        auxiliary = modal_info.get('auxiliary', '').lower()
        
        for token in doc:
            # ä¸»èªã®æŠ½å‡ºï¼ˆä¿®é£¾èªã‚’å«ã‚ãŸå®Œå…¨ãªåè©å¥ï¼‰
            if token.dep_ == 'nsubj' and 'S' not in main_slots:
                main_slots['S'] = self._extract_noun_phrase(token)
            
            # å‹•è©ã®æŠ½å‡ºï¼ˆåŠ©å‹•è©ä»¥å¤–ï¼‰
            elif (token.pos_ == 'VERB' and 
                  token.text.lower() not in auxiliary and
                  'V' not in main_slots):
                main_slots['V'] = token.text
            
            # ç›®çš„èªã®æŠ½å‡ºï¼ˆä¿®é£¾èªã‚’å«ã‚ãŸå®Œå…¨ãªåè©å¥ï¼‰
            elif token.dep_ == 'dobj' and 'O1' not in main_slots:
                main_slots['O1'] = self._extract_noun_phrase(token)
            
            # é–“æ¥ç›®çš„èªï¼ˆä¿®é£¾èªã‚’å«ã‚ãŸå®Œå…¨ãªåè©å¥ï¼‰
            elif token.dep_ == 'iobj' and 'O2' not in main_slots:
                main_slots['O2'] = self._extract_noun_phrase(token)
            
            # è£œèªã®æŠ½å‡ºï¼ˆä¿®é£¾èªã‚’å«ã‚ãŸå®Œå…¨ãªåè©å¥ï¼‰
            elif token.dep_ in ['attr', 'acomp'] and 'C1' not in main_slots:
                main_slots['C1'] = self._extract_noun_phrase(token)
    
    def _extract_noun_phrase(self, head_token) -> str:
        """åè©å¥ã®æŠ½å‡ºï¼ˆä¿®é£¾èªã‚’å«ã‚ãŸå®Œå…¨ãªå¥ã‚’å–å¾—ï¼‰"""
        phrase_tokens = []
        
        # ä¸»è¦ãªåè©ã‹ã‚‰å§‹ã¾ã‚‹å¥ã‚’èªé †é€šã‚Šã«åé›†
        for token in head_token.subtree:
            if token.pos_ not in ['PUNCT']:  # å¥èª­ç‚¹ã‚’é™¤ã
                phrase_tokens.append((token.i, token.text))
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã§ã‚½ãƒ¼ãƒˆã—ã¦æ­£ã—ã„èªé †ã«
        phrase_tokens.sort(key=lambda x: x[0])
        
        return ' '.join([text for _, text in phrase_tokens])
    
    def _extract_modifiers(self, doc, main_slots: Dict, modal_info: Dict):
        """ä¿®é£¾èªã®æŠ½å‡ºï¼ˆRephraseå‰¯è©é…ç½®ãƒ«ãƒ¼ãƒ«æº–æ‹ ï¼‰"""
        
        modifiers = []
        
        for token in doc:
            # å‰¯è©ã®æ¤œå‡º
            if token.pos_ == 'ADV':
                modifiers.append(token.text)
            
            # å‰ç½®è©å¥ã®æ¤œå‡º
            elif token.dep_ == 'prep':
                prep_phrase = self._extract_prepositional_phrase(token)
                if prep_phrase:
                    modifiers.append(prep_phrase)
        
        # Rephraseå‰¯è©é…ç½®ãƒ«ãƒ¼ãƒ«é©ç”¨
        self._apply_modifier_placement_rules(modifiers, main_slots)
    
    def _extract_prepositional_phrase(self, prep_token) -> str:
        """å‰ç½®è©å¥ã®æŠ½å‡ºï¼ˆæ­£ã—ã„èªé †ã§ï¼‰"""
        phrase_tokens = []
        
        # å‰ç½®è©ã‹ã‚‰å§‹ã¾ã‚‹å¥ã‚’èªé †é€šã‚Šã«åé›†
        for token in prep_token.subtree:
            if token.pos_ not in ['PUNCT']:  # å¥èª­ç‚¹ã‚’é™¤ã
                phrase_tokens.append((token.i, token.text))
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã§ã‚½ãƒ¼ãƒˆã—ã¦æ­£ã—ã„èªé †ã«
        phrase_tokens.sort(key=lambda x: x[0])
        
        return ' '.join([text for _, text in phrase_tokens])
    
    def _apply_modifier_placement_rules(self, modifiers: List[str], main_slots: Dict):
        """Rephraseå‰¯è©é…ç½®ãƒ«ãƒ¼ãƒ«é©ç”¨ï¼ˆå€‹æ•°ãƒ™ãƒ¼ã‚¹é…ç½®ï¼‰"""
        
        if not modifiers:
            return
        
        modifier_count = len(modifiers)
        
        if modifier_count == 1:
            # 1å€‹ã®ã¿ â†’ M2ã«é…ç½®
            main_slots['M2'] = modifiers[0]
        
        elif modifier_count == 2:
            # 2å€‹ â†’ å‹•è©ä½ç½®ã§åˆ¤å®šãŒå¿…è¦ã ãŒã€ç°¡ç•¥åŒ–ã—ã¦M2, M3ã«é…ç½®
            main_slots['M2'] = modifiers[0]
            main_slots['M3'] = modifiers[1]
        
        elif modifier_count >= 3:
            # 3å€‹ä»¥ä¸Š â†’ M1, M2, M3ã«é †æ¬¡é…ç½®
            main_slots['M1'] = modifiers[0]
            main_slots['M2'] = modifiers[1]
            main_slots['M3'] = modifiers[2]
            # 4å€‹ä»¥ä¸Šã¯ç„¡è¦–ï¼ˆRephraseã‚¹ãƒ­ãƒƒãƒˆåˆ¶é™ï¼‰
    
    def get_debug_info(self) -> Dict[str, Any]:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å–å¾—"""
        return {
            'handler_name': 'ModalHandler',
            'modal_verbs_count': len(self.modal_verbs),
            'complex_modals_count': len(self.complex_modals),
            'supported_patterns': list(self.modal_verbs) + list(self.complex_modals.keys())
        }


# ãƒ†ã‚¹ãƒˆç”¨ã®å®Ÿè¡Œéƒ¨åˆ†
if __name__ == "__main__":
    handler = ModalHandler()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        "I can swim.",
        "She could speak English fluently.",
        "You will succeed in your career.",
        "He has finished his homework.",
        "They should have called me earlier.",
        "Don't touch that button!"
    ]
    
    print("ğŸ§ª ModalHandler ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    for test_text in test_cases:
        result = handler.process(test_text)
        print(f"ğŸ“ '{test_text}' â†’ {result.get('main_slots', {})}")
