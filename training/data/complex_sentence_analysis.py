#!/usr/bin/env python3
"""
å®Ÿæ–‡ãƒ†ã‚¹ãƒˆ: "Because he was captured by bandits, I must go to the mountain where they live."
ãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³å”èª¿ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹Rephraseå¼ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
"""

import sys
import os
from typing import Dict, List, Any
import json

# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from integrated_multi_engine_coordinator import IntegratedMultiEngineCoordinator
except ImportError:
    print("âš ï¸ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    sys.exit(1)

def analyze_complex_sentence():
    """è¤‡é›‘æ–‡ã®è©³ç´°è§£æ"""
    
    # å¯¾è±¡æ–‡
    target_sentence = "Because he was captured by bandits, I must go to the mountain where they live."
    
    print("ğŸ¯ Rephraseå¼ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 80)
    print(f"å¯¾è±¡æ–‡: '{target_sentence}'")
    print("=" * 80)
    
    # çµ±åˆå”èª¿ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    coordinator = IntegratedMultiEngineCoordinator()
    
    # ã“ã®æ–‡ã«é©ç”¨ã™ã¹ãã‚¨ãƒ³ã‚¸ãƒ³ç¾¤
    relevant_engines = [
        "Basic5Pattern",        # åŸºæœ¬5æ–‡å‹ï¼ˆä¸»ç¯€ãƒ»å¾“å±ç¯€ä¸¡æ–¹ï¼‰
        "PassiveVoice",         # å—å‹•æ…‹ï¼ˆ"was captured"ï¼‰
        "ConditionalMood",      # ç†ç”±ãƒ»æ¡ä»¶ç¯€ï¼ˆ"Because..."ï¼‰
        "RelativePronoun",      # é–¢ä¿‚ä»£åè©ï¼ˆ"where they live"ï¼‰
        "AdverbialModifier",    # å‰¯è©ä¿®é£¾
        "PrepositionalPhrase",  # å‰ç½®è©å¥ï¼ˆ"by bandits", "to the mountain"ï¼‰
        "TenseAspect"          # æ™‚åˆ¶ãƒ»ç›¸ï¼ˆéå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥ï¼‰
    ]
    
    # æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š
    sentence_context = {
        "sentence_type": "complex",
        "has_subordinate_clause": True,
        "subordinate_types": ["reason", "relative"],
        "voice": "mixed",  # èƒ½å‹•æ…‹ãƒ»å—å‹•æ…‹æ··åœ¨
        "tense": "mixed",  # éå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥æ··åœ¨
        "complexity": "high"
    }
    
    print(f"\nğŸ”§ é©ç”¨ã‚¨ãƒ³ã‚¸ãƒ³ç¾¤ ({len(relevant_engines)} ã‚¨ãƒ³ã‚¸ãƒ³):")
    for engine in relevant_engines:
        print(f"   â€¢ {engine}")
    
    print(f"\nğŸ“‹ æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:")
    for key, value in sentence_context.items():
        print(f"   â€¢ {key}: {value}")
    
    # ãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³å”èª¿å‡¦ç†å®Ÿè¡Œ
    print(f"\n" + "="*80)
    result = coordinator.process_with_multi_engine_coordination(
        target_sentence,
        relevant_engines,
        sentence_context
    )
    print("="*80)
    
    # è©³ç´°çµæœåˆ†æ
    if result.success:
        print(f"\nâœ… å”èª¿å‡¦ç†æˆåŠŸ!")
        print(f"   å‡¦ç†æ™‚é–“: {result.processing_time:.3f}ç§’")
        print(f"   ç·ã‚¨ãƒ³ã‚¸ãƒ³æ•°: {sum(len(stage) for stage in result.execution_order)}")
        print(f"   å®Ÿè¡Œæ®µéšæ•°: {len(result.execution_order)}")
        
        # ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœ
        print(f"\nğŸ¯ **Rephraseå¼ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœ**:")
        print("="*50)
        for slot, value in result.normalized_slots.items():
            print(f"   {slot:3} : '{value}'")
        
        # å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
        if result.quality_report:
            print(f"\nğŸ“Š **å“è³ªè©•ä¾¡**:")
            print(f"   ç·åˆã‚¹ã‚³ã‚¢: {result.quality_report.overall_score:.1f}%")
            print(f"   å“è³ªãƒ¬ãƒ™ãƒ«: {result.quality_report.quality_level.value}")
            print(f"   æ¤œå‡ºå•é¡Œæ•°: {len(result.quality_report.issues)}")
            
            if result.quality_report.issues:
                print(f"\nâš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
                for i, issue in enumerate(result.quality_report.issues[:5], 1):
                    print(f"   {i}. {issue.description} ({issue.severity})")
            
            if result.quality_report.recommendations:
                print(f"\nğŸ’¡ æ¨å¥¨æ”¹å–„:")
                for i, rec in enumerate(result.quality_report.recommendations[:3], 1):
                    print(f"   {i}. {rec}")
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥çµæœè©³ç´°
        print(f"\nğŸ” **ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥è§£æçµæœ**:")
        print("="*50)
        for engine_name, engine_result in result.engine_results.items():
            print(f"\n   ã€{engine_name}ã€‘")
            for slot, value in engine_result.items():
                print(f"     {slot}: '{value}'")
        
        # å®Ÿè¡Œé †åºè©³ç´°
        print(f"\nâš¡ **å®Ÿè¡Œæ®µéšè©³ç´°**:")
        print("="*50)
        for stage_idx, stage_engines in enumerate(result.execution_order, 1):
            print(f"   æ®µéš{stage_idx}: {stage_engines}")
        
        # æ–‡æ§‹é€ åˆ†æ
        print(f"\nğŸ—ï¸ **æ–‡æ§‹é€ åˆ†æ**:")
        print("="*50)
        analyze_sentence_structure(result.normalized_slots, target_sentence)
        
    else:
        print(f"\nâŒ å”èª¿å‡¦ç†å¤±æ•—: {result.error_message}")
    
    return result

def analyze_sentence_structure(slots: Dict[str, Any], original: str):
    """æ–‡æ§‹é€ è©³ç´°åˆ†æ"""
    
    # åŸºæœ¬æ§‹é€ åˆ¤å®š
    has_subject = 'S' in slots
    has_verb = 'V' in slots
    has_object = 'O1' in slots
    has_complement = 'C1' in slots or 'C2' in slots
    
    # æ–‡å‹åˆ¤å®š
    if has_subject and has_verb and not has_object and not has_complement:
        sentence_pattern = "SV (ç¬¬1æ–‡å‹)"
    elif has_subject and has_verb and has_object and not has_complement:
        sentence_pattern = "SVO (ç¬¬3æ–‡å‹)"
    elif has_subject and has_verb and not has_object and has_complement:
        sentence_pattern = "SVC (ç¬¬2æ–‡å‹)"
    elif has_subject and has_verb and has_object and has_complement:
        sentence_pattern = "SVOC (ç¬¬5æ–‡å‹)"
    elif 'O2' in slots:
        sentence_pattern = "SVOO (ç¬¬4æ–‡å‹)"
    else:
        sentence_pattern = "è¤‡åˆæ–‡å‹"
    
    print(f"   åŸºæœ¬æ–‡å‹: {sentence_pattern}")
    
    # ä¿®é£¾èªåˆ†æ
    modifiers = [slot for slot in slots.keys() if slot.startswith('M')]
    if modifiers:
        print(f"   ä¿®é£¾èªæ•°: {len(modifiers)} å€‹")
        for mod in modifiers:
            print(f"     {mod}: '{slots[mod]}'")
    
    # ç‰¹æ®Šæ§‹é€ åˆ†æ
    special_structures = []
    
    if 'Aux' in slots:
        special_structures.append("åŠ©å‹•è©æ§‹é€ ")
    
    if any('REL_' in slot for slot in slots.keys()):
        special_structures.append("é–¢ä¿‚ç¯€æ§‹é€ ")
    
    if any('PASS' in slot for slot in slots.keys()):
        special_structures.append("å—å‹•æ…‹æ§‹é€ ")
    
    if any('COMP_' in slot for slot in slots.keys()):
        special_structures.append("æ¯”è¼ƒæ§‹é€ ")
    
    if special_structures:
        print(f"   ç‰¹æ®Šæ§‹é€ : {', '.join(special_structures)}")
    
    # è¤‡é›‘åº¦è©•ä¾¡
    complexity_score = len(slots) + len(modifiers) * 2 + len(special_structures) * 3
    
    if complexity_score <= 5:
        complexity_level = "å˜ç´”"
    elif complexity_score <= 10:
        complexity_level = "æ¨™æº–"
    elif complexity_score <= 15:
        complexity_level = "è¤‡é›‘"
    else:
        complexity_level = "é«˜åº¦è¤‡é›‘"
    
    print(f"   è¤‡é›‘åº¦: {complexity_level} (ã‚¹ã‚³ã‚¢: {complexity_score})")
    
    # å…ƒæ–‡ã¨ã®å¯¾å¿œé–¢ä¿‚
    print(f"   ã‚¹ãƒ­ãƒƒãƒˆæ•°: {len(slots)} å€‹")
    print(f"   å…ƒæ–‡é•·: {len(original.split())} èª")
    coverage_ratio = len(slots) / max(len(original.split()), 1) * 100
    print(f"   ã‚«ãƒãƒ¼ç‡: {coverage_ratio:.1f}%")

if __name__ == "__main__":
    # å®Ÿè¡Œ
    result = analyze_complex_sentence()
