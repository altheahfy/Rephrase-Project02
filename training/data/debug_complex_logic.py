"""
ğŸ” è¤‡é›‘æ–‡å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ‡ãƒãƒƒã‚°
ãªãœç¯€ã®çµ±åˆå‡¦ç†ãŒå‹•ä½œã—ã¦ã„ãªã„ã®ã‹ï¼Ÿ
"""

from simple_unified_rephrase_integrator import SimpleUnifiedRephraseSlotIntegrator
import spacy

def debug_complex_processing():
    """è¤‡é›‘æ–‡å‡¦ç†ã®ãƒ‡ãƒãƒƒã‚°"""
    print("ğŸ” è¤‡é›‘æ–‡å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ‡ãƒãƒƒã‚°")
    print("=" * 60)
    
    nlp = spacy.load("en_core_web_sm")
    sentence = ("That afternoon at the crucial point in the presentation, "
               "the manager who had recently taken charge of the project "
               "had to make the committee responsible for implementation "
               "deliver the final proposal flawlessly even though he was "
               "under intense pressure so the outcome would reflect their full potential.")
    
    print("ğŸ“ å…¥åŠ›æ–‡:")
    print(f"   {sentence}")
    print()
    
    # spaCyè§£æã®è©³ç´°ç¢ºèª
    print("ğŸ”§ spaCyè§£æçµæœ:")
    doc = nlp(sentence)
    for i, token in enumerate(doc):
        print(f"   [{i:2d}] {token.text:<15} | {token.pos_:<8} | {token.dep_:<15} | head: {token.head.text}")
    print()
    
    # çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³ã®å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½è·¡
    engine = SimpleUnifiedRephraseSlotIntegrator()
    
    print("ğŸ¯ å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã®è¿½è·¡:")
    print("-" * 40)
    
    # 1. ç‰¹æ®Šæ§‹æ–‡åˆ¤å®šã®ãƒã‚§ãƒƒã‚¯
    print("1ï¸âƒ£ ç‰¹æ®Šæ§‹æ–‡åˆ¤å®š:")
    
    # Thereæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
    is_there = sentence.lower().startswith('there ')
    print(f"   Thereæ§‹æ–‡: {is_there}")
    
    # è¤‡æ–‡ãƒã‚§ãƒƒã‚¯ï¼ˆthink thatï¼‰
    has_think_that = 'think' in sentence.lower() and 'that' in sentence.lower()
    print(f"   think thatè¤‡æ–‡: {has_think_that}")
    
    # å®Ÿéš›ã«ã¯ä»–ã®è¤‡é›‘æ§‹æ–‡ã‚‚å‡¦ç†ã™ã¹ã
    print("   â†’ ã“ã®æ–‡ã¯ç‰¹æ®Šæ§‹æ–‡ã¨ã—ã¦èªè­˜ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§")
    print()
    
    print("2ï¸âƒ£ åŸºæœ¬è¦ç´ æŠ½å‡ºã®å•é¡Œ:")
    
    # åŸºæœ¬è¦ç´ æŠ½å‡ºã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    roots = [token for token in doc if token.dep_ == 'ROOT']
    subjects = [token for token in doc if token.dep_ == 'nsubj']
    objects = [token for token in doc if token.dep_ in ['dobj', 'iobj']]
    
    print(f"   ROOTå‹•è©: {[t.text for t in roots]}")
    print(f"   ä¸»èª(nsubj): {[t.text for t in subjects]}")  
    print(f"   ç›®çš„èª: {[t.text for t in objects]}")
    print()
    
    print("3ï¸âƒ£ å•é¡Œã®ç‰¹å®š:")
    print("   âŒ è¤‡é›‘æ–‡å°‚ç”¨ã®å‡¦ç†ãƒ‘ã‚¹ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„")
    print("   âŒ 'think that'ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã®ã¿å¯¾å¿œã€ä½¿å½¹å‹•è©ã¯æœªå¯¾å¿œ")
    print("   âŒ é–¢ä¿‚è©ç¯€ã®ç‰¹åˆ¥å‡¦ç†ãŒåŸºæœ¬æŠ½å‡ºã‚’å¦¨å®³")
    print()
    
    # ç†æƒ³çš„ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’è¡¨ç¤º
    print("ğŸ¯ ç†æƒ³çš„ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼:")
    print("=" * 40)
    print("1. ä½¿å½¹å‹•è©æ§‹æ–‡ã‚’æ¤œå‡º (make + O + C)")
    print("2. é–¢ä¿‚è©ç¯€ã‚’çµ±åˆã—ã¦ãƒ•ãƒ¬ãƒ¼ã‚ºåŒ–")
    print("3. æ™‚é–“è¡¨ç¾ã‚’æ–‡é ­ä¿®é£¾èªã¨ã—ã¦é…ç½®")
    print("4. å‰¯è©ç¯€ã‚’é©åˆ‡ãªä¿®é£¾èªã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®")
    print("5. ç¯€å˜ä½ã§ã®æ„å‘³çš„åˆ†è§£å®Ÿè¡Œ")
    print()
    
    print("ğŸ’¡ ä¿®æ­£ãŒå¿…è¦ãªç®‡æ‰€:")
    print("- ä½¿å½¹å‹•è©æ§‹æ–‡ã®å°‚ç”¨å‡¦ç†")
    print("- é–¢ä¿‚è©ç¯€ã®å¥ã¨ã—ã¦çµ±åˆ")  
    print("- å‰¯è©ç¯€ã®é©åˆ‡ãªåˆ†é›¢")
    print("- è¤‡é›‘æ–‡åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã®æ‹¡å¼µ")

if __name__ == "__main__":
    debug_complex_processing()
