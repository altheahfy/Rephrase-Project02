# Step 2: spaCyçµ±åˆç‰ˆã®Rephrase_Parsing_Engine

import sys
import os
sys.path.append(os.path.dirname(__file__))

from Rephrase_Parsing_Engine import RephraseParsingEngine

class SpacyEnhancedRephraseEngine(RephraseParsingEngine):
    """spaCyçµ±åˆç‰ˆRephraseå“è©åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        super().__init__()
        self.engine_name = "Rephrase Parsing Engine v2.0 (spaCy Enhanced)"
        
        # spaCyåˆæœŸåŒ–
        try:
            import spacy
            self.nlp = spacy.load("en_core_web_sm")
            self.spacy_available = True
            print("âœ… spaCyã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ spaCyåˆæœŸåŒ–å¤±æ•—: {e}")
            print("   å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«æ‹¡å¼µã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.spacy_available = False
    
    def analyze_word_spacy(self, word, context=""):
        """spaCyã«ã‚ˆã‚‹é«˜ç²¾åº¦èªå½™è§£æ"""
        
        if not self.spacy_available:
            return self.analyze_word_morphology(word, context)
        
        try:
            # æ–‡è„ˆãŒã‚ã‚‹å ´åˆã¯æ–‡å…¨ä½“ã§è§£æ
            if context and word in context:
                doc = self.nlp(context)
                for token in doc:
                    if token.text.lower() == word.lower():
                        return {
                            'word': word,
                            'pos': token.pos_,
                            'tag': token.tag_,
                            'lemma': token.lemma_,
                            'confidence': 0.95,
                            'method': 'spacy_context'
                        }
            
            # å˜èªå˜ç‹¬ã§è§£æ
            doc = self.nlp(word)
            if doc:
                token = doc[0]
                return {
                    'word': word,
                    'pos': token.pos_,
                    'tag': token.tag_, 
                    'lemma': token.lemma_,
                    'confidence': 0.90,
                    'method': 'spacy_single'
                }
        
        except Exception as e:
            print(f"spaCyã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«ä½¿ç”¨
        return self.analyze_word_morphology(word, context)
    
    def batch_analyze_spacy(self, sentence):
        """æ–‡å…¨ä½“ã®spaCyè§£æ"""
        
        if not self.spacy_available:
            # spaCyåˆ©ç”¨ä¸å¯æ™‚ã¯å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«ã§è§£æ
            words = sentence.split()
            return [self.analyze_word_morphology(word, sentence) for word in words]
        
        try:
            doc = self.nlp(sentence)
            results = []
            
            for token in doc:
                result = {
                    'word': token.text,
                    'pos': token.pos_,
                    'tag': token.tag_,
                    'lemma': token.lemma_,
                    'confidence': 0.95,
                    'method': 'spacy_batch',
                    'is_punct': token.is_punct,
                    'is_stop': token.is_stop
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            print(f"spaCyãƒãƒƒãƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            words = sentence.split()
            return [self.analyze_word_morphology(word, sentence) for word in words]
    
    def compare_methods(self, sentence):
        """å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ« vs spaCy ã®æ¯”è¼ƒ"""
        words = sentence.replace('.', '').replace(',', '').split()
        
        print(f"æ–‡: {sentence}")
        print(f"{'Word':15} {'å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«':20} {'spaCy':20} {'ä¸€è‡´':5}")
        print("-" * 65)
        
        morphology_correct = 0
        spacy_correct = 0
        total_words = len(words)
        agreement = 0
        
        for word in words:
            morph_result = self.analyze_word_morphology(word, sentence)
            spacy_result = self.analyze_word_spacy(word, sentence)
            
            # å“è©ã®ç°¡ç•¥åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰
            morph_pos = morph_result['pos']
            spacy_pos = spacy_result.get('pos', 'UNKNOWN')
            
            # ä¸€è‡´åˆ¤å®šï¼ˆå¤§ã¾ã‹ãªå“è©ã‚«ãƒ†ã‚´ãƒªã§ï¼‰
            match = self.pos_categories_match(morph_pos, spacy_pos)
            match_str = "âœ…" if match else "âŒ"
            
            if match:
                agreement += 1
            
            print(f"{word:15} {morph_pos:20} {spacy_pos:20} {match_str:5}")
        
        agreement_rate = (agreement / total_words) * 100
        print(f"\nğŸ“Š æ‰‹æ³•é–“ä¸€è‡´ç‡: {agreement}/{total_words} ({agreement_rate:.1f}%)")
        
        return {
            'total_words': total_words,
            'agreement': agreement,
            'agreement_rate': agreement_rate
        }
    
    def pos_categories_match(self, morph_pos, spacy_pos):
        """å“è©ã‚«ãƒ†ã‚´ãƒªã®ä¸€è‡´åˆ¤å®š"""
        # å¤§ã¾ã‹ãªã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
        category_map = {
            'ADV': 'ADV', 'NOUN': 'NOUN', 'ADJ': 'ADJ', 
            'VERB_PAST': 'VERB', 'VERB_ING': 'VERB',
            'BE_VERB': 'VERB', 'AUX_VERB': 'AUX',
            'DET': 'DET', 'PRON': 'PRON', 'MODAL': 'AUX'
        }
        
        morph_category = category_map.get(morph_pos, morph_pos)
        spacy_category = spacy_pos
        
        return morph_category == spacy_category or morph_pos == spacy_pos

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    print("=== Step 2: spaCyçµ±åˆç‰ˆãƒ†ã‚¹ãƒˆ ===\n")
    
    engine = SpacyEnhancedRephraseEngine()
    
    # æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
    test_sentences = [
        "The sophisticated analysis is comprehensive.",
        "She efficiently investigated the mysterious disappearance.",
        "Students frequently encounter challenging mathematical equations."
    ]
    
    total_agreement = 0
    total_words_all = 0
    
    for sentence in test_sentences:
        result = engine.compare_methods(sentence)
        total_agreement += result['agreement']
        total_words_all += result['total_words']
        print()
    
    overall_agreement = (total_agreement / total_words_all) * 100
    print(f"ğŸ¯ å…¨ä½“ã®æ‰‹æ³•é–“ä¸€è‡´ç‡: {total_agreement}/{total_words_all} ({overall_agreement:.1f}%)")
    
    print(f"\nğŸ’¡ Step 2 å®Œäº†:")
    print(f"  âœ… spaCyçµ±åˆç‰ˆå®Ÿè£…å®Œäº†")
    print(f"  ğŸ”„ ä¸¡æ‰‹æ³•ã®æ¯”è¼ƒæ¤œè¨¼å®Œäº†")
    print(f"  ğŸ“Š æ‰‹æ³•é–“ä¸€è‡´ç‡: {overall_agreement:.1f}%")
