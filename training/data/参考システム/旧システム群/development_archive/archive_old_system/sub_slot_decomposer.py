"""
ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³
è¤‡æ–‡å†…éƒ¨æ§‹é€ ï¼ˆé–¢ä¿‚è©ç¯€ãƒ»å‰¯è©ç¯€ï¼‰ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«åˆ†è§£
"""
import spacy
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class SubSlotResult:
    """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœ"""
    clause_type: str  # "relative_clause", "adverbial_clause"
    original_text: str
    sub_slots: Dict[str, str]
    confidence: float

class SubSlotDecomposer:
    """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        print("ğŸ”§ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...")
        self.nlp = spacy.load('en_core_web_sm')
        print("âœ… ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº†")
    
    def decompose_complex_slots(self, main_slots: Dict[str, str]) -> Dict[str, List[SubSlotResult]]:
        """ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆã‹ã‚‰è¤‡æ–‡ç®‡æ‰€ã‚’æ¤œå‡ºã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ï¼ˆæ¡ä»¶ç·©å’Œç‰ˆï¼‰"""
        sub_slot_results = {}
        
        print("\nğŸ” è¤‡æ–‡ç®‡æ‰€æ¤œå‡ºãƒ»ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£é–‹å§‹")
        
        # 1. ä¸»èª(S)å†…ã®é–¢ä¿‚è©ç¯€ - æ¡ä»¶ã‚’å¤§å¹…ç·©å’Œ
        if 'S' in main_slots and main_slots['S'].strip():
            s_text = main_slots['S'].strip()
            print(f"\n1ï¸âƒ£ ä¸»èª(S)å†…é–¢ä¿‚è©ç¯€åˆ†æ: {s_text}")
            
            # é–¢ä¿‚ä»£åè©ã®æ¤œå‡ºã‚’æŸ”è»ŸåŒ–
            if any(rel in s_text for rel in ['who', 'which', 'that', 'whose', 'whom']):
                relative_result = self._decompose_relative_clause(s_text)
                if relative_result and relative_result.sub_slots:
                    sub_slot_results['S'] = [relative_result]
                    print(f"   ğŸ¯ é–¢ä¿‚è©ç¯€æŠ½å‡º: {relative_result.original_text}")
            else:
                print("   âŒ é–¢ä¿‚è©ç¯€ãªã—")
        
        # 2. ä¿®é£¾èª(M2)å†…ã®å‰¯è©ç¯€ - ç©ºã§ãªã„å ´åˆã¯å‡¦ç†
        if 'M2' in main_slots and main_slots['M2'].strip():
            m2_text = main_slots['M2'].strip()
            print(f"\n2ï¸âƒ£ ä¿®é£¾èª(M2)å†…å‰¯è©ç¯€åˆ†æ: {m2_text}")
            adverbial_result = self._decompose_adverbial_clause(m2_text)
            if adverbial_result and (adverbial_result.sub_slots or len(m2_text) > 3):
                sub_slot_results['M2'] = [adverbial_result]
        else:
            print(f"\n2ï¸âƒ£ ä¿®é£¾èª(M2)å†…å‰¯è©ç¯€åˆ†æ: ")
            # ç©ºã®å ´åˆã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
            sub_slot_results['M2'] = [SubSlotResult(
                clause_type="adverbial_clause",
                original_text="",
                sub_slots={},
                confidence=0.90
            )]
        
        # 3. ä¿®é£¾èª(M3)å†…ã®å‰¯è©ç¯€ - ç©ºã§ãªã„å ´åˆã¯å‡¦ç†
        if 'M3' in main_slots and main_slots['M3'].strip():
            m3_text = main_slots['M3'].strip()
            print(f"\n3ï¸âƒ£ ä¿®é£¾èª(M3)å†…å‰¯è©ç¯€åˆ†æ: {m3_text}")
            adverbial_result = self._decompose_adverbial_clause(m3_text)
            if adverbial_result and (adverbial_result.sub_slots or len(m3_text) > 3):
                sub_slot_results['M3'] = [adverbial_result]
        else:
            print(f"\n3ï¸âƒ£ ä¿®é£¾èª(M3)å†…å‰¯è©ç¯€åˆ†æ: ")
            # ç©ºã®å ´åˆã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
            sub_slot_results['M3'] = [SubSlotResult(
                clause_type="adverbial_clause",
                original_text="",
                sub_slots={},
                confidence=0.90
            )]
        
        # 4. è£œèª(C2)å†…ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ - ç©ºã§ãªã„å ´åˆã¯å‡¦ç†
        if 'C2' in main_slots and main_slots['C2'].strip():
            c2_text = main_slots['C2'].strip()
            print(f"\n4ï¸âƒ£ è£œèª(C2)å†…ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†æ: {c2_text}")
            complement_result = self._decompose_complement_phrase(c2_text)
            if complement_result and (complement_result.sub_slots or len(c2_text) > 3):
                sub_slot_results['C2'] = [complement_result]
        else:
            print(f"\n4ï¸âƒ£ è£œèª(C2)å†…ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†æ: ")
            # ç©ºã®å ´åˆã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
            sub_slot_results['C2'] = [SubSlotResult(
                clause_type="complement_phrase",
                original_text="",
                sub_slots={},
                confidence=0.95
            )]
        
        print("\nâœ… ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£å®Œäº†")
        
        # ğŸ”§ é‡è¦: ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãŒã‚ã‚‹ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã‚’ç©ºã«ã™ã‚‹
        self._clear_upper_slots_with_subs(main_slots, sub_slot_results)
        
        return sub_slot_results
    
    def _clear_upper_slots_with_subs(self, main_slots: Dict[str, str], sub_slot_results: Dict[str, List[SubSlotResult]]):
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãŒã‚ã‚‹ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã‚’ç©ºã«ã™ã‚‹"""
        print("\nğŸ”§ ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã‚¯ãƒªã‚¢å‡¦ç†é–‹å§‹")
        
        for slot_name in sub_slot_results.keys():
            if slot_name in main_slots and main_slots[slot_name].strip():
                original_content = main_slots[slot_name]
                main_slots[slot_name] = ""  # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã‚’ç©ºã«ã™ã‚‹
                print(f"  âœ… {slot_name}ã‚¹ãƒ­ãƒƒãƒˆ: '{original_content}' â†’ ç©º (ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæœ‰ã®ãŸã‚)")
        
        print("ğŸ”§ ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã‚¯ãƒªã‚¢å‡¦ç†å®Œäº†")
    
    def _decompose_relative_clause(self, text: str) -> SubSlotResult:
        """é–¢ä¿‚è©ç¯€ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ï¼ˆæ­£ã—ã„Rephraseãƒ«ãƒ¼ãƒ«æº–æ‹ ï¼‰"""
        doc = self.nlp(text)
        
        # é–¢ä¿‚è©ç¯€éƒ¨åˆ†ã‚’æŠ½å‡º
        relative_clause = self._extract_relative_clause_text(text)
        if not relative_clause:
            return None
        
        print(f"   ğŸ¯ é–¢ä¿‚è©ç¯€æŠ½å‡º: {relative_clause}")
        
        # ğŸ¯ æ­£ã—ã„Rephraseãƒ«ãƒ¼ãƒ«ï¼š
        # "The book that I bought" â†’
        # sub_O1: "the book that" (é–¢ä¿‚è©ç¯€å†…ã®ç›®çš„èª=å…ˆè¡Œè©)
        # sub_S: "I" (é–¢ä¿‚è©ç¯€å†…ã®ä¸»èª)
        # sub_V: "bought" (é–¢ä¿‚è©ç¯€å†…å‹•è©)
        #
        # "The person who knows me" â†’
        # sub_S: "the person who" (é–¢ä¿‚è©ç¯€å†…ã®ä¸»èª=å…ˆè¡Œè©+é–¢ä¿‚ä»£åè©)
        # sub_V: "knows" (é–¢ä¿‚è©ç¯€å†…å‹•è©)
        # sub_O1: "me" (é–¢ä¿‚è©ç¯€å†…ç›®çš„èª)
        
        sub_slots = {}
        
        # å…ˆè¡Œè©ã‚’æŠ½å‡º
        antecedent = self._extract_antecedent_from_full_text(text, relative_clause)
        
        # é–¢ä¿‚ä»£åè©ã‚’ç‰¹å®š
        relative_pronouns = ['who', 'which', 'that', 'whose', 'whom']
        rel_pronoun = ""
        for rel_pron in relative_pronouns:
            if relative_clause.strip().startswith(rel_pron):
                rel_pronoun = rel_pron
                break
        
        # é–¢ä¿‚è©ç¯€ã®æ§‹æ–‡è§£æ
        rel_doc = self.nlp(relative_clause)
        
        # é–¢ä¿‚ä»£åè©ã®æ©Ÿèƒ½ã‚’åˆ¤å®šï¼ˆä¸»èªã‹ç›®çš„èªã‹ï¼‰
        is_subject_relative = False
        is_object_relative = False
        
        # é–¢ä¿‚è©ç¯€å†…ã®å®Ÿéš›ã®ä¸»èªã‚’æ¤œå‡º
        actual_subject = ""
        for token in rel_doc:
            if token.dep_ == 'nsubj' and token.text.lower() not in relative_pronouns:
                actual_subject = token.text  # "I"
                is_object_relative = True  # åˆ¥ã®èªãŒä¸»èª = é–¢ä¿‚ä»£åè©ã¯ç›®çš„èª
                break
        
        if not actual_subject and rel_pronoun in ['who', 'which', 'that']:
            is_subject_relative = True  # é–¢ä¿‚ä»£åè©ãŒä¸»èª
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
        if is_object_relative:
            # ç›®çš„æ ¼é–¢ä¿‚ä»£åè©ã®å ´åˆ: "The book that I bought"
            sub_slots['sub_O1'] = f"{antecedent} {rel_pronoun}"  # "the book that"
            sub_slots['sub_S'] = actual_subject  # "I"
        elif is_subject_relative:
            # ä¸»æ ¼é–¢ä¿‚ä»£åè©ã®å ´åˆ: "The person who knows me"
            sub_slots['sub_S'] = f"{antecedent} {rel_pronoun}"  # "the person who"
        
        # sub_V: é–¢ä¿‚è©ç¯€å†…ã®å‹•è©
        for token in rel_doc:
            if token.dep_ == 'ROOT' and token.pos_ in ['VERB', 'AUX']:
                sub_slots['sub_V'] = token.text  # "bought" or "knows"
                break
        
        # sub_Aux: åŠ©å‹•è©
        aux_parts = []
        for token in rel_doc:
            if token.dep_ == 'aux':
                aux_parts.append(token.text)
        if aux_parts:
            sub_slots['sub_Aux'] = ' '.join(aux_parts)
        
        # sub_M2: å‰¯è©
        for token in rel_doc:
            if token.dep_ == 'advmod':
                sub_slots['sub_M2'] = token.text
                break
        
        # sub_O1: é–¢ä¿‚è©ç¯€å†…ã®ç›®çš„èªï¼ˆä¸»æ ¼é–¢ä¿‚ä»£åè©ã®å ´åˆã®ã¿ï¼‰
        if is_subject_relative:
            for token in rel_doc:
                if token.dep_ == 'dobj':
                    obj_phrase = self._extract_complete_object_phrase(token, rel_doc)
                    sub_slots['sub_O1'] = obj_phrase  # "me"
                    break
        
        return SubSlotResult(
            clause_type="relative_clause",
            original_text=relative_clause,
            sub_slots=sub_slots,
            confidence=0.95
        )
    
    def _extract_antecedent_from_full_text(self, full_text: str, relative_clause: str) -> str:
        """å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…ˆè¡Œè©ã‚’æŠ½å‡º"""
        # é–¢ä¿‚è©ç¯€ã‚ˆã‚Šå‰ã®éƒ¨åˆ†ã‚’å–å¾—
        rel_start = full_text.find(relative_clause)
        if rel_start > 0:
            antecedent_part = full_text[:rel_start].strip()
            # æœ€å¾Œã®åè©å¥ã‚’æŠ½å‡º
            words = antecedent_part.split()
            if words:
                # å† è©+åè©ã®å½¢ã§æŠ½å‡º
                if len(words) >= 2 and words[-2].lower() in ['the', 'a', 'an']:
                    return f"{words[-2]} {words[-1]}"
                else:
                    return words[-1]
        return ""
    
    def _decompose_adverbial_clause(self, text: str) -> SubSlotResult:
        """å‰¯è©ç¯€ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£"""
        doc = self.nlp(text)
        sub_slots = {}
        
        # æ¥ç¶šè©ã‚’æ¤œå‡º
        conjunction = self._extract_conjunction(text)
        if conjunction:
            sub_slots['sub_M1'] = conjunction
        
        # ä¸»èªã‚’æ¤œå‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                # å®Œå…¨ãªä¸»èªå¥ã‚’æŠ½å‡º
                subject_phrase = self._extract_noun_phrase(token, doc)
                sub_slots['sub_S'] = subject_phrase
                break
        
        # åŠ©å‹•è©ã‚’æ¤œå‡º
        aux_parts = []
        for token in doc:
            if token.dep_ == 'aux':
                aux_parts.append(token.text)
        if aux_parts:
            sub_slots['sub_Aux'] = ' '.join(aux_parts)
        
        # å‹•è©ã‚’æ¤œå‡º
        main_verb = None
        for token in doc:
            if token.pos_ == 'VERB' and token.dep_ != 'aux':
                main_verb = token.text
                break
        if not main_verb:
            for token in doc:
                if token.pos_ == 'AUX' and token.dep_ == 'ROOT':
                    main_verb = token.text
                    break
        if main_verb:
            sub_slots['sub_V'] = main_verb
        
        # ç›®çš„èªã‚’æ¤œå‡º
        for token in doc:
            if token.dep_ == 'dobj':
                obj_phrase = self._extract_noun_phrase(token, doc)
                sub_slots['sub_O1'] = obj_phrase
                break
        
        # å‰ç½®è©å¥ã‚’æ¤œå‡º
        prep_phrases = []
        for token in doc:
            if token.dep_ == 'prep':
                prep_phrase = self._extract_prep_phrase(token, doc)
                if prep_phrase and conjunction not in prep_phrase:
                    prep_phrases.append(prep_phrase)
        if prep_phrases:
            # M2ã‚¹ãƒ­ãƒƒãƒˆã®å ´åˆã¯ sub_M2 ã«è¨­å®š (M3ã§ã¯ãªã)
            sub_slots['sub_M2'] = ' '.join(prep_phrases)
        
        return SubSlotResult(
            clause_type="adverbial_clause",
            original_text=text,
            sub_slots=sub_slots,
            confidence=0.90
        )
    
    def _decompose_complement_phrase(self, text: str) -> SubSlotResult:
        """è£œèªå¥ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ (deliver the final proposal flawlessly)"""
        doc = self.nlp(text)
        sub_slots = {}
        
        # å‹•è©ã‚’æ¤œå‡º (sub_V)
        main_verb = None
        for token in doc:
            if token.pos_ == 'VERB':
                main_verb = token
                sub_slots['sub_V'] = token.text
                break
        
        # ç›®çš„èªã‚’æ¤œå‡º (sub_O1)
        if main_verb:
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    obj_phrase = self._extract_noun_phrase(child, doc)
                    sub_slots['sub_O1'] = obj_phrase
                    break
        
        # ä¿®é£¾èªã‚’æ¤œå‡º (sub_M3)
        for token in doc:
            if token.dep_ == 'advmod':
                sub_slots['sub_M3'] = token.text
                break
        
        return SubSlotResult(
            clause_type="complement_phrase",
            original_text=text,
            sub_slots=sub_slots,
            confidence=0.95
        )
    
    def _extract_relative_clause_text(self, text: str) -> str:
        """é–¢ä¿‚è©ç¯€éƒ¨åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        relative_pronouns = ['who', 'which', 'that', 'whose', 'whom']
        
        for rel_pron in relative_pronouns:
            if f' {rel_pron} ' in text or text.startswith(rel_pron + ' '):
                rel_index = text.find(f' {rel_pron} ')
                if rel_index == -1:  # æ–‡é ­ã®å ´åˆ
                    rel_index = text.find(rel_pron + ' ') - 1
                
                # é–¢ä¿‚è©ç¯€ã®ç¯„å›²ã‚’ç‰¹å®š
                clause_start = rel_index + 1
                clause_text = text[clause_start:].strip()
                
                # é–¢ä¿‚è©ç¯€ã®çµ‚äº†ã‚’æ¤œå‡ºï¼ˆå‹•è©ã‚’å«ã‚€å®Œå…¨ãªç¯€ï¼‰
                words = clause_text.split()
                if len(words) >= 2:  # æœ€ä½é™ã€Œwho wasã€ã®ã‚ˆã†ãªæ§‹é€ 
                    # å‹•è©ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                    doc = self.nlp(clause_text)
                    has_verb = any(token.pos_ in ['VERB', 'AUX'] for token in doc)
                    if has_verb:
                        return clause_text
                    else:
                        # å‹•è©ãŒãªã„å ´åˆã¯ã€æœ€åˆã®å‹•è©ã¾ã§å»¶é•·ã‚’è©¦è¡Œ
                        remaining_text = text[clause_start:].strip()
                        return remaining_text
                
                return clause_text
        
        return ""
    
    def _extract_conjunction(self, text: str) -> str:
        """æ¥ç¶šè©ã‚’æŠ½å‡º"""
        conjunctions = ['even though', 'though', 'although', 'so', 'because', 'since', 'while', 'when']
        
        for conj in conjunctions:
            if text.lower().startswith(conj):
                return conj
        
        # å˜ä¸€èªã®æ¥ç¶šè©
        words = text.split()
        if words and words[0].lower() in ['so', 'because', 'since', 'while', 'when']:
            return words[0]
        
        return ""
    
    def _extract_noun_phrase(self, head_token, doc) -> str:
        """åè©å¥ã‚’æŠ½å‡º"""
        phrase_tokens = []
        
        # ä¿®é£¾èªã‚’åé›†
        for child in head_token.children:
            if child.dep_ in ['det', 'amod', 'poss']:
                phrase_tokens.append((child.i, child.text))
        
        # ãƒ˜ãƒƒãƒ‰èª
        phrase_tokens.append((head_token.i, head_token.text))
        
        # å¾Œç½®ä¿®é£¾èª
        for child in head_token.children:
            if child.dep_ in ['nmod', 'amod'] and child.i > head_token.i:
                phrase_tokens.append((child.i, child.text))
        
        # ä½ç½®ã§ã‚½ãƒ¼ãƒˆ
        phrase_tokens.sort()
        return ' '.join([text for _, text in phrase_tokens])
    
    def _extract_prep_phrase(self, prep_token, doc) -> str:
        """å‰ç½®è©å¥ã‚’æŠ½å‡º"""
        phrase_parts = [prep_token.text]
        
        # å‰ç½®è©ã®ç›®çš„èªã‚’å–å¾—
        for child in prep_token.children:
            if child.dep_ == 'pobj':
                obj_phrase = self._extract_noun_phrase(child, doc)
                phrase_parts.append(obj_phrase)
        
        return ' '.join(phrase_parts)
    
    def _extract_complete_object_phrase(self, obj_token, doc) -> str:
        """ç›®çš„èªã®å®Œå…¨ãªå¥ã‚’æŠ½å‡ºï¼ˆå‰ç½®è©å¥å«ã‚€ï¼‰"""
        phrase_parts = [obj_token.text]
        
        # ç›®çš„èªã«ä»˜éšã™ã‚‹å‰ç½®è©å¥ã‚’åé›†
        for child in obj_token.children:
            if child.dep_ == 'prep':
                prep_phrase = self._extract_prep_phrase(child, doc)
                phrase_parts.append(prep_phrase)
        
        return ' '.join(phrase_parts)
    
    def print_sub_slot_analysis(self, main_slots: Dict[str, str], sub_slot_results: Dict[str, List[SubSlotResult]]):
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†æçµæœã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ” ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çµæœè©³ç´°")
        print("="*60)
        
        for main_slot, sub_results in sub_slot_results.items():
            print(f"\nğŸ“Œ ã€{main_slot}ã‚¹ãƒ­ãƒƒãƒˆã€‘: {main_slots[main_slot]}")
            
            for i, sub_result in enumerate(sub_results, 1):
                print(f"\n   {i}. {sub_result.clause_type} (ä¿¡é ¼åº¦: {sub_result.confidence:.1%})")
                print(f"      åŸæ–‡: {sub_result.original_text}")
                print(f"      ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£:")
                
                for sub_slot, value in sub_result.sub_slots.items():
                    print(f"        {sub_slot}: {value}")
