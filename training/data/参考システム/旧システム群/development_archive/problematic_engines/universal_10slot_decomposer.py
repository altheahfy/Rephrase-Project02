"""
Rephraseä»•æ§˜æº–æ‹  çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ v1.0
æ­£ã—ã„Rephraseã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: çµ±ä¸€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹å†å¸°çš„10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
"""

import spacy
from typing import Dict, Any, Tuple, Optional
from collections import defaultdict

class Universal10SlotDecomposer:
    """çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ - Rephraseä»•æ§˜æº–æ‹ """
    
    def __init__(self):
        print("ğŸš€ çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ v1.0 åˆæœŸåŒ–ä¸­...")
        self.nlp = spacy.load('en_core_web_sm')
        
        # ä¾å­˜é–¢ä¿‚ â†’ ã‚¹ãƒ­ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆçµ±ä¸€ï¼‰
        self.dep_to_slot = {
            # ä¸»è¦æ§‹é€ 
            'nsubj': 'S', 'nsubjpass': 'S',  # ä¸»èª
            'aux': 'Aux', 'auxpass': 'Aux',   # åŠ©å‹•è©
            'dobj': 'O1', 'iobj': 'O2',       # ç›®çš„èª
            'attr': 'C1', 'acomp': 'C1',      # è£œèª
            'xcomp': 'C2', 'ccomp': 'C2',     # è£œèª2
            
            # ä¿®é£¾æ§‹é€   
            'advmod': 'M2',                   # å‰¯è©ä¿®é£¾
            'advcl': 'M3',                    # å‰¯è©ç¯€
            'prep': 'M3',                     # å‰ç½®è©å¥
            'npadvmod': 'M2',                 # åè©å‰¯è©
            
            # ç‰¹æ®Šæ§‹é€ 
            'relcl': 'relcl_marker',          # é–¢ä¿‚ç¯€ãƒãƒ¼ã‚«ãƒ¼
            'mark': 'M1',                     # å¾“å±æ¥ç¶šè©
        }
        
        print("âœ… çµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def decompose_any_text(self, text: str, depth: int = 0) -> Dict[str, Any]:
        """
        çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ãƒ¡ã‚½ãƒƒãƒ‰
        - ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’10ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã«åˆ†è§£
        - å†å¸°é©ç”¨ã«ã‚ˆã‚Šç„¡é™éšå±¤å¯¾å¿œ
        """
        indent = "  " * depth
        print(f"{indent}ğŸ” çµ±ä¸€åˆ†è§£é–‹å§‹: '{text}' (depth={depth})")
        
        doc = self.nlp(text)
        root = self._find_root_verb(doc)
        
        if not root:
            print(f"{indent}âš ï¸ ROOTå‹•è©æœªæ¤œå‡º")
            return {}
        
        print(f"{indent}ğŸ¯ ROOT: '{root.text}' ({root.pos_})")
        
        # çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        slots = {}
        
        # ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡ï¼ˆæ­£ã—ã„Rephraseä»•æ§˜ï¼‰
        subslot_capable_slots = {
            'M1': self._extract_m1,
            'S': self._extract_s,
            'O1': self._extract_o1,
            'O2': self._extract_o2,
            'C1': self._extract_c1,
            'C2': self._extract_c2,
            'M2': self._extract_m2,
            'M3': self._extract_m3
        }
        
        word_only_slots = {
            'Aux': self._extract_aux,
            'V': self._extract_v
        }
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå¯¾å¿œã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†ï¼ˆ8ã‚¹ãƒ­ãƒƒãƒˆçµ±ä¸€ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        for slot_name, extractor in subslot_capable_slots.items():
            content, phrase_type = extractor(doc, root)
            
            if content and phrase_type:
                if phrase_type in ['phrase', 'clause']:
                    # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆç©ºåŒ– + å†å¸°åˆ†è§£
                    print(f"{indent}ğŸ“ {slot_name}ã‚¹ãƒ­ãƒƒãƒˆ: '{content}' ({phrase_type}) â†’ å†å¸°åˆ†è§£")
                    sub_result = self.decompose_any_text(content, depth + 1)
                    
                    if sub_result:
                        # sub-ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã¦æ ¼ç´
                        slots[slot_name] = {}
                        for k, v in sub_result.items():
                            slots[slot_name][f"sub-{k.lower()}"] = v
                        print(f"{indent}âœ… {slot_name}: {len(sub_result)}å€‹ã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ")
                
                elif phrase_type == 'word':
                    # å˜èªãƒ¬ãƒ™ãƒ« - ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆä¿æŒ
                    slots[slot_name] = {slot_name.lower(): content}
                    print(f"{indent}âœ… {slot_name}: å˜èªä¿æŒ '{content}'")
        
        # å˜èªå°‚ç”¨ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†ï¼ˆAux, Vã®ã¿ï¼‰
        for slot_name, extractor in word_only_slots.items():
            content = extractor(doc, root)
            
            if content:
                slots[slot_name] = {slot_name.lower(): content}
                print(f"{indent}âœ… {slot_name}: å˜èªå°‚ç”¨ '{content}'")
        
        print(f"{indent}ğŸ“‹ çµ±ä¸€åˆ†è§£å®Œäº†: {len(slots)}ã‚¹ãƒ­ãƒƒãƒˆ")
        return slots
    
    def _find_root_verb(self, doc):
        """ROOTå‹•è©æ¤œå‡º"""
        for token in doc:
            if token.dep_ == 'ROOT' and token.pos_ in ['VERB', 'AUX']:
                return token
        return None
    
    # çµ±ä¸€ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå…¨ã¦åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    def _extract_m1(self, doc, root) -> Tuple[str, str]:
        """M1: æ–‡é ­ä¿®é£¾å¥æŠ½å‡º"""
        return self._generic_extract(doc, root, ['advmod', 'npadvmod'], position='pre')
    
    def _extract_s(self, doc, root) -> Tuple[str, str]:
        """S: ä¸»èªæŠ½å‡º"""
        for child in root.children:
            if child.dep_ in ['nsubj', 'nsubjpass']:
                # é–¢ä¿‚ç¯€ãƒã‚§ãƒƒã‚¯
                has_relcl = any(gc.dep_ == 'relcl' for gc in child.children)
                if has_relcl:
                    span = self._expand_span_with_relcl(child, doc)
                    return span, 'clause'  # é–¢ä¿‚ç¯€ãŒã‚ã‚‹å ´åˆã¯clause
                else:
                    span = self._basic_span_expansion(child, doc)
                    return span, 'word' if len(span.split()) <= 2 else 'phrase'
        return "", ""
    
    def _extract_aux(self, doc, root) -> str:
        """Aux: åŠ©å‹•è©æŠ½å‡ºï¼ˆå˜èªå°‚ç”¨ï¼‰"""
        for child in root.children:
            if child.dep_ in ['aux', 'auxpass']:
                return child.text
        return ""
    
    def _extract_v(self, doc, root) -> str:
        """V: å‹•è©æŠ½å‡ºï¼ˆå˜èªå°‚ç”¨ï¼‰"""
        return root.text
    
    def _extract_o1(self, doc, root) -> Tuple[str, str]:
        """O1: ç›´æ¥ç›®çš„èªæŠ½å‡º"""
        for child in root.children:
            if child.dep_ == 'dobj':
                span = self._basic_span_expansion(child, doc)
                return span, 'word' if len(span.split()) <= 2 else 'phrase'
        return "", ""
    
    def _extract_o2(self, doc, root) -> Tuple[str, str]:
        """O2: é–“æ¥ç›®çš„èªæŠ½å‡º"""
        for child in root.children:
            if child.dep_ == 'iobj':
                span = self._basic_span_expansion(child, doc)
                return span, 'word' if len(span.split()) <= 2 else 'phrase'
        return "", ""
    
    def _extract_c1(self, doc, root) -> Tuple[str, str]:
        """C1: è£œèªæŠ½å‡º"""
        for child in root.children:
            if child.dep_ in ['attr', 'acomp']:
                span = self._basic_span_expansion(child, doc)
                return span, 'word' if len(span.split()) <= 2 else 'phrase'
        return "", ""
    
    def _extract_c2(self, doc, root) -> Tuple[str, str]:
        """C2: è£œèª2æŠ½å‡º"""
        for child in root.children:
            if child.dep_ in ['xcomp', 'ccomp']:
                span = self._basic_span_expansion(child, doc)
                return span, 'clause'  # é€šå¸¸clause
        return "", ""
    
    def _extract_m2(self, doc, root) -> Tuple[str, str]:
        """M2: å‰¯è©å¥æŠ½å‡º"""
        for child in root.children:
            if child.dep_ == 'advmod':
                return child.text, 'word'
        return "", ""
    
    def _extract_m3(self, doc, root) -> Tuple[str, str]:
        """M3: å‰¯è©ç¯€æŠ½å‡º"""
        for child in root.children:
            if child.dep_ == 'advcl':
                # å‰¯è©ç¯€ã®å®Œå…¨ãªã‚¹ãƒ‘ãƒ³ã‚’å–å¾—ï¼ˆæ¥ç¶šè©å«ã‚€ï¼‰
                span = self._get_adverbial_clause_span(child, doc)
                return span, 'clause'  # å‰¯è©ç¯€ã¯clause
        return "", ""
    
    def _get_adverbial_clause_span(self, advcl_root, doc) -> str:
        """å‰¯è©ç¯€ã®å®Œå…¨ãªã‚¹ãƒ‘ãƒ³ã‚’å–å¾—ï¼ˆæ¥ç¶šè©å«ã‚€ï¼‰"""
        tokens = [advcl_root]  # å‰¯è©ç¯€ã®å‹•è©
        
        # æ¥ç¶šè©ï¼ˆmarkï¼‰ã‚’æ¢ã™
        for child in advcl_root.children:
            if child.dep_ == 'mark':  # because, although, etc.
                tokens.append(child)
            else:
                tokens.append(child)
                # å­è¦ç´ ã‚‚å†å¸°çš„ã«è¿½åŠ 
                self._collect_all_children(child, tokens)
        
        # é †åºã§ã‚½ãƒ¼ãƒˆ
        tokens.sort(key=lambda t: t.i)
        
        return ' '.join([t.text for t in tokens])
    
    def _collect_all_children(self, token, tokens_list):
        """å…¨ã¦ã®å­è¦ç´ ã‚’å†å¸°çš„ã«åé›†"""
        for child in token.children:
            tokens_list.append(child)
            self._collect_all_children(child, tokens_list)
    
    def _generic_extract(self, doc, root, dep_types, position='any') -> Tuple[str, str]:
        """æ±ç”¨çš„ãªæŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰"""
        for child in root.children:
            if child.dep_ in dep_types:
                if position == 'pre' and child.i > root.i:
                    continue
                span = self._basic_span_expansion(child, doc)
                return span, 'word' if len(span.split()) <= 2 else 'phrase'
        return "", ""
    
    def _basic_span_expansion(self, token, doc) -> str:
        """åŸºæœ¬çš„ãªã‚¹ãƒ‘ãƒ³æ‹¡å¼µ"""
        expand_deps = ['det', 'amod', 'compound', 'poss']
        
        start = token.i
        end = token.i
        
        for child in token.children:
            if child.dep_ in expand_deps:
                start = min(start, child.i)
                end = max(end, child.i)
        
        return ' '.join([doc[i].text for i in range(start, end + 1)])
    
    def _expand_span_with_relcl(self, token, doc) -> str:
        """é–¢ä¿‚ç¯€ã‚’å«ã‚€ã‚¹ãƒ‘ãƒ³æ‹¡å¼µï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        # åŸºæœ¬æ‹¡å¼µï¼ˆä¸»èªéƒ¨åˆ†ï¼‰
        base_span = self._basic_span_expansion(token, doc)
        
        # é–¢ä¿‚ç¯€éƒ¨åˆ†ã‚’æŠ½å‡º
        for child in token.children:
            if child.dep_ == 'relcl':
                # é–¢ä¿‚ä»£åè©ã‚’æ¢ã™
                rel_pronoun = ""
                for relcl_child in child.children:
                    if relcl_child.dep_ == 'nsubj' and relcl_child.pos_ == 'PRON':
                        rel_pronoun = relcl_child.text
                        break
                
                # é–¢ä¿‚ç¯€å…¨ä½“ã‚’å–å¾—ï¼ˆé–¢ä¿‚ä»£åè© + å‹•è©ä»¥é™ï¼‰
                relcl_span = self._get_full_clause_span(child, doc)
                
                # çµåˆï¼ˆé‡è¤‡å›é¿ï¼‰
                if rel_pronoun and rel_pronoun not in base_span:
                    return f"{base_span} {rel_pronoun} {relcl_span}"
                else:
                    return f"{base_span} {relcl_span}"
        
        return base_span
    
    def _get_full_clause_span(self, clause_root, doc) -> str:
        """ç¯€ã®å®Œå…¨ãªã‚¹ãƒ‘ãƒ³ã‚’å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        # ç¯€ã®ROOTä»¥å¤–ã®è¦ç´ ã‚’å–å¾—
        tokens = []
        
        def collect_non_root_tokens(token):
            for child in token.children:
                if child.dep_ != 'nsubj':  # é–¢ä¿‚ä»£åè©ã¯é™¤å¤–ï¼ˆæ—¢ã«å‡¦ç†æ¸ˆã¿ï¼‰
                    tokens.append(child)
                    collect_non_root_tokens(child)
        
        # ROOTå‹•è©è‡ªä½“ã‚‚å«ã‚ã‚‹
        tokens.append(clause_root)
        collect_non_root_tokens(clause_root)
        
        # é †åºã§ã‚½ãƒ¼ãƒˆ
        tokens.sort(key=lambda t: t.i)
        
        return ' '.join([t.text for t in tokens])

def test_universal_decomposer():
    """çµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ"""
    decomposer = Universal10SlotDecomposer()
    
    test_cases = [
        "She gave him a message.",
        "The woman who seemed indecisive knew the answer.",
        "He figured out the solution because he feared upsetting her."
    ]
    
    print("=" * 80)
    print("ğŸ§ª çµ±ä¸€10ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    for i, sentence in enumerate(test_cases, 1):
        print(f"\n[ãƒ†ã‚¹ãƒˆ{i}] {sentence}")
        print("-" * 60)
        
        result = decomposer.decompose_any_text(sentence)
        
        print(f"\nğŸ“‹ åˆ†è§£çµæœ:")
        for slot, content in result.items():
            if isinstance(content, dict):
                print(f"  {slot}:")
                for key, value in content.items():
                    print(f"    {key}: {value}")
            else:
                print(f"  {slot}: {content}")

if __name__ == "__main__":
    test_universal_decomposer()
