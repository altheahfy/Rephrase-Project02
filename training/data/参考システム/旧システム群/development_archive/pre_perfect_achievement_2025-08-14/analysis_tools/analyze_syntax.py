#!/usr/bin/env python3
"""Stanza/spaCyã®æ§‹æ–‡è§£ææ©Ÿèƒ½ã‚’èª¿æŸ»"""

import stanza
import spacy
from advanced_grammar_detector import AdvancedGrammarDetector

def analyze_syntactic_structures():
    """Stanza/spaCyã®æ§‹æ–‡è§£æçµæœã‚’è©³ç´°èª¿æŸ»"""
    
    # åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    detector = AdvancedGrammarDetector()
    
    test_sentences = [
        "I think that he is smart.",           # thatç¯€
        "Being a teacher, she knows well.",    # åˆ†è©æ§‹æ–‡  
        "The book that I read was good.",      # é–¢ä¿‚ä»£åè©
        "If I were rich, I would travel.",     # ä»®å®šæ³•
        "Having finished work, he went home.", # å®Œäº†åˆ†è©æ§‹æ–‡
        "To succeed, you must work hard.",     # ä¸å®šè©å¥
    ]
    
    print("ğŸ” Stanza/spaCy æ§‹æ–‡è§£æè©³ç´°èª¿æŸ»")
    print("=" * 60)
    
    for sentence in test_sentences:
        print(f"\nğŸ“ åˆ†ææ–‡: \"{sentence}\"")
        print("-" * 50)
        
        try:
            # Stanzaè§£æ
            stanza_doc = detector.nlp_stanza(sentence)
            
            print("ğŸ”µ Stanzaä¾å­˜æ§‹é€ :")
            for sent in stanza_doc.sentences:
                for word in sent.words:
                    if word.head != 0:  # rootã§ãªã„å ´åˆ
                        head_word = sent.words[word.head-1].text
                        print(f"  {word.text} --{word.deprel}--> {head_word}")
                    else:
                        print(f"  {word.text} [ROOT]")
            
            print("\nğŸ”µ å¥æ§‹é€  (Constituency):")
            for sent in stanza_doc.sentences:
                if hasattr(sent, 'constituency'):
                    print(f"  {sent.constituency}")
                
            # spaCyè§£æ
            spacy_doc = detector.nlp_spacy(sentence)
            
            print("\nğŸŸ¢ spaCyåè©å¥ãƒ»å‹•è©å¥:")
            for chunk in spacy_doc.noun_chunks:
                print(f"  NP: '{chunk.text}' (root: {chunk.root.text}, dep: {chunk.root.dep_})")
                
            print("\nğŸŸ¢ spaCyä¾å­˜æ§‹é€  (ä¸»è¦):")
            for token in spacy_doc:
                if token.dep_ in ['nsubj', 'dobj', 'ccomp', 'xcomp', 'advcl', 'acl', 'relcl']:
                    print(f"  {token.text} --{token.dep_}--> {token.head.text}")
                    
        except Exception as e:
            print(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    analyze_syntactic_structures()
