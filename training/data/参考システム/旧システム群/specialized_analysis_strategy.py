#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°‚é–€åˆ†æ‹…å‹åˆ†ææˆ¦ç•¥
å„è§£ææ‰‹æ³•ã‚’å¾—æ„åˆ†é‡ã«ç‰¹åŒ–ã—ã¦ä½¿ç”¨
"""

import spacy
from typing import Dict, Any, Optional

class SpecializedAnalysisStrategy:
    """è§£ææ‰‹æ³•ã®å°‚é–€åˆ†æ‹…ç®¡ç†"""
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        
        # å°‚é–€åˆ†æ‹…ãƒãƒƒãƒ—
        self.analysis_assignments = {
            # å“è©åˆ†æãŒå¾—æ„ãªåˆ†é‡
            'adverb_detection': 'pos_analysis',
            'passive_voice_pattern': 'pos_analysis', 
            'be_verb_identification': 'pos_analysis',
            'simple_sentence_verb': 'pos_analysis',
            'perfect_tense_aux': 'pos_analysis',
            
            # ä¾å­˜é–¢ä¿‚ãŒå¾—æ„ãªåˆ†é‡
            'main_verb_in_complex': 'dependency_analysis',
            'relative_clause_structure': 'dependency_analysis',
            'sentence_root': 'dependency_analysis'
        }
    
    def detect_adverbs(self, doc) -> list:
        """å‰¯è©æ¤œå‡º - å“è©åˆ†æå°‚ç”¨"""
        adverbs = []
        for token in doc:
            if token.pos_ == 'ADV':
                adverbs.append({
                    'text': token.text,
                    'index': token.i,
                    'method': 'pos_analysis'
                })
        return adverbs
    
    def detect_passive_voice(self, doc) -> Optional[Dict]:
        """å—å‹•æ…‹æ¤œå‡º - å“è©åˆ†æå°‚ç”¨"""
        be_verbs = ['am', 'is', 'are', 'was', 'were', 'be', 'been', 'being']
        
        for i, token in enumerate(doc):
            if token.text.lower() in be_verbs and i + 1 < len(doc):
                next_token = doc[i + 1]
                # é–“ã«å‰¯è©ãŒã‚ã£ã¦ã‚‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¤œå‡º
                check_idx = i + 1
                while check_idx < len(doc) and doc[check_idx].pos_ == 'ADV':
                    check_idx += 1
                
                if check_idx < len(doc) and doc[check_idx].tag_ == 'VBN':
                    return {
                        'aux': token.text,
                        'verb': doc[check_idx].text,
                        'pattern': 'passive_voice',
                        'method': 'pos_analysis'
                    }
        return None
    
    def find_main_verb_complex(self, doc) -> Optional[int]:
        """è¤‡æ–‡ã®ä¸»å‹•è©æ¤œå‡º - ä¾å­˜é–¢ä¿‚å°‚ç”¨"""
        for token in doc:
            if token.dep_ == 'ROOT':
                return token.i
        return None
    
    def analyze_relative_clause_structure(self, doc) -> Dict:
        """é–¢ä¿‚ç¯€æ§‹é€ åˆ†æ - ä¾å­˜é–¢ä¿‚å°‚ç”¨"""
        structure = {
            'has_relative_clause': False,
            'relative_pronouns': [],
            'relative_verbs': [],
            'main_verb': None,
            'method': 'dependency_analysis'
        }
        
        # é–¢ä¿‚ä»£åè©æ¤œå‡º
        rel_pronouns = ['who', 'which', 'that', 'whose']
        for token in doc:
            if token.text.lower() in rel_pronouns:
                structure['relative_pronouns'].append({
                    'text': token.text,
                    'index': token.i
                })
                structure['has_relative_clause'] = True
        
        # é–¢ä¿‚ç¯€å‹•è©ã¨ä¸»å‹•è©ã‚’ä¾å­˜é–¢ä¿‚ã§åŒºåˆ¥
        for token in doc:
            if token.dep_ == 'relcl':  # é–¢ä¿‚ç¯€å‹•è©
                structure['relative_verbs'].append({
                    'text': token.text,
                    'index': token.i
                })
            elif token.dep_ == 'ROOT':  # ä¸»å‹•è©
                structure['main_verb'] = {
                    'text': token.text,
                    'index': token.i
                }
        
        return structure
    
    def get_analysis_method(self, task: str) -> str:
        """ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸè§£ææ‰‹æ³•ã‚’è¿”ã™"""
        return self.analysis_assignments.get(task, 'pos_analysis')
    
    def analyze_sentence_comprehensive(self, sentence: str) -> Dict[str, Any]:
        """æ–‡ã®åŒ…æ‹¬çš„åˆ†æ - å°‚é–€åˆ†æ‹…ä½¿ç”¨"""
        doc = self.nlp(sentence)
        
        result = {
            'sentence': sentence,
            'analysis_methods_used': [],
            'components': {}
        }
        
        # å‰¯è©æ¤œå‡ºï¼ˆå“è©åˆ†æï¼‰
        adverbs = self.detect_adverbs(doc)
        if adverbs:
            result['components']['adverbs'] = adverbs
            result['analysis_methods_used'].append('pos_analysis')
        
        # å—å‹•æ…‹æ¤œå‡ºï¼ˆå“è©åˆ†æï¼‰
        passive = self.detect_passive_voice(doc)
        if passive:
            result['components']['passive_voice'] = passive
            result['analysis_methods_used'].append('pos_analysis')
        
        # é–¢ä¿‚ç¯€æ§‹é€ ï¼ˆä¾å­˜é–¢ä¿‚ï¼‰
        rel_structure = self.analyze_relative_clause_structure(doc)
        if rel_structure['has_relative_clause']:
            result['components']['relative_clause'] = rel_structure
            result['analysis_methods_used'].append('dependency_analysis')
            
            # è¤‡æ–‡ã®ä¸»å‹•è©ï¼ˆä¾å­˜é–¢ä¿‚ï¼‰
            main_verb_idx = self.find_main_verb_complex(doc)
            if main_verb_idx is not None:
                result['components']['main_verb'] = {
                    'text': doc[main_verb_idx].text,
                    'index': main_verb_idx,
                    'method': 'dependency_analysis'
                }
        else:
            # å˜ç´”æ–‡ã®å‹•è©ï¼ˆå“è©åˆ†æï¼‰
            verbs = [token for token in doc if token.pos_ == 'VERB']
            if verbs:
                result['components']['main_verb'] = {
                    'text': verbs[-1].text,
                    'index': verbs[-1].i,
                    'method': 'pos_analysis'
                }
                result['analysis_methods_used'].append('pos_analysis')
        
        # ä½¿ç”¨ã—ãŸæ‰‹æ³•ã‚’é‡è¤‡å‰Šé™¤
        result['analysis_methods_used'] = list(set(result['analysis_methods_used']))
        
        return result

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    strategy = SpecializedAnalysisStrategy()
    
    test_sentences = [
        'She sings beautifully.',                                    # å˜ç´”æ–‡ + å‰¯è©
        'The letter was written by John.',                           # å—å‹•æ…‹
        'The man who runs fast is strong.',                          # é–¢ä¿‚ç¯€
        'The teacher whose class runs efficiently is respected.'     # è¤‡é›‘ãªé–¢ä¿‚ç¯€
    ]
    
    print("=== å°‚é–€åˆ†æ‹…å‹åˆ†æãƒ†ã‚¹ãƒˆ ===")
    for sentence in test_sentences:
        result = strategy.analyze_sentence_comprehensive(sentence)
        print(f"\nğŸ“ {sentence}")
        print(f"ğŸ”§ ä½¿ç”¨æ‰‹æ³•: {', '.join(result['analysis_methods_used'])}")
        
        for component, data in result['components'].items():
            if 'method' in data:
                print(f"  {component}: {data.get('text', data)} (æ‰‹æ³•: {data['method']})")
            else:
                print(f"  {component}: {data}")
