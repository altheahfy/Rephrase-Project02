"""
Enhanced Adverb Precision System - Phase A Implementation
å‰¯è©é…ç½®ç²¾å¯†åŒ–ã‚·ã‚¹ãƒ†ãƒ  - ãƒ•ã‚§ãƒ¼ã‚ºAå®Ÿè£…

ä¿®æ­£ã™ã¹ãå•é¡Œ:
1. M1/M2/M3ã®å‹•è©ä½ç½®ãƒ™ãƒ¼ã‚¹åˆ†é¡ãŒä¸æ­£ç¢º
2. è¤‡åˆå‰¯è©å¥ï¼ˆ"very carefully"ï¼‰ã®åˆ†é›¢å¤±æ•—
3. å‰ç½®è©å¥ï¼ˆ"to school"ï¼‰ã®ç›®çš„èªèª¤èªè­˜
4. ä¸»èªèªè­˜ã‚¨ãƒ©ãƒ¼ï¼ˆ"She" â†’ O1ï¼‰

ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:
1. spaCyä¾å­˜æ§‹é€ è§£æã§SVé–¢ä¿‚ã‚’æ­£ç¢ºã«ç‰¹å®š
2. å‹•è©ä½ç½®ãƒ™ãƒ¼ã‚¹ã®æ­£ç¢ºãªM1/M2/M3é…ç½®
3. è¤‡åˆå‰¯è©å¥ã®çµ±åˆå‡¦ç†
4. å‰ç½®è©å¥ã®M2é…ç½®å„ªå…ˆ
"""

import spacy
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass

@dataclass
class AdverbElement:
    """å‰¯è©è¦ç´ ã®æ§‹é€ åŒ–è¡¨ç¾"""
    text: str
    tokens: List
    start_idx: int
    end_idx: int
    adverb_type: str  # 'simple', 'compound', 'prepositional'
    position_relative_to_verb: str  # 'pre', 'post'
    
class EnhancedAdverbSystem:
    """å‰¯è©é…ç½®ç²¾å¯†åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # spaCy NLPãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            self.logger.error("spaCyè‹±èªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`python -m spacy download en_core_web_sm`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            self.nlp = None
            
        # å‰¯è©å¥ãƒ‘ã‚¿ãƒ¼ãƒ³è¾æ›¸
        self.compound_adverb_patterns = {
            'very carefully', 'quite slowly', 'really fast', 'extremely well',
            'so quickly', 'too late', 'pretty good', 'somewhat difficult'
        }
        
        # å‰ç½®è©å¥ã®æ–¹å‘æŒ‡ç¤ºèª
        self.directional_prepositions = {
            'to', 'from', 'into', 'onto', 'towards', 'through',
            'across', 'over', 'under', 'around', 'along', 'at', 'in', 'on'
        }
        
    def analyze_adverb_precision(self, sentence: str, current_result: Dict) -> Dict[str, str]:
        """
        å‰¯è©é…ç½®ç²¾å¯†åˆ†æãƒ¡ã‚¤ãƒ³é–¢æ•°
        
        Args:
            sentence: åˆ†æå¯¾è±¡æ–‡
            current_result: æ—¢å­˜ã®æ–‡æ³•è§£æçµæœ
            
        Returns:
            Dict: M1/M2/M3ã®æ­£ç¢ºãªé…ç½®çµæœ
        """
        if not self.nlp:
            return {}
            
        try:
            # spaCyè§£æå®Ÿè¡Œ
            doc = self.nlp(sentence)
            
            # Phase 1: å‹•è©ä½ç½®ã®æ­£ç¢ºãªç‰¹å®š
            main_verb_info = self._identify_main_verb_precise(doc)
            if not main_verb_info:
                self.logger.warning(f"ãƒ¡ã‚¤ãƒ³å‹•è©ãŒç‰¹å®šã§ãã¾ã›ã‚“: {sentence}")
                return {}
                
            # Phase 2: å‰¯è©è¦ç´ ã®æŠ½å‡ºã¨åˆ†é¡
            adverb_elements = self._extract_adverb_elements(doc, main_verb_info)
            
            # Phase 3: M1/M2/M3ã¸ã®æ­£ç¢ºãªé…ç½®
            placement_result = self._assign_m1_m2_m3_precise(adverb_elements, main_verb_info)
            
            self.logger.info(f"å‰¯è©ç²¾å¯†åˆ†æçµæœ: {placement_result}")
            return placement_result
            
        except Exception as e:
            self.logger.error(f"å‰¯è©ç²¾å¯†åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _identify_main_verb_precise(self, doc) -> Optional[Dict]:
        """
        ãƒ¡ã‚¤ãƒ³å‹•è©ã®æ­£ç¢ºãªç‰¹å®šï¼ˆspaCyä¾å­˜æ§‹é€ è§£æä½¿ç”¨ï¼‰
        
        Returns:
            Dict: {'token': spacy.Token, 'index': int, 'lemma': str}
        """
        # ROOTã‚’æ¢ã™ï¼ˆæ–‡ã®ä¸»å‹•è©ï¼‰
        for token in doc:
            if token.dep_ == "ROOT" and token.pos_ == "VERB":
                return {
                    'token': token,
                    'index': token.i,
                    'lemma': token.lemma_,
                    'text': token.text
                }
        
        # ROOTãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€åˆã®VERBã‚’ä½¿ç”¨
        for token in doc:
            if token.pos_ == "VERB":
                return {
                    'token': token,
                    'index': token.i,
                    'lemma': token.lemma_,
                    'text': token.text
                }
        
        return None
    
    def _extract_adverb_elements(self, doc, main_verb_info: Dict) -> List[AdverbElement]:
        """
        å‰¯è©è¦ç´ ã®æŠ½å‡ºã¨åˆ†é¡ï¼ˆè¤‡åˆå‰¯è©å¥å¯¾å¿œï¼‰
        
        Returns:
            List[AdverbElement]: æ§‹é€ åŒ–ã•ã‚ŒãŸå‰¯è©è¦ç´ ãƒªã‚¹ãƒˆ
        """
        adverb_elements = []
        processed_indices = set()
        
        main_verb_idx = main_verb_info['index']
        
        for i, token in enumerate(doc):
            if i in processed_indices:
                continue
                
            # 1. å˜ç´”å‰¯è©ã®æ¤œå‡º
            if token.pos_ == "ADV":
                # è¤‡åˆå‰¯è©å¥ã‹ãƒã‚§ãƒƒã‚¯
                compound_element = self._check_compound_adverb(doc, i)
                if compound_element:
                    adverb_elements.append(compound_element)
                    processed_indices.update(range(compound_element.start_idx, compound_element.end_idx + 1))
                else:
                    # å˜ç´”å‰¯è©
                    adverb_elements.append(AdverbElement(
                        text=token.text,
                        tokens=[token],
                        start_idx=i,
                        end_idx=i,
                        adverb_type='simple',
                        position_relative_to_verb='pre' if i < main_verb_idx else 'post'
                    ))
                    processed_indices.add(i)
            
            # ğŸ”§ 2. æ™‚é–“å‰¯è©ã®æ¤œå‡ºï¼ˆ"Yesterday", "Today", "Tomorrow"ç­‰ï¼‰
            elif token.text.lower() in ['yesterday', 'today', 'tomorrow', 'now', 'then', 'soon', 'always', 'never', 'often', 'sometimes']:
                adverb_elements.append(AdverbElement(
                    text=token.text,
                    tokens=[token],
                    start_idx=i,
                    end_idx=i,
                    adverb_type='temporal',
                    position_relative_to_verb='pre' if i < main_verb_idx else 'post'
                ))
                processed_indices.add(i)
            
            # 3. å‰ç½®è©å¥ã®æ¤œå‡ºï¼ˆæ–¹å‘æŒ‡ç¤ºï¼‰
            elif token.pos_ == "ADP" and token.text.lower() in self.directional_prepositions:
                prep_phrase = self._extract_prepositional_phrase(doc, i)
                if prep_phrase:
                    adverb_elements.append(prep_phrase)
                    processed_indices.update(range(prep_phrase.start_idx, prep_phrase.end_idx + 1))
        
        return adverb_elements
    
    def _check_compound_adverb(self, doc, start_idx: int) -> Optional[AdverbElement]:
        """
        è¤‡åˆå‰¯è©å¥ã®æ¤œå‡ºï¼ˆ"very carefully"ç­‰ï¼‰
        
        Args:
            doc: spaCy Doc
            start_idx: é–‹å§‹ä½ç½®
            
        Returns:
            AdverbElement or None
        """
        if start_idx >= len(doc) - 1:
            return None
            
        token = doc[start_idx]
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å¼·èª¿å‰¯è© + ç¨‹åº¦å‰¯è© ("very carefully")
        if (token.text.lower() in ['very', 'quite', 'really', 'extremely', 'so', 'too'] and
            start_idx + 1 < len(doc) and doc[start_idx + 1].pos_ == "ADV"):
            
            next_token = doc[start_idx + 1]
            compound_text = f"{token.text} {next_token.text}"
            
            return AdverbElement(
                text=compound_text,
                tokens=[token, next_token],
                start_idx=start_idx,
                end_idx=start_idx + 1,
                adverb_type='compound',
                position_relative_to_verb='pre' if start_idx < self._get_main_verb_index(doc) else 'post'
            )
        
        return None
    
    def _extract_prepositional_phrase(self, doc, prep_idx: int) -> Optional[AdverbElement]:
        """
        å‰ç½®è©å¥ã®æŠ½å‡ºï¼ˆ"to school"ç­‰ï¼‰
        
        Args:
            doc: spaCy Doc
            prep_idx: å‰ç½®è©ã®ä½ç½®
            
        Returns:
            AdverbElement or None
        """
        if prep_idx >= len(doc) - 1:
            return None
            
        prep_token = doc[prep_idx]
        phrase_tokens = [prep_token]
        phrase_text = prep_token.text
        
        # å‰ç½®è©ã®ç›´å¾Œã®åè©å¥ã‚’æ¢ã™
        for i in range(prep_idx + 1, min(prep_idx + 3, len(doc))):
            next_token = doc[i]
            if next_token.pos_ in ["NOUN", "PROPN", "PRON"] or next_token.tag_ in ["DT"]:
                phrase_tokens.append(next_token)
                phrase_text += f" {next_token.text}"
            else:
                break
        
        if len(phrase_tokens) > 1:  # å‰ç½®è© + æœ€ä½1èª
            main_verb_idx = self._get_main_verb_index(doc)
            
            return AdverbElement(
                text=phrase_text,
                tokens=phrase_tokens,
                start_idx=prep_idx,
                end_idx=prep_idx + len(phrase_tokens) - 1,
                adverb_type='prepositional',
                position_relative_to_verb='pre' if prep_idx < main_verb_idx else 'post'
            )
        
        return None
    
    def _get_main_verb_index(self, doc) -> int:
        """ãƒ¡ã‚¤ãƒ³å‹•è©ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—ï¼ˆãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼‰"""
        for token in doc:
            if token.dep_ == "ROOT" and token.pos_ == "VERB":
                return token.i
        return len(doc)  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æ–‡æœ«
    
    def _assign_m1_m2_m3_precise(self, adverb_elements: List[AdverbElement], main_verb_info: Dict) -> Dict[str, str]:
        """
        M1/M2/M3ã¸ã®ç²¾å¯†é…ç½®ï¼ˆRephraseãƒ«ãƒ¼ãƒ«æº–æ‹ ï¼‰
        
        ä¿®æ­£ã•ã‚ŒãŸRephraseãƒ«ãƒ¼ãƒ«ï¼ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æœŸå¾…å€¤ãƒ™ãƒ¼ã‚¹ï¼‰:
        - å‹•è©å‰å‰¯è© â†’ M1
        - å‹•è©ç›´å¾Œå‰¯è©/å‰ç½®è©å¥ â†’ M2  
        - æ–‡æœ«å‰¯è©/æ™‚é–“è¡¨ç¾ â†’ M3
        - 1å€‹: å‹•è©å‰â†’M1, å‹•è©å¾Œâ†’M2
        - 2å€‹: å‹•è©å‰1å€‹â†’M1, å‹•è©å¾Œ1å€‹â†’M2
        - 3å€‹ä»¥ä¸Š: M1(å‹•è©å‰), M2(å‹•è©ç›´å¾Œ), M3(æ–‡æœ«)
        
        Args:
            adverb_elements: æ§‹é€ åŒ–å‰¯è©è¦ç´ ãƒªã‚¹ãƒˆ
            main_verb_info: ãƒ¡ã‚¤ãƒ³å‹•è©æƒ…å ±
            
        Returns:
            Dict: M1/M2/M3ã®é…ç½®çµæœ
        """
        if not adverb_elements:
            return {}
        
        # ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
        adverb_elements.sort(key=lambda x: x.start_idx)
        
        # å‹•è©å‰å¾Œã®åˆ†é¡
        main_verb_idx = main_verb_info['index']
        pre_verb_adverbs = [adv for adv in adverb_elements if adv.position_relative_to_verb == 'pre']
        post_verb_adverbs = [adv for adv in adverb_elements if adv.position_relative_to_verb == 'post']
        
        self.logger.debug(f"å‹•è©å‰å‰¯è©: {[adv.text for adv in pre_verb_adverbs]}")
        self.logger.debug(f"å‹•è©å¾Œå‰¯è©: {[adv.text for adv in post_verb_adverbs]}")
        
        result = {}
        
        # ğŸ”§ ä¿®æ­£ã•ã‚ŒãŸRephraseãƒ«ãƒ¼ãƒ«ï¼ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æœŸå¾…å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
        
        # å‹•è©å‰å‰¯è© â†’ M1é…ç½®ï¼ˆå„ªå…ˆï¼‰
        if pre_verb_adverbs:
            result['M1'] = pre_verb_adverbs[0].text
            # å‹•è©å‰ã«è¤‡æ•°ã‚ã‚‹å ´åˆã¯æœ€åˆã®1ã¤ã®ã¿M1
        
        # å‹•è©å¾Œå‰¯è© â†’ M2, M3é…ç½®
        if post_verb_adverbs:
            if len(post_verb_adverbs) == 1:
                # å‹•è©å¾Œ1å€‹ â†’ M2
                result['M2'] = post_verb_adverbs[0].text
            elif len(post_verb_adverbs) >= 2:
                # å‹•è©å¾Œ2å€‹ä»¥ä¸Š â†’ M2(æœ€åˆ), M3(æœ€å¾Œ)
                result['M2'] = post_verb_adverbs[0].text
                result['M3'] = post_verb_adverbs[-1].text  # æœ€å¾Œã®è¦ç´ 
        
        # å‹•è©å‰å‰¯è©ãŒãªãã€å‹•è©å¾Œå‰¯è©ã®ã¿ã®å ´åˆ
        if not pre_verb_adverbs and post_verb_adverbs:
            if len(post_verb_adverbs) == 1:
                # å‹•è©å¾Œ1å€‹ã®ã¿ â†’ M2
                result['M2'] = post_verb_adverbs[0].text
            elif len(post_verb_adverbs) >= 2:
                # å‹•è©å¾Œ2å€‹ä»¥ä¸Š â†’ M2, M3
                result['M2'] = post_verb_adverbs[0].text
                result['M3'] = post_verb_adverbs[1].text
        
        return result
    
    def validate_accuracy(self, test_cases: List[Dict]) -> float:
        """
        ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§ã®ç²¾åº¦æ¤œè¨¼
        
        Args:
            test_cases: [{'sentence': str, 'expected': Dict}, ...]
            
        Returns:
            float: ç²¾åº¦ï¼ˆ0.0-1.0ï¼‰
        """
        if not test_cases:
            return 0.0
            
        correct_count = 0
        
        for test_case in test_cases:
            sentence = test_case['sentence']
            expected = test_case['expected']
            
            # ç²¾å¯†åˆ†æå®Ÿè¡Œ
            result = self.analyze_adverb_precision(sentence, {})
            
            # æœŸå¾…å€¤ã¨æ¯”è¼ƒ
            is_correct = True
            for slot in ['M1', 'M2', 'M3']:
                expected_value = expected.get(slot, '')
                actual_value = result.get(slot, '')
                
                if expected_value != actual_value:
                    is_correct = False
                    self.logger.debug(f"ä¸ä¸€è‡´: {sentence} - {slot}: æœŸå¾…='{expected_value}', å®Ÿéš›='{actual_value}'")
                    break
            
            if is_correct:
                correct_count += 1
                self.logger.debug(f"âœ… æ­£è§£: {sentence}")
            else:
                self.logger.debug(f"âŒ ä¸æ­£è§£: {sentence}")
        
        accuracy = correct_count / len(test_cases)
        self.logger.info(f"å‰¯è©é…ç½®ç²¾åº¦: {accuracy:.1%} ({correct_count}/{len(test_cases)})")
        
        return accuracy

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_enhanced_adverb_system():
    """Enhanced Adverb Systemã®ãƒ†ã‚¹ãƒˆ"""
    
    system = EnhancedAdverbSystem()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆtest_adverb_precision.pyã®æœŸå¾…å€¤ã«åŸºã¥ãä¿®æ­£ç‰ˆï¼‰
    test_cases = [
        {
            'sentence': "She quickly runs to school.",
            'expected': {'M1': 'quickly', 'M2': 'to school'}  # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹11ã®æœŸå¾…å€¤
        },
        {
            'sentence': "He carefully opened the door.",
            'expected': {'M1': 'carefully'}  # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹12ã®æœŸå¾…å€¤
        },
        {
            'sentence': "They very carefully moved the furniture.",
            'expected': {'M1': 'very carefully'}  # è¤‡åˆå‰¯è©ã®ãƒ†ã‚¹ãƒˆ
        },
        {
            'sentence': "Yesterday she spoke softly to him.",
            'expected': {'M1': 'Yesterday', 'M2': 'softly', 'M3': 'to him'}  # 3å€‹å‰¯è©ãƒ†ã‚¹ãƒˆ
        }
    ]
    
    print("=== Enhanced Adverb Precision System Test ===")
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nTest {i}: {test_case['sentence']}")
        result = system.analyze_adverb_precision(test_case['sentence'], {})
        expected = test_case['expected']
        
        print(f"æœŸå¾…å€¤: {expected}")
        print(f"çµæœ:   {result}")
        
        # ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        matches = all(result.get(k, '') == v for k, v in expected.items())
        print(f"åˆ¤å®š:   {'âœ… æ­£è§£' if matches else 'âŒ ä¸æ­£è§£'}")
    
    # å…¨ä½“ç²¾åº¦è¨ˆç®—
    accuracy = system.validate_accuracy(test_cases)
    print(f"\n=== ç·åˆç²¾åº¦: {accuracy:.1%} ===")

if __name__ == "__main__":
    test_enhanced_adverb_system()
