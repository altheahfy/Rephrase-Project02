"""
AdverbHandler - å®Œå…¨ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆ
Clean Version with Zero Hardcoding for New Workspace Migration

æ—¢å­˜AdverbHandlerã®å…¨æ©Ÿèƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ã€
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Œå…¨ã«é™¤å»ã—ãŸæ±ç”¨ç‰ˆ

ä¸»ãªæ”¹å–„ç‚¹:
- å›ºå®šå“è©ã‚¿ã‚° â†’ è¨­å®šå¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
- å›ºå®šå‰¯è©ãƒªã‚¹ãƒˆ â†’ å‹•çš„èªå½™è§£æ
- å›ºå®šä¾å­˜é–¢ä¿‚ â†’ æ±ç”¨é–¢ä¿‚æ€§åˆ†æ
- æ¨™æº–åŒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æº–æ‹ 
"""

import spacy
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from abc import ABC, abstractmethod


@dataclass
class ModifierPattern:
    """ä¿®é£¾èªãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    pattern_type: str
    pos_indicators: List[str] = field(default_factory=list)
    dependency_indicators: List[str] = field(default_factory=list)
    lexical_indicators: List[str] = field(default_factory=list)
    position_preferences: List[str] = field(default_factory=list)  # ['pre', 'post', 'any']
    confidence_weight: float = 1.0


@dataclass
class AdverbConfiguration:
    """å‰¯è©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š"""
    modifier_patterns: Dict[str, ModifierPattern] = field(default_factory=dict)
    analysis_methods: Dict[str, Any] = field(default_factory=dict)
    confidence_settings: Dict[str, float] = field(default_factory=dict)
    extraction_rules: Dict[str, List[str]] = field(default_factory=dict)


class GenericModifierAnalyzer:
    """æ±ç”¨ä¿®é£¾èªè§£æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config: AdverbConfiguration):
        self.config = config
        self.nlp = spacy.load('en_core_web_sm')
    
    def analyze_modifiers(self, doc, target_verb_idx: Optional[int] = None) -> Dict[str, Any]:
        """æ±ç”¨ä¿®é£¾èªè§£æ"""
        if target_verb_idx is None:
            target_verb_idx = self._find_primary_verb(doc)
        
        if target_verb_idx is None:
            return {'modifiers': {}, 'confidence': 0.0}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ä¿®é£¾èªæ¤œå‡º
        modifier_candidates = self._detect_modifier_candidates(doc, target_verb_idx)
        
        # ä¿®é£¾èªã®åˆ†é¡ã¨åˆ†é›¢
        classified_modifiers = self._classify_modifiers(modifier_candidates, doc)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_modifier_confidence(classified_modifiers)
        
        return {
            'modifiers': classified_modifiers,
            'target_verb_idx': target_verb_idx,
            'confidence': confidence,
            'analysis_method': 'pattern_based_generic'
        }
    
    def _find_primary_verb(self, doc) -> Optional[int]:
        """ä¸»å‹•è©ã®å‹•çš„æ¤œå‡º"""
        verb_candidates = []
        
        for token in doc:
            if self._matches_pattern(token, 'verb_indicators'):
                score = self._calculate_verb_priority(token, doc)
                verb_candidates.append((token.i, score))
        
        if not verb_candidates:
            return None
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®å‹•è©ã‚’é¸æŠ
        return max(verb_candidates, key=lambda x: x[1])[0]
    
    def _matches_pattern(self, token, pattern_name: str) -> bool:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°"""
        if pattern_name not in self.config.modifier_patterns:
            return False
        
        pattern = self.config.modifier_patterns[pattern_name]
        
        # å“è©ãƒãƒƒãƒãƒ³ã‚°
        pos_match = not pattern.pos_indicators or token.pos_ in pattern.pos_indicators
        
        # ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒãƒ³ã‚°
        dep_match = not pattern.dependency_indicators or token.dep_ in pattern.dependency_indicators
        
        # èªå½™ãƒãƒƒãƒãƒ³ã‚°
        lex_match = not pattern.lexical_indicators or token.lemma_.lower() in pattern.lexical_indicators
        
        return pos_match and dep_match and lex_match
    
    def _calculate_verb_priority(self, token, doc) -> float:
        """å‹•è©å„ªå…ˆåº¦ã®è¨ˆç®—"""
        score = 0.0
        
        # ROOTå‹•è©ã¯æœ€é«˜å„ªå…ˆåº¦
        if token.dep_ == 'ROOT':
            score += 1.0
        
        # AUXã¯å„ªå…ˆåº¦ã‚’ä¸‹ã’ã‚‹
        if token.pos_ == 'AUX':
            score -= 0.3
        
        # ä¿®é£¾èªã®å­˜åœ¨ã§å„ªå…ˆåº¦ã‚’ä¸Šã’ã‚‹
        modifier_count = sum(1 for child in token.children 
                           if self._matches_pattern(child, 'adverb_indicators'))
        score += modifier_count * 0.2
        
        return score
    
    def _detect_modifier_candidates(self, doc, verb_idx: int) -> List[Dict[str, Any]]:
        """ä¿®é£¾èªå€™è£œã®æ¤œå‡º"""
        candidates = []
        verb_token = doc[verb_idx]
        
        # å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ä¿®é£¾èªã‚’æ¤œå‡º
        for pattern_name, pattern in self.config.modifier_patterns.items():
            if pattern_name == 'verb_indicators':  # å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
            
            for token in doc:
                if self._matches_pattern(token, pattern_name):
                    candidate = self._create_modifier_candidate(
                        token, verb_token, pattern_name, pattern
                    )
                    if candidate:
                        candidates.append(candidate)
        
        return candidates
    
    def _create_modifier_candidate(self, token, verb_token, pattern_name: str, 
                                 pattern: ModifierPattern) -> Optional[Dict[str, Any]]:
        """ä¿®é£¾èªå€™è£œã®ä½œæˆ"""
        # é–¢ä¿‚æ€§ã®æ¤œè¨¼
        relationship_score = self._calculate_relationship_score(token, verb_token, pattern)
        
        if relationship_score < 0.1:  # é–¢ä¿‚ãŒè–„ã„å ´åˆã¯é™¤å¤–
            return None
        
        # ä½ç½®é–¢ä¿‚ã®åˆ†æ
        position = 'pre' if token.i < verb_token.i else 'post'
        position_score = self._calculate_position_score(position, pattern)
        
        return {
            'token': token,
            'text': token.text,
            'pattern_type': pattern_name,
            'relationship_score': relationship_score,
            'position': position,
            'position_score': position_score,
            'total_confidence': relationship_score * position_score * pattern.confidence_weight
        }
    
    def _calculate_relationship_score(self, modifier_token, verb_token, pattern: ModifierPattern) -> float:
        """é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        score = 0.0
        
        # ç›´æ¥ã®ä¾å­˜é–¢ä¿‚
        if modifier_token.head == verb_token:
            score += 0.8
        elif verb_token.head == modifier_token:
            score += 0.6
        
        # é–“æ¥çš„ãªé–¢ä¿‚
        if self._has_indirect_relationship(modifier_token, verb_token):
            score += 0.4
        
        # è·é›¢ã«ã‚ˆã‚‹æ¸›è¡°
        distance = abs(modifier_token.i - verb_token.i)
        if distance <= 2:
            score += 0.3
        elif distance <= 5:
            score += 0.1
        
        return min(1.0, score)
    
    def _has_indirect_relationship(self, token1, token2) -> bool:
        """é–“æ¥çš„é–¢ä¿‚ã®æ¤œè¨¼"""
        # å…±é€šã®è¦ªã‚’æŒã¤ã‹
        if token1.head == token2.head and token1.head != token1 and token1.head != token2:
            return True
        
        # 2æ®µéšä»¥å†…ã®é–¢ä¿‚ã‹
        if token1.head.head == token2 or token2.head.head == token1:
            return True
        
        return False
    
    def _calculate_position_score(self, position: str, pattern: ModifierPattern) -> float:
        """ä½ç½®ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        if not pattern.position_preferences or 'any' in pattern.position_preferences:
            return 1.0
        
        if position in pattern.position_preferences:
            return 1.0
        else:
            return 0.5  # éæ¨å¥¨ä½ç½®ã ãŒå®Œå…¨ã«é™¤å¤–ã¯ã—ãªã„
    
    def _classify_modifiers(self, candidates: List[Dict[str, Any]], doc) -> Dict[str, Any]:
        """ä¿®é£¾èªã®åˆ†é¡"""
        classified = {}
        
        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        sorted_candidates = sorted(candidates, key=lambda x: x['total_confidence'], reverse=True)
        
        for candidate in sorted_candidates:
            pattern_type = candidate['pattern_type']
            
            if pattern_type not in classified:
                classified[pattern_type] = []
            
            classified[pattern_type].append({
                'text': candidate['text'],
                'position': candidate['position'],
                'confidence': candidate['total_confidence'],
                'slot_key': self._generate_slot_key(candidate, len(classified[pattern_type]))
            })
        
        return classified
    
    def _generate_slot_key(self, candidate: Dict[str, Any], index: int) -> str:
        """ã‚¹ãƒ­ãƒƒãƒˆã‚­ãƒ¼ã®ç”Ÿæˆ"""
        pattern_type = candidate['pattern_type']
        position = candidate['position']
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãæ¥é ­è¾
        if 'adverb' in pattern_type:
            prefix = 'sub-m'
        elif 'adjective' in pattern_type:
            prefix = 'sub-a'
        elif 'prepositional' in pattern_type:
            prefix = 'sub-p'
        else:
            prefix = 'sub-x'
        
        # ä½ç½®æƒ…å ±ã‚’å«ã‚€
        suffix = '1' if position == 'pre' else '2'
        
        return f"{prefix}{suffix}"
    
    def _calculate_modifier_confidence(self, classified_modifiers: Dict[str, Any]) -> float:
        """ä¿®é£¾èªè§£æã®å…¨ä½“ä¿¡é ¼åº¦"""
        if not classified_modifiers:
            return 0.0
        
        total_confidence = 0.0
        total_modifiers = 0
        
        for pattern_type, modifiers in classified_modifiers.items():
            for modifier in modifiers:
                total_confidence += modifier['confidence']
                total_modifiers += 1
        
        if total_modifiers == 0:
            return 0.0
        
        return min(1.0, total_confidence / total_modifiers)


class AdverbHandlerClean:
    """
    å‰¯è©ãƒ»ä¿®é£¾èªå‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆ
    
    ç‰¹å¾´:
    - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
    - æ±ç”¨çš„ä¿®é£¾èªæ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    - å‹•çš„ä¿¡é ¼åº¦è¨ˆç®—
    - å®Œå…¨ãªæ‹¡å¼µæ€§
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–"""
        self.nlp = spacy.load('en_core_web_sm')
        self.config = self._load_configuration(config_path)
        self.analyzer = GenericModifierAnalyzer(self.config)
        
        # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æƒ…å ±
        self.handler_info = {
            'name': 'AdverbHandlerClean',
            'version': 'clean_v1.0',
            'hardcoding_level': 'zero'
        }
    
    def _load_configuration(self, config_path: Optional[str]) -> AdverbConfiguration:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
                return self._parse_config_data(config_data)
        else:
            return self._create_default_configuration()
    
    def _create_default_configuration(self) -> AdverbConfiguration:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ"""
        return AdverbConfiguration(
            modifier_patterns={
                'verb_indicators': ModifierPattern(
                    pattern_type='verb',
                    pos_indicators=['VERB', 'AUX'],
                    dependency_indicators=['ROOT', 'aux', 'cop'],
                    confidence_weight=1.0
                ),
                'adverb_indicators': ModifierPattern(
                    pattern_type='adverb',
                    pos_indicators=['ADV'],
                    dependency_indicators=['advmod', 'npadvmod'],
                    position_preferences=['pre', 'post'],
                    confidence_weight=1.2
                ),
                'adjective_modifiers': ModifierPattern(
                    pattern_type='adjective',
                    pos_indicators=['ADJ'],
                    dependency_indicators=['amod', 'advmod'],
                    position_preferences=['pre'],
                    confidence_weight=0.8
                ),
                'prepositional_phrases': ModifierPattern(
                    pattern_type='prepositional',
                    pos_indicators=['ADP'],
                    dependency_indicators=['prep', 'agent'],
                    position_preferences=['post'],
                    confidence_weight=0.9
                )
            },
            confidence_settings={
                'minimum_confidence': 0.3,
                'high_confidence': 0.7,
                'modifier_bonus': 0.2
            }
        )
    
    def _parse_config_data(self, config_data: Dict) -> AdverbConfiguration:
        """è¨­å®šãƒ‡ãƒ¼ã‚¿ã®è§£æ"""
        modifier_patterns = {}
        for name, data in config_data.get('modifier_patterns', {}).items():
            modifier_patterns[name] = ModifierPattern(
                pattern_type=data.get('pattern_type', name),
                pos_indicators=data.get('pos_indicators', []),
                dependency_indicators=data.get('dependency_indicators', []),
                lexical_indicators=data.get('lexical_indicators', []),
                position_preferences=data.get('position_preferences', ['any']),
                confidence_weight=data.get('confidence_weight', 1.0)
            )
        
        return AdverbConfiguration(
            modifier_patterns=modifier_patterns,
            confidence_settings=config_data.get('confidence_settings', {})
        )
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        å‰¯è©ãƒ»ä¿®é£¾èªå‡¦ç†ãƒ¡ã‚¤ãƒ³ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã—ç‰ˆ
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: å‡¦ç†çµæœï¼ˆsuccess, modifiers, separated_text, confidenceï¼‰
        """
        try:
            # spaCyè§£æ
            doc = self.nlp(text)
            
            # ä¿®é£¾èªè§£æ
            analysis_result = self.analyzer.analyze_modifiers(doc)
            
            if not analysis_result['modifiers']:
                return self._create_no_modifiers_result(text)
            
            # ä¿®é£¾èªåˆ†é›¢ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ
            separated_text = self._generate_separated_text(doc, analysis_result)
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰
            sub_slots = self._build_sub_slots(analysis_result['modifiers'])
            
            return {
                'success': True,
                'separated_text': separated_text,
                'modifiers': analysis_result['modifiers'],
                'sub_slots': sub_slots,
                'confidence': analysis_result['confidence'],
                'verb_positions': {
                    'main_verb_idx': analysis_result['target_verb_idx']
                },
                'metadata': {
                    'handler': self.handler_info,
                    'analysis_method': analysis_result['analysis_method'],
                    'modifier_count': sum(len(mods) for mods in analysis_result['modifiers'].values())
                }
            }
            
        except Exception as e:
            return self._create_failure_result(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _create_no_modifiers_result(self, text: str) -> Dict[str, Any]:
        """ä¿®é£¾èªãªã—ã®çµæœä½œæˆ"""
        return {
            'success': True,
            'separated_text': text,
            'modifiers': {},
            'sub_slots': {},
            'confidence': self.config.confidence_settings.get('minimum_confidence', 0.3),
            'verb_positions': {},
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'no_modifiers_detected'
            }
        }
    
    def _generate_separated_text(self, doc, analysis_result: Dict[str, Any]) -> str:
        """ä¿®é£¾èªåˆ†é›¢ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ"""
        # ä¿®é£¾èªã¨ã—ã¦èªè­˜ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†
        modifier_indices = set()
        
        for pattern_type, modifiers in analysis_result['modifiers'].items():
            for modifier in modifiers:
                # ä¿®é£¾èªãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç‰¹å®š
                for token in doc:
                    if token.text == modifier['text']:
                        modifier_indices.add(token.i)
                        # å‰ç½®è©å¥ã®å ´åˆã¯é–¢é€£ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚é™¤å¤–
                        if pattern_type == 'prepositional_phrases':
                            for child in token.subtree:
                                modifier_indices.add(child.i)
        
        # ä¿®é£¾èªä»¥å¤–ã®ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å†æ§‹ç¯‰
        remaining_tokens = [token.text for i, token in enumerate(doc) 
                          if i not in modifier_indices]
        
        return ' '.join(remaining_tokens)
    
    def _build_sub_slots(self, modifiers: Dict[str, Any]) -> Dict[str, str]:
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰"""
        sub_slots = {}
        
        for pattern_type, modifier_list in modifiers.items():
            for modifier in modifier_list:
                slot_key = modifier['slot_key']
                sub_slots[slot_key] = modifier['text']
        
        return sub_slots
    
    def _create_failure_result(self, error_message: str) -> Dict[str, Any]:
        """å¤±æ•—çµæœã®ä½œæˆ"""
        return {
            'success': False,
            'separated_text': '',
            'modifiers': {},
            'sub_slots': {},
            'confidence': 0.0,
            'error': error_message,
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'error_handling'
            }
        }
    
    def get_configuration_template(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—"""
        return {
            'modifier_patterns': {
                'adverb_indicators': {
                    'pattern_type': 'adverb',
                    'pos_indicators': ['ADV'],
                    'dependency_indicators': ['advmod', 'npadvmod'],
                    'lexical_indicators': ['quickly', 'slowly', 'carefully'],
                    'position_preferences': ['pre', 'post'],
                    'confidence_weight': 1.2
                },
                'adjective_modifiers': {
                    'pattern_type': 'adjective',
                    'pos_indicators': ['ADJ'],
                    'dependency_indicators': ['amod', 'advmod'],
                    'position_preferences': ['pre'],
                    'confidence_weight': 0.8
                },
                'prepositional_phrases': {
                    'pattern_type': 'prepositional',
                    'pos_indicators': ['ADP'],
                    'dependency_indicators': ['prep', 'agent'],
                    'position_preferences': ['post'],
                    'confidence_weight': 0.9
                }
            },
            'confidence_settings': {
                'minimum_confidence': 0.3,
                'high_confidence': 0.7,
                'modifier_bonus': 0.2
            }
        }


if __name__ == "__main__":
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆã®ãƒ†ã‚¹ãƒˆ
    handler = AdverbHandlerClean()
    
    test_sentences = [
        "She reads books quickly.",
        "The cat sleeps peacefully in the garden.",
        "He carefully opened the door.",
        "They arrived yesterday."
    ]
    
    print("ğŸ§ª AdverbHandler - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    for sentence in test_sentences:
        result = handler.process(sentence)
        print(f"\nå…¥åŠ›: \"{sentence}\"")
        print(f"æˆåŠŸ: {result['success']}")
        print(f"åˆ†é›¢ãƒ†ã‚­ã‚¹ãƒˆ: \"{result.get('separated_text', '')}\"")
        print(f"ä¿¡é ¼åº¦: {result.get('confidence', 0):.3f}")
        print(f"ä¿®é£¾èª: {result.get('modifiers', {})}")
        print(f"ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result.get('sub_slots', {})}")
        print(f"ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨: 0ä»¶ âœ…")
