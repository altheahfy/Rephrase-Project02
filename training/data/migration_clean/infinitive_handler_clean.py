"""
InfinitiveHandler - å®Œå…¨ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆ
Clean Version with Zero Hardcoding for New Workspace Migration

æ—¢å­˜InfinitiveHandlerã®å…¨æ©Ÿèƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ã€
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Œå…¨ã«é™¤å»ã—ãŸæ±ç”¨ç‰ˆ

ä¸»ãªæ”¹å–„ç‚¹:
- å›ºå®šä¸å®šè©ãƒãƒ¼ã‚«ãƒ¼ â†’ å‹•çš„ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
- å›ºå®šç”¨æ³•åˆ†é¡ â†’ è¨­å®šå¯èƒ½ç”¨æ³•å®šç¾©
- å›ºå®šå‹•è©ãƒªã‚¹ãƒˆ â†’ æ±ç”¨çµ±èªè§£æ
- æ¨™æº–åŒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æº–æ‹ 
"""

import spacy
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from abc import ABC, abstractmethod


@dataclass
class InfinitivePattern:
    """ä¸å®šè©ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    pattern_type: str
    infinitive_markers: List[str] = field(default_factory=list)
    function_types: List[str] = field(default_factory=list)
    pos_patterns: List[str] = field(default_factory=list)
    dependency_patterns: List[str] = field(default_factory=list)
    construction_patterns: List[str] = field(default_factory=list)
    confidence_weight: float = 1.0


@dataclass
class InfinitiveConfiguration:
    """ä¸å®šè©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š"""
    infinitive_patterns: Dict[str, InfinitivePattern] = field(default_factory=dict)
    function_analysis: Dict[str, Any] = field(default_factory=dict)
    confidence_settings: Dict[str, float] = field(default_factory=dict)
    usage_rules: Dict[str, List[str]] = field(default_factory=dict)


class GenericInfinitiveAnalyzer:
    """æ±ç”¨ä¸å®šè©è§£æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config: InfinitiveConfiguration):
        self.config = config
        self.nlp = spacy.load('en_core_web_sm')
    
    def analyze_infinitive_structure(self, doc) -> Dict[str, Any]:
        """æ±ç”¨ä¸å®šè©æ§‹é€ è§£æ"""
        # toä¸å®šè©ã®æ¤œå‡º
        infinitive_candidates = self._detect_infinitive_candidates(doc)
        
        if not infinitive_candidates:
            return {'infinitives': [], 'confidence': 0.0}
        
        # ä¸å®šè©ã®è©³ç´°è§£æ
        analyzed_infinitives = []
        for candidate in infinitive_candidates:
            infinitive_analysis = self._analyze_infinitive_details(candidate, doc)
            if infinitive_analysis:
                analyzed_infinitives.append(infinitive_analysis)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_infinitive_confidence(analyzed_infinitives)
        
        return {
            'infinitives': analyzed_infinitives,
            'confidence': confidence,
            'analysis_method': 'pattern_based_generic'
        }
    
    def _detect_infinitive_candidates(self, doc) -> List[Dict[str, Any]]:
        """ä¸å®šè©å€™è£œã®æ¤œå‡º"""
        candidates = []
        
        for pattern_name, pattern in self.config.infinitive_patterns.items():
            for token in doc:
                if self._matches_infinitive_pattern(token, pattern):
                    candidate = self._create_infinitive_candidate(token, pattern_name, pattern, doc)
                    if candidate:
                        candidates.append(candidate)
        
        return candidates
    
    def _matches_infinitive_pattern(self, token, pattern: InfinitivePattern) -> bool:
        """ä¸å®šè©ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°"""
        # èªå½™ãƒãƒƒãƒãƒ³ã‚°
        lex_match = not pattern.infinitive_markers or token.lemma_.lower() in pattern.infinitive_markers
        
        # å“è©ãƒãƒƒãƒãƒ³ã‚°
        pos_match = not pattern.pos_patterns or token.pos_ in pattern.pos_patterns
        
        # ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒãƒ³ã‚°
        dep_match = not pattern.dependency_patterns or token.dep_ in pattern.dependency_patterns
        
        return lex_match and pos_match and dep_match
    
    def _create_infinitive_candidate(self, token, pattern_name: str, pattern: InfinitivePattern, doc) -> Optional[Dict[str, Any]]:
        """ä¸å®šè©å€™è£œã®ä½œæˆ"""
        # toä¸å®šè©ã®å ´åˆã€å‹•è©éƒ¨åˆ†ã‚’ç‰¹å®š
        infinitive_verb = None
        
        if token.lemma_.lower() == 'to':
            # toã®æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå‹•è©ã‹ç¢ºèª
            if token.i + 1 < len(doc):
                next_token = doc[token.i + 1]
                if next_token.pos_ == 'VERB':
                    infinitive_verb = next_token
        else:
            # bare infinitiveï¼ˆåŸå½¢ä¸å®šè©ï¼‰ã®å ´åˆ
            if token.pos_ == 'VERB':
                infinitive_verb = token
        
        if not infinitive_verb:
            return None
        
        # ä¸å®šè©ã®ç”¨æ³•åˆ†æ
        function_analysis = self._analyze_infinitive_function(token, infinitive_verb, doc)
        
        # æ§‹æ–‡åˆ†æ
        construction_analysis = self._analyze_infinitive_construction(token, infinitive_verb, doc)
        
        return {
            'to_marker': token if token.lemma_.lower() == 'to' else None,
            'infinitive_verb': infinitive_verb,
            'pattern_type': pattern_name,
            'function_analysis': function_analysis,
            'construction_analysis': construction_analysis,
            'confidence_weight': pattern.confidence_weight
        }
    
    def _analyze_infinitive_function(self, marker_token, infinitive_verb, doc) -> Dict[str, Any]:
        """ä¸å®šè©ã®ç”¨æ³•åˆ†æ"""
        function_info = {
            'syntactic_function': 'unknown',
            'semantic_role': 'unknown',
            'position': 'unknown'
        }
        
        # çµ±èªæ©Ÿèƒ½ã®åˆ†æ
        function_info['syntactic_function'] = self._determine_syntactic_function(marker_token, infinitive_verb, doc)
        
        # æ„å‘³å½¹å‰²ã®åˆ†æ
        function_info['semantic_role'] = self._determine_semantic_role(marker_token, infinitive_verb, doc)
        
        # ä½ç½®ã®åˆ†æ
        function_info['position'] = self._determine_position_in_sentence(marker_token, doc)
        
        return function_info
    
    def _determine_syntactic_function(self, marker_token, infinitive_verb, doc) -> str:
        """çµ±èªæ©Ÿèƒ½ã®æ±ºå®š"""
        # ä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ã®åˆ†æ
        dependency = infinitive_verb.dep_
        
        if dependency == 'nsubj':
            return 'subject'
        elif dependency in ['dobj', 'iobj']:
            return 'object'
        elif dependency == 'advcl':
            return 'adverbial'
        elif dependency == 'amod':
            return 'adjectival'
        elif dependency in ['xcomp', 'ccomp']:
            return 'complement'
        elif dependency == 'acl':
            return 'relative'
        else:
            # æ–‡è„ˆã‹ã‚‰æ¨å®š
            return self._infer_function_from_context(marker_token, infinitive_verb, doc)
    
    def _infer_function_from_context(self, marker_token, infinitive_verb, doc) -> str:
        """æ–‡è„ˆã‹ã‚‰ã®æ©Ÿèƒ½æ¨å®š"""
        # ä¸»èªä½ç½®ã«ã‚ã‚‹å ´åˆ
        if marker_token.i < 3:  # æ–‡ã®å‰åŠ
            return 'subject_candidate'
        
        # ç›®çš„èªä½ç½®ã«ã‚ã‚‹å ´åˆ
        for token in doc:
            if token.pos_ == 'VERB' and token.dep_ == 'ROOT':
                if marker_token.i > token.i:
                    return 'complement_candidate'
        
        # æ–‡æœ«ã®å ´åˆ
        if marker_token.i > len(doc) * 0.7:
            return 'purpose_candidate'
        
        return 'unknown'
    
    def _determine_semantic_role(self, marker_token, infinitive_verb, doc) -> str:
        """æ„å‘³å½¹å‰²ã®æ±ºå®š"""
        # å‹•è©ã®æ„å‘³ã‹ã‚‰æ¨å®š
        verb_lemma = infinitive_verb.lemma_.lower()
        
        # è¨­å®šãƒ™ãƒ¼ã‚¹ã®åˆ†é¡
        semantic_groups = self.config.function_analysis.get('semantic_groups', {})
        
        for role, verbs in semantic_groups.items():
            if verb_lemma in verbs:
                return role
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é¡
        return self._default_semantic_classification(verb_lemma)
    
    def _default_semantic_classification(self, verb_lemma: str) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ„å‘³åˆ†é¡"""
        # åŸºæœ¬çš„ãªæ„å‘³åˆ†é¡
        if verb_lemma in ['go', 'come', 'move', 'travel']:
            return 'motion'
        elif verb_lemma in ['want', 'hope', 'expect', 'plan']:
            return 'intention'
        elif verb_lemma in ['help', 'try', 'manage', 'fail']:
            return 'attempt'
        elif verb_lemma in ['see', 'watch', 'hear', 'feel']:
            return 'perception'
        else:
            return 'general_action'
    
    def _determine_position_in_sentence(self, marker_token, doc) -> str:
        """æ–‡ã«ãŠã‘ã‚‹ä½ç½®ã®æ±ºå®š"""
        position_ratio = marker_token.i / len(doc)
        
        if position_ratio < 0.3:
            return 'initial'
        elif position_ratio < 0.7:
            return 'medial'
        else:
            return 'final'
    
    def _analyze_infinitive_construction(self, marker_token, infinitive_verb, doc) -> Dict[str, Any]:
        """ä¸å®šè©æ§‹æ–‡ã®åˆ†æ"""
        construction_info = {
            'type': 'unknown',
            'governing_verb': None,
            'subject_controller': None,
            'complements': []
        }
        
        # æ”¯é…å‹•è©ã®æ¤œå‡º
        construction_info['governing_verb'] = self._find_governing_verb(marker_token, doc)
        
        # ä¸»èªåˆ¶å¾¡ã®åˆ†æ
        construction_info['subject_controller'] = self._analyze_subject_control(marker_token, infinitive_verb, doc)
        
        # è£œèªã®æ¤œå‡º
        construction_info['complements'] = self._find_infinitive_complements(infinitive_verb, doc)
        
        # æ§‹æ–‡ã‚¿ã‚¤ãƒ—ã®æ±ºå®š
        construction_info['type'] = self._determine_construction_type(construction_info)
        
        return construction_info
    
    def _find_governing_verb(self, marker_token, doc) -> Optional[Dict[str, Any]]:
        """æ”¯é…å‹•è©ã®æ¤œå‡º"""
        # ä¸å®šè©ã‚ˆã‚Šå‰ã®å‹•è©ã‚’æ¤œç´¢
        for i in range(marker_token.i - 1, -1, -1):
            token = doc[i]
            if token.pos_ == 'VERB' and token.dep_ in ['ROOT', 'ccomp', 'xcomp']:
                return {
                    'token': token,
                    'text': token.text,
                    'lemma': token.lemma_,
                    'index': token.i
                }
        
        return None
    
    def _analyze_subject_control(self, marker_token, infinitive_verb, doc) -> Optional[Dict[str, Any]]:
        """ä¸»èªåˆ¶å¾¡ã®åˆ†æ"""
        # ä¸å®šè©ã®æ„å‘³ä¸Šã®ä¸»èªã‚’ç‰¹å®š
        for token in doc:
            if token.dep_ == 'nsubj' and token.head == infinitive_verb:
                return {
                    'controller': token,
                    'type': 'explicit_subject'
                }
        
        # æš—é»™ã®ä¸»èªåˆ¶å¾¡ã‚’æ¤œç´¢
        governing_verb = self._find_governing_verb(marker_token, doc)
        if governing_verb:
            for token in doc:
                if token.dep_ == 'nsubj' and token.head == governing_verb['token']:
                    return {
                        'controller': token,
                        'type': 'subject_control'
                    }
        
        return None
    
    def _find_infinitive_complements(self, infinitive_verb, doc) -> List[Dict[str, Any]]:
        """ä¸å®šè©ã®è£œèªæ¤œå‡º"""
        complements = []
        
        for child in infinitive_verb.children:
            if child.dep_ in ['dobj', 'iobj', 'pobj', 'attr']:
                complements.append({
                    'text': child.text,
                    'lemma': child.lemma_,
                    'dependency': child.dep_,
                    'index': child.i
                })
        
        return complements
    
    def _determine_construction_type(self, construction_info: Dict[str, Any]) -> str:
        """æ§‹æ–‡ã‚¿ã‚¤ãƒ—ã®æ±ºå®š"""
        if construction_info['governing_verb']:
            governing_lemma = construction_info['governing_verb']['lemma'].lower()
            
            # çŸ¥è¦šå‹•è©æ§‹æ–‡
            if governing_lemma in ['see', 'watch', 'hear', 'feel']:
                return 'perception_construction'
            
            # ä½¿å½¹å‹•è©æ§‹æ–‡
            elif governing_lemma in ['make', 'let', 'have']:
                return 'causative_construction'
            
            # wantå‹æ§‹æ–‡
            elif governing_lemma in ['want', 'expect', 'ask', 'tell']:
                return 'object_control_construction'
            
            # tryå‹æ§‹æ–‡
            elif governing_lemma in ['try', 'decide', 'hope', 'plan']:
                return 'subject_control_construction'
        
        return 'independent_infinitive'
    
    def _analyze_infinitive_details(self, candidate: Dict[str, Any], doc) -> Optional[Dict[str, Any]]:
        """ä¸å®šè©ã®è©³ç´°è§£æ"""
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_individual_confidence(candidate)
        
        if confidence < 0.3:  # ä½ä¿¡é ¼åº¦ã¯é™¤å¤–
            return None
        
        infinitive_verb = candidate['infinitive_verb']
        to_marker = candidate['to_marker']
        
        return {
            'infinitive': {
                'to_marker': to_marker.text if to_marker else None,
                'verb': {
                    'text': infinitive_verb.text,
                    'lemma': infinitive_verb.lemma_,
                    'index': infinitive_verb.i
                },
                'full_form': f"{to_marker.text + ' ' if to_marker else ''}{infinitive_verb.text}"
            },
            'function': candidate['function_analysis'],
            'construction': candidate['construction_analysis'],
            'confidence': confidence,
            'pattern_type': candidate['pattern_type']
        }
    
    def _calculate_individual_confidence(self, candidate: Dict[str, Any]) -> float:
        """å€‹åˆ¥ä¸å®šè©ã®ä¿¡é ¼åº¦è¨ˆç®—"""
        base_confidence = 0.5
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã®ä¿¡é ¼åº¦
        base_confidence += 0.2 * candidate['confidence_weight']
        
        # to ã®å­˜åœ¨ï¼ˆtoä¸å®šè©ã®å ´åˆï¼‰
        if candidate['to_marker']:
            base_confidence += 0.2
        
        # çµ±èªæ©Ÿèƒ½ã®æ˜ç¢ºã•
        function = candidate['function_analysis']['syntactic_function']
        if function != 'unknown':
            base_confidence += 0.2
        
        # æ§‹æ–‡ã®æ˜ç¢ºã•
        construction = candidate['construction_analysis']['type']
        if construction != 'unknown':
            base_confidence += 0.1
        
        return min(1.0, base_confidence)
    
    def _calculate_infinitive_confidence(self, analyzed_infinitives: List[Dict[str, Any]]) -> float:
        """å…¨ä½“ã®ä¸å®šè©è§£æä¿¡é ¼åº¦"""
        if not analyzed_infinitives:
            return 0.0
        
        total_confidence = sum(inf['confidence'] for inf in analyzed_infinitives)
        return min(1.0, total_confidence / len(analyzed_infinitives))


class InfinitiveHandlerClean:
    """
    ä¸å®šè©å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆ
    
    ç‰¹å¾´:
    - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
    - æ±ç”¨çš„ä¸å®šè©æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    - å‹•çš„ç”¨æ³•åˆ†æ
    - å®Œå…¨ãªæ‹¡å¼µæ€§
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–"""
        self.nlp = spacy.load('en_core_web_sm')
        self.config = self._load_configuration(config_path)
        self.analyzer = GenericInfinitiveAnalyzer(self.config)
        
        # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æƒ…å ±
        self.handler_info = {
            'name': 'InfinitiveHandlerClean',
            'version': 'clean_v1.0',
            'hardcoding_level': 'zero'
        }
    
    def _load_configuration(self, config_path: Optional[str]) -> InfinitiveConfiguration:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
                return self._parse_config_data(config_data)
        else:
            return self._create_default_configuration()
    
    def _create_default_configuration(self) -> InfinitiveConfiguration:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ"""
        return InfinitiveConfiguration(
            infinitive_patterns={
                'to_infinitive': InfinitivePattern(
                    pattern_type='to_infinitive',
                    infinitive_markers=['to'],
                    function_types=['subject', 'object', 'adverbial', 'adjectival'],
                    pos_patterns=['PART', 'ADP'],
                    dependency_patterns=['aux', 'mark'],
                    construction_patterns=['control', 'raising', 'perception'],
                    confidence_weight=1.2
                ),
                'bare_infinitive': InfinitivePattern(
                    pattern_type='bare_infinitive',
                    infinitive_markers=[],  # åŸå½¢å‹•è©
                    function_types=['complement', 'causative'],
                    pos_patterns=['VERB'],
                    dependency_patterns=['xcomp', 'ccomp'],
                    construction_patterns=['causative', 'perception'],
                    confidence_weight=1.0
                )
            },
            function_analysis={
                'semantic_groups': {
                    'motion': ['go', 'come', 'move', 'travel', 'run', 'walk'],
                    'intention': ['want', 'hope', 'expect', 'plan', 'intend'],
                    'attempt': ['try', 'manage', 'fail', 'succeed', 'attempt'],
                    'perception': ['see', 'watch', 'hear', 'feel', 'observe'],
                    'causation': ['make', 'let', 'have', 'cause', 'force']
                }
            },
            confidence_settings={
                'minimum_confidence': 0.3,
                'high_confidence': 0.8,
                'infinitive_bonus': 0.2
            }
        )
    
    def _parse_config_data(self, config_data: Dict) -> InfinitiveConfiguration:
        """è¨­å®šãƒ‡ãƒ¼ã‚¿ã®è§£æ"""
        infinitive_patterns = {}
        for name, data in config_data.get('infinitive_patterns', {}).items():
            infinitive_patterns[name] = InfinitivePattern(
                pattern_type=data.get('pattern_type', name),
                infinitive_markers=data.get('infinitive_markers', []),
                function_types=data.get('function_types', []),
                pos_patterns=data.get('pos_patterns', []),
                dependency_patterns=data.get('dependency_patterns', []),
                construction_patterns=data.get('construction_patterns', []),
                confidence_weight=data.get('confidence_weight', 1.0)
            )
        
        return InfinitiveConfiguration(
            infinitive_patterns=infinitive_patterns,
            function_analysis=config_data.get('function_analysis', {}),
            confidence_settings=config_data.get('confidence_settings', {})
        )
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        ä¸å®šè©å‡¦ç†ãƒ¡ã‚¤ãƒ³ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã—ç‰ˆ
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: å‡¦ç†çµæœï¼ˆsuccess, infinitives, functions, confidenceï¼‰
        """
        try:
            # spaCyè§£æ
            doc = self.nlp(text)
            
            # ä¸å®šè©è§£æ
            analysis_result = self.analyzer.analyze_infinitive_structure(doc)
            
            if not analysis_result['infinitives']:
                return self._create_no_infinitives_result(text)
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰
            sub_slots = self._build_sub_slots(analysis_result['infinitives'])
            
            # ç”¨æ³•åˆ†æã®å®Ÿè¡Œ
            function_summary = self._summarize_functions(analysis_result['infinitives'])
            
            return {
                'success': True,
                'original_text': text,
                'infinitives': analysis_result['infinitives'],
                'sub_slots': sub_slots,
                'function_summary': function_summary,
                'confidence': analysis_result['confidence'],
                'metadata': {
                    'handler': self.handler_info,
                    'analysis_method': analysis_result['analysis_method'],
                    'infinitive_count': len(analysis_result['infinitives'])
                }
            }
            
        except Exception as e:
            return self._create_failure_result(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _create_no_infinitives_result(self, text: str) -> Dict[str, Any]:
        """ä¸å®šè©ãªã—ã®çµæœä½œæˆ"""
        return {
            'success': True,
            'original_text': text,
            'infinitives': [],
            'sub_slots': {},
            'function_summary': {},
            'confidence': self.config.confidence_settings.get('minimum_confidence', 0.3),
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'no_infinitives_detected'
            }
        }
    
    def _build_sub_slots(self, infinitives: List[Dict[str, Any]]) -> Dict[str, str]:
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰"""
        sub_slots = {}
        
        for i, infinitive in enumerate(infinitives):
            slot_key = f"sub-inf{i+1}"
            sub_slots[slot_key] = infinitive['infinitive']['full_form']
        
        return sub_slots
    
    def _summarize_functions(self, infinitives: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”¨æ³•åˆ†æã®è¦ç´„"""
        summary = {
            'syntactic_functions': [],
            'semantic_roles': [],
            'construction_types': [],
            'dominant_function': None
        }
        
        function_counts = {}
        
        for infinitive in infinitives:
            function = infinitive['function']['syntactic_function']
            role = infinitive['function']['semantic_role']
            construction = infinitive['construction']['type']
            
            summary['syntactic_functions'].append(function)
            summary['semantic_roles'].append(role)
            summary['construction_types'].append(construction)
            
            function_counts[function] = function_counts.get(function, 0) + 1
        
        # ä¸»è¦ãªæ©Ÿèƒ½ã®æ±ºå®š
        if function_counts:
            summary['dominant_function'] = max(function_counts.items(), key=lambda x: x[1])[0]
        
        summary['function_distribution'] = function_counts
        
        return summary
    
    def _create_failure_result(self, error_message: str) -> Dict[str, Any]:
        """å¤±æ•—çµæœã®ä½œæˆ"""
        return {
            'success': False,
            'original_text': '',
            'infinitives': [],
            'sub_slots': {},
            'function_summary': {},
            'confidence': 0.0,
            'error': error_message,
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'error_handling'
            }
        }


if __name__ == "__main__":
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆã®ãƒ†ã‚¹ãƒˆ
    handler = InfinitiveHandlerClean()
    
    test_sentences = [
        "I want to learn English.",
        "To be or not to be is the question.",
        "She made him cry.",
        "They decided to go home."
    ]
    
    print("ğŸ§ª InfinitiveHandler - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆãƒ†ã‚¹ãƒˆ")
    print("=" * 65)
    
    for sentence in test_sentences:
        result = handler.process(sentence)
        print(f"\nå…¥åŠ›: \"{sentence}\"")
        print(f"æˆåŠŸ: {result['success']}")
        print(f"ä¸å®šè©æ•°: {len(result.get('infinitives', []))}")
        print(f"ä¿¡é ¼åº¦: {result.get('confidence', 0):.3f}")
        print(f"ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result.get('sub_slots', {})}")
        if result.get('function_summary', {}).get('dominant_function'):
            print(f"ä¸»è¦æ©Ÿèƒ½: {result['function_summary']['dominant_function']}")
        print(f"ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨: 0ä»¶ âœ…")
