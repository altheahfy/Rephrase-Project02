"""
ConditionalHandler - å®Œå…¨ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆ
Clean Version with Zero Hardcoding for New Workspace Migration

æ—¢å­˜ConditionalHandlerã®å…¨æ©Ÿèƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ã€
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Œå…¨ã«é™¤å»ã—ãŸæ±ç”¨ç‰ˆ

ä¸»ãªæ”¹å–„ç‚¹:
- å›ºå®šæ¡ä»¶ãƒãƒ¼ã‚«ãƒ¼ â†’ å‹•çš„ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
- å›ºå®šä»®å®šæ³•åˆ¤å®š â†’ æ±ç”¨æ™‚åˆ¶è§£æ
- å›ºå®šç¯€æ§‹é€  â†’ å‹•çš„å¢ƒç•Œæ¤œå‡º
- æ¨™æº–åŒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æº–æ‹ 
"""

import spacy
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from abc import ABC, abstractmethod


@dataclass
class ConditionalPattern:
    """æ¡ä»¶æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    pattern_type: str
    condition_markers: List[str] = field(default_factory=list)
    result_markers: List[str] = field(default_factory=list)
    pos_patterns: List[str] = field(default_factory=list)
    dependency_patterns: List[str] = field(default_factory=list)
    conditional_types: List[str] = field(default_factory=list)
    confidence_weight: float = 1.0


@dataclass
class ConditionalConfiguration:
    """æ¡ä»¶æ–‡ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š"""
    conditional_patterns: Dict[str, ConditionalPattern] = field(default_factory=dict)
    clause_detection: Dict[str, Any] = field(default_factory=dict)
    confidence_settings: Dict[str, float] = field(default_factory=dict)
    type_classification: Dict[str, List[str]] = field(default_factory=dict)


class GenericConditionalAnalyzer:
    """æ±ç”¨æ¡ä»¶æ–‡è§£æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config: ConditionalConfiguration):
        self.config = config
        self.nlp = spacy.load('en_core_web_sm')
    
    def analyze_conditional_structure(self, doc) -> Dict[str, Any]:
        """æ±ç”¨æ¡ä»¶æ–‡æ§‹é€ è§£æ"""
        # æ¡ä»¶ãƒãƒ¼ã‚«ãƒ¼ã®æ¤œå‡º
        condition_markers = self._detect_condition_markers(doc)
        
        if not condition_markers:
            return {'conditionals': [], 'confidence': 0.0}
        
        # æ¡ä»¶æ–‡ã®æ§‹é€ è§£æ
        analyzed_conditionals = []
        for marker in condition_markers:
            conditional_analysis = self._analyze_conditional_structure_detail(marker, doc)
            if conditional_analysis:
                analyzed_conditionals.append(conditional_analysis)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_conditional_confidence(analyzed_conditionals)
        
        return {
            'conditionals': analyzed_conditionals,
            'confidence': confidence,
            'analysis_method': 'pattern_based_generic'
        }
    
    def _detect_condition_markers(self, doc) -> List[Dict[str, Any]]:
        """æ¡ä»¶ãƒãƒ¼ã‚«ãƒ¼ã®æ¤œå‡º"""
        markers = []
        
        for pattern_name, pattern in self.config.conditional_patterns.items():
            for token in doc:
                if self._matches_conditional_pattern(token, pattern):
                    marker = self._create_condition_marker(token, pattern_name, pattern, doc)
                    if marker:
                        markers.append(marker)
        
        return markers
    
    def _matches_conditional_pattern(self, token, pattern: ConditionalPattern) -> bool:
        """æ¡ä»¶æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°"""
        # èªå½™ãƒãƒƒãƒãƒ³ã‚°
        lex_match = not pattern.condition_markers or token.lemma_.lower() in pattern.condition_markers
        
        # å“è©ãƒãƒƒãƒãƒ³ã‚°
        pos_match = not pattern.pos_patterns or token.pos_ in pattern.pos_patterns
        
        # ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒãƒ³ã‚°
        dep_match = not pattern.dependency_patterns or token.dep_ in pattern.dependency_patterns
        
        return lex_match and pos_match and dep_match
    
    def _create_condition_marker(self, token, pattern_name: str, pattern: ConditionalPattern, doc) -> Optional[Dict[str, Any]]:
        """æ¡ä»¶ãƒãƒ¼ã‚«ãƒ¼ã®ä½œæˆ"""
        # æ¡ä»¶ç¯€ã®å¢ƒç•Œæ¤œå‡º
        condition_clause = self._detect_condition_clause(token, doc)
        
        if not condition_clause:
            return None
        
        # çµæœç¯€ã®æ¤œå‡º
        result_clause = self._detect_result_clause(token, condition_clause, doc)
        
        # æ¡ä»¶æ–‡ã‚¿ã‚¤ãƒ—ã®åˆ†é¡
        conditional_type = self._classify_conditional_type(token, condition_clause, result_clause)
        
        return {
            'marker_token': token,
            'pattern_type': pattern_name,
            'condition_clause': condition_clause,
            'result_clause': result_clause,
            'conditional_type': conditional_type,
            'confidence_weight': pattern.confidence_weight
        }
    
    def _detect_condition_clause(self, marker_token, doc) -> Optional[Dict[str, Any]]:
        """æ¡ä»¶ç¯€ã®æ¤œå‡º"""
        # ãƒãƒ¼ã‚«ãƒ¼ã‹ã‚‰æ¡ä»¶ç¯€ã®çµ‚ç«¯ã‚’æ¤œç´¢
        clause_start = marker_token.i
        clause_end = self._find_condition_clause_end(marker_token, doc)
        
        if clause_end is None or clause_end <= clause_start:
            return None
        
        clause_tokens = doc[clause_start:clause_end + 1]
        
        # æ¡ä»¶ç¯€ã®å‹•è©æ¤œå‡º
        verbs = [token for token in clause_tokens if token.pos_ in ['VERB', 'AUX']]
        
        # æ™‚åˆ¶åˆ†æ
        tense_analysis = self._analyze_clause_tense(verbs)
        
        return {
            'start': clause_start,
            'end': clause_end,
            'text': ' '.join([token.text for token in clause_tokens]),
            'verbs': [{'text': v.text, 'lemma': v.lemma_, 'morph': v.morph.to_dict()} for v in verbs],
            'tense_analysis': tense_analysis
        }
    
    def _find_condition_clause_end(self, marker_token, doc) -> Optional[int]:
        """æ¡ä»¶ç¯€ã®çµ‚ç«¯æ¤œå‡º"""
        # å¥èª­ç‚¹ã¾ãŸã¯ã‚³ãƒ³ãƒã¾ã§ã‚’æ¤œç´¢
        for i in range(marker_token.i + 1, len(doc)):
            token = doc[i]
            
            # å¥èª­ç‚¹ã§åŒºåˆ‡ã‚Š
            if token.pos_ == 'PUNCT' and token.text in [',', ';']:
                return i - 1
            
            # ä¸»ç¯€ã®é–‹å§‹ã‚’ç¤ºã™ãƒãƒ¼ã‚«ãƒ¼
            if token.lemma_.lower() in ['then', 'so'] and token.dep_ == 'advmod':
                return i - 1
        
        # æ–‡ã®åŠåˆ†ã¾ã§ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        return min(marker_token.i + 10, len(doc) - 1)
    
    def _detect_result_clause(self, marker_token, condition_clause: Dict[str, Any], doc) -> Optional[Dict[str, Any]]:
        """çµæœç¯€ã®æ¤œå‡º"""
        # æ¡ä»¶ç¯€ã®å¾Œã‹ã‚‰æ–‡æœ«ã¾ã§
        result_start = condition_clause['end'] + 1
        
        # ã‚³ãƒ³ãƒã‚’ã‚¹ã‚­ãƒƒãƒ—
        while result_start < len(doc) and doc[result_start].pos_ == 'PUNCT':
            result_start += 1
        
        if result_start >= len(doc):
            return None
        
        result_end = len(doc) - 1
        result_tokens = doc[result_start:result_end + 1]
        
        # çµæœç¯€ã®å‹•è©æ¤œå‡º
        verbs = [token for token in result_tokens if token.pos_ in ['VERB', 'AUX']]
        
        # æ™‚åˆ¶åˆ†æ
        tense_analysis = self._analyze_clause_tense(verbs)
        
        return {
            'start': result_start,
            'end': result_end,
            'text': ' '.join([token.text for token in result_tokens]),
            'verbs': [{'text': v.text, 'lemma': v.lemma_, 'morph': v.morph.to_dict()} for v in verbs],
            'tense_analysis': tense_analysis
        }
    
    def _analyze_clause_tense(self, verbs: List) -> Dict[str, Any]:
        """ç¯€ã®æ™‚åˆ¶åˆ†æ"""
        tense_info = {
            'primary_tense': 'unknown',
            'auxiliary_info': [],
            'modality': 'none'
        }
        
        if not verbs:
            return tense_info
        
        # ä¸»å‹•è©ã®ç‰¹å®š
        main_verb = None
        for verb in verbs:
            if verb.dep_ == 'ROOT' or verb.pos_ == 'VERB':
                main_verb = verb
                break
        
        if not main_verb:
            main_verb = verbs[0]
        
        # æ™‚åˆ¶ã®åˆ¤å®š
        morph_dict = main_verb.morph.to_dict()
        tense = morph_dict.get('Tense', 'unknown')
        
        if tense == 'Past':
            tense_info['primary_tense'] = 'past'
        elif tense == 'Pres':
            tense_info['primary_tense'] = 'present'
        else:
            # èªå½¢ã§åˆ¤å®š
            if main_verb.text.endswith('ed'):
                tense_info['primary_tense'] = 'past'
            elif main_verb.text.endswith(('s', 'es')):
                tense_info['primary_tense'] = 'present'
        
        # åŠ©å‹•è©ã®åˆ†æ
        for verb in verbs:
            if verb.pos_ == 'AUX':
                tense_info['auxiliary_info'].append({
                    'text': verb.text,
                    'lemma': verb.lemma_,
                    'type': self._classify_auxiliary(verb)
                })
        
        # æ³•ï¼ˆmoodï¼‰ã®åˆ¤å®š
        if any(aux['lemma'] in ['would', 'could', 'might'] for aux in tense_info['auxiliary_info']):
            tense_info['modality'] = 'subjunctive'
        elif tense_info['primary_tense'] == 'past':
            tense_info['modality'] = 'past_indicative'
        else:
            tense_info['modality'] = 'indicative'
        
        return tense_info
    
    def _classify_auxiliary(self, verb) -> str:
        """åŠ©å‹•è©ã®åˆ†é¡"""
        lemma = verb.lemma_.lower()
        
        if lemma in ['will', 'would', 'shall']:
            return 'future'
        elif lemma in ['have', 'has', 'had']:
            return 'perfect'
        elif lemma in ['be', 'am', 'is', 'are', 'was', 'were']:
            return 'progressive_passive'
        elif lemma in ['can', 'could', 'may', 'might', 'must', 'should']:
            return 'modal'
        else:
            return 'other'
    
    def _classify_conditional_type(self, marker_token, condition_clause: Dict[str, Any], result_clause: Optional[Dict[str, Any]]) -> str:
        """æ¡ä»¶æ–‡ã‚¿ã‚¤ãƒ—ã®åˆ†é¡"""
        if not result_clause:
            return 'incomplete_conditional'
        
        condition_tense = condition_clause['tense_analysis']
        result_tense = result_clause['tense_analysis']
        
        # ç¬¬ä¸€æ¡ä»¶æ–‡ï¼ˆç¾åœ¨å½¢ + will/ç¾åœ¨å½¢ï¼‰
        if (condition_tense['primary_tense'] == 'present' and 
            any(aux['type'] == 'future' for aux in result_tense['auxiliary_info'])):
            return 'first_conditional'
        
        # ç¬¬äºŒæ¡ä»¶æ–‡ï¼ˆéå»å½¢ + wouldï¼‰
        elif (condition_tense['primary_tense'] == 'past' and 
              any(aux['lemma'] == 'would' for aux in result_tense['auxiliary_info'])):
            return 'second_conditional'
        
        # ç¬¬ä¸‰æ¡ä»¶æ–‡ï¼ˆéå»å®Œäº† + would haveï¼‰
        elif (any(aux['type'] == 'perfect' for aux in condition_tense['auxiliary_info']) and
              any(aux['lemma'] == 'would' for aux in result_tense['auxiliary_info']) and
              any(aux['type'] == 'perfect' for aux in result_tense['auxiliary_info'])):
            return 'third_conditional'
        
        # ã‚¼ãƒ­æ¡ä»¶æ–‡ï¼ˆç¾åœ¨å½¢ + ç¾åœ¨å½¢ï¼‰
        elif (condition_tense['primary_tense'] == 'present' and 
              result_tense['primary_tense'] == 'present'):
            return 'zero_conditional'
        
        else:
            return 'mixed_conditional'
    
    def _analyze_conditional_structure_detail(self, marker: Dict[str, Any], doc) -> Optional[Dict[str, Any]]:
        """æ¡ä»¶æ–‡æ§‹é€ ã®è©³ç´°è§£æ"""
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_individual_confidence(marker)
        
        if confidence < 0.4:  # ä½ä¿¡é ¼åº¦ã¯é™¤å¤–
            return None
        
        return {
            'marker': {
                'text': marker['marker_token'].text,
                'index': marker['marker_token'].i,
                'pattern_type': marker['pattern_type']
            },
            'condition_clause': marker['condition_clause'],
            'result_clause': marker['result_clause'],
            'conditional_type': marker['conditional_type'],
            'confidence': confidence
        }
    
    def _calculate_individual_confidence(self, marker: Dict[str, Any]) -> float:
        """å€‹åˆ¥æ¡ä»¶æ–‡ã®ä¿¡é ¼åº¦è¨ˆç®—"""
        base_confidence = 0.5
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã®ä¿¡é ¼åº¦
        base_confidence += 0.2 * marker['confidence_weight']
        
        # æ¡ä»¶ç¯€ã®å­˜åœ¨
        if marker['condition_clause']:
            base_confidence += 0.2
        
        # çµæœç¯€ã®å­˜åœ¨
        if marker['result_clause']:
            base_confidence += 0.2
        
        # æ¡ä»¶æ–‡ã‚¿ã‚¤ãƒ—ã®æ˜ç¢ºã•
        if marker['conditional_type'] != 'mixed_conditional':
            base_confidence += 0.1
        
        return min(1.0, base_confidence)
    
    def _calculate_conditional_confidence(self, analyzed_conditionals: List[Dict[str, Any]]) -> float:
        """å…¨ä½“ã®æ¡ä»¶æ–‡è§£æä¿¡é ¼åº¦"""
        if not analyzed_conditionals:
            return 0.0
        
        total_confidence = sum(cond['confidence'] for cond in analyzed_conditionals)
        return min(1.0, total_confidence / len(analyzed_conditionals))


class ConditionalHandlerClean:
    """
    æ¡ä»¶æ–‡å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆ
    
    ç‰¹å¾´:
    - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
    - æ±ç”¨çš„æ¡ä»¶æ–‡æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    - å‹•çš„æ™‚åˆ¶åˆ†æ
    - å®Œå…¨ãªæ‹¡å¼µæ€§
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–"""
        self.nlp = spacy.load('en_core_web_sm')
        self.config = self._load_configuration(config_path)
        self.analyzer = GenericConditionalAnalyzer(self.config)
        
        # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æƒ…å ±
        self.handler_info = {
            'name': 'ConditionalHandlerClean',
            'version': 'clean_v1.0',
            'hardcoding_level': 'zero'
        }
    
    def _load_configuration(self, config_path: Optional[str]) -> ConditionalConfiguration:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
                return self._parse_config_data(config_data)
        else:
            return self._create_default_configuration()
    
    def _create_default_configuration(self) -> ConditionalConfiguration:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ"""
        return ConditionalConfiguration(
            conditional_patterns={
                'if_conditionals': ConditionalPattern(
                    pattern_type='if_conditional',
                    condition_markers=['if', 'unless', 'provided', 'supposing'],
                    pos_patterns=['SCONJ', 'ADP'],
                    dependency_patterns=['mark', 'prep'],
                    conditional_types=['first', 'second', 'third', 'zero'],
                    confidence_weight=1.2
                ),
                'time_conditionals': ConditionalPattern(
                    pattern_type='time_conditional',
                    condition_markers=['when', 'whenever', 'as soon as', 'once'],
                    pos_patterns=['SCONJ', 'ADV'],
                    dependency_patterns=['mark', 'advmod'],
                    conditional_types=['temporal'],
                    confidence_weight=1.0
                )
            },
            confidence_settings={
                'minimum_confidence': 0.4,
                'high_confidence': 0.8,
                'conditional_bonus': 0.2
            }
        )
    
    def _parse_config_data(self, config_data: Dict) -> ConditionalConfiguration:
        """è¨­å®šãƒ‡ãƒ¼ã‚¿ã®è§£æ"""
        conditional_patterns = {}
        for name, data in config_data.get('conditional_patterns', {}).items():
            conditional_patterns[name] = ConditionalPattern(
                pattern_type=data.get('pattern_type', name),
                condition_markers=data.get('condition_markers', []),
                result_markers=data.get('result_markers', []),
                pos_patterns=data.get('pos_patterns', []),
                dependency_patterns=data.get('dependency_patterns', []),
                conditional_types=data.get('conditional_types', []),
                confidence_weight=data.get('confidence_weight', 1.0)
            )
        
        return ConditionalConfiguration(
            conditional_patterns=conditional_patterns,
            confidence_settings=config_data.get('confidence_settings', {})
        )
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        æ¡ä»¶æ–‡å‡¦ç†ãƒ¡ã‚¤ãƒ³ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã—ç‰ˆ
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: å‡¦ç†çµæœï¼ˆsuccess, conditionals, separated_clauses, confidenceï¼‰
        """
        try:
            # spaCyè§£æ
            doc = self.nlp(text)
            
            # æ¡ä»¶æ–‡è§£æ
            analysis_result = self.analyzer.analyze_conditional_structure(doc)
            
            if not analysis_result['conditionals']:
                return self._create_no_conditionals_result(text)
            
            # ç¯€åˆ†é›¢ã®å®Ÿè¡Œ
            separated_clauses = self._separate_clauses(analysis_result['conditionals'])
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰
            sub_slots = self._build_sub_slots(analysis_result['conditionals'])
            
            return {
                'success': True,
                'original_text': text,
                'conditionals': analysis_result['conditionals'],
                'separated_clauses': separated_clauses,
                'sub_slots': sub_slots,
                'confidence': analysis_result['confidence'],
                'metadata': {
                    'handler': self.handler_info,
                    'analysis_method': analysis_result['analysis_method'],
                    'conditional_count': len(analysis_result['conditionals'])
                }
            }
            
        except Exception as e:
            return self._create_failure_result(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _create_no_conditionals_result(self, text: str) -> Dict[str, Any]:
        """æ¡ä»¶æ–‡ãªã—ã®çµæœä½œæˆ"""
        return {
            'success': True,
            'original_text': text,
            'conditionals': [],
            'separated_clauses': {'condition': '', 'result': ''},
            'sub_slots': {},
            'confidence': self.config.confidence_settings.get('minimum_confidence', 0.4),
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'no_conditionals_detected'
            }
        }
    
    def _separate_clauses(self, conditionals: List[Dict[str, Any]]) -> Dict[str, str]:
        """ç¯€ã®åˆ†é›¢"""
        if not conditionals:
            return {'condition': '', 'result': ''}
        
        # æœ€åˆã®æ¡ä»¶æ–‡ã‚’ä½¿ç”¨
        conditional = conditionals[0]
        
        condition_text = conditional['condition_clause']['text'] if conditional['condition_clause'] else ''
        result_text = conditional['result_clause']['text'] if conditional['result_clause'] else ''
        
        return {
            'condition': condition_text,
            'result': result_text
        }
    
    def _build_sub_slots(self, conditionals: List[Dict[str, Any]]) -> Dict[str, str]:
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ§‹ç¯‰"""
        sub_slots = {}
        
        for i, conditional in enumerate(conditionals):
            if conditional['condition_clause']:
                sub_slots[f"sub-cond{i+1}"] = conditional['condition_clause']['text']
            if conditional['result_clause']:
                sub_slots[f"sub-res{i+1}"] = conditional['result_clause']['text']
        
        return sub_slots
    
    def _create_failure_result(self, error_message: str) -> Dict[str, Any]:
        """å¤±æ•—çµæœã®ä½œæˆ"""
        return {
            'success': False,
            'original_text': '',
            'conditionals': [],
            'separated_clauses': {'condition': '', 'result': ''},
            'sub_slots': {},
            'confidence': 0.0,
            'error': error_message,
            'metadata': {
                'handler': self.handler_info,
                'analysis_method': 'error_handling'
            }
        }


if __name__ == "__main__":
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é™¤å»ç‰ˆã®ãƒ†ã‚¹ãƒˆ
    handler = ConditionalHandlerClean()
    
    test_sentences = [
        "If it rains, we will stay home.",
        "If I were rich, I would travel the world.",
        "When you arrive, call me.",
        "Unless you study, you will fail."
    ]
    
    print("ğŸ§ª ConditionalHandler - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œå…¨é™¤å»ç‰ˆãƒ†ã‚¹ãƒˆ")
    print("=" * 65)
    
    for sentence in test_sentences:
        result = handler.process(sentence)
        print(f"\nå…¥åŠ›: \"{sentence}\"")
        print(f"æˆåŠŸ: {result['success']}")
        print(f"æ¡ä»¶æ–‡æ•°: {len(result.get('conditionals', []))}")
        print(f"ä¿¡é ¼åº¦: {result.get('confidence', 0):.3f}")
        if result.get('conditionals'):
            cond = result['conditionals'][0]
            print(f"ã‚¿ã‚¤ãƒ—: {cond.get('conditional_type', 'N/A')}")
        print(f"ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result.get('sub_slots', {})}")
        print(f"ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä½¿ç”¨: 0ä»¶ âœ…")
