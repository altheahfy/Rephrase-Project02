#!/usr/bin/env python3
"""
å¢ƒç•Œæ‹¡å¼µé‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ  v1.0
ãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³å”èª¿ã«ãŠã‘ã‚‹å¢ƒç•Œæ‹¡å¼µã®é‡è¤‡é˜²æ­¢ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

å•é¡Œ:
- 'The cat' â†’ 'The The The cat' ãªã©å¢ƒç•Œæ‹¡å¼µã«ã‚ˆã‚‹é‡è¤‡
- è¤‡æ•°ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆæ‹¡å¼µ
- ã‚¹ãƒ­ãƒƒãƒˆé–“ã®å¹²æ¸‰ã«ã‚ˆã‚‹å“è³ªåŠ£åŒ–

è§£æ±ºæ–¹æ³•:
1. é©ç”¨å±¥æ­´ç®¡ç†ã«ã‚ˆã‚‹é‡è¤‡æ¤œå‡º
2. æ‹¡å¼µçµæœã®æ­£è¦åŒ–
3. ã‚¨ãƒ³ã‚¸ãƒ³é–“èª¿æ•´ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
"""

import re
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class ExpansionRecord:
    """å¢ƒç•Œæ‹¡å¼µè¨˜éŒ²"""
    original_text: str
    expanded_text: str
    slot_type: str
    engine_name: str
    expansion_type: str
    timestamp: str

class DuplicationPreventionSystem:
    """å¢ƒç•Œæ‹¡å¼µé‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """é‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ›¡ï¸ å¢ƒç•Œæ‹¡å¼µé‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ  v1.0 èµ·å‹•ä¸­...")
        
        # é©ç”¨å±¥æ­´ç®¡ç†
        self.expansion_history: Dict[str, List[ExpansionRecord]] = defaultdict(list)
        self.applied_expansions: Set[str] = set()
        self.normalized_cache: Dict[str, str] = {}
        
        # é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºè¨­å®š
        self.duplication_patterns = [
            r'\b(\w+)\s+\1\s+\1\b',  # é€£ç¶š3å›é‡è¤‡ (the the the)
            r'\b(\w+)\s+\1\b',       # é€£ç¶š2å›é‡è¤‡ (the the)
            r'\b(a|an|the)\s+(a|an|the)\b',  # å† è©é‡è¤‡
            r'\b(is|are|was|were)\s+(is|are|was|were)\b',  # beå‹•è©é‡è¤‡
        ]
        
        # æ­£è¦åŒ–è¨­å®š
        self.normalization_rules = {
            'article_normalization': True,
            'whitespace_normalization': True,
            'case_normalization': False,
            'punctuation_normalization': True
        }
        
        print("âœ… é‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†")
    
    def prevent_expansion_duplication(self, text: str, slot_type: str, 
                                    engine_name: str, expansion_func) -> str:
        """
        å¢ƒç•Œæ‹¡å¼µé‡è¤‡é˜²æ­¢ãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        Args:
            text: å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            slot_type: ã‚¹ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒ—
            engine_name: ã‚¨ãƒ³ã‚¸ãƒ³å
            expansion_func: æ‹¡å¼µé–¢æ•°
            
        Returns:
            é‡è¤‡é˜²æ­¢ã•ã‚ŒãŸæ‹¡å¼µãƒ†ã‚­ã‚¹ãƒˆ
        """
        print(f"ğŸ” é‡è¤‡é˜²æ­¢å‡¦ç†é–‹å§‹: '{text}' [{slot_type}] by {engine_name}")
        
        # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        cache_key = f"{text}|{slot_type}|{engine_name}"
        if cache_key in self.normalized_cache:
            cached_result = self.normalized_cache[cache_key]
            print(f"ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: '{cached_result}'")
            return cached_result
        
        # 2. æ—¢å­˜é‡è¤‡æ¤œå‡º
        if self._has_existing_duplication(text):
            print(f"âš ï¸ æ—¢å­˜é‡è¤‡æ¤œå‡º: '{text}'")
            normalized = self._normalize_existing_duplication(text)
            print(f"ğŸ”§ æ­£è¦åŒ–çµæœ: '{normalized}'")
            text = normalized
        
        # 3. å¢ƒç•Œæ‹¡å¼µå®Ÿè¡Œ
        try:
            expanded_text = expansion_func(text)
            print(f"ğŸš€ æ‹¡å¼µå®Ÿè¡Œ: '{text}' â†’ '{expanded_text}'")
        except Exception as e:
            print(f"âŒ æ‹¡å¼µå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return text
        
        # 4. æ–°è¦é‡è¤‡æ¤œå‡ºãƒ»ä¿®æ­£
        if self._has_new_duplication(expanded_text, text):
            print(f"ğŸš¨ æ–°è¦é‡è¤‡æ¤œå‡º: '{expanded_text}'")
            corrected_text = self._correct_new_duplication(expanded_text, text)
            print(f"ğŸ”§ é‡è¤‡ä¿®æ­£: '{expanded_text}' â†’ '{corrected_text}'")
            expanded_text = corrected_text
        
        # 5. å±¥æ­´è¨˜éŒ²
        self._record_expansion(text, expanded_text, slot_type, engine_name)
        
        # 6. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        self.normalized_cache[cache_key] = expanded_text
        
        print(f"âœ… é‡è¤‡é˜²æ­¢å®Œäº†: '{expanded_text}'")
        return expanded_text
    
    def _has_existing_duplication(self, text: str) -> bool:
        """æ—¢å­˜é‡è¤‡åˆ¤å®š"""
        for pattern in self.duplication_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False
    
    def _normalize_existing_duplication(self, text: str) -> str:
        """æ—¢å­˜é‡è¤‡æ­£è¦åŒ–"""
        normalized = text
        
        # é€£ç¶šé‡è¤‡é™¤å»
        for pattern in self.duplication_patterns:
            if pattern == r'\b(\w+)\s+\1\s+\1\b':
                # 3å›é‡è¤‡ â†’ 1å›
                normalized = re.sub(pattern, r'\1', normalized, flags=re.IGNORECASE)
            elif pattern == r'\b(\w+)\s+\1\b':
                # 2å›é‡è¤‡ â†’ 1å›
                normalized = re.sub(pattern, r'\1', normalized, flags=re.IGNORECASE)
        
        # ç‰¹æ®Šã‚±ãƒ¼ã‚¹å‡¦ç†
        normalized = self._handle_special_duplications(normalized)
        
        return normalized.strip()
    
    def _has_new_duplication(self, expanded: str, original: str) -> bool:
        """æ–°è¦é‡è¤‡åˆ¤å®š"""
        # æ‹¡å¼µå‰å¾Œã§æ–°ãŸãªé‡è¤‡ãŒç™ºç”Ÿã—ãŸã‹
        original_duplications = sum(1 for p in self.duplication_patterns 
                                  if re.search(p, original, re.IGNORECASE))
        expanded_duplications = sum(1 for p in self.duplication_patterns 
                                  if re.search(p, expanded, re.IGNORECASE))
        
        return expanded_duplications > original_duplications
    
    def _correct_new_duplication(self, expanded: str, original: str) -> str:
        """æ–°è¦é‡è¤‡ä¿®æ­£"""
        corrected = expanded
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ä¿®æ­£
        for pattern in self.duplication_patterns:
            corrected = re.sub(pattern, r'\1', corrected, flags=re.IGNORECASE)
        
        # éå‰°ä¿®æ­£é˜²æ­¢: å…ƒãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’ä¿æŒ
        if self._is_over_corrected(corrected, original):
            print("âš ï¸ éå‰°ä¿®æ­£æ¤œå‡º - èª¿æ•´ä¸­...")
            corrected = self._adjust_over_correction(corrected, original, expanded)
        
        return corrected.strip()
    
    def _handle_special_duplications(self, text: str) -> str:
        """ç‰¹æ®Šé‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†"""
        special_cases = [
            # å† è©ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³
            (r'\bthe\s+the\s+(\w+)', r'the \1'),
            (r'\ba\s+a\s+(\w+)', r'a \1'),
            (r'\ban\s+an\s+(\w+)', r'an \1'),
            
            # å‹•è©ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³  
            (r'\bis\s+is\b', 'is'),
            (r'\bare\s+are\b', 'are'),
            (r'\bwas\s+was\b', 'was'),
            (r'\bwere\s+were\b', 'were'),
            
            # ä¿®é£¾èªé‡è¤‡
            (r'\bvery\s+very\b', 'very'),
            (r'\bquite\s+quite\b', 'quite'),
        ]
        
        normalized = text
        for pattern, replacement in special_cases:
            normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)
        
        return normalized
    
    def _is_over_corrected(self, corrected: str, original: str) -> bool:
        """éå‰°ä¿®æ­£åˆ¤å®š"""
        # é•·ã•ãŒå¤§å¹…ã«çŸ­ç¸®ã•ã‚ŒãŸå ´åˆ
        length_ratio = len(corrected) / max(len(original), 1)
        if length_ratio < 0.5:
            return True
        
        # é‡è¦èªå½™ãŒæ¶ˆå¤±ã—ãŸå ´åˆ
        original_words = set(original.lower().split())
        corrected_words = set(corrected.lower().split())
        lost_words = original_words - corrected_words
        
        important_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were'}
        lost_important = lost_words & important_words
        
        return len(lost_important) > len(original_words) * 0.3
    
    def _adjust_over_correction(self, corrected: str, original: str, expanded: str) -> str:
        """éå‰°ä¿®æ­£èª¿æ•´"""
        # ã‚ˆã‚Šä¿å®ˆçš„ãªä¿®æ­£ã‚’é©ç”¨
        words = expanded.split()
        adjusted_words = []
        previous_word = None
        
        for word in words:
            if previous_word and word.lower() == previous_word.lower():
                # é€£ç¶šã™ã‚‹åŒä¸€èªã®2ã¤ç›®ä»¥é™ã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue
            adjusted_words.append(word)
            previous_word = word
        
        return ' '.join(adjusted_words)
    
    def _record_expansion(self, original: str, expanded: str, slot_type: str, engine_name: str):
        """æ‹¡å¼µå±¥æ­´è¨˜éŒ²"""
        from datetime import datetime
        
        record = ExpansionRecord(
            original_text=original,
            expanded_text=expanded,
            slot_type=slot_type,
            engine_name=engine_name,
            expansion_type="boundary_expansion",
            timestamp=datetime.now().isoformat()
        )
        
        self.expansion_history[original].append(record)
        self.applied_expansions.add(f"{original}|{slot_type}|{engine_name}")
    
    def get_expansion_statistics(self) -> Dict:
        """æ‹¡å¼µçµ±è¨ˆæƒ…å ±å–å¾—"""
        total_expansions = sum(len(records) for records in self.expansion_history.values())
        unique_texts = len(self.expansion_history)
        cache_hits = len(self.normalized_cache)
        
        engine_stats = defaultdict(int)
        slot_stats = defaultdict(int)
        
        for records in self.expansion_history.values():
            for record in records:
                engine_stats[record.engine_name] += 1
                slot_stats[record.slot_type] += 1
        
        return {
            'total_expansions': total_expansions,
            'unique_texts': unique_texts,
            'cache_hits': cache_hits,
            'engine_distribution': dict(engine_stats),
            'slot_distribution': dict(slot_stats)
        }
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self.normalized_cache.clear()
        print("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")
    
    def reset_history(self):
        """å±¥æ­´ãƒªã‚»ãƒƒãƒˆ"""
        self.expansion_history.clear()
        self.applied_expansions.clear()
        self.clear_cache()
        print("ğŸ”„ å±¥æ­´ãƒªã‚»ãƒƒãƒˆå®Œäº†")

# === ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼ç”¨é–¢æ•° ===

def test_duplication_prevention():
    """é‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    system = DuplicationPreventionSystem()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "input": "The the cat",
            "slot": "S",
            "engine": "Basic5Pattern",
            "description": "æ—¢å­˜é‡è¤‡ï¼ˆå† è©ï¼‰",
            "expected_improvement": True
        },
        {
            "input": "very very quickly",
            "slot": "M2", 
            "engine": "AdverbialModifier",
            "description": "æ—¢å­˜é‡è¤‡ï¼ˆå‰¯è©ï¼‰",
            "expected_improvement": True
        },
        {
            "input": "normal text",
            "slot": "O1",
            "engine": "Basic5Pattern",
            "description": "æ­£å¸¸ãƒ†ã‚­ã‚¹ãƒˆ",
            "expected_improvement": False
        },
        {
            "input": "is is running",
            "slot": "V",
            "engine": "VerbCluster",
            "description": "å‹•è©é‡è¤‡",
            "expected_improvement": True
        }
    ]
    
    print("ğŸ§ª é‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    def mock_expansion_func(text):
        # ãƒ¢ãƒƒã‚¯æ‹¡å¼µé–¢æ•°ï¼ˆé‡è¤‡ã‚’æ„å›³çš„ã«ç™ºç”Ÿï¼‰
        if "normal" in text:
            return text + " expanded"
        return text + " " + text.split()[0]  # æœ€åˆã®èªã‚’é‡è¤‡
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{i}. {case['description']}: '{case['input']}'")
        
        # é‡è¤‡é˜²æ­¢å‡¦ç†å®Ÿè¡Œ
        result = system.prevent_expansion_duplication(
            case['input'], 
            case['slot'], 
            case['engine'], 
            mock_expansion_func
        )
        
        print(f"   å…¥åŠ›: '{case['input']}'")
        print(f"   å‡ºåŠ›: '{result}'")
        
        # æ”¹å–„åˆ¤å®š
        improved = case['input'] != result and not system._has_existing_duplication(result)
        expected = case['expected_improvement']
        
        status = "âœ… æˆåŠŸ" if improved == expected else "âŒ å¤±æ•—"
        print(f"   çµæœ: {status}")
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    print(f"\nğŸ“Š æ‹¡å¼µçµ±è¨ˆæƒ…å ±:")
    stats = system.get_expansion_statistics()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\nâœ… é‡è¤‡é˜²æ­¢ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_duplication_prevention()
