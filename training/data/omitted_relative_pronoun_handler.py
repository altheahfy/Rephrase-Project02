#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœç•¥é–¢ä¿‚è©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (OmittedRelativePronounHandler)

çœç•¥ã•ã‚ŒãŸé–¢ä¿‚ä»£åè©ï¼ˆthat, which, whomç­‰ï¼‰ã‚’æ¤œå‡ºã—ã€
é©åˆ‡ã«å¾©å…ƒã—ã¦æ–‡æ³•æ§‹é€ ã‚’åˆ†è§£ã™ã‚‹å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼

Examples:
- "The book I read was interesting." â†’ "The book [that] I read"
- "The man I met yesterday was kind." â†’ "The man [whom] I met"
"""

import spacy
import re
from typing import Dict, List, Any, Optional, Tuple

class OmittedRelativePronounHandler:
    """çœç•¥é–¢ä¿‚è©æ§‹é€ å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        try:
            self.nlp = spacy.load('en_core_web_sm')
        except OSError:
            print("âš ï¸ spaCyè‹±èªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            self.nlp = None
        
        # çœç•¥é–¢ä¿‚è©ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå…ˆè¡Œè© + ä¸»èª + å‹•è©ï¼‰
        self.omitted_patterns = [
            # åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³: The + åè© + ä»£åè© + å‹•è©
            r'\b(The\s+\w+)\s+(I|you|he|she|it|we|they)\s+(\w+)',
            # è¤‡æ•°å½¢ãƒ‘ã‚¿ãƒ¼ãƒ³
            r'\b(The\s+\w+)\s+(I|you|he|she|it|we|they)\s+(\w+(?:ed|s)?)',
            # ä¸€èˆ¬åè©ãƒ‘ã‚¿ãƒ¼ãƒ³
            r'\b([A-Z]\w*(?:\s+\w+)*)\s+(I|you|he|she|it|we|they)\s+(\w+)'
        ]
    
    def can_handle(self, text: str) -> bool:
        """çœç•¥é–¢ä¿‚è©æ§‹é€ ã®æ¤œå‡º"""
        if not self.nlp:
            return False
            
        # åŸºæœ¬çš„ãªçœç•¥é–¢ä¿‚è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        for pattern in self.omitted_patterns:
            if re.search(pattern, text):
                print(f"ğŸ” çœç•¥é–¢ä¿‚è©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: {pattern}")
                return True
        
        # spaCyã«ã‚ˆã‚‹è©³ç´°åˆ†æ
        if self._has_omitted_relative_structure(text):
            print(f"ğŸ” spaCyåˆ†æã«ã‚ˆã‚‹çœç•¥é–¢ä¿‚è©æ¤œå‡º: {text}")
            return True
            
        return False
    
    def _has_omitted_relative_structure(self, text: str) -> bool:
        """spaCyã‚’ä½¿ç”¨ã—ãŸçœç•¥é–¢ä¿‚è©æ§‹é€ ã®æ¤œå‡º"""
        try:
            doc = self.nlp(text)
            
            # ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã™å ´åˆã€çœç•¥é–¢ä¿‚è©ã¨åˆ¤å®š
            # 1. æ˜ç¤ºçš„ãªé–¢ä¿‚ä»£åè©ãŒãªã„
            # 2. è¤‡æ•°ã®å‹•è©ãŒã‚ã‚‹
            # 3. å…ˆè¡Œè©ã¨ãªã‚‹åè©ãŒã‚ã‚‹
            
            relative_pronouns = ['who', 'which', 'that', 'whom', 'whose']
            has_explicit_relative = any(token.text.lower() in relative_pronouns for token in doc)
            
            if has_explicit_relative:
                return False  # æ˜ç¤ºçš„ãªé–¢ä¿‚è©ãŒã‚ã‚‹å ´åˆã¯å¯¾è±¡å¤–
            
            # å‹•è©ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            verbs = [token for token in doc if token.pos_ in ['VERB', 'AUX'] and token.dep_ != 'aux']
            
            # ä¸»èªã®å€™è£œã‚’ãƒã‚§ãƒƒã‚¯
            subjects = [token for token in doc if token.dep_ in ['nsubj', 'nsubjpass']]
            
            # è¤‡æ•°ã®å‹•è©ã¨ä¸»èªãŒã‚ã‚‹å ´åˆã€çœç•¥é–¢ä¿‚è©ã®å¯èƒ½æ€§
            if len(verbs) >= 2 and len(subjects) >= 1:
                print(f"  ğŸ“Š å‹•è©æ•°: {len(verbs)}, ä¸»èªæ•°: {len(subjects)}")
                return True
                
        except Exception as e:
            print(f"âš ï¸ spaCyåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            
        return False
    
    def handle(self, text: str) -> Dict[str, Any]:
        """çœç•¥é–¢ä¿‚è©æ§‹é€ ã®åˆ†è§£å‡¦ç†"""
        try:
            print(f"ğŸš€ çœç•¥é–¢ä¿‚è©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–‹å§‹: '{text}'")
            
            # spaCyè§£æ
            if not self.nlp:
                return self._create_error_result(text, "spaCyãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            
            doc = self.nlp(text)
            self._print_dependency_analysis(doc)
            
            # çœç•¥é–¢ä¿‚è©ã®å¾©å…ƒã¨åˆ†è§£
            restoration_result = self._restore_omitted_relative(text, doc)
            if not restoration_result['success']:
                return restoration_result
            
            # ä¸»ç¯€ã¨é–¢ä¿‚ç¯€ã®åˆ†é›¢
            separation_result = self._separate_main_and_relative_clauses(
                text, doc, restoration_result['restored_relative']
            )
            
            if not separation_result['success']:
                return separation_result
            
            # æœ€çµ‚çµæœã®æ§‹ç¯‰
            result = self._build_final_result(text, separation_result)
            print(f"âœ… çœç•¥é–¢ä¿‚è©å‡¦ç†å®Œäº†: {result}")
            
            return result
            
        except Exception as e:
            print(f"âŒ çœç•¥é–¢ä¿‚è©å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_error_result(text, str(e))
    
    def _restore_omitted_relative(self, text: str, doc) -> Dict[str, Any]:
        """çœç•¥ã•ã‚ŒãŸé–¢ä¿‚ä»£åè©ã®å¾©å…ƒ"""
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹å¾©å…ƒ
            for pattern in self.omitted_patterns:
                match = re.search(pattern, text)
                if match:
                    antecedent = match.group(1)  # å…ˆè¡Œè©
                    subject = match.group(2)     # é–¢ä¿‚ç¯€å†…ä¸»èª
                    verb = match.group(3)        # é–¢ä¿‚ç¯€å†…å‹•è©
                    
                    # äººç§°ã«å¿œã˜ãŸé–¢ä¿‚ä»£åè©ã®é¸æŠ
                    if 'person' in antecedent.lower() or 'man' in antecedent.lower() or 'woman' in antecedent.lower():
                        relative_pronoun = 'whom' if self._is_object_position(text, antecedent) else 'who'
                    else:
                        relative_pronoun = 'that'
                    
                    restored = f"{antecedent} [{relative_pronoun}]"
                    
                    print(f"ğŸ”§ é–¢ä¿‚è©å¾©å…ƒ: '{antecedent}' â†’ '{restored}'")
                    
                    return {
                        'success': True,
                        'restored_relative': restored,
                        'antecedent': antecedent,
                        'relative_pronoun': relative_pronoun,
                        'relative_subject': subject,
                        'relative_verb': verb
                    }
            
            return {
                'success': False,
                'error': 'çœç•¥é–¢ä¿‚è©ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'é–¢ä¿‚è©å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}'
            }
    
    def _is_object_position(self, text: str, antecedent: str) -> bool:
        """å…ˆè¡Œè©ãŒé–¢ä¿‚ç¯€å†…ã§ç›®çš„èªã®ä½ç½®ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # ç°¡æ˜“çš„ãªåˆ¤å®š: é–¢ä¿‚ç¯€å†…ã«ä»–ã®ç›®çš„èªãŒã‚ã‚‹å ´åˆã€å…ˆè¡Œè©ã¯ç›®çš„èªä½ç½®
        pattern = antecedent + r'\s+\w+\s+\w+\s+\w+'  # å…ˆè¡Œè© + ä¸»èª + å‹•è© + ãã®ä»–
        if re.search(pattern, text):
            return True
        return False
    
    def _separate_main_and_relative_clauses(self, text: str, doc, restored_relative: str) -> Dict[str, Any]:
        """ä¸»ç¯€ã¨é–¢ä¿‚ç¯€ã®åˆ†é›¢"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸»ç¯€ã¨é–¢ä¿‚ç¯€ã«åˆ†é›¢
            verbs = [token for token in doc if token.pos_ in ['VERB', 'AUX'] and token.dep_ != 'aux']
            
            if len(verbs) < 2:
                return {
                    'success': False,
                    'error': 'ä¸»ç¯€ãƒ»é–¢ä¿‚ç¯€ã®åˆ†é›¢ã«å¿…è¦ãªå‹•è©ãŒä¸è¶³'
                }
            
            # æœ€åˆã®å‹•è©ã‚’é–¢ä¿‚ç¯€ã€æœ€å¾Œã®å‹•è©ã‚’ä¸»ç¯€ã¨ã—ã¦åˆ†é¡
            relative_verb = verbs[0]
            main_verb = verbs[-1]
            
            # é–¢ä¿‚ç¯€ã®æ§‹æˆè¦ç´ ã‚’æŠ½å‡º
            relative_elements = self._extract_relative_elements(doc, relative_verb, restored_relative)
            
            # ä¸»ç¯€ã®æ§‹æˆè¦ç´ ã‚’æŠ½å‡º
            main_elements = self._extract_main_elements(doc, main_verb)
            
            return {
                'success': True,
                'main_elements': main_elements,
                'relative_elements': relative_elements,
                'main_verb': main_verb.text,
                'relative_verb': relative_verb.text
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ç¯€åˆ†é›¢ã‚¨ãƒ©ãƒ¼: {e}'
            }
    
    def _extract_relative_elements(self, doc, relative_verb, restored_relative: str) -> Dict[str, str]:
        """é–¢ä¿‚ç¯€è¦ç´ ã®æŠ½å‡º"""
        elements = {}
        
        # é–¢ä¿‚ç¯€ã®ä¸»èªã‚’æ¤œå‡º
        for token in doc:
            if token.head == relative_verb and token.dep_ == 'nsubj':
                elements['sub-s'] = token.text
                break
        
        # é–¢ä¿‚ç¯€ã®å‹•è©
        elements['sub-v'] = relative_verb.text
        
        # é–¢ä¿‚ç¯€ã®ç›®çš„èªãƒ»ä¿®é£¾èªã‚’æ¤œå‡º
        for child in relative_verb.children:
            if child.dep_ == 'dobj':
                # ç›´æ¥ç›®çš„èªã®ä½ç½®ã«å¿œã˜ã¦ã‚¹ãƒ­ãƒƒãƒˆæ±ºå®š
                if restored_relative.endswith('[that]') or restored_relative.endswith('[which]'):
                    elements['sub-o1'] = child.text
                else:
                    elements['sub-o2'] = restored_relative
                    elements['sub-o1'] = child.text
            elif child.dep_ == 'iobj':
                elements['sub-o1'] = child.text
            elif child.dep_ in ['prep', 'advmod', 'npadvmod']:
                # ä¿®é£¾èªå¥ã‚’å®Œå…¨ã«æŠ½å‡ºï¼ˆä¾å­˜èªã‚‚å«ã‚ã‚‹ï¼‰
                modifier_text = self._extract_complete_phrase(child)
                if 'sub-m2' not in elements:
                    elements['sub-m2'] = modifier_text
                else:
                    elements['sub-m3'] = modifier_text
        
        # å…ˆè¡Œè©ã‚’é©åˆ‡ãªã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®
        if 'sub-o1' not in elements:
            elements['sub-o1'] = restored_relative
        elif 'sub-o2' not in elements:
            elements['sub-o2'] = restored_relative
        
        elements['_parent_slot'] = 'S'
        
        return elements
    
    def _extract_complete_phrase(self, token) -> str:
        """ãƒˆãƒ¼ã‚¯ãƒ³ã¨ãã®ä¾å­˜èªã‚’å«ã‚€å®Œå…¨ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡º"""
        # å½¢å®¹è©ä¿®é£¾èªã‚„ãã®ä»–ã®ä¿®é£¾èªã‚’å«ã‚ã¦å®Œå…¨ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ§‹ç¯‰
        phrase_tokens = []
        
        # ä¿®é£¾èªã‚’åé›†ï¼ˆleft childrenï¼‰
        for child in token.lefts:
            if child.dep_ in ['amod', 'det', 'advmod', 'compound']:
                phrase_tokens.append(child.text)
        
        # ãƒ¡ã‚¤ãƒ³ã®ãƒˆãƒ¼ã‚¯ãƒ³
        phrase_tokens.append(token.text)
        
        # å¾Œç½®ä¿®é£¾èªã‚’åé›†ï¼ˆright childrenï¼‰
        for child in token.rights:
            if child.dep_ in ['compound', 'prep', 'advmod']:
                phrase_tokens.append(child.text)
        
        return ' '.join(phrase_tokens) if phrase_tokens else token.text
    
    def _extract_main_elements(self, doc, main_verb) -> Dict[str, str]:
        """ä¸»ç¯€è¦ç´ ã®æŠ½å‡º"""
        elements = {}
        
        # ä¸»ç¯€ã®å‹•è©
        elements['V'] = main_verb.text
        
        # ä¸»èªã¯ç©ºï¼ˆé–¢ä¿‚ç¯€ã«å«ã¾ã‚Œã‚‹ãŸã‚ï¼‰
        elements['S'] = ''
        
        # ä¸»ç¯€ã®è£œèªãƒ»ç›®çš„èªãƒ»ä¿®é£¾èªã‚’æ¤œå‡º
        for child in main_verb.children:
            if child.dep_ in ['attr', 'acomp', 'oprd']:  # oprdã‚’è¿½åŠ 
                elements['C1'] = child.text
            elif child.dep_ == 'dobj' and 'O1' not in elements:
                elements['O1'] = child.text
            elif child.dep_ == 'iobj':
                elements['O1'] = child.text
            elif child.dep_ in ['prep', 'advmod', 'npadvmod']:
                if 'M2' not in elements:
                    elements['M2'] = child.text
                else:
                    elements['M3'] = child.text
            elif child.dep_ == 'aux':
                if 'Aux' not in elements:
                    elements['Aux'] = child.text
        
        return elements
    
    def _build_final_result(self, text: str, separation_result: Dict) -> Dict[str, Any]:
        """æœ€çµ‚çµæœã®æ§‹ç¯‰"""
        return {
            'success': True,
            'text': text,
            'main_slots': separation_result['main_elements'],
            'sub_slots': separation_result['relative_elements'],
            'metadata': {
                'handler': 'omitted_relative_pronoun',
                'relative_verb': separation_result['relative_verb'],
                'main_verb': separation_result['main_verb'],
                'confidence': 0.85
            }
        }
    
    def _create_error_result(self, text: str, error_message: str) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼çµæœã®ä½œæˆ"""
        return {
            'success': False,
            'text': text,
            'error': error_message,
            'handler': 'omitted_relative_pronoun'
        }
    
    def _print_dependency_analysis(self, doc):
        """ä¾å­˜é–¢ä¿‚åˆ†æã®è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        print("ğŸ” spaCyä¾å­˜é–¢ä¿‚åˆ†æ:")
        for token in doc:
            print(f"   {token.text}: dep={token.dep_}, pos={token.pos_}, tag={token.tag_}")


def test_omitted_relative_pronoun_handler():
    """çœç•¥é–¢ä¿‚è©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª çœç•¥é–¢ä¿‚è©ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    handler = OmittedRelativePronounHandler()
    
    test_sentences = [
        "The book I read was interesting.",
        "The man I met yesterday was kind.",
        "The car she drives looks expensive.",
        "The movie we watched last night was amazing.",
        "The gift he bought her was expensive."
    ]
    
    for i, sentence in enumerate(test_sentences, 1):
        print(f"\nã€ãƒ†ã‚¹ãƒˆ {i}ã€‘: {sentence}")
        
        # æ¤œå‡ºãƒ†ã‚¹ãƒˆ
        can_handle = handler.can_handle(sentence)
        print(f"  æ¤œå‡ºçµæœ: {can_handle}")
        
        if can_handle:
            # å‡¦ç†ãƒ†ã‚¹ãƒˆ
            result = handler.handle(sentence)
            print(f"  å‡¦ç†çµæœ: {result.get('success', False)}")
            
            if result.get('success'):
                print(f"  ä¸»ç¯€: {result['main_slots']}")
                print(f"  é–¢ä¿‚ç¯€: {result['sub_slots']}")
            else:
                print(f"  ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown error')}")
        
        print("-" * 30)


if __name__ == "__main__":
    test_omitted_relative_pronoun_handler()
