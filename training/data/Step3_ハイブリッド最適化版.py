# Step 3: æœ€é©åŒ–çµ±åˆç‰ˆ - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³

import sys
import os
sys.path.append(os.path.dirname(__file__))

from Rephrase_Parsing_Engine import RephraseParsingEngine

class HybridOptimizedEngine(RephraseParsingEngine):
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ - å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ« + spaCy"""
    
    def __init__(self):
        super().__init__()
        self.engine_name = "Rephrase Hybrid Engine v3.0 (Optimized)"
        
        # spaCyåˆæœŸåŒ–ï¼ˆè­¦å‘ŠæŠ‘åˆ¶ï¼‰
        try:
            import warnings
            warnings.filterwarnings("ignore")
            import spacy
            self.nlp = spacy.load("en_core_web_sm")
            self.spacy_available = True
            print("âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ spaCyåˆæœŸåŒ–å¤±æ•—: {e}")
            print("   å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«å°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œ")
            self.spacy_available = False
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'morphology_success': 0,
            'spacy_success': 0,
            'fallback_used': 0,
            'total_analyzed': 0
        }
    
    def analyze_word_hybrid(self, word, context=""):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æ: å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«å„ªå…ˆ â†’ spaCyè£œå®Œ"""
        self.stats['total_analyzed'] += 1
        
        # Step 1: å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«è§£æ
        morph_result = self.analyze_word_morphology(word, context)
        
        # å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«ã§ç¢ºå®Ÿã«åˆ¤å®šã§ããŸå ´åˆ
        if (morph_result['pos'] not in ['UNKNOWN', 'VERB_3SG_OR_NOUN_PLURAL', 'NOUN_OR_ADJ']
            and morph_result['confidence'] > 0.8):
            self.stats['morphology_success'] += 1
            morph_result['method'] = 'morphology_primary'
            return morph_result
        
        # Step 2: spaCyè£œå®Œè§£æ
        if self.spacy_available:
            try:
                # æ–‡è„ˆè§£æ
                if context and word in context:
                    doc = self.nlp(context)
                    for token in doc:
                        if token.text.lower() == word.lower():
                            self.stats['spacy_success'] += 1
                            return {
                                'word': word,
                                'pos': token.pos_,
                                'tag': token.tag_,
                                'lemma': token.lemma_,
                                'confidence': 0.95,
                                'method': 'spacy_context'
                            }
                
                # å˜ç‹¬è§£æ
                doc = self.nlp(word)
                if doc:
                    token = doc[0]
                    self.stats['spacy_success'] += 1
                    return {
                        'word': word,
                        'pos': token.pos_,
                        'tag': token.tag_,
                        'lemma': token.lemma_,
                        'confidence': 0.90,
                        'method': 'spacy_single'
                    }
            except:
                pass
        
        # Step 3: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«çµæœï¼‰
        self.stats['fallback_used'] += 1
        morph_result['method'] = 'morphology_fallback'
        return morph_result
    
    def analyze_sentence_hybrid(self, sentence):
        """æ–‡å…¨ä½“ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æ"""
        words = sentence.replace('.', '').replace(',', '').split()
        results = []
        
        for word in words:
            result = self.analyze_word_hybrid(word, sentence)
            results.append(result)
        
        return results
    
    def performance_test(self, test_sentences):
        """æ€§èƒ½ãƒ†ã‚¹ãƒˆã¨çµ±è¨ˆè¡¨ç¤º"""
        print(f"=== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³æ€§èƒ½ãƒ†ã‚¹ãƒˆ ===\n")
        
        all_results = []
        
        for i, sentence in enumerate(test_sentences, 1):
            print(f"ğŸ“ ãƒ†ã‚¹ãƒˆ {i}: {sentence}")
            results = self.analyze_sentence_hybrid(sentence)
            all_results.extend(results)
            
            # èªå½™åˆ¥è©³ç´°è¡¨ç¤º
            print(f"{'Word':15} {'POS':12} {'Method':20} {'Confidence':12}")
            print("-" * 65)
            for result in results:
                conf_str = f"{result['confidence']:.2f}"
                print(f"{result['word']:15} {result['pos']:12} {result['method']:20} {conf_str:12}")
            print()
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        total = self.stats['total_analyzed']
        morphology_rate = (self.stats['morphology_success'] / total) * 100
        spacy_rate = (self.stats['spacy_success'] / total) * 100  
        fallback_rate = (self.stats['fallback_used'] / total) * 100
        
        print(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ:")
        print(f"  å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ«æˆåŠŸ: {self.stats['morphology_success']}/{total} ({morphology_rate:.1f}%)")
        print(f"  spaCyè£œå®ŒæˆåŠŸ:    {self.stats['spacy_success']}/{total} ({spacy_rate:.1f}%)")
        print(f"  ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:   {self.stats['fallback_used']}/{total} ({fallback_rate:.1f}%)")
        print(f"  ç·åˆèªè­˜ç‡:       {total - self.stats['fallback_used']}/{total} ({100 - fallback_rate:.1f}%)")
        
        # è§£æå“è³ªè©•ä¾¡
        recognized_words = [r for r in all_results if r['pos'] != 'UNKNOWN']
        recognition_rate = (len(recognized_words) / len(all_results)) * 100
        
        print(f"\nğŸ¯ èªå½™èªè­˜å“è³ª:")
        print(f"  èªè­˜æˆåŠŸ:         {len(recognized_words)}/{len(all_results)} ({recognition_rate:.1f}%)")
        print(f"  æœªèªè­˜èªå½™:       {len(all_results) - len(recognized_words)}")
        
        return {
            'total_words': len(all_results),
            'recognized_words': len(recognized_words),
            'recognition_rate': recognition_rate,
            'stats': self.stats
        }

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    print("=== Step 3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ ===\n")
    
    engine = HybridOptimizedEngine()
    
    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ
    test_sentences = [
        "The sophisticated analysis is comprehensive.",
        "She efficiently investigated the mysterious disappearance.",
        "Students frequently encounter challenging mathematical equations.",
        "Innovative technologies revolutionize traditional methodologies.",
        "The remarkable achievement demonstrates exceptional capabilities."
    ]
    
    # æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = engine.performance_test(test_sentences)
    
    print(f"\nğŸ† Step 3 æœ€çµ‚çµæœ:")
    print(f"  âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…å®Œäº†")
    print(f"  ğŸ¯ èªå½™èªè­˜ç‡: {results['recognition_rate']:.1f}%")
    print(f"  âš¡ å‡¦ç†èªå½™æ•°: {results['total_words']} èª")
    print(f"  ğŸ”§ æœ€é©åŒ–æ‰‹æ³•ä½µç”¨: å½¢æ…‹ç´ ãƒ«ãƒ¼ãƒ« + spaCy")
    
    # 16,000ä¾‹æ–‡å¯¾å¿œå¯èƒ½æ€§ã®è©•ä¾¡
    if results['recognition_rate'] >= 90:
        print(f"  ğŸŒŸ 16,000ä¾‹æ–‡å‡¦ç†: æº–å‚™å®Œäº† (èªè­˜ç‡{results['recognition_rate']:.1f}%)")
    else:
        print(f"  ğŸ”„ 16,000ä¾‹æ–‡å‡¦ç†: è¿½åŠ èª¿æ•´æ¨å¥¨ (ç¾åœ¨{results['recognition_rate']:.1f}%)")
