"""
æ®µéšåˆ†é›¢å‡¦ç†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¤œè¨¼
1. ç¯€å¢ƒç•Œã®æ¤œå‡ºèƒ½åŠ›ç¢ºèª
2. ç¯€ã‚¿ã‚¤ãƒ—åˆ†é¡ã®ç²¾åº¦ç¢ºèª  
3. ç‹¬ç«‹å‡¦ç†å¾Œã®çµ±åˆå¯èƒ½æ€§ç¢ºèª
"""
import sys
sys.path.append('.')
from hierarchical_grammar_detector_v4 import HierarchicalGrammarDetectorV4
import stanza
import spacy

def test_clause_boundary_detection():
    """Stanzaã¨spaCyã§ã®ç¯€å¢ƒç•Œæ¤œå‡ºèƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ” Clause Boundary Detection Analysis")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆæ–‡
    test_sentence = "Having finished the project, the student submitted it confidently."
    print(f"Target: {test_sentence}")
    print()
    
    # Stanzaè§£æ
    print("ğŸ“Š Stanza Analysis:")
    nlp_stanza = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse', verbose=False)
    stanza_doc = nlp_stanza(test_sentence)
    
    for i, sent in enumerate(stanza_doc.sentences):
        print(f"Sentence {i+1}:")
        for word in sent.words:
            print(f"  {word.text:<15} | {word.upos:<8} | Head: {word.head} ({sent.words[word.head-1].text if word.head > 0 else 'ROOT'}) | Dep: {word.deprel}")
    
    print()
    
    # spaCyè§£æ
    print("ğŸ“Š spaCy Analysis:")
    nlp_spacy = spacy.load('en_core_web_sm')
    spacy_doc = nlp_spacy(test_sentence)
    
    for token in spacy_doc:
        print(f"  {token.text:<15} | {token.pos_:<8} | Head: {token.head.text:<12} | Dep: {token.dep_:<12} | Children: {[child.text for child in token.children]}")
    
    print()
    
    # ç¯€å¢ƒç•Œã®è‡ªå‹•æ¤œå‡ºè©¦è¡Œ
    print("ğŸ¯ Automatic Clause Boundary Detection:")
    
    # Stanzaãƒ™ãƒ¼ã‚¹ã®ç¯€æ¤œå‡º
    stanza_clauses = []
    for sent in stanza_doc.sentences:
        main_verbs = []
        subordinate_clauses = []
        
        for word in sent.words:
            if word.upos == 'VERB' and word.deprel in ['root', 'advcl', 'ccomp', 'xcomp', 'acl', 'acl:relcl']:
                clause_info = {
                    'verb': word.text,
                    'position': word.id,
                    'deprel': word.deprel,
                    'clause_type': 'main' if word.deprel == 'root' else 'subordinate'
                }
                
                # ç¯€ã®ç¯„å›²ã‚’æ¨å®š
                clause_tokens = [word.text]
                for dep_word in sent.words:
                    if dep_word.head == word.id:
                        clause_tokens.append(dep_word.text)
                
                clause_info['tokens'] = clause_tokens
                clause_info['estimated_span'] = ' '.join(clause_tokens)
                
                if word.deprel == 'root':
                    main_verbs.append(clause_info)
                else:
                    subordinate_clauses.append(clause_info)
        
        stanza_clauses.append({
            'main_verbs': main_verbs,
            'subordinate_clauses': subordinate_clauses
        })
    
    for i, clause_analysis in enumerate(stanza_clauses):
        print(f"Clause Analysis {i+1}:")
        print(f"  Main clauses: {len(clause_analysis['main_verbs'])}")
        for j, main in enumerate(clause_analysis['main_verbs']):
            print(f"    Main {j+1}: {main['verb']} (deprel: {main['deprel']})")
            print(f"      Estimated span: {main['estimated_span']}")
        
        print(f"  Subordinate clauses: {len(clause_analysis['subordinate_clauses'])}")
        for j, sub in enumerate(clause_analysis['subordinate_clauses']):
            print(f"    Sub {j+1}: {sub['verb']} (deprel: {sub['deprel']})")
            print(f"      Estimated span: {sub['estimated_span']}")
    
    print()
    
    # æœŸå¾…ã•ã‚Œã‚‹å¢ƒç•Œã¨ã®æ¯”è¼ƒ
    print("ğŸ¯ Expected vs Detected Boundaries:")
    expected_boundaries = [
        {
            'clause': 'Having finished the project',
            'type': 'subordinate',
            'function': 'adverbial (participle)',
            'span': (0, 4)  # token positions
        },
        {
            'clause': 'the student submitted it confidently',
            'type': 'main',
            'function': 'main clause',
            'span': (5, 9)
        }
    ]
    
    for expected in expected_boundaries:
        print(f"Expected: '{expected['clause']}' ({expected['type']}, {expected['function']})")
    
    return stanza_clauses

def test_clause_type_classification():
    """ç¯€ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ç²¾åº¦ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("\n" + "=" * 60)
    print("ğŸ” Clause Type Classification Test")
    print("=" * 60)
    
    test_cases = [
        {
            "sentence": "Having finished the project, the student submitted it confidently.",
            "expected_clauses": [
                {"text": "Having finished the project", "type": "adverbial", "subtype": "participle"},
                {"text": "the student submitted it confidently", "type": "main", "subtype": "svo"}
            ]
        },
        {
            "sentence": "While she was reading, she discovered what made the story compelling.",
            "expected_clauses": [
                {"text": "While she was reading", "type": "adverbial", "subtype": "temporal"},
                {"text": "she discovered what made the story compelling", "type": "main", "subtype": "svo"},
                {"text": "what made the story compelling", "type": "noun_clause", "subtype": "object"}
            ]
        },
        {
            "sentence": "The book that he wrote became very popular.",
            "expected_clauses": [
                {"text": "The book became very popular", "type": "main", "subtype": "svc"},
                {"text": "that he wrote", "type": "relative", "subtype": "restrictive"}
            ]
        }
    ]
    
    detector = HierarchicalGrammarDetectorV4()
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"ğŸ“ Test Case {i}:")
        print(f"Sentence: {test_case['sentence']}")
        
        # ç¾åœ¨ã®æ¤œå‡ºçµæœ
        result = detector.detect_hierarchical_grammar(test_case['sentence'])
        
        print("Current Detection:")
        print(f"  Main: {result.main_clause.grammatical_pattern.value} - '{result.main_clause.text[:40]}...'")
        for j, sub in enumerate(result.subordinate_clauses, 1):
            print(f"  Sub {j}: {sub.grammatical_pattern.value} - '{sub.text[:40]}...'")
        
        print("Expected Clauses:")
        for j, expected in enumerate(test_case['expected_clauses'], 1):
            print(f"  Expected {j}: {expected['type']} ({expected['subtype']}) - '{expected['text']}'")
        
        print()
    
    return True

def propose_staged_processing_architecture():
    """æ®µéšå‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ææ¡ˆ"""
    
    print("\n" + "=" * 60)
    print("ğŸ—ï¸ Staged Processing Architecture Proposal")
    print("=" * 60)
    
    architecture = """
    ğŸ¯ ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
    
    Stage 1: Clause Boundary Detection
    â”œâ”€ Stanzaã¨spaCyã«ã‚ˆã‚‹ä¾å­˜æ§‹é€ è§£æ
    â”œâ”€ å‹•è©ã®ä¾å­˜é–¢ä¿‚ã‹ã‚‰clauseå¢ƒç•Œã‚’ç‰¹å®š
    â”œâ”€ å„ç¯€ã®é–‹å§‹ãƒ»çµ‚äº†ä½ç½®ã‚’æ±ºå®š
    â””â”€ ç¯€ã‚¿ã‚¤ãƒ—ã®ç²—åˆ†é¡ (main/subordinate/relative/noun_clause)
    
    Stage 2: Clause Function Classification  
    â”œâ”€ å„ç¯€ã®ä¸Šä½æ–‡æ§‹é€ ã§ã®æ©Ÿèƒ½ã‚’åˆ¤å®š
    â”œâ”€ å‰¯è©ç¯€/å½¢å®¹è©ç¯€/åè©ç¯€ã®ç´°åˆ†é¡
    â”œâ”€ ä¸»ç¯€ã®ä½ç½®æƒ…å ±ã®æ±ºå®š
    â””â”€ å…¥ã‚Œå­é–¢ä¿‚ã®éšå±¤ãƒãƒƒãƒ”ãƒ³ã‚°
    
    Stage 3: Individual Clause Pattern Recognition
    â”œâ”€ å„ç¯€ã‚’ç‹¬ç«‹ã—ãŸã€Œä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã€ã¨ã—ã¦æ‰±ã„
    â”œâ”€ æ—¢å­˜ã®é«˜ç²¾åº¦ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ã‚’é©ç”¨
    â”œâ”€ SV/SVO/SVC/SVOO/SVOCç­‰ã®è©³ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š
    â””â”€ å„ç¯€å†…éƒ¨ã§ã®æœ€é©ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ
    
    Stage 4: Results Integration
    â”œâ”€ Stage 2ã®éšå±¤æƒ…å ± + Stage 3ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±ã‚’çµ±åˆ
    â”œâ”€ Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã¸ã®å¤‰æ›
    â”œâ”€ ä¸»ç¯€ãƒ»å‰¯ç¯€ã®æœ€çµ‚çš„ãªçµ„ã¿åˆã‚ã›æ±ºå®š
    â””â”€ ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®çµ±åˆè¨ˆç®—
    """
    
    print(architecture)
    
    advantages = """
    ğŸ’¡ ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åˆ©ç‚¹:
    
    1. å•é¡Œã®åˆ†é›¢åŒ–
       â”œâ”€ ç¯€å¢ƒç•Œæ¤œå‡º (æ§‹é€ çš„å•é¡Œ)
       â”œâ”€ ç¯€æ©Ÿèƒ½åˆ†é¡ (æ„å‘³çš„å•é¡Œ)  
       â””â”€ ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ (èªæ³•çš„å•é¡Œ)
    
    2. æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®æ´»ç”¨
       â”œâ”€ 83.3%ã®é«˜ç²¾åº¦ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆåˆ¤å®šã‚’å†åˆ©ç”¨
       â”œâ”€ è¤‡é›‘æ€§ã‚’æ®µéšçš„ã«å‡¦ç†
       â””â”€ ãƒ‡ãƒãƒƒã‚°ãƒ»æ”¹å–„ãŒå®¹æ˜“
    
    3. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
       â”œâ”€ å„æ®µéšã‚’ç‹¬ç«‹ã—ã¦æ”¹å–„å¯èƒ½
       â”œâ”€ æ–°ã—ã„ç¯€ã‚¿ã‚¤ãƒ—ã®è¿½åŠ ãŒå®¹æ˜“
       â””â”€ ã‚¨ãƒ©ãƒ¼ã®å±€æ‰€åŒ–ãŒå¯èƒ½
    
    4. Rephraseè¨­è¨ˆã¨ã®æ•´åˆæ€§
       â”œâ”€ äºŒé‡å…¥ã‚Œå­åˆ¶é™ã®è‡ªç„¶ãªå®Ÿè£…
       â”œâ”€ ä¸Šä½ãƒ»ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã®æ˜ç¢ºãªåˆ†é›¢
       â””â”€ Type phraseã®æ§‹é€ ã¨ã®å¯¾å¿œ
    """
    
    print(advantages)
    
    implementation_plan = """
    ğŸ› ï¸ å®Ÿè£…è¨ˆç”»:
    
    Phase 1: ç¾çŠ¶èª¿æŸ» (æœ¬ãƒ†ã‚¹ãƒˆã§å®Ÿæ–½ä¸­)
    â”œâ”€ Stanza/spaCyã®ç¯€å¢ƒç•Œæ¤œå‡ºèƒ½åŠ›ç¢ºèª âœ…
    â”œâ”€ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆç‚¹ç¢ºèª 
    â””â”€ æŠ€è¡“çš„å®Ÿç¾æ€§ã®æ¤œè¨¼
    
    Phase 2: Stage 1ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
    â”œâ”€ ç¯€å¢ƒç•Œæ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…
    â”œâ”€ åŸºæœ¬çš„ãªç¯€ã‚¿ã‚¤ãƒ—åˆ†é¡
    â””â”€ å¢ƒç•Œæ¤œå‡ºç²¾åº¦ã®è©•ä¾¡
    
    Phase 3: Stage 2-3çµ±åˆ
    â”œâ”€ ç¯€æ©Ÿèƒ½åˆ†é¡å™¨ã®é–‹ç™º
    â”œâ”€ æ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®é©ç”¨
    â””â”€ å€‹åˆ¥å‡¦ç†çµæœã®çµ±åˆ
    
    Phase 4: æœ€é©åŒ–ã¨ãƒ†ã‚¹ãƒˆ
    â”œâ”€ å…¨ä½“çš„ãªç²¾åº¦æ”¹å–„
    â”œâ”€ Rephraseã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
    â””â”€ å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒãƒƒã‚°
    """
    
    print(implementation_plan)
    
    return True

if __name__ == "__main__":
    # Stage 1: ç¯€å¢ƒç•Œæ¤œå‡ºèƒ½åŠ›ã®ç¢ºèª
    clause_analysis = test_clause_boundary_detection()
    
    # Stage 2: ç¯€ã‚¿ã‚¤ãƒ—åˆ†é¡ã®ç¢ºèª
    classification_test = test_clause_type_classification()
    
    # Stage 3: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ææ¡ˆ
    architecture_proposal = propose_staged_processing_architecture()
