# Option 2: spaCy NLP ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ´»ç”¨
# ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆãƒ»å®Ÿè£…æ–¹æ³•ã®è©³ç´°

# spaCyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã®èª¬æ˜
print("=== spaCy NLP ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚‹èªå½™è§£æ±º ===\n")

print("ğŸ“¦ spaCyã¨ã¯:")
print("  - ç”£æ¥­ãƒ¬ãƒ™ãƒ«ã®è‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
print("  - 50ä¸‡èªä»¥ä¸Šã®èªå½™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…è”µ")
print("  - é«˜é€Ÿãªå“è©ã‚¿ã‚°ä»˜ã‘æ©Ÿèƒ½")
print("  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸è¦ï¼‰")

print("\nğŸ”§ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:")
print("  pip install spacy")
print("  python -m spacy download en_core_web_sm")
print("  ï¼ˆç´„50MBã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ï¼‰")

print("\n=== spaCyã®å®Ÿè£…ä¾‹ ===")

# å®Ÿè£…ä¾‹ã®ã‚³ãƒ¼ãƒ‰ï¼ˆspaCyãªã—ã§ã‚‚è¡¨ç¤ºï¼‰
implementation_code = '''
import spacy

class SpacyVocabularyEngine:
    def __init__(self):
        # è‹±èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        self.nlp = spacy.load("en_core_web_sm")
    
    def analyze_sentence(self, sentence):
        # spaCyã§è§£æ
        doc = self.nlp(sentence)
        
        # å„èªã®å“è©æƒ…å ±ã‚’å–å¾—
        word_analyses = []
        for token in doc:
            word_analyses.append({
                'word': token.text,
                'pos': token.pos_,           # åŸºæœ¬å“è©
                'tag': token.tag_,           # è©³ç´°å“è©
                'lemma': token.lemma_,       # èªå¹¹
                'is_verb': token.pos_ == 'VERB',
                'is_noun': token.pos_ == 'NOUN',
                'is_adj': token.pos_ == 'ADJ'
            })
        
        return word_analyses

# ä½¿ç”¨ä¾‹
engine = SpacyVocabularyEngine()
result = engine.analyze_sentence("She efficiently investigated the comprehensive analysis.")

for analysis in result:
    print(f"{analysis['word']}: {analysis['pos']} ({analysis['tag']})")
'''

print(implementation_code)

print("\n=== spaCyå‡¦ç†çµæœä¾‹ ===")
# spaCyãŒå®Ÿéš›ã«å‡ºåŠ›ã™ã‚‹çµæœä¾‹
example_results = [
    "She: PRON (PRP)",
    "efficiently: ADV (RB)", 
    "investigated: VERB (VBD)",
    "the: DET (DT)",
    "comprehensive: ADJ (JJ)",
    "analysis: NOUN (NN)"
]

for result in example_results:
    print(f"  {result}")

print(f"\n=== spaCyã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ ===")
print("âœ… ãƒ¡ãƒªãƒƒãƒˆ:")
print("  - é«˜ç²¾åº¦ã®å“è©åˆ¤å®šï¼ˆ95%ä»¥ä¸Šï¼‰")
print("  - é«˜é€Ÿå‡¦ç†ï¼ˆ1000æ–‡/ç§’ä»¥ä¸Šï¼‰")
print("  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œï¼ˆãƒãƒƒãƒˆæ¥ç¶šä¸è¦ï¼‰")
print("  - 50ä¸‡èªä»¥ä¸Šã®èªå½™ã‚«ãƒãƒ¬ãƒƒã‚¸")
print("  - èªå¹¹æŠ½å‡ºã€ä¾å­˜é–¢ä¿‚è§£æã‚‚å¯èƒ½")

print("\nâŒ ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:")
print("  - åˆæœŸã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ï¼ˆ50MBï¼‰")
print("  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ï¼ˆç´„200MBï¼‰")
print("  - Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ä¾å­˜é–¢ä¿‚")
print("  - å­¦ç¿’ã‚³ã‚¹ãƒˆãŒã‚„ã‚„é«˜ã„")

print(f"\n=== 16,000ä¾‹æ–‡å‡¦ç†æ™‚ã®äºˆæ¸¬ ===")
print("å‡¦ç†é€Ÿåº¦: ç´„1,000æ–‡/ç§’")
print("16,000ä¾‹æ–‡å‡¦ç†æ™‚é–“: ç´„16ç§’")
print("èªå½™èªè­˜ç‡: 95%ä»¥ä¸Š")
print("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ç´„200MB")
print("âœ… éå¸¸ã«å®Ÿç”¨çš„")

print(f"\n=== æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆæ–¹æ³• ===")
integration_code = '''
# æ—¢å­˜ã®Rephrase_Parsing_Engineã«çµ±åˆ
class EnhancedRephraseEngine(RephraseParsingEngine):
    def __init__(self):
        super().__init__()
        try:
            import spacy
            self.nlp = spacy.load("en_core_web_sm")
            self.spacy_available = True
        except:
            self.spacy_available = False
            print("spaCy not available, using basic mode")
    
    def analyze_word_pos(self, word, context=""):
        if self.spacy_available:
            # spaCyã§é«˜ç²¾åº¦åˆ¤å®š
            doc = self.nlp(context if context else word)
            for token in doc:
                if token.text.lower() == word.lower():
                    return token.pos_
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢å­˜ã®ç°¡æ˜“åˆ¤å®š
        return self.basic_pos_detection(word)
'''

print(integration_code)
