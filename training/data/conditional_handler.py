"""
Conditional Handler - ä»®å®šæ³•å‡¦ç†å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
Phase 9: ConditionalHandlerå®Ÿè£…

è¨­è¨ˆæ–¹é‡:
- Ifä»®å®šæ³•: ç¾åœ¨ã€éå»ã€éå»å®Œäº†ã€æ··åˆå‹
- å€’ç½®ä»®å®šæ³•: Were/Had/Shouldå€’ç½®æ§‹é€ 
- Wishä»®å®šæ³•: é¡˜æœ›è¡¨ç¾ã®ä»®å®šæ³•
- As if/As thoughä»®å®šæ³•: æ¯”å–©çš„ä»®å®šæ³•
- ä»®å®šæ³•ç›¸å½“èªå¥: without/but for/unless/supposeç­‰
- Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ å®Œå…¨æº–æ‹ 
- Human Grammar Pattern: spaCyä¾å­˜é–¢ä¿‚è§£æã‚’æ´»ç”¨ã—ãŸæ¡ä»¶ç¯€ãƒ»ä¸»ç¯€åˆ†é›¢
"""

import spacy
import re
from typing import Dict, List, Any, Optional, Tuple


class ConditionalHandler:
    """
    ä»®å®šæ³•å‡¦ç†å°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    è²¬ä»»:
    - æ¡ä»¶ç¯€ã¨ä¸»ç¯€ã®åˆ†é›¢ãƒ»åˆ†æ
    - ä»®å®šæ³•æ™‚åˆ¶ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è­˜åˆ¥
    - å€’ç½®ä»®å®šæ³•ã®æ§‹é€ è§£æ
    - wish/as ifç­‰ã®ç‰¹æ®Šä»®å®šæ³•å‡¦ç†
    - ä»®å®šæ³•ç›¸å½“èªå¥ã®å‡¦ç†
    - Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã¸ã®å¤‰æ›
    
    å¯¾è±¡ç¯„å›²:
    - If conditionals: ç¾åœ¨/éå»/éå»å®Œäº†/æ··åˆå‹
    - Inverted conditionals: Were/Had/Shouldå€’ç½®
    - Wish subjunctive: I wishæ§‹æ–‡
    - As if/though subjunctive: æ¯”å–©çš„ä»®å®šæ³•
    - Conditional equivalents: without/but for/unless/suppose/providedç­‰
    """
    
    def __init__(self, nlp=None):
        """åˆæœŸåŒ–: spaCyä¾å­˜é–¢ä¿‚è§£æå™¨ã¨ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨­å®š"""
        self.nlp = nlp if nlp else spacy.load('en_core_web_sm')
        
        # ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–
        self._initialize_conditional_patterns()
        
        print("ğŸ¯ ConditionalHandleråˆæœŸåŒ–å®Œäº†")
    
    def _initialize_conditional_patterns(self):
        """ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆæœŸåŒ–"""
        
        # Ifç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.if_patterns = {
            'basic_if': r'\bIf\s+',
            'even_if': r'\bEven\s+if\s+',
            'as_if': r'\bas\s+if\s+',
            'as_though': r'\bas\s+though\s+'
        }
        
        # å€’ç½®ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.inversion_patterns = {
            'were': r'^\s*Were\s+\w+',
            'had': r'^\s*Had\s+\w+',
            'should': r'^\s*Should\s+\w+'
        }
        
        # ä»®å®šæ³•ç›¸å½“èªå¥
        self.conditional_equivalents = {
            'unless': r'\bUnless\s+',
            'suppose': r'\bSuppose\s+',
            'imagine': r'\bImagine\s+(?:if\s+)?',
            'provided': r'\bProvided\s+(?:that\s+)?',
            'as_long_as': r'\bAs\s+long\s+as\s+',
            'without': r'\bWithout\s+',
            'but_for': r'\bBut\s+for\s+'
        }
        
        # Wishæ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.wish_patterns = {
            'wish': r'\b(?:wish|wishes|wished)\s+'
        }
        
        # ä»®å®šæ³•æ™‚åˆ¶è­˜åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.tense_patterns = {
            'present': r'\b(?:study|studies|work|works|am|is|are)\b',
            'past': r'\b(?:were|had|studied|worked|went|came)\b',
            'past_perfect': r'\b(?:had\s+\w+ed|had\s+\w+en|had\s+been)\b',
            'present_perfect': r'\b(?:have|has)\s+\w+(?:ed|en)\b'
        }
        
        print("ğŸ”§ ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def detect_conditional_patterns(self, text: str) -> List[str]:
        """
        ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        
        Args:
            text: åˆ†æå¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            List[str]: æ¤œå‡ºã•ã‚ŒãŸä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
        """
        detected_patterns = []
        text_lower = text.lower()
        
        # Ifç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        for pattern_name, pattern in self.if_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                detected_patterns.append(pattern_name)
        
        # å€’ç½®ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        for pattern_name, pattern in self.inversion_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                detected_patterns.append(f"inversion_{pattern_name}")
        
        # ä»®å®šæ³•ç›¸å½“èªå¥ã®æ¤œå‡º
        for pattern_name, pattern in self.conditional_equivalents.items():
            if re.search(pattern, text, re.IGNORECASE):
                detected_patterns.append(f"equivalent_{pattern_name}")
        
        # Wishæ§‹æ–‡ã®æ¤œå‡º
        for pattern_name, pattern in self.wish_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                detected_patterns.append(f"wish_{pattern_name}")
        
        return detected_patterns
    
    def process(self, sentence: str) -> Dict[str, Any]:
        """
        ä»®å®šæ³•æ–‡ã®å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
        
        Args:
            sentence: å‡¦ç†å¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            å‡¦ç†çµæœè¾æ›¸ (success, main_slots, sub_slots, metadata)
        """
        try:
            print(f"ğŸ¯ ConditionalHandlerå‡¦ç†é–‹å§‹: '{sentence}'")
            
            # spaCyè§£æ
            doc = self.nlp(sentence)
            
            # å‰å‡¦ç†: å¥èª­ç‚¹é™¤å»ã¨æ­£è¦åŒ–
            clean_sentence = self._preprocess_sentence(sentence)
            
            # ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
            conditional_type = self._identify_conditional_type(clean_sentence)
            
            if not conditional_type:
                return {'success': False, 'error': 'No conditional pattern detected'}
            
            print(f"ğŸ” ä»®å®šæ³•ã‚¿ã‚¤ãƒ—æ¤œå‡º: {conditional_type}")
            
            # ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
            if conditional_type.startswith('if_'):
                return self._process_if_conditional(doc, clean_sentence, conditional_type)
            elif conditional_type.startswith('inversion_'):
                return self._process_inversion_conditional(doc, clean_sentence, conditional_type)
            elif conditional_type == 'wish':
                return self._process_wish_conditional(doc, clean_sentence)
            elif conditional_type in ['as_if', 'as_though']:
                return self._process_as_if_conditional(doc, clean_sentence, conditional_type)
            elif conditional_type in ['without', 'but_for']:
                return self._process_without_conditional(doc, clean_sentence, conditional_type)
            else:
                return self._process_other_conditional(doc, clean_sentence, conditional_type)
                
        except Exception as e:
            print(f"âŒ ConditionalHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _preprocess_sentence(self, sentence: str) -> str:
        """æ–‡ã®å‰å‡¦ç†"""
        # å¥èª­ç‚¹å‡¦ç†
        clean = re.sub(r'[,.]', ' ', sentence).strip()
        # ä½™åˆ†ãªç©ºç™½é™¤å»
        clean = re.sub(r'\s+', ' ', clean)
        return clean
    
    def _identify_conditional_type(self, sentence: str) -> Optional[str]:
        """ä»®å®šæ³•ã‚¿ã‚¤ãƒ—ã®è­˜åˆ¥"""
        
        # Ifç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern in self.if_patterns.items():
            if re.search(pattern, sentence, re.IGNORECASE):
                return pattern_name
        
        # å€’ç½®ä»®å®šæ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern in self.inversion_patterns.items():
            if re.search(pattern, sentence, re.IGNORECASE):
                return f"inversion_{pattern_name}"
        
        # Wishæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern in self.wish_patterns.items():
            if re.search(pattern, sentence, re.IGNORECASE):
                return 'wish'
        
        # ä»®å®šæ³•ç›¸å½“èªå¥ãƒã‚§ãƒƒã‚¯
        for pattern_name, pattern in self.conditional_equivalents.items():
            if re.search(pattern, sentence, re.IGNORECASE):
                return pattern_name
        
        return None
    
    def _process_if_conditional(self, doc, sentence: str, conditional_type: str) -> Dict[str, Any]:
        """Ifä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” Ifä»®å®šæ³•å‡¦ç†é–‹å§‹: {conditional_type}")
            
            # Ifç¯€ã¨ä¸»ç¯€ã®åˆ†é›¢
            if_clause, main_clause = self._split_if_conditional(sentence)
            
            if not if_clause or not main_clause:
                return {'success': False, 'error': 'Failed to split conditional clauses'}
            
            print(f"ğŸ“ Ifç¯€: '{if_clause}'")
            print(f"ğŸ“ ä¸»ç¯€: '{main_clause}'")
            
            # Ifç¯€ã®è§£æ
            sub_slots = self._analyze_if_clause(if_clause)
            
            # ä¸»ç¯€ã®è§£æ
            main_slots = self._analyze_main_clause(main_clause)
            
            # è¦ªã‚¹ãƒ­ãƒƒãƒˆæ±ºå®š
            parent_slot = self._determine_parent_slot(conditional_type, main_clause)
            
            # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã«ç©ºãƒãƒ¼ã‚«ãƒ¼è¿½åŠ 
            if parent_slot in main_slots:
                main_slots[parent_slot] = ""
            else:
                main_slots[parent_slot] = ""
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«è¦ªæƒ…å ±è¿½åŠ 
            sub_slots['_parent_slot'] = parent_slot
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'metadata': {
                    'handler': 'conditional',
                    'type': conditional_type,
                    'if_clause': if_clause,
                    'main_clause': main_clause,
                    'confidence': 0.9
                }
            }
            
        except Exception as e:
            print(f"âŒ Ifä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_if_conditional(self, sentence: str) -> Tuple[str, str]:
        """Ifä»®å®šæ³•ã®æ¡ä»¶ç¯€ã¨ä¸»ç¯€ã‚’åˆ†é›¢"""
        
        # ã‚³ãƒ³ãƒã§åˆ†å‰²
        parts = sentence.split(',')
        
        if len(parts) == 2:
            # "If clause, main clause" ãƒ‘ã‚¿ãƒ¼ãƒ³
            if_clause = parts[0].strip()
            main_clause = parts[1].strip()
        elif len(parts) == 1:
            # ã‚³ãƒ³ãƒãªã—ã®å ´åˆã€spaCyä¾å­˜é–¢ä¿‚ã‚’åˆ©ç”¨
            doc = self.nlp(sentence)
            if_clause, main_clause = self._split_by_dependency(doc)
        else:
            # è¤‡æ•°ã‚³ãƒ³ãƒã®å ´åˆã¯æœ€åˆã®åˆ†å‰²ç‚¹ã‚’ä½¿ç”¨
            if_clause = parts[0].strip()
            main_clause = ','.join(parts[1:]).strip()
        
        return if_clause, main_clause
    
    def _split_by_dependency(self, doc) -> Tuple[str, str]:
        """ä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹ç¯€åˆ†é›¢"""
        
        if_start = -1
        if_end = -1
        
        # Ifç¯€ã®ç¯„å›²ã‚’ç‰¹å®š
        for i, token in enumerate(doc):
            if token.text.lower() == 'if':
                if_start = i
            elif if_start != -1 and token.dep_ == 'ROOT':
                if_end = i
                break
        
        if if_start != -1 and if_end != -1:
            if_clause = ' '.join([token.text for token in doc[if_start:if_end]])
            main_clause = ' '.join([token.text for token in doc[if_end:]])
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”åˆ†å‰²
            text = doc.text
            if 'if ' in text.lower():
                parts = text.lower().split('if ', 1)
                if_clause = 'If ' + parts[1]
                main_clause = parts[0].strip() if parts[0].strip() else 'Unknown'
            else:
                if_clause = text
                main_clause = ''
        
        return if_clause, main_clause
    
    def _analyze_if_clause(self, if_clause: str) -> Dict[str, str]:
        """Ifç¯€ã®è§£æ"""
        
        sub_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(if_clause)
        
        # åŸºæœ¬æ§‹é€ æŠ½å‡º
        if_word = ""
        subject = ""
        verb = ""
        auxiliary = ""
        obj = ""
        complement = ""
        modifier = ""
        
        for token in doc:
            if token.text.lower() in ['if', 'even', 'unless', 'suppose', 'imagine', 'provided', 'as']:
                if_word += token.text + " "
            elif token.dep_ == 'nsubj':
                subject = token.text
            elif token.pos_ == 'AUX' and token.dep_ != 'ROOT':
                auxiliary = token.text
            elif token.dep_ == 'ROOT' or (token.pos_ == 'VERB' and not auxiliary):
                verb = token.text
            elif token.dep_ in ['dobj', 'pobj']:
                obj += token.text + " "
            elif token.dep_ in ['acomp', 'attr']:
                complement = token.text
            elif token.dep_ in ['advmod', 'npadvmod']:
                modifier += token.text + " "
        
        # If + ä¸»èªã®çµåˆ
        if_word = if_word.strip()
        if subject:
            sub_slots['sub-s'] = f"{if_word} {subject}".strip()
        else:
            sub_slots['sub-s'] = if_word
        
        # å‹•è©é–¢é€£
        if auxiliary:
            sub_slots['sub-aux'] = auxiliary
        if verb:
            sub_slots['sub-v'] = verb
        
        # ç›®çš„èªãƒ»è£œèª
        if obj.strip():
            sub_slots['sub-o1'] = obj.strip()
        if complement:
            sub_slots['sub-c1'] = complement
        
        # ä¿®é£¾èª
        if modifier.strip():
            sub_slots['sub-m2'] = modifier.strip()
        
        return sub_slots
    
    def _analyze_main_clause(self, main_clause: str) -> Dict[str, str]:
        """ä¸»ç¯€ã®è§£æ"""
        
        main_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(main_clause)
        
        # åŸºæœ¬æ§‹é€ æŠ½å‡º
        subject = ""
        verb = ""
        auxiliary = ""
        obj = ""
        complement = ""
        modifier = ""
        
        for token in doc:
            if token.dep_ == 'nsubj':
                subject = token.text
            elif token.pos_ == 'AUX' and token.dep_ != 'ROOT':
                auxiliary += token.text + " "
            elif token.dep_ == 'ROOT' or (token.pos_ == 'VERB' and verb == ""):
                verb = token.text
            elif token.dep_ in ['dobj']:
                obj = token.text + " " + obj if obj else token.text
            elif token.dep_ in ['acomp', 'attr']:
                complement = token.text
            elif token.dep_ in ['advmod', 'npadvmod'] and token.text.lower() not in ['please']:
                modifier += token.text + " "
            elif token.text.lower() == 'please':
                # pleaseã¯ç‰¹åˆ¥æ‰±ã„
                if 'M2' not in main_slots:
                    main_slots['M2'] = 'please'
        
        # ã‚¹ãƒ­ãƒƒãƒˆè¨­å®š
        if subject:
            main_slots['S'] = subject
        if auxiliary.strip():
            main_slots['Aux'] = auxiliary.strip()
        if verb:
            main_slots['V'] = verb
        if obj:
            main_slots['O1'] = obj.strip()
        if complement:
            main_slots['C1'] = complement
        if modifier.strip():
            if 'M2' not in main_slots:
                main_slots['M2'] = modifier.strip()
        
        return main_slots
    
    def _determine_parent_slot(self, conditional_type: str, main_clause: str) -> str:
        """è¦ªã‚¹ãƒ­ãƒƒãƒˆã®æ±ºå®š"""
        
        # æ–‡é ­æ¡ä»¶ã®å ´åˆã¯M1
        if conditional_type in ['basic_if'] and any(word in main_clause.lower() for word in ['now', 'today', 'tomorrow']):
            return 'M1'
        
        # ãã®ä»–ã®å¤šãã®å ´åˆã¯M2
        return 'M2'
    
    def _process_inversion_conditional(self, doc, sentence: str, conditional_type: str) -> Dict[str, Any]:
        """å€’ç½®ä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” å€’ç½®ä»®å®šæ³•å‡¦ç†é–‹å§‹: {conditional_type}")
            
            # å€’ç½®ç¯€ã¨ä¸»ç¯€ã®åˆ†é›¢
            inversion_clause, main_clause = self._split_inversion_conditional(sentence)
            
            print(f"ğŸ“ å€’ç½®ç¯€: '{inversion_clause}'")
            print(f"ğŸ“ ä¸»ç¯€: '{main_clause}'")
            
            # å€’ç½®ç¯€ã®è§£æ
            sub_slots = self._analyze_inversion_clause(inversion_clause, conditional_type)
            
            # ä¸»ç¯€ã®è§£æ
            main_slots = self._analyze_main_clause(main_clause)
            
            # è¦ªã‚¹ãƒ­ãƒƒãƒˆæ±ºå®šï¼ˆå€’ç½®ä»®å®šæ³•ã¯é€šå¸¸M1ã¾ãŸã¯M2ï¼‰
            parent_slot = 'M1' if 'had' in conditional_type else 'M2'
            
            # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã«ç©ºãƒãƒ¼ã‚«ãƒ¼è¿½åŠ 
            main_slots[parent_slot] = ""
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«è¦ªæƒ…å ±è¿½åŠ 
            sub_slots['_parent_slot'] = parent_slot
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'metadata': {
                    'handler': 'conditional',
                    'type': conditional_type,
                    'inversion_clause': inversion_clause,
                    'main_clause': main_clause,
                    'confidence': 0.85
                }
            }
            
        except Exception as e:
            print(f"âŒ å€’ç½®ä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_inversion_conditional(self, sentence: str) -> Tuple[str, str]:
        """å€’ç½®ä»®å®šæ³•ã®åˆ†é›¢"""
        
        parts = sentence.split(',')
        if len(parts) >= 2:
            inversion_clause = parts[0].strip()
            main_clause = ','.join(parts[1:]).strip()
        else:
            # ã‚³ãƒ³ãƒãŒãªã„å ´åˆã®å‡¦ç†
            inversion_clause = sentence
            main_clause = ""
        
        return inversion_clause, main_clause
    
    def _analyze_inversion_clause(self, inversion_clause: str, conditional_type: str) -> Dict[str, str]:
        """å€’ç½®ç¯€ã®è§£æ"""
        
        sub_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(inversion_clause)
        tokens = [token.text for token in doc]
        
        if 'were' in conditional_type:
            # "Were I you" ãƒ‘ã‚¿ãƒ¼ãƒ³
            if len(tokens) >= 3:
                sub_slots['sub-v'] = tokens[0]  # Were
                sub_slots['sub-s'] = tokens[1]  # I
                sub_slots['sub-c1'] = tokens[2]  # you
        
        elif 'had' in conditional_type:
            # "Had she known the truth" ãƒ‘ã‚¿ãƒ¼ãƒ³
            sub_slots['sub-aux'] = tokens[0]  # Had
            sub_slots['sub-s'] = tokens[1] if len(tokens) > 1 else ""  # she
            
            # æ®‹ã‚Šã®éƒ¨åˆ†ã‚’è§£æ
            remaining = ' '.join(tokens[2:]) if len(tokens) > 2 else ""
            doc_remaining = self.nlp(remaining)
            
            verb = ""
            obj = ""
            
            for token in doc_remaining:
                if token.pos_ == 'VERB' and not verb:
                    verb = token.text
                elif token.dep_ in ['dobj', 'pobj']:
                    obj += token.text + " "
            
            if verb:
                sub_slots['sub-v'] = verb
            if obj.strip():
                sub_slots['sub-o1'] = obj.strip()
        
        elif 'should' in conditional_type:
            # "Should you need help" ãƒ‘ã‚¿ãƒ¼ãƒ³
            sub_slots['sub-aux'] = tokens[0]  # Should
            sub_slots['sub-s'] = tokens[1] if len(tokens) > 1 else ""  # you
            
            # æ®‹ã‚Šã®éƒ¨åˆ†ã‚’è§£æ
            remaining = ' '.join(tokens[2:]) if len(tokens) > 2 else ""
            doc_remaining = self.nlp(remaining)
            
            verb = ""
            obj = ""
            
            for token in doc_remaining:
                if token.pos_ == 'VERB' and not verb:
                    verb = token.text
                elif token.dep_ in ['dobj', 'pobj']:
                    obj += token.text + " "
            
            if verb:
                sub_slots['sub-v'] = verb
            if obj.strip():
                sub_slots['sub-o1'] = obj.strip()
        
        return sub_slots
    
    def _process_wish_conditional(self, doc, sentence: str) -> Dict[str, Any]:
        """Wishä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” Wishä»®å®šæ³•å‡¦ç†é–‹å§‹")
            
            # wishã¨ç›®çš„èªç¯€ã®åˆ†é›¢
            wish_part, object_clause = self._split_wish_conditional(sentence)
            
            print(f"ğŸ“ Wishéƒ¨åˆ†: '{wish_part}'")
            print(f"ğŸ“ ç›®çš„èªç¯€: '{object_clause}'")
            
            # Wishéƒ¨åˆ†ã®è§£æï¼ˆä¸»ç¯€ï¼‰
            main_slots = self._analyze_wish_main(wish_part)
            
            # ç›®çš„èªç¯€ã®è§£æï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆï¼‰
            sub_slots = self._analyze_wish_object(object_clause)
            
            # è¦ªã‚¹ãƒ­ãƒƒãƒˆè¨­å®š
            main_slots['O1'] = ""
            sub_slots['_parent_slot'] = 'O1'
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'metadata': {
                    'handler': 'conditional',
                    'type': 'wish',
                    'wish_part': wish_part,
                    'object_clause': object_clause,
                    'confidence': 0.9
                }
            }
            
        except Exception as e:
            print(f"âŒ Wishä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_wish_conditional(self, sentence: str) -> Tuple[str, str]:
        """Wishæ§‹æ–‡ã®åˆ†é›¢"""
        
        # "I wish" ã®å¾Œã‚ã‚’ç›®çš„èªç¯€ã¨ã™ã‚‹
        wish_match = re.search(r'^(.+?wish)\s+(.+)$', sentence, re.IGNORECASE)
        
        if wish_match:
            wish_part = wish_match.group(1).strip()
            object_clause = wish_match.group(2).strip()
        else:
            wish_part = sentence
            object_clause = ""
        
        return wish_part, object_clause
    
    def _analyze_wish_main(self, wish_part: str) -> Dict[str, str]:
        """Wishä¸»ç¯€ã®è§£æ"""
        
        main_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(wish_part)
        
        for token in doc:
            if token.dep_ == 'nsubj':
                main_slots['S'] = token.text
            elif token.lemma_ == 'wish':
                main_slots['V'] = token.text
        
        return main_slots
    
    def _analyze_wish_object(self, object_clause: str) -> Dict[str, str]:
        """Wishç›®çš„èªç¯€ã®è§£æ"""
        
        sub_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(object_clause)
        
        subject = ""
        verb = ""
        auxiliary = ""
        obj = ""
        complement = ""
        modifier = ""
        
        for token in doc:
            if token.dep_ == 'nsubj':
                subject = token.text
            elif token.pos_ == 'AUX':
                auxiliary = token.text
            elif token.pos_ == 'VERB':
                verb = token.text
            elif token.dep_ in ['dobj', 'pobj']:
                obj += token.text + " "
            elif token.dep_ in ['acomp', 'attr']:
                complement = token.text
            elif token.dep_ in ['advmod', 'npadvmod']:
                modifier += token.text + " "
        
        # ã‚¹ãƒ­ãƒƒãƒˆè¨­å®š
        if subject:
            sub_slots['sub-s'] = subject
        if auxiliary:
            sub_slots['sub-aux'] = auxiliary
        if verb:
            sub_slots['sub-v'] = verb
        if obj.strip():
            sub_slots['sub-o1'] = obj.strip()
        if complement:
            sub_slots['sub-c1'] = complement
        if modifier.strip():
            sub_slots['sub-m2'] = modifier.strip()
        
        return sub_slots
    
    def _process_as_if_conditional(self, doc, sentence: str, conditional_type: str) -> Dict[str, Any]:
        """As if/As thoughä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” As if/thoughä»®å®šæ³•å‡¦ç†é–‹å§‹: {conditional_type}")
            
            # ä¸»ç¯€ã¨as ifç¯€ã®åˆ†é›¢
            main_part, as_if_clause = self._split_as_if_conditional(sentence, conditional_type)
            
            print(f"ğŸ“ ä¸»ç¯€: '{main_part}'")
            print(f"ğŸ“ As ifç¯€: '{as_if_clause}'")
            
            # ä¸»ç¯€ã®è§£æ
            main_slots = self._analyze_main_clause(main_part)
            
            # As ifç¯€ã®è§£æ
            sub_slots = self._analyze_as_if_clause(as_if_clause, conditional_type)
            
            # è¦ªã‚¹ãƒ­ãƒƒãƒˆè¨­å®š
            main_slots['M2'] = ""
            sub_slots['_parent_slot'] = 'M2'
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'metadata': {
                    'handler': 'conditional',
                    'type': conditional_type,
                    'main_part': main_part,
                    'as_if_clause': as_if_clause,
                    'confidence': 0.85
                }
            }
            
        except Exception as e:
            print(f"âŒ As if/thoughä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_as_if_conditional(self, sentence: str, conditional_type: str) -> Tuple[str, str]:
        """As if/thoughæ§‹æ–‡ã®åˆ†é›¢"""
        
        pattern = r'\bas\s+(?:if|though)\s+' if conditional_type == 'as_if' else r'\bas\s+though\s+'
        
        match = re.search(pattern, sentence, re.IGNORECASE)
        
        if match:
            main_part = sentence[:match.start()].strip()
            as_if_clause = sentence[match.start():].strip()
        else:
            main_part = sentence
            as_if_clause = ""
        
        return main_part, as_if_clause
    
    def _analyze_as_if_clause(self, as_if_clause: str, conditional_type: str) -> Dict[str, str]:
        """As if/thoughç¯€ã®è§£æ"""
        
        sub_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(as_if_clause)
        tokens = [token.text for token in doc]
        
        # "as if he" ã®å½¢ã§sub-sã‚’è¨­å®š
        if len(tokens) >= 3:
            sub_slots['sub-s'] = f"{tokens[0]} {tokens[1]} {tokens[2]}"  # "as if he"
        
        # æ®‹ã‚Šã®éƒ¨åˆ†ã‚’è§£æ
        remaining_start = 3 if len(tokens) > 3 else len(tokens)
        remaining = ' '.join(tokens[remaining_start:]) if remaining_start < len(tokens) else ""
        
        if remaining:
            doc_remaining = self.nlp(remaining)
            
            verb = ""
            auxiliary = ""
            obj = ""
            complement = ""
            
            for token in doc_remaining:
                if token.pos_ == 'AUX':
                    auxiliary = token.text
                elif token.pos_ == 'VERB':
                    verb = token.text
                elif token.dep_ in ['dobj', 'pobj']:
                    obj += token.text + " "
                elif token.dep_ in ['acomp', 'attr']:
                    complement = token.text
            
            if auxiliary:
                sub_slots['sub-aux'] = auxiliary
            if verb:
                sub_slots['sub-v'] = verb
            if obj.strip():
                sub_slots['sub-o1'] = obj.strip()
            if complement:
                sub_slots['sub-c1'] = complement
        
        return sub_slots
    
    def _process_without_conditional(self, doc, sentence: str, conditional_type: str) -> Dict[str, Any]:
        """Without/But forä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” Without/But forä»®å®šæ³•å‡¦ç†é–‹å§‹: {conditional_type}")
            
            # without/but forå¥ã¨ä¸»ç¯€ã®åˆ†é›¢
            prep_phrase, main_clause = self._split_without_conditional(sentence, conditional_type)
            
            print(f"ğŸ“ å‰ç½®è©å¥: '{prep_phrase}'")
            print(f"ğŸ“ ä¸»ç¯€: '{main_clause}'")
            
            # ä¸»ç¯€ã®è§£æ
            main_slots = self._analyze_main_clause(main_clause)
            
            # å‰ç½®è©å¥ã‚’M2ã«è¨­å®š
            main_slots['M2'] = prep_phrase
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': {},
                'metadata': {
                    'handler': 'conditional',
                    'type': conditional_type,
                    'prep_phrase': prep_phrase,
                    'main_clause': main_clause,
                    'confidence': 0.9
                }
            }
            
        except Exception as e:
            print(f"âŒ Without/But forä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_without_conditional(self, sentence: str, conditional_type: str) -> Tuple[str, str]:
        """Without/But foræ§‹æ–‡ã®åˆ†é›¢"""
        
        if conditional_type == 'without':
            pattern = r'(Without\s+[^,]+),?\s*(.*)'
        else:  # but_for
            pattern = r'(But\s+for\s+[^,]+),?\s*(.*)'
        
        match = re.search(pattern, sentence, re.IGNORECASE)
        
        if match:
            prep_phrase = match.group(1).strip()
            main_clause = match.group(2).strip()
        else:
            prep_phrase = sentence
            main_clause = ""
        
        return prep_phrase, main_clause
    
    def _process_other_conditional(self, doc, sentence: str, conditional_type: str) -> Dict[str, Any]:
        """ãã®ä»–ã®ä»®å®šæ³•ã®å‡¦ç†"""
        try:
            print(f"ğŸ” ãã®ä»–ä»®å®šæ³•å‡¦ç†é–‹å§‹: {conditional_type}")
            
            # æ¡ä»¶ç¯€ã¨ä¸»ç¯€ã®åˆ†é›¢ï¼ˆæ±ç”¨ï¼‰
            condition_clause, main_clause = self._split_generic_conditional(sentence, conditional_type)
            
            print(f"ğŸ“ æ¡ä»¶ç¯€: '{condition_clause}'")
            print(f"ğŸ“ ä¸»ç¯€: '{main_clause}'")
            
            # æ¡ä»¶ç¯€ã®è§£æ
            sub_slots = self._analyze_generic_condition(condition_clause, conditional_type)
            
            # ä¸»ç¯€ã®è§£æ
            main_slots = self._analyze_main_clause(main_clause)
            
            # è¦ªã‚¹ãƒ­ãƒƒãƒˆæ±ºå®š
            parent_slot = 'M1' if conditional_type in ['imagine'] else 'M2'
            
            # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆã«ç©ºãƒãƒ¼ã‚«ãƒ¼è¿½åŠ 
            main_slots[parent_slot] = ""
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«è¦ªæƒ…å ±è¿½åŠ 
            sub_slots['_parent_slot'] = parent_slot
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'metadata': {
                    'handler': 'conditional',
                    'type': conditional_type,
                    'condition_clause': condition_clause,
                    'main_clause': main_clause,
                    'confidence': 0.8
                }
            }
            
        except Exception as e:
            print(f"âŒ ãã®ä»–ä»®å®šæ³•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _split_generic_conditional(self, sentence: str, conditional_type: str) -> Tuple[str, str]:
        """æ±ç”¨çš„ãªæ¡ä»¶æ–‡åˆ†é›¢"""
        
        # ã‚³ãƒ³ãƒã§åˆ†å‰²ã‚’è©¦ã™
        parts = sentence.split(',')
        
        if len(parts) >= 2:
            condition_clause = parts[0].strip()
            main_clause = ','.join(parts[1:]).strip()
        else:
            # ã‚³ãƒ³ãƒãŒãªã„å ´åˆã€ç–‘å•æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®
            if '?' in sentence:
                # "Suppose you had money, what would you do?" ãƒ‘ã‚¿ãƒ¼ãƒ³
                question_match = re.search(r'^(.+?),?\s*(what|how|when|where|why.+\?)$', sentence, re.IGNORECASE)
                if question_match:
                    condition_clause = question_match.group(1).strip()
                    main_clause = question_match.group(2).strip()
                else:
                    condition_clause = sentence
                    main_clause = ""
            else:
                condition_clause = sentence
                main_clause = ""
        
        return condition_clause, main_clause
    
    def _analyze_generic_condition(self, condition_clause: str, conditional_type: str) -> Dict[str, str]:
        """æ±ç”¨çš„ãªæ¡ä»¶ç¯€è§£æ"""
        
        sub_slots = {}
        
        # spaCyè§£æ
        doc = self.nlp(condition_clause)
        
        # æ¡ä»¶è© + ä¸»èªã®æŠ½å‡º
        condition_words = {
            'unless': 'Unless',
            'suppose': 'Suppose',
            'imagine': 'Imagine if',
            'provided': 'Provided that',
            'as_long_as': 'As long as'
        }
        
        condition_word = condition_words.get(conditional_type, conditional_type.title())
        
        # ä¸»èªã®æ¤œå‡º
        subject = ""
        for token in doc:
            if token.dep_ == 'nsubj':
                subject = token.text
                break
        
        # æ¡ä»¶è© + ä¸»èª
        if subject:
            sub_slots['sub-s'] = f"{condition_word} {subject}".strip()
        else:
            sub_slots['sub-s'] = condition_word
        
        # å‹•è©ãƒ»åŠ©å‹•è©ãƒ»ç›®çš„èªç­‰ã®è§£æ
        verb = ""
        auxiliary = ""
        obj = ""
        modifier = ""
        
        for token in doc:
            if token.pos_ == 'AUX' and not auxiliary:
                auxiliary = token.text
            elif token.pos_ == 'VERB' and not verb:
                verb = token.text
            elif token.dep_ in ['dobj', 'pobj']:
                obj += token.text + " "
            elif token.dep_ in ['advmod', 'npadvmod']:
                modifier += token.text + " "
        
        if auxiliary:
            sub_slots['sub-aux'] = auxiliary
        if verb:
            sub_slots['sub-v'] = verb
        if obj.strip():
            sub_slots['sub-o1'] = obj.strip()
        if modifier.strip():
            sub_slots['sub-m2'] = modifier.strip()
        
        return sub_slots


# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
if __name__ == "__main__":
    handler = ConditionalHandler()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_sentences = [
        "If it rains tomorrow, I will stay home.",
        "If I were rich, I would travel the world.",
        "Had she known the truth, she would have acted differently.",
        "I wish I were taller.",
        "He talks as if he were the boss.",
        "Without your help, I would have failed."
    ]
    
    for sentence in test_sentences:
        print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ: {sentence}")
        result = handler.process(sentence)
        print(f"çµæœ: {result}")
