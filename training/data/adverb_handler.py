#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AdverbHandler: å‰¯è©ãƒ»ä¿®é£¾èªå‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
spaCyå“è©åˆ†æãƒ™ãƒ¼ã‚¹ï¼ˆãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç¦æ­¢ï¼‰
è²¬ä»»åˆ†æ‹…åŸå‰‡ã«åŸºã¥ãå°‚é–€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
"""

import spacy
from typing import Dict, Any, List, Tuple

class AdverbHandler:
    """å‰¯è©ãƒ»ä¿®é£¾èªå‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆspaCy POSåˆ¤å®šãƒ™ãƒ¼ã‚¹ï¼‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.name = "AdverbHandler"
        self.version = "spaCy_v1.0"
        self.nlp = spacy.load('en_core_web_sm')  # spaCyå“è©åˆ¤å®šç”¨
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        å‰¯è©ãƒ»ä¿®é£¾èªå‡¦ç†ãƒ¡ã‚¤ãƒ³
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        try:
            # æ–‡å…¨ä½“ã‚’spaCyã§è§£æ
            doc = self.nlp(text)
            
            # å‹•è©ã¨ä¿®é£¾èªã®ãƒšã‚¢ã‚’ç‰¹å®š
            verb_modifier_pairs = self._identify_verb_modifier_pairs(doc)
            
            if not verb_modifier_pairs:
                # ä¿®é£¾èªãŒãªã„å ´åˆã‚‚æˆåŠŸã¨ã—ã¦æ‰±ã†ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™ï¼‰
                return {
                    'success': True,
                    'separated_text': text,
                    'modifiers': {},
                    'verb_positions': {},
                    'modifier_slots': {}
                }
            
            # ä¿®é£¾èªã‚’åˆ†é›¢ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ä¿®é£¾èªæƒ…å ±ã‚’è¿”ã™
            result = self._separate_modifiers(doc, verb_modifier_pairs)
            
            return {
                'success': True,
                'separated_text': result['separated_text'],
                'modifiers': result['modifiers'],
                'verb_positions': result['verb_positions'],
                'modifier_slots': self._assign_modifier_slots(result['modifiers'], verb_modifier_pairs)
            }
            
        except Exception as e:
            return {'success': False, 'error': f'å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def _identify_verb_modifier_pairs(self, doc) -> List[Dict]:
        """å‹•è©ã¨ä¿®é£¾èªã®ãƒšã‚¢ã‚’ç‰¹å®š"""
        pairs = []
        
        for i, token in enumerate(doc):
            # å‹•è©ã‚’è¦‹ã¤ã‘ã‚‹
            if token.pos_ in ['VERB', 'AUX']:
                verb_info = {
                    'verb_idx': i,
                    'verb_text': token.text,
                    'verb_lemma': token.lemma_,
                    'modifiers': []
                }
                
                # å‹•è©ã®å¾Œç¶šä¿®é£¾èªã‚’åé›†
                modifiers = self._collect_verb_modifiers(doc, i)
                if modifiers:
                    verb_info['modifiers'] = modifiers
                    pairs.append(verb_info)
        
        return pairs
    
    def _collect_verb_modifiers(self, doc, verb_idx: int) -> List[Dict]:
        """å‹•è©ã®ä¿®é£¾èªã‚’åé›†ï¼ˆå‰å¾Œä¸¡æ–¹å‘ã‹ã‚‰ï¼‰- å°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æ"""
        modifiers = []
        
        # æ–‡é ­å‰¯è©ã®ç‰¹åˆ¥å‡¦ç†ï¼ˆå°‚é–€åˆ†æ‹…: ä¾å­˜é–¢ä¿‚ã§æ¤œå‡ºï¼‰
        if verb_idx > 0:  # å‹•è©ãŒæ–‡é ­ã§ãªã„å ´åˆ
            first_token = doc[0]
            # æ–‡é ­å‰¯è©ã‚’æ¤œå‡ºï¼ˆnpadvmod ã¾ãŸã¯ advmodï¼‰
            is_sentence_initial_adverb = (
                (first_token.dep_ == 'npadvmod' and first_token.head.i == verb_idx) or
                (first_token.dep_ == 'advmod' and first_token.head.i == verb_idx and first_token.pos_ == 'ADV')
            )
            
            if is_sentence_initial_adverb:
                modifier_info = {
                    'text': first_token.text,
                    'pos': first_token.pos_,
                    'tag': first_token.tag_,
                    'idx': 0,
                    'type': 'sentence_adverb' if first_token.dep_ == 'advmod' else 'temporal',
                    'position': 'sentence-initial',  # æ–‡é ­ä½ç½®
                    'method': 'dependency_analysis'  # ä½¿ç”¨æ‰‹æ³•æ˜ç¤º
                }
                modifiers.append(modifier_info)
                print(f"ğŸ” æ–‡é ­å‰¯è©æ¤œå‡º: {first_token.text} (ä¾å­˜é–¢ä¿‚: {first_token.dep_})")
        
        # Part 1: å‹•è©ã®å‰ã«ã‚ã‚‹ä¿®é£¾èªã‚’æ¤œç´¢ï¼ˆé€†é †ï¼‰
        for i in range(verb_idx - 1, -1, -1):
            token = doc[i]
            
            # æ–‡é ­å‰¯è©ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
            if i == 0 and (token.dep_ == 'npadvmod' or 
                          (token.dep_ == 'advmod' and token.pos_ == 'ADV')):
                continue
            
            # ä¿®é£¾èªã¨ã—ã¦è­˜åˆ¥ï¼ˆã“ã®å‹•è©ã‚’ä¿®é£¾ã—ã¦ã„ã‚‹ã‹ç¢ºèªï¼‰
            if self._is_modifier(token) and token.head.i == verb_idx:
                modifier_info = {
                    'text': token.text,
                    'pos': token.pos_,
                    'tag': token.tag_,
                    'idx': i,
                    'type': self._classify_modifier_type(token),
                    'position': 'pre-verb',  # å‹•è©å‰ä¿®é£¾èª
                    'method': 'pos_analysis'  # ä½¿ç”¨æ‰‹æ³•æ˜ç¤º
                }
                modifiers.append(modifier_info)
            
            # ä¸»èªã«é”ã—ãŸã‚‰åœæ­¢ï¼ˆå‹•è©å‰ä¿®é£¾èªã®ç¯„å›²ã‚’åˆ¶é™ï¼‰
            if token.dep_ in ['nsubj', 'nsubjpass']:
                break
        
        # Part 2: å‹•è©ã®ç›´å¾Œã‹ã‚‰æ–‡æœ«ã¾ã§ï¼ˆã¾ãŸã¯æ¬¡ã®ä¸»è¦è¦ç´ ã¾ã§ï¼‰ã‚’æ¤œç´¢
        for i in range(verb_idx + 1, len(doc)):
            token = doc[i]
            
            # å¥èª­ç‚¹ã§åœæ­¢
            if token.pos_ == 'PUNCT':
                break
            
            # æ¬¡ã®å‹•è©ã§åœæ­¢ï¼ˆä¸»ç¯€ã®å‹•è©ãªã©ï¼‰
            if token.pos_ in ['VERB', 'AUX'] and self._is_main_clause_verb(doc, i):
                break
            
            # ä¿®é£¾èªã¨ã—ã¦è­˜åˆ¥ï¼ˆä¿å®ˆçš„åˆ¤å®šï¼‰
            if self._is_modifier(token):
                # å‰ç½®è©å¥ã®å ´åˆã¯å…¨ä½“ã‚’ãƒã‚§ãƒƒã‚¯
                if token.pos_ == 'ADP':
                    prep_phrase = self._get_prepositional_phrase(doc, i)
                    if prep_phrase['is_modifiable']:
                        modifier_info = {
                            'text': prep_phrase['text'],
                            'pos': token.pos_,
                            'tag': token.tag_,
                            'idx': i,
                            'type': 'prepositional_phrase',
                            'phrase_end': prep_phrase['end_idx'],
                            'position': 'post-verb'  # å‹•è©å¾Œä¿®é£¾èª
                        }
                        modifiers.append(modifier_info)
                        # å‰ç½®è©å¥ã®æ®‹ã‚Šã®éƒ¨åˆ†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                        i = prep_phrase['end_idx']
                        continue
                else:
                    modifier_info = {
                        'text': token.text,
                        'pos': token.pos_,
                        'tag': token.tag_,
                        'idx': i,
                        'type': self._classify_modifier_type(token),
                        'position': 'post-verb'  # å‹•è©å¾Œä¿®é£¾èª
                    }
                    modifiers.append(modifier_info)
        
        return modifiers
    
    def _is_modifier(self, token) -> bool:
        """ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¿®é£¾èªã‹ã©ã†ã‹åˆ¤å®šï¼ˆé©åˆ‡ãªãƒãƒ©ãƒ³ã‚¹ï¼‰"""
        # å‰¯è©ã¯åŸºæœ¬çš„ã«ä¿®é£¾èªã¨ã—ã¦æ‰±ã†ï¼ˆ5æ–‡å‹ã®æ ¸å¿ƒè¦ç´ ã§ã¯ãªã„ï¼‰
        if token.pos_ == 'ADV':
            # ãŸã ã—ã€æ–‡æ³•çš„ã«å¿…é ˆã®å¦å®šå‰¯è©ã®ã¿é™¤å¤–
            essential_adverbs = ['not', "n't", 'never']
            return token.text.lower() not in essential_adverbs
        
        # å‰ç½®è©å¥ã¯ä¿®é£¾èªã¨ã—ã¦æ‰±ã†ï¼ˆãŸã ã—åŸºæœ¬çš„ãªå‰ç½®è©ã®ã¿ï¼‰
        if token.pos_ == 'ADP':
            # 5æ–‡å‹ã®æ ¸å¿ƒã§ãªã„å‰ç½®è©å¥ã¯ä¿®é£¾èª
            modifier_preps = ['for', 'with', 'in', 'on', 'at', 'by', 'during', 'throughout', 'despite', 'besides', 'except']
            return token.text.lower() in modifier_preps
        
        # æ˜ç¢ºãªæ™‚é–“ãƒ»å ´æ‰€å‰¯è©ï¼ˆå ´æ‰€å‰¯è©here/thereã¯ä¿®é£¾èªã¨ã—ã¦æ‰±ã†ï¼‰
        if token.pos_ in ['NOUN', 'PROPN'] and self._is_adverbial_noun(token):
            temporal_locative = ['yesterday', 'today', 'tomorrow', 'here', 'there']
            return token.text.lower() in temporal_locative
        
        # å ´æ‰€å‰¯è©here/thereã¯ä¿®é£¾èªã¨ã—ã¦æ‰±ã†
        if token.pos_ == 'ADV' and token.text.lower() in ['here', 'there']:
            return True
        
        return False
    
    def _is_adverbial_noun(self, token) -> bool:
        """å‰¯è©çš„ãªåè©ã‹ã©ã†ã‹åˆ¤å®šï¼ˆå ´æ‰€ãƒ»æ™‚é–“ãªã©ï¼‰"""
        # å ´æ‰€ãƒ»æ™‚é–“ã‚’è¡¨ã™ä¸€èˆ¬çš„ãªèª
        adverbial_patterns = [
            'here', 'there', 'everywhere', 'somewhere',
            'today', 'yesterday', 'tomorrow', 'now',
            'home', 'abroad', 'upstairs', 'downtown'
        ]
        
        return token.text.lower() in adverbial_patterns
    
    def _get_prepositional_phrase(self, doc, prep_idx: int) -> Dict:
        """å‰ç½®è©å¥å…¨ä½“ã‚’å–å¾—ã—ã€åˆ†é›¢å¯èƒ½ã‹ã©ã†ã‹åˆ¤å®š"""
        prep_token = doc[prep_idx]
        phrase_tokens = [prep_token.text]
        end_idx = prep_idx
        
        # å‰ç½®è©ã®å¾Œç¶šè¦ç´ ã‚’åé›†
        for i in range(prep_idx + 1, len(doc)):
            token = doc[i]
            
            # å¥èª­ç‚¹ã‚„æ¬¡ã®å‰ç½®è©ã€å‹•è©ã§åœæ­¢
            if token.pos_ in ['PUNCT', 'ADP', 'VERB', 'AUX']:
                break
                
            phrase_tokens.append(token.text)
            end_idx = i
        
        phrase_text = ' '.join(phrase_tokens)
        
        # å‰ç½®è©å¥ãŒä¿®é£¾èªã¨ã—ã¦åˆ†é›¢å¯èƒ½ã‹ã©ã†ã‹åˆ¤å®š
        is_modifiable = self._is_prepositional_phrase_modifiable(prep_token.text, phrase_tokens)
        
        return {
            'text': phrase_text,
            'end_idx': end_idx,
            'is_modifiable': is_modifiable
        }
    
    def _is_prepositional_phrase_modifiable(self, preposition: str, phrase_tokens: List[str]) -> bool:
        """å‰ç½®è©å¥ãŒä¿®é£¾èªã¨ã—ã¦åˆ†é›¢å¯èƒ½ã‹ã©ã†ã‹åˆ¤å®š"""
        prep_lower = preposition.lower()
        
        # ä¿®é£¾èªã¨ã—ã¦åˆ†é›¢å¯èƒ½ãªå‰ç½®è©å¥
        # åŸºæœ¬5æ–‡å‹ã®æ ¸å¿ƒæ§‹é€ ã§ãªã„å ´åˆã¯åˆ†é›¢å¯¾è±¡
        modifiable_preps = ['for', 'with', 'in', 'on', 'at', 'by', 'during', 'throughout', 'despite', 'without', 'besides', 'except']
        
        # ãŸã ã—ã€å‹•è©ã®ç›®çš„èªã‚’å°ãåŸºæœ¬çš„ãªå‰ç½®è©ã¯é™¤å¤–
        # ä¾‹: look at, listen to, think of ãªã©
        essential_for_verbs = ['to', 'of', 'from']
        
        if prep_lower in essential_for_verbs:
            return False
            
        return prep_lower in modifiable_preps
    
    def _classify_modifier_type(self, token) -> str:
        """ä¿®é£¾èªã®ç¨®é¡ã‚’åˆ†é¡"""
        if token.pos_ == 'ADV':
            return 'adverb'
        elif token.pos_ == 'ADP':
            return 'prepositional'
        elif self._is_adverbial_noun(token):
            return 'adverbial_noun'
        else:
            return 'other'
    
    def _is_main_clause_verb(self, doc, verb_idx: int) -> bool:
        """ä¸»ç¯€ã®å‹•è©ã‹ã©ã†ã‹åˆ¤å®šï¼ˆé–¢ä¿‚ç¯€å†…ã®å‹•è©ã¨åŒºåˆ¥ï¼‰"""
        # ç°¡æ˜“åˆ¤å®šï¼šé–¢ä¿‚ä»£åè©ã‚ˆã‚Šå¾Œã«ã‚ã‚‹å‹•è©ã¯é–¢ä¿‚ç¯€ã€
        # ãã‚Œã‚ˆã‚Šå‰ã¾ãŸã¯é–¢ä¿‚ä»£åè©ãŒãªã„å ´åˆã¯ä¸»ç¯€
        relative_pronouns = ['who', 'which', 'that', 'whom', 'whose']
        
        # é–¢ä¿‚ä»£åè©ã®ä½ç½®ã‚’ç‰¹å®š
        rel_pronoun_idx = None
        for i, token in enumerate(doc):
            if token.text.lower() in relative_pronouns:
                rel_pronoun_idx = i
                break
        
        # é–¢ä¿‚ä»£åè©ãŒãªã„å ´åˆã€ä¸»ç¯€ã®å‹•è©
        if rel_pronoun_idx is None:
            return True
        
        # é–¢ä¿‚ä»£åè©ã‚ˆã‚Šå¾Œã®æœ€åˆã®å‹•è©ã¯é–¢ä¿‚ç¯€ã€ãã®å¾Œã¯ä¸»ç¯€
        if verb_idx > rel_pronoun_idx:
            # é–¢ä¿‚ç¯€å†…ã®æœ€åˆã®å‹•è©ã‚’ãƒã‚§ãƒƒã‚¯
            first_rel_verb_idx = None
            for i in range(rel_pronoun_idx + 1, len(doc)):
                if doc[i].pos_ in ['VERB', 'AUX']:
                    first_rel_verb_idx = i
                    break
            
            # é–¢ä¿‚ç¯€å†…ã®æœ€åˆã®å‹•è©ã§ã¯ãªã„å ´åˆã€ä¸»ç¯€ã®å‹•è©
            return verb_idx != first_rel_verb_idx
        
        return True
    
    def _separate_modifiers(self, doc, verb_modifier_pairs: List[Dict]) -> Dict:
        """ä¿®é£¾èªã‚’åˆ†é›¢ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ä¿®é£¾èªæƒ…å ±ã‚’ç”Ÿæˆ"""
        separated_tokens = []
        modifiers_info = {}
        verb_positions = {}
        
        modifier_indices = set()
        
        # ä¿®é£¾èªã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†
        for pair in verb_modifier_pairs:
            verb_idx = pair['verb_idx']
            verb_text = pair['verb_text']
            
            # å‹•è©ä½ç½®ã‚’è¨˜éŒ²
            verb_positions[verb_idx] = {
                'original_text': verb_text,
                'modifiers': []
            }
            
            for modifier in pair['modifiers']:
                modifier_idx = modifier['idx']
                modifier_text = modifier['text']
                
                # å‰ç½®è©å¥ã®å ´åˆã€å¥å…¨ä½“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†
                if modifier['type'] == 'prepositional_phrase':
                    # å‰ç½®è©å¥ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‰Šé™¤å¯¾è±¡ã«ã™ã‚‹
                    phrase_parts = modifier_text.split()
                    current_idx = modifier_idx
                    for part in phrase_parts:
                        if current_idx < len(doc) and doc[current_idx].text == part:
                            modifier_indices.add(current_idx)
                            current_idx += 1
                else:
                    # å˜ä¸€èªã®ä¿®é£¾èª
                    modifier_indices.add(modifier_idx)
                
                # ä¿®é£¾èªæƒ…å ±ã‚’è¨˜éŒ²
                if verb_idx not in modifiers_info:
                    modifiers_info[verb_idx] = []
                
                modifiers_info[verb_idx].append({
                    'text': modifier['text'],
                    'type': modifier['type'],
                    'pos': modifier['pos'],
                    'idx': modifier['idx']  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’ä¿æŒ
                })
                
                verb_positions[verb_idx]['modifiers'].append(modifier['text'])
        
        # ä¿®é£¾èªã‚’é™¤ã„ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        for i, token in enumerate(doc):
            if i not in modifier_indices:
                separated_tokens.append(token.text)
        
        separated_text = ' '.join(separated_tokens)
        
        return {
            'separated_text': separated_text,
            'modifiers': modifiers_info,
            'verb_positions': verb_positions
        }
    
    def _assign_modifier_slots(self, modifiers_info: Dict, verb_modifier_pairs: List[Dict]) -> Dict[str, str]:
        """
        REPHRASE_SLOT_STRUCTURE_MANDATORY_REFERENCE.mdä»•æ§˜ã«å¾“ã£ã¦ä¿®é£¾èªã‚’Mã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®
        
        å€‹æ•°ãƒ™ãƒ¼ã‚¹é…ç½®ï¼ˆä½ç½®ç„¡é–¢ä¿‚ï¼‰:
        1å€‹ã®ã¿ä½¿ã‚ã‚Œã¦ã„ã‚‹ã¨ã â†’ M2
        2å€‹ä½¿ã‚ã‚Œã¦ã„ã‚‹ã¨ã â†’ å·¦ã‹ã‚‰M2, M3ã®é †
        3å€‹ä½¿ã‚ã‚Œã¦ã„ã‚‹ã¨ã â†’ ä½ç½®é †ã§M1, M2, M3
        """
        modifier_slots = {}
        
        if not modifiers_info:
            return modifier_slots
        
        # å…¨ä¿®é£¾èªã‚’åé›†ï¼ˆé †åºä¿æŒï¼‰
        all_modifiers = []
        for verb_idx, modifier_list in modifiers_info.items():
            for modifier_info in modifier_list:
                all_modifiers.append({
                    'text': modifier_info['text'],
                    'verb_idx': verb_idx,
                    'modifier_idx': modifier_info.get('idx', 0)
                })
        
        # ä¿®é£¾èªã‚’æ–‡ä¸­ã®ä½ç½®é †ã§ã‚½ãƒ¼ãƒˆ
        all_modifiers.sort(key=lambda x: x['modifier_idx'])
        
        modifier_count = len(all_modifiers)
        
        if modifier_count == 1:
            # 1å€‹ã®ã¿ â†’ M2ï¼ˆä»•æ§˜é€šã‚Šï¼‰
            modifier_slots['M2'] = all_modifiers[0]['text']
        elif modifier_count == 2:
            # 2å€‹ä½¿ã‚ã‚Œã¦ã„ã‚‹ã¨ã â†’ å·¦ã‹ã‚‰M2, M3ã®é †ï¼ˆä»•æ§˜é€šã‚Šï¼‰
            modifier_slots['M2'] = all_modifiers[0]['text']
            modifier_slots['M3'] = all_modifiers[1]['text']
        elif modifier_count == 3:
            # 3å€‹ â†’ M1, M2, M3ï¼ˆå…¬å¼ä»•æ§˜ï¼‰
            modifier_slots['M1'] = all_modifiers[0]['text']
            modifier_slots['M2'] = all_modifiers[1]['text']
            modifier_slots['M3'] = all_modifiers[2]['text']
        
        return modifier_slots
    
    def _get_verb_positions(self, verb_modifier_pairs: List[Dict]) -> List[int]:
        """å‹•è©ã®ä½ç½®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        positions = []
        for pair in verb_modifier_pairs:
            positions.append(pair['verb_idx'])
        return positions
