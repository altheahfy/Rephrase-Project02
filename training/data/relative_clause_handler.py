#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RelativeClauseHandler: é–¢ä¿‚ç¯€å‡¦ç†å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼

Phase 2å¯¾å¿œ: é–¢ä¿‚ç¯€æ¤œå‡ºãƒ»åˆ†è§£ãƒ»ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
POSè§£æã®ã¿ä½¿ç”¨ï¼ˆdependency parsingç¦æ­¢ï¼‰
"""

import spacy
from typing import Dict, List, Any, Optional, Tuple

class RelativeClauseHandler:
    """
    é–¢ä¿‚ç¯€å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    å‡¦ç†æ‰‹é †:
    1. é–¢ä¿‚è©æ¤œå‡ºï¼ˆwho, which, that, whoseï¼‰
    2. é–¢ä¿‚ç¯€å¢ƒç•Œç‰¹å®š
    3. å…ˆè¡Œè©ç‰¹å®š
    4. ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆï¼ˆsub-s, sub-v, sub-m, etc.ï¼‰
    5. è¦ªã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ä»˜ä¸ï¼ˆ_parent_slotï¼‰
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.nlp = spacy.load('en_core_web_sm')
        
        # é–¢ä¿‚è©åˆ†é¡
        self.relative_pronouns = {
            'subjective': ['who', 'which', 'that'],    # ä¸»æ ¼
            'objective': ['whom', 'which', 'that'],    # ç›®çš„æ ¼  
            'possessive': ['whose'],                   # æ‰€æœ‰æ ¼
            'adverbial': ['where', 'when', 'why', 'how']  # é–¢ä¿‚å‰¯è©
        }
        
        # å…¨é–¢ä¿‚è©ãƒªã‚¹ãƒˆ
        self.all_relatives = []
        for rel_list in self.relative_pronouns.values():
            self.all_relatives.extend(rel_list)
        self.all_relatives = list(set(self.all_relatives))  # é‡è¤‡é™¤å»
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        é–¢ä¿‚ç¯€å‡¦ç†ãƒ¡ã‚¤ãƒ³
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            
        Returns:
            Dict: å‡¦ç†çµæœï¼ˆsuccess, main_slots, sub_slots, segmentsï¼‰
        """
        try:
            doc = self.nlp(text)
            
            # 1. é–¢ä¿‚è©å­˜åœ¨ç¢ºèª
            relative_info = self._detect_relative_pronouns(doc)
            if not relative_info:
                return {'success': False, 'error': 'é–¢ä¿‚è©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ'}
            
            # 2. é–¢ä¿‚ç¯€å¢ƒç•Œç‰¹å®š
            segments = self._identify_clause_boundaries(doc, relative_info)
            if not segments:
                return {'success': False, 'error': 'é–¢ä¿‚ç¯€å¢ƒç•Œã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ'}
            
            # 3. å…ˆè¡Œè©ç‰¹å®šã¨ä»£è¡¨èªå¥ä½œæˆ
            antecedent_info = self._identify_antecedent(doc, segments)
            
            # 4. ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
            sub_slots = self._generate_sub_slots(doc, segments, antecedent_info)
            
            # 5. ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆèª¿æ•´ï¼ˆä»£è¡¨èªå¥ã®ã¿ï¼‰
            main_slots = self._create_main_slots(antecedent_info)
            
            return {
                'success': True,
                'main_slots': main_slots,
                'sub_slots': sub_slots,
                'segments': segments,
                'antecedent_info': antecedent_info
            }
            
        except Exception as e:
            return {'success': False, 'error': f'å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def _detect_relative_pronouns(self, doc) -> List[Dict[str, Any]]:
        """
        é–¢ä¿‚è©æ¤œå‡º
        
        Args:
            doc: spaCy Doc ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Returns:
            List[Dict]: æ¤œå‡ºã•ã‚ŒãŸé–¢ä¿‚è©æƒ…å ±
        """
        relatives = []
        
        for i, token in enumerate(doc):
            if token.text.lower() in self.all_relatives:
                # é–¢ä¿‚è©ã‚¿ã‚¤ãƒ—åˆ¤å®š
                rel_type = None
                for type_name, type_list in self.relative_pronouns.items():
                    if token.text.lower() in type_list:
                        rel_type = type_name
                        break
                
                relatives.append({
                    'token': token,
                    'index': i,
                    'text': token.text,
                    'type': rel_type,
                    'lemma': token.lemma_
                })
        
        return relatives
    
    def _identify_clause_boundaries(self, doc, relative_info: List[Dict]) -> Dict[str, Any]:
        """
        é–¢ä¿‚ç¯€å¢ƒç•Œç‰¹å®š
        
        Args:
            doc: spaCy Doc ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            relative_info: æ¤œå‡ºã•ã‚ŒãŸé–¢ä¿‚è©æƒ…å ±
            
        Returns:
            Dict: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ï¼ˆantecedent, relative_clause, main_clauseï¼‰
        """
        if not relative_info:
            return {}
        
        # æœ€åˆã®é–¢ä¿‚è©ã‚’åŸºæº–ã«å‡¦ç†ï¼ˆè¤‡æ•°é–¢ä¿‚è©ã®å ´åˆã¯æœ€åˆã®ã‚‚ã®ã‚’å„ªå…ˆï¼‰
        rel_pronoun = relative_info[0]
        rel_index = rel_pronoun['index']
        
        # å…ˆè¡Œè©éƒ¨åˆ†ï¼ˆé–¢ä¿‚è©ã®å‰ï¼‰
        antecedent_tokens = [token for token in doc[:rel_index] if token.pos_ != 'PUNCT']
        
        # é–¢ä¿‚ç¯€éƒ¨åˆ†ï¼ˆé–¢ä¿‚è©ã‹ã‚‰æ¬¡ã®ä¸»å‹•è©ã¾ã§ï¼‰
        relative_clause_tokens = []
        main_clause_start = len(doc)
        
        # é–¢ä¿‚è©ã‹ã‚‰é–‹å§‹
        relative_clause_tokens.append(doc[rel_index])
        
        # é–¢ä¿‚ç¯€ã®çµ‚äº†ç‚¹ã‚’æ¤œå‡º
        verb_count = 0
        for i in range(rel_index + 1, len(doc)):
            token = doc[i]
            
            if token.pos_ == 'PUNCT':
                continue
            
            # å‹•è©ã‚«ã‚¦ãƒ³ãƒˆ
            if token.pos_ in ['VERB', 'AUX']:
                verb_count += 1
                
            relative_clause_tokens.append(token)
            
            # é–¢ä¿‚ç¯€çµ‚äº†æ¡ä»¶ï¼š2ç•ªç›®ã®å‹•è©ã®ç›´å‰ã¾ã§
            if verb_count >= 2:
                # ç¾åœ¨ã®å‹•è©ã¯ä¸»ç¯€ã®å‹•è©ãªã®ã§ã€ãã‚Œã‚ˆã‚Šå‰ã§é–¢ä¿‚ç¯€çµ‚äº†
                relative_clause_tokens.pop()  # ä¸»ç¯€å‹•è©ã‚’é™¤å»
                main_clause_start = i
                break
        
        # ä¸»ç¯€éƒ¨åˆ†ï¼ˆé–¢ä¿‚ç¯€çµ‚äº†å¾Œï¼‰
        main_clause_tokens = [token for token in doc[main_clause_start:] if token.pos_ != 'PUNCT']
        
        return {
            'antecedent': antecedent_tokens,
            'relative_clause': relative_clause_tokens,
            'main_clause': main_clause_tokens,
            'relative_pronoun': rel_pronoun
        }
    
    def _identify_antecedent(self, doc, segments: Dict) -> Dict[str, Any]:
        """
        å…ˆè¡Œè©ç‰¹å®šã¨ä»£è¡¨èªå¥ä½œæˆ
        
        Args:
            doc: spaCy Doc ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ  
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±
            
        Returns:
            Dict: å…ˆè¡Œè©æƒ…å ±ï¼ˆrepresentative_phrase, original_phraseï¼‰
        """
        antecedent_tokens = segments.get('antecedent', [])
        relative_pronoun = segments.get('relative_pronoun', {})
        
        if not antecedent_tokens:
            return {}
        
        # å…ˆè¡Œè©ã®æ ¸ã¨ãªã‚‹åè©ã‚’ç‰¹å®š
        head_noun = None
        for token in reversed(antecedent_tokens):  # å¾Œã‚ã‹ã‚‰æ¤œç´¢
            if token.pos_ in ['NOUN', 'PROPN', 'PRON']:
                head_noun = token
                break
        
        if not head_noun:
            return {}
        
        # ä»£è¡¨èªå¥ä½œæˆï¼ˆå…ˆè¡Œè© + é–¢ä¿‚è©ï¼‰
        original_phrase = ' '.join([t.text for t in antecedent_tokens])
        relative_text = relative_pronoun.get('text', '')
        representative_phrase = f"{original_phrase} {relative_text}"
        
        return {
            'head_noun': head_noun,
            'original_phrase': original_phrase,
            'representative_phrase': representative_phrase,
            'tokens': antecedent_tokens
        }
    
    def _generate_sub_slots(self, doc, segments: Dict, antecedent_info: Dict) -> Dict[str, Any]:
        """
        ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
        
        Args:
            doc: spaCy Doc ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±
            antecedent_info: å…ˆè¡Œè©æƒ…å ±
            
        Returns:
            Dict: ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±
        """
        relative_clause = segments.get('relative_clause', [])
        relative_pronoun = segments.get('relative_pronoun', {})
        
        if not relative_clause:
            return {}
        
        sub_slots = {}
        
        # é–¢ä¿‚è©ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ
        rel_type = relative_pronoun.get('type')
        rel_text = relative_pronoun.get('text', '')
        
        if rel_type == 'subjective':
            # ä¸»æ ¼é–¢ä¿‚ä»£åè©: who/which/that runs
            sub_slots['sub-s'] = antecedent_info.get('representative_phrase', '')
            
            # é–¢ä¿‚ç¯€å†…ã®å‹•è©æ¤œå‡º
            for token in relative_clause[1:]:  # é–¢ä¿‚è©ã®æ¬¡ã‹ã‚‰
                if token.pos_ in ['VERB', 'AUX']:
                    sub_slots['sub-v'] = token.text
                    break
            
            # é–¢ä¿‚ç¯€å†…ã®ä¿®é£¾èªæ¤œå‡º  
            modifiers = []
            for token in relative_clause[1:]:
                if token.pos_ in ['ADV', 'ADJ'] and token.text not in sub_slots.values():
                    modifiers.append(token.text)
            
            if modifiers:
                sub_slots['sub-m2'] = ' '.join(modifiers)
        
        elif rel_type == 'objective':
            # ç›®çš„æ ¼é–¢ä¿‚ä»£åè©: which I bought
            # é–¢ä¿‚ç¯€å†…ã®ä¸»èªæ¤œå‡º
            for token in relative_clause[1:]:
                if token.pos_ in ['PRON', 'NOUN', 'PROPN']:
                    sub_slots['sub-s'] = token.text
                    break
            
            # é–¢ä¿‚ç¯€å†…ã®å‹•è©æ¤œå‡º
            for token in relative_clause[1:]:
                if token.pos_ in ['VERB', 'AUX']:
                    sub_slots['sub-v'] = token.text
                    break
                    
        elif rel_type == 'possessive':
            # æ‰€æœ‰æ ¼é–¢ä¿‚ä»£åè©: whose car
            # whose ã®æ¬¡ã®åè©ãŒæ‰€æœ‰ç‰©
            for i, token in enumerate(relative_clause):
                if token.text.lower() == 'whose' and i + 1 < len(relative_clause):
                    possessed = relative_clause[i + 1]
                    if possessed.pos_ in ['NOUN', 'PROPN']:
                        sub_slots['sub-s'] = f"whose {possessed.text}"
                        break
            
            # é–¢ä¿‚ç¯€å†…ã®å‹•è©æ¤œå‡º
            for token in relative_clause[1:]:
                if token.pos_ in ['VERB', 'AUX']:
                    sub_slots['sub-v'] = token.text
                    break
        
        # è¦ªã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ï¼ˆã¨ã‚Šã‚ãˆãšSã¨ã—ã¦è¨­å®šã€å¾Œã§èª¿æ•´ï¼‰
        sub_slots['_parent_slot'] = 'S'
        
        return sub_slots
    
    def _create_main_slots(self, antecedent_info: Dict) -> Dict[str, str]:
        """
        ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆä½œæˆï¼ˆä»£è¡¨èªå¥ã®ã¿ï¼‰
        
        Args:
            antecedent_info: å…ˆè¡Œè©æƒ…å ±
            
        Returns:
            Dict: ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆï¼ˆé–¢ä¿‚ç¯€éƒ¨åˆ†ã¯ç©ºæ–‡å­—åˆ—ã§ãƒã‚¹ã‚¯ï¼‰
        """
        representative = antecedent_info.get('representative_phrase', '')
        
        return {
            'S': '',  # é–¢ä¿‚ç¯€ã‚’å«ã‚€ä¸»èªã¯ç©ºã§ãƒã‚¹ã‚¯ï¼ˆå¾Œã§BasicFivePatternHandlerãŒå‡¦ç†ï¼‰
            '_representative_subject': representative  # ä»£è¡¨èªå¥æƒ…å ±ã‚’ä¿æŒ
        }


if __name__ == "__main__":
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    handler = RelativeClauseHandler()
    
    test_cases = [
        "The man who runs fast is strong.",
        "The book which lies there is mine.",
        "The car whose owner is here is red."
    ]
    
    print("ğŸ” RelativeClauseHandler ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 50)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case}")
        result = handler.process(test_case)
        
        if result['success']:
            print(f"âœ… æˆåŠŸ")
            print(f"  ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: {result['main_slots']}")
            print(f"  ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result['sub_slots']}")
        else:
            print(f"âŒ å¤±æ•—: {result['error']}")
