#!/usr/bin/env python3
"""
spaCyã®å…¨ä¾å­˜é–¢ä¿‚ã‚¿ã‚°ã¨POSå“è©ã‚¿ã‚°ã®å®Œå…¨ãƒªã‚¹ãƒˆå–å¾—
"""

import spacy

def get_spacy_complete_labels():
    print("ğŸ” spaCyå®Œå…¨ãƒ©ãƒ™ãƒ«ä½“ç³»èª¿æŸ»")
    
    try:
        nlp = spacy.load("en_core_web_sm")
        print("âœ… spaCyèªå½™èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âŒ spaCyåˆæœŸåŒ–å¤±æ•—: {e}")
        return
    
    # å…¨ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«
    print(f"\nğŸ“Š spaCyå…¨ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«:")
    dep_labels = list(nlp.get_pipe("parser").labels)
    print(f"  ç·æ•°: {len(dep_labels)}ç¨®é¡")
    
    print("\nğŸ·ï¸ å…¨ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ä¸€è¦§:")
    for i, dep in enumerate(sorted(dep_labels), 1):
        print(f"  {i:2d}. {dep}")
    
    # å…¨POSå“è©ãƒ©ãƒ™ãƒ«
    print(f"\nğŸ“Š spaCyPOSå“è©ãƒ©ãƒ™ãƒ«:")
    pos_labels = list(nlp.get_pipe("tagger").labels)
    print(f"  ç·æ•°: {len(pos_labels)}ç¨®é¡")
    
    print("\nğŸ·ï¸ å…¨POSå“è©ãƒ©ãƒ™ãƒ«ä¸€è¦§:")
    for i, pos in enumerate(sorted(pos_labels), 1):
        print(f"  {i:2d}. {pos}")
    
    # ä»Šå›æ¤œå‡ºã•ã‚ŒãŸ21ç¨®é¡ã¨ã®æ¯”è¼ƒ
    detected_deps = {
        "nsubj", "ROOT", "poss", "dobj", "punct", "dative", "det", "amod", 
        "acl", "advmod", "aux", "prep", "pobj", "npadvmod", "acomp", "prt", 
        "intj", "mark", "advcl", "csubj", "relcl"
    }
    
    print(f"\nğŸ” ä»Šå›ã®æ¤œè¨¼çµæœã¨ã®æ¯”è¼ƒ:")
    print(f"  ä»Šå›æ¤œå‡º: {len(detected_deps)}ç¨®é¡")
    print(f"  spaCyå…¨ä½“: {len(dep_labels)}ç¨®é¡")
    print(f"  æœªæ¤œå‡º: {len(dep_labels) - len(detected_deps)}ç¨®é¡")
    
    missing_deps = set(dep_labels) - detected_deps
    print(f"\nâŒ ä»Šå›æœªæ¤œå‡ºã®ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ« ({len(missing_deps)}ç¨®é¡):")
    for i, dep in enumerate(sorted(missing_deps), 1):
        print(f"  {i:2d}. {dep}")

if __name__ == "__main__":
    get_spacy_complete_labels()
