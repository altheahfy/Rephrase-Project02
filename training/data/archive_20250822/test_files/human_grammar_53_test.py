#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ å°‚ç”¨ãƒ†ã‚¹ãƒˆï¼ˆ53ä¾‹æ–‡ç‰ˆï¼‰- çµ±ä¸€å½¢å¼å¯¾å¿œ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã¿ã‚’ä½¿ã£ã¦53ä¾‹æ–‡ã‚’å‡¦ç†ã—ã€
æ—¢å­˜ã®compare_results.pyã§æ¤œè¨¼å¯èƒ½ãªçµ±ä¸€å½¢å¼ã§çµæœã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¨­å®š
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from unified_stanza_rephrase_mapper import UnifiedStanzaRephraseMapper

def run_human_grammar_batch_test():
    """äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã§53ä¾‹æ–‡ã‚’ãƒãƒƒãƒå‡¦ç†ï¼ˆçµ±ä¸€å½¢å¼ï¼‰"""
    
    print("=" * 70)
    print("ğŸ§  äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ å°‚ç”¨ãƒãƒƒãƒãƒ†ã‚¹ãƒˆï¼ˆçµ±ä¸€å½¢å¼ï¼‰")
    print("=" * 70)
    
    # 53ä¾‹æ–‡ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
    test_data_path = project_root / "final_test_system" / "final_54_test_data.json"
    if not test_data_path.exists():
        print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_data_path}")
        return
    
    with open(test_data_path, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’å¤‰æ›
    test_sentences = []
    for key, test_case in raw_data['data'].items():
        test_sentences.append(test_case['sentence'])
    
    print(f"ğŸ“ ãƒ†ã‚¹ãƒˆå¯¾è±¡æ–‡æ•°: {len(test_sentences)}")
    print()
    
    # ãƒãƒƒãƒ‘ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆäººé–“å°‚ç”¨ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    mapper = UnifiedStanzaRephraseMapper(test_mode='human_only')
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    batch_results = []
    start_time = datetime.now()
    
    for i, sentence in enumerate(test_sentences, 1):
        print(f"ğŸ” å‡¦ç†ä¸­ {i:2d}/{len(test_sentences)}: {sentence}")
        
        try:
            # äººé–“æ–‡æ³•èªè­˜ã®ã¿ã§å‡¦ç†
            result = mapper.process(sentence)
            
            # çµ±ä¸€å½¢å¼ã«å¤‰æ›ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨åŒã˜å½¢å¼ï¼‰
            batch_result = {
                'sentence': sentence,
                'status': 'success',
                'analysis_result': {
                    'sentence': sentence,
                    'slots': result.get('slots', {}),          # main_slots â†’ slots  
                    'sub_slots': result.get('sub_slots', {}),  # sub_slots ã¯ãã®ã¾ã¾
                    'grammar_info': {
                        'detected_patterns': [],
                        'handler_contributions': {}
                    },
                    'processing_time': result.get('meta', {}).get('processing_time', 0.0)
                },
                'processing_time': result.get('meta', {}).get('processing_time', 0.0),
                'meta': {
                    'sentence_id': i,
                    'test_mode': 'human_only',
                    'timestamp': datetime.now().isoformat()
                }
            }
            
            batch_results.append(batch_result)
            
            # é€²æ—è¡¨ç¤º
            if i % 10 == 0:
                print(f"   ğŸ“Š é€²æ—: {i}/{len(test_sentences)} å®Œäº†")
                
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºçµæœã‚’è¿½åŠ 
            batch_results.append({
                'sentence': sentence,
                'status': 'error',
                'analysis_result': {
                    'sentence': sentence,
                    'slots': {},
                    'sub_slots': {},
                    'grammar_info': {
                        'detected_patterns': [],
                        'handler_contributions': {}
                    },
                    'processing_time': 0.0
                },
                'processing_time': 0.0,
                'meta': {
                    'sentence_id': i,
                    'test_mode': 'human_only',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
            })
    
    end_time = datetime.now()
    
    # çµ±ä¸€å½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ï¼ˆcompare_results.pyç”¨ï¼‰
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_path = project_root / f"human_grammar_batch_results_{timestamp}.json"
    
    # ãƒãƒƒãƒçµæœã‚’compare_results.pyäº’æ›ã®è¾æ›¸å½¢å¼ã«å¤‰æ›
    results_dict = {}
    for i, result in enumerate(batch_results, 1):
        test_id = str(i)  # "1", "2", "3"... ã®å½¢å¼ã§ final_54_test_data.json ã¨ä¸€è‡´
        results_dict[test_id] = result
    
    # æ—¢å­˜ã®ãƒãƒƒãƒå‡¦ç†çµæœã¨åŒã˜å½¢å¼ã§å‡ºåŠ›
    output_data = {
        'meta': {
            'test_type': 'human_grammar_recognition_batch',
            'total_sentences': len(batch_results),
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'total_time': str(end_time - start_time),
            'system_version': 'unified_mapper_v1.0_human_only'
        },
        'results': results_dict
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print()
    print("=" * 70)
    print("ğŸ“Š ãƒãƒƒãƒãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)
    print(f"âœ… å‡¦ç†æ¸ˆã¿æ–‡æ•°: {len(batch_results)}")
    print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    
    # çµ±è¨ˆæƒ…å ±
    total_time = sum(r.get('processing_time', 0) for r in batch_results)
    avg_time = total_time / len(batch_results) if batch_results else 0
    print(f"â±ï¸ åˆè¨ˆå‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
    print(f"â±ï¸ å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.4f}ç§’/æ–‡")
    
    # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
    error_count = sum(1 for r in batch_results if 'error' in r.get('meta', {}))
    if error_count > 0:
        print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ–‡æ•°: {error_count}/{len(batch_results)}")
    
    # ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£æˆåŠŸçµ±è¨ˆ
    slot_success_count = sum(1 for r in batch_results if r.get('slots') or r.get('sub_slots'))
    slot_success_rate = (slot_success_count / len(batch_results)) * 100 if batch_results else 0
    print(f"ğŸ¯ ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£æˆåŠŸ: {slot_success_count}/{len(batch_results)} ({slot_success_rate:.1f}%)")
    
    print()
    print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"1. compare_results.py --results {output_path.name} ã§æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ")
    print("2. compare_results.py --results {} --detail ã§è©³ç´°åˆ†æ".format(output_path.name))
    print("3. äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„ç®‡æ‰€ã‚’ç‰¹å®š")
    
    return output_path

if __name__ == "__main__":
    result_file = run_human_grammar_batch_test()
    if result_file:
        print(f"\nğŸš€ ä»Šã™ãå®Ÿè¡Œå¯èƒ½:")
        print(f"   python compare_results.py --results {result_file.name}")
        print(f"   python compare_results.py --results {result_file.name} --detail")
