import spacy
import pandas as pd
from collections import defaultdict

class CompleteSpacyRephraseEngine:
    """
    spaCyä¾å­˜é–¢ä¿‚45å€‹å®Œå…¨å¯¾å¿œ Rephraseçµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³
    â‘  spaCyãŒå…¨å˜èªã®ä¾å­˜é–¢ä¿‚ã‚’è§£æ
    â‘¡ ã‚¨ãƒ³ã‚¸ãƒ³ãŒRephraseãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®
    â‘¢ 100%å˜èªä¿å…¨ã‚’ä¿è¨¼
    """
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        
        # spaCyä¾å­˜é–¢ä¿‚45å€‹ â†’ Rephraseã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå®Œå…¨ãƒãƒƒãƒ”ãƒ³ã‚°
        self.dep_to_subslot = {
            # ä¸»èªé–¢é€£
            'nsubj': 'sub-s',           # åè©ä¸»èª
            'nsubjpass': 'sub-s',       # å—å‹•æ…‹ä¸»èª
            'csubj': 'sub-s',           # ç¯€ä¸»èª
            'csubjpass': 'sub-s',       # å—å‹•ç¯€ä¸»èª
            'expl': 'sub-s',            # è™šè¾ä¸»èª(there, it)
            
            # å‹•è©ãƒ»è¿°èªé–¢é€£
            'ROOT': 'sub-v',            # ä¸»å‹•è©
            'cop': 'sub-v',             # ã‚³ãƒ”ãƒ¥ãƒ©(beå‹•è©)
            'aux': 'sub-aux',           # åŠ©å‹•è©
            'auxpass': 'sub-aux',       # å—å‹•æ…‹åŠ©å‹•è©
            
            # ç›®çš„èªé–¢é€£
            'dobj': 'sub-o1',           # ç›´æ¥ç›®çš„èª
            'iobj': 'sub-o2',           # é–“æ¥ç›®çš„èª
            'pobj': 'sub-o1',           # å‰ç½®è©ç›®çš„èª
            'dative': 'sub-o2',         # ä¸æ ¼ç›®çš„èª
            
            # è£œèªé–¢é€£
            'attr': 'sub-c1',           # å±æ€§è£œèª
            'acomp': 'sub-c1',          # å½¢å®¹è©è£œèª
            'pcomp': 'sub-c1',          # å‰ç½®è©è£œèª
            'xcomp': 'sub-c2',          # é–‹æ”¾è£œèª
            'ccomp': 'sub-c2',          # ç¯€è£œèª
            
            # ä¿®é£¾èªé–¢é€£ï¼ˆM1/M2/M3ï¼‰
            'advmod': 'sub-m2',         # å‰¯è©ä¿®é£¾
            'amod': 'sub-m2',           # å½¢å®¹è©ä¿®é£¾
            'npadvmod': 'sub-m3',       # åè©å¥å‰¯è©ä¿®é£¾
            'tmod': 'sub-m3',           # æ™‚é–“ä¿®é£¾
            'nummod': 'sub-m2',         # æ•°è©ä¿®é£¾
            'quantmod': 'sub-m2',       # é‡è©ä¿®é£¾
            
            # æ¥ç¶šè©ãƒ»æ¨™è­˜é–¢é€£
            'mark': 'sub-m1',           # å¾“å±æ¥ç¶šè©(although, thatç­‰)
            'cc': 'sub-m1',             # ç­‰ä½æ¥ç¶šè©
            'preconj': 'sub-m1',        # å‰æ¥ç¶šè©
            
            # ç¯€ãƒ»å¥é–¢é€£
            'advcl': 'sub-m3',          # å‰¯è©ç¯€
            'relcl': 'sub-m3',          # é–¢ä¿‚ç¯€
            'acl': 'sub-m3',            # ç¯€ä¿®é£¾èª
            'prt': 'sub-m3',            # åŠ©è©
            
            # å‰ç½®è©é–¢é€£
            'prep': 'sub-m3',           # å‰ç½®è©
            'poss': 'sub-m2',           # æ‰€æœ‰æ ¼
            'possessive': 'sub-m2',     # æ‰€æœ‰æ ¼ãƒãƒ¼ã‚«ãƒ¼
            
            # ãã®ä»–é‡è¦ãªé–¢ä¿‚
            'agent': 'sub-s',           # å‹•ä½œä¸»
            'neg': 'sub-m2',            # å¦å®š
            'det': 'sub-m2',            # é™å®šè©
            'predet': 'sub-m2',         # å‰é™å®šè©
            'appos': 'sub-m3',          # åŒæ ¼
            'compound': 'sub-m2',       # è¤‡åˆèª
            'conj': 'sub-m3',           # æ¥ç¶šé …
            'discourse': 'sub-m1',      # è«‡è©±æ¨™è­˜
            'vocative': 'sub-m1',       # å‘¼æ ¼
            'intj': 'sub-m1',           # é–“æŠ•è©
            'meta': 'sub-m3',           # ãƒ¡ã‚¿æƒ…å ±
            'parataxis': 'sub-m3',      # ä¸¦åˆ—æ§‹é€ 
            'punct': '',                # å¥èª­ç‚¹ï¼ˆé™¤å¤–ï¼‰
            'dep': 'sub-m3'             # ãã®ä»–ä¾å­˜é–¢ä¿‚
        }
        
        # å„ªå…ˆé †ä½ï¼ˆè¤‡æ•°å€™è£œãŒã‚ã‚‹å ´åˆï¼‰
        self.subslot_priority = {
            'sub-m1': 1,
            'sub-s': 2,
            'sub-aux': 3,
            'sub-m2': 4,
            'sub-v': 5,
            'sub-c1': 6,
            'sub-o1': 7,
            'sub-o2': 8,
            'sub-c2': 9,
            'sub-m3': 10
        }
    
    def decompose(self, phrase):
        """
        çµ±ä¸€åˆ†è§£ãƒ¡ã‚½ãƒƒãƒ‰ï¼šspaCyè§£æ â†’ Rephraseãƒ«ãƒ¼ãƒ«é©ç”¨
        """
        if not phrase or phrase.strip() == "":
            return self._empty_subslots()
        
        phrase = phrase.strip()
        doc = self.nlp(phrase)
        
        # ãƒ‡ãƒãƒƒã‚°ï¼šspaCyè§£æçµæœè¡¨ç¤º
        print(f"\nğŸ” spaCyè§£æ: '{phrase}'")
        for token in doc:
            print(f"  {token.text:12} | {token.dep_:12} | {token.pos_:8} | {token.head.text}")
        
        # â‘  spaCyä¾å­˜é–¢ä¿‚è§£æ
        token_assignments = self._analyze_dependencies(doc)
        
        # â‘¡ Rephraseãƒ«ãƒ¼ãƒ«é©ç”¨
        result = self._apply_rephrase_rules(doc, token_assignments)
        
        # â‘¢ 100%å˜èªä¿å…¨ãƒã‚§ãƒƒã‚¯
        if not self._verify_complete_coverage(phrase, result):
            print(f"âš ï¸  å˜èªæ¬ è½æ¤œå‡º: '{phrase}'")
            result = self._recover_missing_words(phrase, doc, result)
        
        return result
    
    def _analyze_dependencies(self, doc):
        """spaCyä¾å­˜é–¢ä¿‚ã‚’è§£æã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³å‰²ã‚Šå½“ã¦ã‚’æ±ºå®š"""
        assignments = {}
        
        for token in doc:
            dep = token.dep_
            
            # ä¾å­˜é–¢ä¿‚ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°
            if dep in self.dep_to_subslot:
                target_subslot = self.dep_to_subslot[dep]
                if target_subslot:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆ
                    assignments[token.i] = {
                        'token': token,
                        'subslot': target_subslot,
                        'priority': self.subslot_priority.get(target_subslot, 999)
                    }
        
        return assignments
    
    def _apply_rephrase_rules(self, doc, assignments):
        """Rephraseãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®"""
        result = self._empty_subslots()
        subslot_tokens = defaultdict(list)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ¥ã«åˆ†é¡
        for token_idx, assignment in assignments.items():
            subslot = assignment['subslot']
            token = assignment['token']
            subslot_tokens[subslot].append((token, assignment['priority']))
        
        # å„ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§æœ€é©ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠãƒ»çµåˆ
        for subslot, token_list in subslot_tokens.items():
            if token_list:
                # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆ
                token_list.sort(key=lambda x: (x[1], x[0].i))
                
                # ã‚¹ãƒ‘ãƒ³ã‚’æ§‹ç¯‰ï¼ˆéš£æ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’çµåˆï¼‰
                span_text = self._build_coherent_span(token_list, doc)
                result[subslot] = span_text
        
        return result
    
    def _build_coherent_span(self, token_list, doc):
        """æ–‡æ³•çš„ã«ä¸€è²«ã—ãŸã‚¹ãƒ‘ãƒ³ã‚’æ§‹ç¯‰"""
        if len(token_list) == 1:
            token = token_list[0][0]
            return self._get_extended_span(token, doc)
        
        # è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®å ´åˆã€æœ€ã‚‚ä»£è¡¨çš„ãªã‚‚ã®ã‚’é¸æŠ
        primary_token = token_list[0][0]
        return self._get_extended_span(primary_token, doc)
    
    def _get_extended_span(self, token, doc):
        """ãƒˆãƒ¼ã‚¯ãƒ³ã¨ãã®ä¿®é£¾èªã‚’å«ã‚€æ‹¡å¼µã‚¹ãƒ‘ãƒ³"""
        # å­ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä¿®é£¾èªï¼‰ã‚’å«ã‚ã‚‹
        span_tokens = [token]
        
        for child in token.children:
            # é‡è¦ãªä¿®é£¾èªã®ã¿å«ã‚ã‚‹
            if child.dep_ in ['det', 'amod', 'compound', 'poss']:
                span_tokens.append(child)
        
        # ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
        span_tokens.sort(key=lambda t: t.i)
        
        if len(span_tokens) == 1:
            return token.text
        else:
            # é€£ç¶šã‚¹ãƒ‘ãƒ³ã‚’æ§‹ç¯‰
            start_idx = min(t.i for t in span_tokens)
            end_idx = max(t.i for t in span_tokens) + 1
            return doc[start_idx:end_idx].text
    
    def _verify_complete_coverage(self, original, subslots):
        """100%å˜èªä¿å…¨ç¢ºèª"""
        original_words = set(w.lower() for w in original.split() if w.strip())
        covered_words = set()
        
        for value in subslots.values():
            if value and value.strip():
                covered_words.update(w.lower() for w in value.split() if w.strip())
        
        missing = original_words - covered_words
        return len(missing) == 0
    
    def _recover_missing_words(self, original, doc, current_result):
        """æ¬ è½å˜èªã®å›å¾©"""
        original_words = set(w.lower() for w in original.split())
        covered_words = set()
        
        for value in current_result.values():
            if value:
                covered_words.update(w.lower() for w in value.split())
        
        missing_words = original_words - covered_words
        
        if missing_words:
            # æ¬ è½å˜èªã‚’sub-m3ã«è¿½åŠ ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            missing_text = ' '.join(missing_words)
            if current_result['sub-m3']:
                current_result['sub-m3'] += f" {missing_text}"
            else:
                current_result['sub-m3'] = missing_text
        
        return current_result
    
    def _empty_subslots(self):
        """ç©ºã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ """
        return {
            'sub-m1': '',
            'sub-s': '',
            'sub-aux': '',
            'sub-m2': '',
            'sub-v': '',
            'sub-c1': '',
            'sub-o1': '',
            'sub-o2': '',
            'sub-c2': '',
            'sub-m3': ''
        }


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    engine = CompleteSpacyRephraseEngine()
    
    print('ğŸ¯ spaCyä¾å­˜é–¢ä¿‚45å€‹å®Œå…¨å¯¾å¿œ çµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ')
    print('=' * 100)
    
    # ãƒ•ãƒ«ã‚»ãƒƒãƒˆã®é‡è¦ä¾‹æ–‡ã§ãƒ†ã‚¹ãƒˆ
    test_cases = [
        "although it was emotionally hard",
        "that he had been trying to avoid Tom",
        "the woman who seemed indecisive",
        "because he was afraid of hurting her feelings",
        "the manager who had recently taken charge of the project"
    ]
    
    for phrase in test_cases:
        print(f'\n' + '='*80)
        print(f'ğŸ“‹ å…¥åŠ›: "{phrase}"')
        result = engine.decompose(phrase)
        
        print('\nâœ… åˆ†è§£çµæœ:')
        for key, value in result.items():
            if value:
                print(f'  {key:8}: "{value}"')
        
        # å˜èªä¿å…¨ç¢ºèª
        original_words = len(phrase.split())
        covered_words = sum(len(v.split()) for v in result.values() if v)
        
        print(f'\nğŸ“Š å˜èªä¿å…¨: {original_words}èª â†’ {covered_words}èª', end='')
        if original_words == covered_words:
            print(' âœ… 100%ä¿å…¨')
        else:
            print(' âŒ å˜èªæ•°ä¸ä¸€è‡´')
