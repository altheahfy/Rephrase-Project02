#!/usr/bin/env python3
"""
äººé–“æ–‡æ³•èªè­˜çµæœæ¯”è¼ƒãƒ„ãƒ¼ãƒ«
========================

äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®53ä¾‹æ–‡ãƒ†ã‚¹ãƒˆçµæœã‚’æœŸå¾…å€¤ã¨æ¯”è¼ƒã—ã€
è©³ç´°ãªç²¾åº¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

ä½¿ç”¨æ³•:
    python compare_human_grammar_results.py
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime

def normalize_slot_data(data: Any) -> Dict[str, Any]:
    """
    ã‚¹ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€å½¢å¼ã«æ­£è¦åŒ–
    """
    if isinstance(data, dict):
        # ã™ã§ã«nestedå½¢å¼ã®å ´åˆï¼ˆexpectedå€¤ï¼‰
        if "main_slots" in data and "sub_slots" in data:
            return data
        
        # ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›å½¢å¼ã®å ´åˆ
        if "main_slots" in data:
            return {
                "main_slots": data.get("main_slots", {}),
                "sub_slots": data.get("sub_slots", {})
            }
        
        # flatå½¢å¼ã‚’nestedå½¢å¼ã«å¤‰æ›
        main_slots = {}
        sub_slots = {}
        
        for key, value in data.items():
            if key.startswith("sub-"):
                sub_slots[key] = value
            elif key in ["S", "V", "O1", "O2", "C1", "C2", "Aux", "M1", "M2", "M3", "Adv"]:
                main_slots[key] = value
                
        return {"main_slots": main_slots, "sub_slots": sub_slots}
    
    return {"main_slots": {}, "sub_slots": {}}

def normalize_value(value: str) -> str:
    """å€¤ã®æ­£è¦åŒ–"""
    if not value:
        return ""
    return str(value).strip()

def compare_slots(actual: Dict[str, str], expected: Dict[str, str], slot_type: str) -> Tuple[bool, List[str]]:
    """ã‚¹ãƒ­ãƒƒãƒˆã®æ¯”è¼ƒ"""
    errors = []
    
    # æœŸå¾…å€¤ã®å…¨ã‚¹ãƒ­ãƒƒãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    for slot, expected_value in expected.items():
        actual_value = actual.get(slot, "")
        
        expected_norm = normalize_value(expected_value)
        actual_norm = normalize_value(actual_value)
        
        if expected_norm != actual_norm:
            errors.append(f"{slot_type}[{slot}]: æœŸå¾…å€¤='{expected_norm}', å®Ÿéš›å€¤='{actual_norm}'")
    
    # å®Ÿéš›å€¤ã«ä½™åˆ†ãªã‚¹ãƒ­ãƒƒãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    for slot, actual_value in actual.items():
        if slot not in expected and normalize_value(actual_value):
            errors.append(f"{slot_type}[{slot}]: äºˆæœŸã—ãªã„å€¤='{normalize_value(actual_value)}'")
    
    return len(errors) == 0, errors

def compare_human_grammar_results():
    """äººé–“æ–‡æ³•èªè­˜ã®çµæœã‚’æœŸå¾…å€¤ã¨æ¯”è¼ƒ"""
    
    print("=" * 80)
    print("ğŸ§  äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ çµæœæ¯”è¼ƒåˆ†æ")
    print("=" * 80)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
    project_root = Path(__file__).parent
    results_file = project_root / "human_grammar_test_results.json"
    expected_file = project_root / "final_test_system" / "final_54_test_data.json"
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not results_file.exists():
        print(f"âŒ çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {results_file}")
        print("   å…ˆã«human_grammar_53_test.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    
    if not expected_file.exists():
        print(f"âŒ æœŸå¾…å€¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_file}")
        return
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open(results_file, 'r', encoding='utf-8') as f:
        results_data = json.load(f)
    
    with open(expected_file, 'r', encoding='utf-8') as f:
        expected_data = json.load(f)
    
    results = results_data['results']
    expected_dict = {case['sentence']: case for case in expected_data['data'].values()}
    
    print(f"ğŸ“Š æ¯”è¼ƒå¯¾è±¡: {len(results)}æ–‡")
    print(f"ğŸ“Š æœŸå¾…å€¤ãƒ‡ãƒ¼ã‚¿: {len(expected_dict)}æ–‡")
    print()
    
    # æ¯”è¼ƒå‡¦ç†
    total_count = 0
    perfect_matches = 0
    main_slot_errors = 0
    sub_slot_errors = 0
    missing_sentences = 0
    
    detailed_results = []
    
    for result in results:
        sentence = result['sentence']
        total_count += 1
        
        if sentence not in expected_dict:
            print(f"âš ï¸  æœŸå¾…å€¤ãªã—: {sentence}")
            missing_sentences += 1
            continue
        
        expected = expected_dict[sentence]['expected']
        
        # å®Ÿéš›å€¤ã¨æœŸå¾…å€¤ã‚’æ­£è¦åŒ–
        actual_norm = normalize_slot_data(result)
        expected_norm = normalize_slot_data(expected)
        
        # ä¸»ç¯€ã‚¹ãƒ­ãƒƒãƒˆæ¯”è¼ƒ
        main_match, main_errors = compare_slots(
            actual_norm['main_slots'], 
            expected_norm['main_slots'], 
            "ä¸»ç¯€"
        )
        
        # é–¢ä¿‚ç¯€ã‚¹ãƒ­ãƒƒãƒˆæ¯”è¼ƒ
        sub_match, sub_errors = compare_slots(
            actual_norm['sub_slots'], 
            expected_norm['sub_slots'], 
            "é–¢ä¿‚ç¯€"
        )
        
        # å®Œå…¨ä¸€è‡´åˆ¤å®š
        is_perfect = main_match and sub_match
        
        if is_perfect:
            perfect_matches += 1
        else:
            if not main_match:
                main_slot_errors += 1
            if not sub_match:
                sub_slot_errors += 1
        
        # è©³ç´°çµæœè¨˜éŒ²
        detailed_results.append({
            'sentence': sentence,
            'perfect_match': is_perfect,
            'main_match': main_match,
            'sub_match': sub_match,
            'main_errors': main_errors,
            'sub_errors': sub_errors,
            'actual_main': actual_norm['main_slots'],
            'expected_main': expected_norm['main_slots'],
            'actual_sub': actual_norm['sub_slots'],
            'expected_sub': expected_norm['sub_slots'],
            'processing_time': result.get('processing_time', 0),
            'has_error': 'error' in result
        })
    
    # çµ±è¨ˆæƒ…å ±å‡ºåŠ›
    print("=" * 80)
    print("ğŸ“ˆ åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    accuracy = (perfect_matches / total_count * 100) if total_count > 0 else 0
    print(f"âœ… å®Œå…¨ä¸€è‡´: {perfect_matches}/{total_count} ({accuracy:.1f}%)")
    print(f"âŒ ä¸»ç¯€ã‚¨ãƒ©ãƒ¼: {main_slot_errors}/{total_count} ({main_slot_errors/total_count*100:.1f}%)")
    print(f"âŒ é–¢ä¿‚ç¯€ã‚¨ãƒ©ãƒ¼: {sub_slot_errors}/{total_count} ({sub_slot_errors/total_count*100:.1f}%)")
    
    if missing_sentences > 0:
        print(f"âš ï¸  æœŸå¾…å€¤ä¸æ˜: {missing_sentences}æ–‡")
    
    # ã‚¨ãƒ©ãƒ¼æ–‡ã®è©³ç´°è¡¨ç¤º
    error_cases = [r for r in detailed_results if not r['perfect_match']]
    
    if error_cases:
        print()
        print("=" * 80)
        print("ğŸ” ã‚¨ãƒ©ãƒ¼æ–‡è©³ç´°åˆ†æ")
        print("=" * 80)
        
        for i, case in enumerate(error_cases[:10], 1):  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
            print(f"\nã€ã‚¨ãƒ©ãƒ¼ {i}ã€‘ {case['sentence']}")
            
            if case['main_errors']:
                print("  ä¸»ç¯€ã‚¨ãƒ©ãƒ¼:")
                for error in case['main_errors']:
                    print(f"    â€¢ {error}")
            
            if case['sub_errors']:
                print("  é–¢ä¿‚ç¯€ã‚¨ãƒ©ãƒ¼:")
                for error in case['sub_errors']:
                    print(f"    â€¢ {error}")
            
            if case['has_error']:
                print("  âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã‚ã‚Š")
        
        if len(error_cases) > 10:
            print(f"\n... ä»–{len(error_cases) - 10}ä»¶ã®ã‚¨ãƒ©ãƒ¼ã‚ã‚Š")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    processing_times = [r['processing_time'] for r in detailed_results if not r['has_error']]
    if processing_times:
        avg_time = sum(processing_times) / len(processing_times)
        max_time = max(processing_times)
        min_time = min(processing_times)
        
        print()
        print("=" * 80)
        print("â±ï¸  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        print("=" * 80)
        print(f"å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.4f}ç§’")
        print(f"æœ€å¤§å‡¦ç†æ™‚é–“: {max_time:.4f}ç§’")
        print(f"æœ€å°å‡¦ç†æ™‚é–“: {min_time:.4f}ç§’")
    
    # ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çŠ¶æ³åˆ†æ
    print()
    print("=" * 80)
    print("ğŸ¯ ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£çŠ¶æ³åˆ†æ")
    print("=" * 80)
    
    has_main_slots = sum(1 for r in detailed_results if r['actual_main'])
    has_sub_slots = sum(1 for r in detailed_results if r['actual_sub'])
    no_slots = sum(1 for r in detailed_results if not r['actual_main'] and not r['actual_sub'])
    
    print(f"ä¸»ç¯€ã‚¹ãƒ­ãƒƒãƒˆæ¤œå‡º: {has_main_slots}/{total_count} ({has_main_slots/total_count*100:.1f}%)")
    print(f"é–¢ä¿‚ç¯€ã‚¹ãƒ­ãƒƒãƒˆæ¤œå‡º: {has_sub_slots}/{total_count} ({has_sub_slots/total_count*100:.1f}%)")
    print(f"ã‚¹ãƒ­ãƒƒãƒˆæœªæ¤œå‡º: {no_slots}/{total_count} ({no_slots/total_count*100:.1f}%)")
    
    # æ¨å¥¨æ”¹å–„ç­–
    print()
    print("=" * 80)
    print("ğŸ’¡ æ¨å¥¨æ”¹å–„ç­–")
    print("=" * 80)
    
    if accuracy < 50:
        print("ğŸ”´ é‡å¤§: ç²¾åº¦ãŒ50%æœªæº€ã§ã™")
        print("   â€¢ åŸºæœ¬5æ–‡å‹ã®äººé–“æ–‡æ³•èªè­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®å®Ÿè£…ãŒå¿…è¦")
        print("   â€¢ ç¾åœ¨ã®3ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã§ã¯å¯¾å¿œç¯„å›²ãŒé™å®šçš„")
    elif accuracy < 80:
        print("ğŸŸ¡ æ³¨æ„: ç²¾åº¦æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™")
        print("   â€¢ ç‰¹å®šã®æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èªè­˜ç²¾åº¦å‘ä¸Š")
        print("   â€¢ ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®è©³ç´°åˆ†æã¨å¯¾ç­–")
    else:
        print("ğŸŸ¢ è‰¯å¥½: äººé–“æ–‡æ³•èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã¯æœŸå¾…é€šã‚Šã«å‹•ä½œã—ã¦ã„ã¾ã™")
    
    if no_slots > total_count * 0.5:
        print("   â€¢ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºç¯„å›²ã®æ‹¡å¼µãŒæ€¥å‹™")
        print("   â€¢ åŸºæœ¬æ–‡å‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®å„ªå…ˆå®Ÿè£…ã‚’æ¨å¥¨")
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    report_file = project_root / f"human_grammar_comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    report_data = {
        'meta': {
            'comparison_timestamp': datetime.now().isoformat(),
            'total_sentences': total_count,
            'perfect_matches': perfect_matches,
            'accuracy_percentage': accuracy,
            'main_slot_errors': main_slot_errors,
            'sub_slot_errors': sub_slot_errors
        },
        'detailed_results': detailed_results
    }
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")

if __name__ == "__main__":
    compare_human_grammar_results()
