#!/usr/bin/env python3
"""
Stanzaæº–æ‹ å¾“å±æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆçµ±åˆå‹ï¼‰
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æœ€å°åŒ–ã—ã€Stanzaã®æ§‹é€ è§£æã«ä¾å­˜

çµ±åˆå‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼:
1. ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆé…ç½® + ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ã‚’å˜ä¸€ã‚¨ãƒ³ã‚¸ãƒ³ã§å‡¦ç†
2. å¾“å±ç¯€ï¼šM1,M2,M3ä½ç½®ï¼ˆæ„å‘³åˆ†é¡åˆ¥ï¼‰ + sub-vï¼ˆå¾“å±ç¯€å‹•è©ã®ã¿ï¼‰
3. Rephraseãƒ«ãƒ¼ãƒ«æº–æ‹ ï¼šå¤§æ–‡å­—ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆ + å°æ–‡å­—ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ
4. æƒ…å ±ä¿æŒã¨ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡ã®ä¸¡ç«‹
"""

import stanza
from typing import Dict, List, Optional, Any

class StanzaBasedConjunctionEngine:
    """Stanzaæ§‹é€ è§£ææº–æ‹ ã®æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆçµ±åˆå‹ï¼‰"""
    
    def __init__(self):
        print("ğŸš€ Stanzaæº–æ‹ æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...")
        self.nlp = stanza.Pipeline('en', verbose=False)
        
        # æœ€å°é™ã®æ„å‘³åˆ†é¡ï¼ˆèªå½™çš„çŸ¥è­˜ã¨ã—ã¦å¿…è¦ï¼‰+ ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆé…ç½®
        self.semantic_mapping = {
            # ç†ç”± -> M1ä½ç½®
            'because': 'M1', 'since': 'M1', 'as': 'M1',
            # æ¡ä»¶ -> M1ä½ç½®  
            'if': 'M1', 'unless': 'M1', 'provided': 'M1',
            # è­²æ­© -> M2ä½ç½®
            'although': 'M2', 'though': 'M2', 'whereas': 'M2',
            # æ™‚é–“ -> M3ä½ç½®
            'when': 'M3', 'while': 'M3', 'after': 'M3', 'before': 'M3', 'until': 'M3'
        }
        print("âœ… åˆæœŸåŒ–å®Œäº†")
    
    def process(self, text: str) -> Dict[str, str]:
        """çµ±åˆå‹ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        print(f"ğŸ” å¾“å±æ¥ç¶šè©æ§‹æ–‡è§£æ: '{text}'")
        
        doc = self.nlp(text)
        sent = doc.sentences[0]
        
        # å¾“å±ç¯€æ¤œå‡º
        subordinate_info = self._analyze_subordinate_structure(sent)
        if subordinate_info:
            return self._process_complete_subordinate_construction(sent, subordinate_info)
        else:
            return self._process_simple_sentence(sent)
    
    def _analyze_subordinate_structure(self, sent) -> Optional[Dict]:
        """å¾“å±ç¯€æ§‹é€ ã®çµ±åˆåˆ†æ"""
        # marké–¢ä¿‚ã®æ¥ç¶šè©ã‚’æ¢ã™
        for word in sent.words:
            if word.deprel == 'mark' and word.text.lower() in self.semantic_mapping:
                # æ¥ç¶šè©ãŒä¿®é£¾ã™ã‚‹å¾“å±ç¯€å‹•è©ã‚’æ¢ã™
                subordinate_verb = sent.words[word.head - 1] if word.head > 0 else None
                
                # ä¸»ç¯€å‹•è©ã‚’æ¢ã™
                main_verb = None
                if subordinate_verb and subordinate_verb.deprel == 'advcl':
                    main_verb = sent.words[subordinate_verb.head - 1] if subordinate_verb.head > 0 else None
                
                structure_info = {
                    'conjunction': word,
                    'subordinate_verb': subordinate_verb,
                    'main_verb': main_verb,
                    'conjunction_type': word.text.lower(),
                    'semantic_slot': self.semantic_mapping[word.text.lower()]
                }
                
                print(f"  ğŸ“‹ å¾“å±ç¯€æ¤œå‡º:")
                print(f"    æ¥ç¶šè©: {word.text} ({word.deprel})")
                print(f"    å¾“å±å‹•è©: {subordinate_verb.text if subordinate_verb else '?'}")
                print(f"    ä¸»å‹•è©: {main_verb.text if main_verb else '?'}")
                print(f"    æ„å‘³åˆ†é¡: {structure_info['semantic_slot']}")
                return structure_info
        
        return None
    
    def _process_complete_subordinate_construction(self, sent, subordinate_info) -> Dict[str, str]:
        """å¾“å±æ¥ç¶šè©æ§‹æ–‡ã®å®Œå…¨å‡¦ç† - çµ±åˆå‹"""
        result = {}
        conjunction = subordinate_info['conjunction']
        subordinate_verb = subordinate_info['subordinate_verb']
        main_verb = subordinate_info['main_verb']
        semantic_slot = subordinate_info['semantic_slot']
        
        print(f"  ğŸ¯ çµ±åˆå‡¦ç†é–‹å§‹: {semantic_slot}ä½ç½®å¾“å±ç¯€")
        
        # ä¸»ç¯€ã®å‡¦ç†
        if main_verb:
            main_elements = self._extract_main_clause_elements(sent, main_verb, [subordinate_verb, conjunction])
            result.update(main_elements)
        
        # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆé…ç½® + ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£
        # å¾“å±ç¯€å…¨ä½“ã‚’æ„å‘³åˆ†é¡ã«å¿œã˜ãŸä½ç½®ã«é…ç½®
        subordinate_clause = self._build_subordinate_clause(sent, conjunction, subordinate_verb)
        result[semantic_slot] = subordinate_clause
        
        # å¾“å±ç¯€å‹•è©ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«
        subordinate_verb_phrase = self._build_subordinate_verb_phrase(sent, subordinate_verb)
        result['sub-v'] = subordinate_verb_phrase
        
        print(f"    ä¸Šä½é…ç½®: {semantic_slot} = '{subordinate_clause}'")
        print(f"    ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆé…ç½®: sub-v = '{subordinate_verb_phrase}'")
        print(f"  âœ… çµ±åˆå‹å®Œå…¨åˆ†è§£: {result}")
        return result
    
    def _build_subordinate_clause(self, sent, conjunction, subordinate_verb):
        """å¾“å±ç¯€å…¨ä½“ã®æ§‹ç¯‰"""
        if not subordinate_verb:
            return conjunction.text
        
        # æ¥ç¶šè©ã‹ã‚‰å¾“å±ç¯€çµ‚äº†ã¾ã§
        start_idx = conjunction.id - 1
        
        # å¾“å±ç¯€ã®ç¯„å›²ã‚’ç‰¹å®š
        sub_words = self._get_subordinate_clause_words(sent, subordinate_verb)
        if sub_words:
            end_idx = max(w.id - 1 for w in sub_words)
            # æ¥ç¶šè©ã‚‚å«ã‚ã‚‹
            if conjunction not in sub_words:
                sub_words.append(conjunction)
            clause_words = sorted(sub_words, key=lambda x: x.id)
            return ' '.join(w.text for w in clause_words)
        
        return f"{conjunction.text} {subordinate_verb.text}"
    
    def _build_subordinate_verb_phrase(self, sent, subordinate_verb):
        """å¾“å±ç¯€å‹•è©éƒ¨åˆ†ã®æ§‹ç¯‰"""
        if not subordinate_verb:
            return ""
        
        # å¾“å±å‹•è©ã¨ãã®ç›´æ¥çš„ãªä¿®é£¾èª
        verb_words = self._get_subordinate_clause_words(sent, subordinate_verb)
        if verb_words:
            return ' '.join(w.text for w in sorted(verb_words, key=lambda x: x.id))
        
        return subordinate_verb.text
    
    def _get_subordinate_clause_words(self, sent, subordinate_verb):
        """å¾“å±ç¯€ã«å±ã™ã‚‹å˜èªã‚’åé›†"""
        if not subordinate_verb:
            return []
        
        sub_words = [subordinate_verb]
        
        # å¾“å±å‹•è©ã®å­è¦ç´ ã‚’å†å¸°çš„ã«åé›†
        for word in sent.words:
            if word.head == subordinate_verb.id:
                sub_words.append(word)
                sub_words.extend(self._get_children(sent, word))
        
        return sub_words
    
    def _get_children(self, sent, parent):
        """æŒ‡å®šèªã®å­è¦ç´ ã‚’å†å¸°çš„ã«åé›†"""
        children = []
        for word in sent.words:
            if word.head == parent.id:
                children.append(word)
                children.extend(self._get_children(sent, word))
        return children
    
    def _extract_main_clause_elements(self, sent, main_verb, exclude_words=None):
        """ä¸»ç¯€è¦ç´ ã®æŠ½å‡º"""
        result = {}
        exclude_ids = set()
        if exclude_words:
            exclude_ids = {w.id for w in exclude_words if w}
        
        result['V'] = main_verb.text
        
        # ä¸»èª
        for word in sent.words:
            if word.head == main_verb.id and word.deprel == 'nsubj' and word.id not in exclude_ids:
                result['S'] = word.text
                break
        
        # ç›®çš„èªï¼ˆå¾“å±ç¯€ä»¥å¤–ï¼‰
        for word in sent.words:
            if word.head == main_verb.id and word.deprel == 'obj' and word.id not in exclude_ids:
                result['O1'] = word.text
                break
        
        # è£œèª
        for word in sent.words:
            if word.head == main_verb.id and word.deprel in ['xcomp', 'ccomp'] and word.id not in exclude_ids:
                result['C1'] = word.text
                break
        
        return result
    
    def _process_simple_sentence(self, sent):
        """å˜ç´”æ–‡ã®å‡¦ç†"""
        print("  ğŸ“ å˜ç´”æ–‡å‡¦ç†")
        result = {}
        
        # ãƒ«ãƒ¼ãƒˆå‹•è©ã‚’æ¢ã™
        main_verb = None
        for word in sent.words:
            if word.deprel == 'root' and word.upos == 'VERB':
                main_verb = word
                break
        
        if main_verb:
            result.update(self._extract_main_clause_elements(sent, main_verb))
        
        return result
                structure_info['advcl_word'] = word
                
            elif word.deprel == 'root':
                structure_info['main_verb'] = word
        
        # 2. å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        if structure_info['mark_word'] or structure_info['advcl_word']:
            print(f"  ğŸ“‹ å¾“å±æ§‹é€ æ¤œå‡º:")
            print(f"    æ¥ç¶šè©: {structure_info['mark_word'].text if structure_info['mark_word'] else '?'}")
            print(f"    å¾“å±å‹•è©: {structure_info['advcl_word'].text if structure_info['advcl_word'] else '?'}")
            print(f"    ä¸»å‹•è©: {structure_info['main_verb'].text if structure_info['main_verb'] else '?'}")
            return structure_info
        
        return None
    
    def _process_by_stanza_structure(self, sent, structure_info) -> Dict[str, str]:
        """Stanzaæ§‹é€ ã«åŸºã¥ãåˆ†è§£å‡¦ç†"""
        mark_word = structure_info['mark_word']
        advcl_word = structure_info['advcl_word']
        main_verb = structure_info['main_verb']
        conjunction_type = structure_info['conjunction_type']
        
        result = {}
        
        # å˜ç‹¬å¾“å±ç¯€ã®å ´åˆï¼ˆä¸»ç¯€ãªã—ã€ã¾ãŸã¯ advclæ¤œå‡ºãªã—ï¼‰
        if mark_word and (not main_verb or not advcl_word):
            print("  ğŸ“ å˜ç‹¬å¾“å±ç¯€å‡¦ç†")
            return self._process_single_subordinate_clause(sent, mark_word)
        
        # è¤‡åˆæ–‡ã®å ´åˆ
        if mark_word and advcl_word and main_verb:
            print(f"  ğŸ“ è¤‡åˆæ–‡å‡¦ç† (æ¥ç¶šè©ä½ç½®: {conjunction_type})")
            
            # å¾“å±ç¯€è¦ç´ ã®æŠ½å‡º
            sub_elements = self._extract_subordinate_elements(sent, advcl_word, mark_word)
            # ä¸»ç¯€è¦ç´ ã®æŠ½å‡º  
            main_elements = self._extract_main_elements(sent, main_verb)
            
            # Rephraseåˆ†è§£çµæœã®æ§‹ç¯‰
            result.update(sub_elements)
            result.update(main_elements)
            
            return result
        
        return {"error": "æ§‹é€ è§£æå¤±æ•—"}
    
    def _process_single_subordinate_clause(self, sent, mark_word) -> Dict[str, str]:
        """å˜ç‹¬å¾“å±ç¯€ã®å‡¦ç†"""
        result = {}
        
        # æ¥ç¶šè©
        conjunction_type = self.semantic_mapping.get(mark_word.lemma.lower(), 'M1')
        result[f"sub-{conjunction_type.lower()}"] = mark_word.text.lower()
        
        # å¾“å±ç¯€ã®å‹•è©ã‚’æ¢ã™
        subordinate_verb = None
        for word in sent.words:
            if word.upos in ['VERB', 'AUX'] and word.id > mark_word.id:
                subordinate_verb = word
                break
        
        if subordinate_verb:
            # å¾“å±ç¯€ã®è¦ç´ ã‚’æŠ½å‡º
            sub_elements = self._extract_clause_elements(sent, subordinate_verb, "sub-")
            result.update(sub_elements)
        
        print(f"  âœ… å˜ç‹¬å¾“å±ç¯€çµæœ: {result}")
        return result
    
    def _extract_subordinate_elements(self, sent, advcl_verb, mark_word) -> Dict[str, str]:
        """å¾“å±ç¯€è¦ç´ ã®æŠ½å‡º"""
        elements = {}
        
        # æ¥ç¶šè©ã®ä½ç½®åˆ†é¡
        conjunction_type = self.semantic_mapping.get(mark_word.lemma.lower(), 'M1')
        elements[f"sub-{conjunction_type.lower()}"] = mark_word.text.lower()
        
        # å¾“å±ç¯€ã®æ–‡æ³•è¦ç´ 
        clause_elements = self._extract_clause_elements(sent, advcl_verb, "sub-")
        elements.update(clause_elements)
        
        return elements
    
    def _extract_main_elements(self, sent, main_verb) -> Dict[str, str]:
        """ä¸»ç¯€è¦ç´ ã®æŠ½å‡º"""
        return self._extract_clause_elements(sent, main_verb, "")
    
    def _extract_clause_elements(self, sent, verb, prefix="") -> Dict[str, str]:
        """ç¯€ã®æ–‡æ³•è¦ç´ æŠ½å‡º"""
        elements = {}
        
        # å‹•è©å‘¨è¾ºã®ä¾å­˜é–¢ä¿‚ã‚’åˆ†æ
        for word in sent.words:
            if word.head == verb.id:
                if word.deprel == 'nsubj':
                    elements[f"{prefix}s"] = word.text
                elif word.deprel == 'obj':
                    elements[f"{prefix}o1"] = word.text
                elif word.deprel == 'iobj':
                    elements[f"{prefix}o2"] = word.text
                elif word.deprel == 'advmod':
                    elements[f"{prefix}m1"] = word.text
            elif word.id == verb.id:
                if word.upos == 'AUX':
                    elements[f"{prefix}aux"] = word.text
                elif word.upos == 'VERB':
                    elements[f"{prefix}v"] = word.text
                elif word.upos == 'ADJ':
                    elements[f"{prefix}c1"] = word.text
        
        return elements
    
    def _process_simple_sentence(self, sent) -> Dict[str, str]:
        """å˜ç´”æ–‡ã®å‡¦ç†"""
        print("  ğŸ“ å˜ç´”æ–‡å‡¦ç†")
        
        # rootå‹•è©ã‚’æ¢ã™
        main_verb = None
        for word in sent.words:
            if word.deprel == 'root':
                main_verb = word
                break
        
        if main_verb:
            return self._extract_clause_elements(sent, main_verb)
        
        return {"error": "å‹•è©æœªæ¤œå‡º"}

def test_stanza_based_engine():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    engine = StanzaBasedConjunctionEngine()
    
    test_cases = [
        "Because he is tired",
        "If you come tomorrow",
        "Although she tried hard",
        "When the bell rings",
        "Because he is tired, he went home",
        "If it rains, we stay inside"
    ]
    
    print("\n" + "="*50)
    print("ğŸ§ª Stanzaæº–æ‹ æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³ ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nã€Test {i}ã€‘ '{test}'")
        result = engine.process(test)
        
        print("ğŸ“Š çµæœ:")
        for key, value in result.items():
            print(f"  {key}: {value}")

if __name__ == "__main__":
    test_stanza_based_engine()
