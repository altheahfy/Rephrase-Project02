#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import stanza
import logging

def main():
    # Stanzaãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
    nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse')
    
    # åˆ†è©æ§‹æ–‡ã®ä¾‹æ–‡ã‚’è©³ç´°åˆ†æ
    sentences = [
        "The team working overtime completed the project successfully yesterday.",
        "The woman standing quietly near the door was waiting patiently.",
        "The documents being reviewed thoroughly will be approved soon."
    ]
    
    for i, sentence in enumerate(sentences, 1):
        print(f"\n=== Case {48+i}: {sentence} ===")
        doc = nlp(sentence)
        
        for word in doc.sentences[0].words:
            print(f"ID:{word.id:2} {word.text:12} | POS:{word.upos:4} | xPOS:{word.xpos:4} | HEAD:{word.head:2} | DEP:{word.deprel:10}")
        
        # VBGï¼ˆç¾åœ¨åˆ†è©ï¼‰ã‚’æ¢ã™
        print("\nğŸ” ç¾åœ¨åˆ†è©ï¼ˆVBGï¼‰ã®æ¤œå‡º:")
        for word in doc.sentences[0].words:
            if word.xpos == 'VBG':
                print(f"  VBG found: {word.text} (ID:{word.id}, HEAD:{word.head}, DEP:{word.deprel})")
                
                # åˆ†è©ã®ä¾å­˜èªã‚’ç¢ºèª
                dependents = [w for w in doc.sentences[0].words if w.head == word.id]
                if dependents:
                    print(f"    Dependents: {[f'{w.text}({w.deprel})' for w in dependents]}")
        
        # beingã®æ¤œå‡º
        print("\nğŸ” being + éå»åˆ†è©ã®æ¤œå‡º:")
        for word in doc.sentences[0].words:
            if word.text.lower() == 'being':
                print(f"  being found: {word.text} (ID:{word.id}, HEAD:{word.head}, DEP:{word.deprel})")
                
                # beingã®ä¾å­˜èªã‚’ç¢ºèª
                dependents = [w for w in doc.sentences[0].words if w.head == word.id]
                if dependents:
                    print(f"    Dependents: {[f'{w.text}({w.deprel})' for w in dependents]}")

if __name__ == "__main__":
    main()
