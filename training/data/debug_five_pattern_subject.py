#!/usr/bin/env python3
"""
5æ–‡å‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä¸»èªæ¤œå‡ºãƒ‡ãƒãƒƒã‚°
=====================================

å•é¡Œ: "She quickly runs to school." ã§ä¸»èª 'She' ãŒO1ã¨ã—ã¦èª¤èªè­˜ã•ã‚Œã‚‹
åŸå› èª¿æŸ»: 5æ–‡å‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã® _find_subject ã¨ _assign_grammar_roles ã‚’è©³ç´°æ¤œè¨¼

æœŸå¾…: S='She', M1='quickly', V='runs', M2='to school'
å®Ÿéš›: O1='She', M1='quickly', V='runs', M2='to school'
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from dynamic_grammar_mapper import DynamicGrammarMapper
import spacy

def debug_five_pattern_subject():
    """5æ–‡å‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä¸»èªæ¤œå‡ºã‚’æ®µéšçš„ã«ãƒ‡ãƒãƒƒã‚°"""
    
    print("=== 5æ–‡å‹ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ä¸»èªæ¤œå‡ºãƒ‡ãƒãƒƒã‚° ===")
    
    # ãƒ†ã‚¹ãƒˆæ–‡
    sentence = "She quickly runs to school."
    print(f"å¯¾è±¡æ–‡: {sentence}")
    
    # DynamicGrammarMapperã‚’åˆæœŸåŒ–
    mapper = DynamicGrammarMapper()
    
    # spaCyè§£æ
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(sentence)
    
    print("\n--- spaCyè§£æçµæœ ---")
    for token in doc:
        print(f"Token: '{token.text}' | POS: {token.pos_} | Tag: {token.tag_} | Dep: {token.dep_} | Head: {token.head.text}")
    
    # ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆå¤‰æ›
    tokens = [
        {
            'text': token.text,
            'lemma': token.lemma_,
            'pos': token.pos_,
            'tag': token.tag_,
            'dep': token.dep_,
            'head': token.head.text if token.head != token else 'ROOT'
        }
        for token in doc
    ]
    
    print("\n--- ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆ ---")
    for i, token in enumerate(tokens):
        print(f"[{i}] {token}")
    
    # Step 1: _identify_core_elements ã§ã®ä¸»èªæ¤œå‡º
    print("\n--- Step 1: _identify_core_elements ---")
    core_elements = mapper._identify_core_elements(tokens)
    
    print(f"Subject: {core_elements.get('subject')}")
    print(f"Subject indices: {core_elements.get('subject_indices')}")
    print(f"Verb: {core_elements.get('verb')}")
    print(f"Verb indices: {core_elements.get('verb_indices')}")
    
    # Step 2: _find_subject ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
    print("\n--- Step 2: _find_subject ç›´æ¥ãƒ†ã‚¹ãƒˆ ---")
    verb_idx = core_elements.get('verb_indices', [0])[0] if core_elements.get('verb_indices') else 2  # 'runs'ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    subject_indices = mapper._find_subject(tokens, verb_idx)
    
    print(f"å‹•è©ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {verb_idx} ('{tokens[verb_idx]['text']}')")
    print(f"æ¤œå‡ºã•ã‚ŒãŸä¸»èªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {subject_indices}")
    if subject_indices:
        subject_text = ' '.join([tokens[i]['text'] for i in subject_indices])
        print(f"ä¸»èªãƒ†ã‚­ã‚¹ãƒˆ: '{subject_text}'")
    
    # Step 3: æ–‡å‹åˆ¤å®š
    print("\n--- Step 3: æ–‡å‹åˆ¤å®š ---")
    pattern = mapper._determine_sentence_pattern(core_elements, tokens)
    print(f"åˆ¤å®šã•ã‚ŒãŸæ–‡å‹: {pattern}")
    
    # Step 4: _assign_grammar_roles ã§ã®æœ€çµ‚é…ç½®
    print("\n--- Step 4: _assign_grammar_roles ---")
    elements = mapper._assign_grammar_roles(tokens, pattern, core_elements)
    
    print("æœ€çµ‚çš„ãªæ–‡æ³•è¦ç´ :")
    for element in elements:
        print(f"  Role: {element.role} | Text: '{element.text}' | Indices: {element.start_idx}-{element.end_idx}")
    
    # Step 5: æœ€çµ‚çµæœã®ç¢ºèª
    print("\n--- Step 5: æœ€çµ‚çµæœå¤‰æ› ---")
    result = mapper._convert_to_rephrase_format(elements, pattern)
    main_slots = result.get('main_slots', {})
    
    print("ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ:")
    for slot, text in main_slots.items():
        print(f"  {slot}: '{text}'")
    
    # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
    expected = {'S': 'She', 'M1': 'quickly', 'V': 'runs', 'M2': 'to school'}
    print(f"\n--- æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ ---")
    print(f"æœŸå¾…: {expected}")
    print(f"å®Ÿéš›: {main_slots}")
    
    # å•é¡Œç®‡æ‰€ã®ç‰¹å®š
    issues = []
    if main_slots.get('S') != expected.get('S'):
        issues.append(f"ä¸»èªä¸ä¸€è‡´: å®Ÿéš›='{main_slots.get('S')}', æœŸå¾…='{expected.get('S')}'")
    if 'O1' in main_slots and main_slots['O1'] == 'She':
        issues.append("ä¸»èª'She'ãŒç›®çš„èªO1ã¨ã—ã¦èª¤åˆ†é¡")
    
    if issues:
        print("ğŸ”¥ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")

if __name__ == "__main__":
    debug_five_pattern_subject()
