import spacy
import pandas as pd
from collections import defaultdict
import re

class Step18UnifiedRephraseSystem:
    """
    Step18: spaCy45å€‹ä¾å­˜é–¢ä¿‚å®Œå…¨å¯¾å¿œ çµ±ä¸€Rephraseã‚·ã‚¹ãƒ†ãƒ 
    - 8ã‚¹ãƒ­ãƒƒãƒˆçµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³é©ç”¨ (M1, S, M2, C1, O1, O2, C2, M3)
    - 2ã‚¹ãƒ­ãƒƒãƒˆå˜ä¸€è¦ç´ å‡¦ç† (Aux, V)
    - ãƒ•ãƒ«ã‚»ãƒƒãƒˆ12ä¾‹æ–‡å¯¾å¿œ
    - Excelç”Ÿæˆæ©Ÿèƒ½æ­è¼‰
    """
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        
        # spaCyä¾å­˜é–¢ä¿‚45å€‹ â†’ Rephraseã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå®Œå…¨ãƒãƒƒãƒ”ãƒ³ã‚°
        self.dep_to_subslot = {
            # ä¸»èªé–¢é€£
            'nsubj': 'sub-s',           # åè©ä¸»èª
            'nsubjpass': 'sub-s',       # å—å‹•æ…‹ä¸»èª
            'csubj': 'sub-s',           # ç¯€ä¸»èª
            'csubjpass': 'sub-s',       # å—å‹•ç¯€ä¸»èª
            'expl': 'sub-s',            # è™šè¾ä¸»èª(there, it)
            
            # å‹•è©ãƒ»è¿°èªé–¢é€£
            'ROOT': 'sub-v',            # ä¸»å‹•è©
            'cop': 'sub-v',             # ã‚³ãƒ”ãƒ¥ãƒ©(beå‹•è©)
            'aux': 'sub-aux',           # åŠ©å‹•è©
            'auxpass': 'sub-aux',       # å—å‹•æ…‹åŠ©å‹•è©
            
            # ç›®çš„èªé–¢é€£
            'dobj': 'sub-o1',           # ç›´æ¥ç›®çš„èª
            'iobj': 'sub-o2',           # é–“æ¥ç›®çš„èª
            'pobj': 'sub-o1',           # å‰ç½®è©ç›®çš„èª
            'dative': 'sub-o2',         # ä¸æ ¼ç›®çš„èª
            
            # è£œèªé–¢é€£
            'attr': 'sub-c1',           # å±æ€§è£œèª
            'acomp': 'sub-c1',          # å½¢å®¹è©è£œèª
            'pcomp': 'sub-c1',          # å‰ç½®è©è£œèª
            'xcomp': 'sub-c2',          # é–‹æ”¾è£œèª
            'ccomp': 'sub-c2',          # ç¯€è£œèª
            'oprd': 'sub-c1',           # ç›®çš„èªè¿°èª
            
            # ä¿®é£¾èªé–¢é€£ï¼ˆM1/M2/M3ï¼‰
            'advmod': 'sub-m2',         # å‰¯è©ä¿®é£¾
            'amod': 'sub-m2',           # å½¢å®¹è©ä¿®é£¾
            'npadvmod': 'sub-m3',       # åè©å¥å‰¯è©ä¿®é£¾
            'tmod': 'sub-m3',           # æ™‚é–“ä¿®é£¾
            'nummod': 'sub-m2',         # æ•°è©ä¿®é£¾
            'quantmod': 'sub-m2',       # é‡è©ä¿®é£¾
            
            # æ¥ç¶šè©ãƒ»æ¨™è­˜é–¢é€£
            'mark': 'sub-m1',           # å¾“å±æ¥ç¶šè©(although, thatç­‰)
            'cc': 'sub-m1',             # ç­‰ä½æ¥ç¶šè©
            'preconj': 'sub-m1',        # å‰æ¥ç¶šè©
            
            # ç¯€ãƒ»å¥é–¢é€£
            'advcl': 'sub-m3',          # å‰¯è©ç¯€
            'relcl': 'sub-m3',          # é–¢ä¿‚ç¯€
            'acl': 'sub-m3',            # ç¯€ä¿®é£¾èª
            'prt': 'sub-m3',            # åŠ©è©
            
            # å‰ç½®è©é–¢é€£
            'prep': 'sub-m3',           # å‰ç½®è©
            'poss': 'sub-m2',           # æ‰€æœ‰æ ¼
            'possessive': 'sub-m2',     # æ‰€æœ‰æ ¼ãƒãƒ¼ã‚«ãƒ¼
            
            # ãã®ä»–é‡è¦ãªé–¢ä¿‚
            'agent': 'sub-s',           # å‹•ä½œä¸»
            'neg': 'sub-m2',            # å¦å®š
            'det': 'sub-m2',            # é™å®šè©
            'predet': 'sub-m2',         # å‰é™å®šè©
            'appos': 'sub-m3',          # åŒæ ¼
            'compound': 'sub-m2',       # è¤‡åˆèª
            'conj': 'sub-m3',           # æ¥ç¶šé …
            'discourse': 'sub-m1',      # è«‡è©±æ¨™è­˜
            'vocative': 'sub-m1',       # å‘¼æ ¼
            'intj': 'sub-m1',           # é–“æŠ•è©
            'meta': 'sub-m3',           # ãƒ¡ã‚¿æƒ…å ±
            'parataxis': 'sub-m3',      # ä¸¦åˆ—æ§‹é€ 
            'punct': '',                # å¥èª­ç‚¹ï¼ˆé™¤å¤–ï¼‰
            'dep': 'sub-m3'             # ãã®ä»–ä¾å­˜é–¢ä¿‚
        }
        
        # çµ±ä¸€åˆ†è§£å¯¾è±¡ã‚¹ãƒ­ãƒƒãƒˆ
        self.decomposable_slots = {'M1', 'S', 'M2', 'C1', 'O1', 'O2', 'C2', 'M3'}
        
        # å˜ä¸€è¦ç´ ã‚¹ãƒ­ãƒƒãƒˆ
        self.single_slots = {'Aux', 'V'}
    
    def process_sentence(self, sentence):
        """1ã¤ã®ä¾‹æ–‡ã‚’å®Œå…¨å‡¦ç†"""
        print(f"\nğŸ¯ Step18å‡¦ç†é–‹å§‹: '{sentence}'")
        
        # spaCyè§£æ
        doc = self.nlp(sentence)
        
        # ã‚¹ãƒ­ãƒƒãƒˆåˆ†å‰²ï¼ˆä»®æƒ³çš„ - å®Ÿéš›ã¯ä¸Šä½ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å—ã‘å–ã‚‹ï¼‰
        slot_phrases = self._extract_slot_phrases(sentence, doc)
        
        # å„ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†
        results = {}
        for slot_name, phrase in slot_phrases.items():
            if slot_name in self.single_slots:
                # å˜ä¸€è¦ç´ å‡¦ç†
                results[slot_name] = {slot_name.lower(): phrase}
            else:
                # çµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³é©ç”¨
                results[slot_name] = self._unified_decompose(phrase)
        
        return results
    
    def _extract_slot_phrases(self, sentence, doc):
        """ãƒ†ã‚¹ãƒˆç”¨ï¼šç°¡æ˜“ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º"""
        # å®Ÿéš›ã®é‹ç”¨ã§ã¯ä¸Šä½ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã‚¹ãƒ­ãƒƒãƒˆåˆ†å‰²æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹
        return {
            'S': 'the woman who seemed indecisive',
            'M2': 'although it was emotionally hard',
            'V': 'known',
            'O1': 'that he had been trying to avoid Tom',
            'M3': 'because he was afraid of hurting her feelings'
        }
    
    def _unified_decompose(self, phrase):
        """çµ±ä¸€åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ï¼š8ã‚¹ãƒ­ãƒƒãƒˆå…±é€š"""
        if not phrase or phrase.strip() == "":
            return self._empty_subslots()
        
        phrase = phrase.strip()
        doc = self.nlp(phrase)
        
        print(f"  ğŸ” çµ±ä¸€åˆ†è§£: '{phrase}'")
        
        # spaCyä¾å­˜é–¢ä¿‚è§£æ
        token_assignments = self._analyze_dependencies(doc)
        
        # Rephraseãƒ«ãƒ¼ãƒ«é©ç”¨
        result = self._apply_rephrase_rules(doc, token_assignments)
        
        # 100%å˜èªä¿å…¨ãƒã‚§ãƒƒã‚¯
        if not self._verify_complete_coverage(phrase, result):
            result = self._recover_missing_words(phrase, doc, result)
        
        return result
    
    def _analyze_dependencies(self, doc):
        """spaCyä¾å­˜é–¢ä¿‚è§£æ - é–¢ä¿‚ç¯€å‹•è©å¯¾å¿œå¼·åŒ–"""
        assignments = {}
        
        for token in doc:
            dep = token.dep_
            pos = token.pos_
            
            # ç‰¹åˆ¥å‡¦ç†: é–¢ä¿‚ç¯€å†…ã®å‹•è©
            if dep == 'relcl' and pos == 'VERB':
                target_subslot = 'sub-v'  # å‹•è©ã¨ã—ã¦èªè­˜
            elif dep in self.dep_to_subslot:
                target_subslot = self.dep_to_subslot[dep]
            else:
                continue
                
            if target_subslot:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆ
                assignments[token.i] = {
                    'token': token,
                    'subslot': target_subslot,
                    'text': token.text
                }
        
        return assignments
    
    def _apply_rephrase_rules(self, doc, assignments):
        """Rephraseãƒ«ãƒ¼ãƒ«é©ç”¨"""
        result = self._empty_subslots()
        subslot_tokens = defaultdict(list)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ¥ã«åˆ†é¡
        for token_idx, assignment in assignments.items():
            subslot = assignment['subslot']
            token = assignment['token']
            subslot_tokens[subslot].append(token)
        
    def _apply_rephrase_rules(self, doc, assignments):
        """Rephraseãƒ«ãƒ¼ãƒ«é©ç”¨ - å‹•è©å„ªå…ˆåº¦å¯¾å¿œå¼·åŒ–"""
        result = self._empty_subslots()
        subslot_tokens = defaultdict(list)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåˆ¥ã«åˆ†é¡
        for token_idx, assignment in assignments.items():
            subslot = assignment['subslot']
            token = assignment['token']
            subslot_tokens[subslot].append(token)
        
        # å„ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠãƒ»çµåˆ
        for subslot, tokens in subslot_tokens.items():
            if tokens:
                if subslot == 'sub-v':
                    # å‹•è©ã¯ç‰¹åˆ¥å‡¦ç†ï¼šæœ€ã‚‚é©åˆ‡ãª1ã¤ã‚’é¸æŠ
                    result[subslot] = self._select_best_verb(tokens)
                elif len(tokens) == 1:
                    # å˜ä¸€ãƒˆãƒ¼ã‚¯ãƒ³ï¼šæ‹¡å¼µã‚¹ãƒ‘ãƒ³é©ç”¨
                    result[subslot] = self._get_extended_span(tokens[0], doc)
                else:
                    # è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ï¼šé€£ç¶šã‚¹ãƒ‘ãƒ³æ§‹ç¯‰
                    tokens.sort(key=lambda t: t.i)
                    start_idx = tokens[0].i
                    end_idx = tokens[-1].i + 1
                    result[subslot] = doc[start_idx:end_idx].text
        
        return result
    
    def _select_best_verb(self, tokens):
        """å‹•è©ã®æœ€é©é¸æŠ"""
        # å‹•è©ã®å„ªå…ˆåº¦å®šç¾©
        verb_priority = {
            'relcl': 1,    # é–¢ä¿‚ç¯€å‹•è©ï¼ˆæœ€å„ªå…ˆï¼‰
            'ROOT': 2,     # ä¸»å‹•è©
            'cop': 3,      # ã‚³ãƒ”ãƒ¥ãƒ©
            'aux': 4       # åŠ©å‹•è©ï¼ˆä½å„ªå…ˆï¼‰
        }
        
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        sorted_tokens = sorted(tokens, 
                              key=lambda t: verb_priority.get(t.dep_, 999))
        
        # æœ€å„ªå…ˆã®å‹•è©ã‚’é¸æŠ
        best_token = sorted_tokens[0]
        return best_token.text
    
    def _get_extended_span(self, token, doc):
        """æ‹¡å¼µã‚¹ãƒ‘ãƒ³æ§‹ç¯‰ - é–¢ä¿‚ä»£åè©å¥å¯¾å¿œå¼·åŒ–"""
        # é–¢ä¿‚ä»£åè©ã‚’å«ã‚€ä¸»èªå¥ã®ç‰¹åˆ¥å‡¦ç†
        if token.dep_ == 'nsubj' and any(child.text.lower() in ['who', 'which', 'that'] for child in token.head.children):
            # é–¢ä¿‚ä»£åè©å¥å…¨ä½“ã‚’ä¸»èªã¨ã—ã¦èªè­˜
            span_tokens = []
            
            # ä¸»èªéƒ¨åˆ†ï¼ˆé–¢ä¿‚ä»£åè©ã‚ˆã‚Šå‰ï¼‰
            for t in doc:
                if t.i <= token.i:
                    span_tokens.append(t)
                else:
                    break
            
            # é–¢ä¿‚ä»£åè©ã‚’å«ã‚ã‚‹
            for child in token.head.children:
                if child.text.lower() in ['who', 'which', 'that'] and child.i > token.i:
                    span_tokens.append(child)
                    break
            
            if len(span_tokens) > 1:
                span_tokens.sort(key=lambda t: t.i)
                return doc[span_tokens[0].i:span_tokens[-1].i + 1].text
        
        # é€šå¸¸ã®æ‹¡å¼µã‚¹ãƒ‘ãƒ³å‡¦ç†
        span_tokens = [token]
        
        for child in token.children:
            if child.dep_ in ['det', 'amod', 'compound', 'poss']:
                span_tokens.append(child)
        
        if len(span_tokens) == 1:
            return token.text
        
        # é€£ç¶šã‚¹ãƒ‘ãƒ³ã‚’æ§‹ç¯‰
        span_tokens.sort(key=lambda t: t.i)
        start_idx = span_tokens[0].i
        end_idx = span_tokens[-1].i + 1
        return doc[start_idx:end_idx].text
    
    def _verify_complete_coverage(self, original, subslots):
        """100%å˜èªä¿å…¨ç¢ºèª"""
        original_words = set(w.lower() for w in original.split() if w.strip())
        covered_words = set()
        
        for value in subslots.values():
            if value and value.strip():
                covered_words.update(w.lower() for w in value.split() if w.strip())
        
        return original_words.issubset(covered_words)
    
    def _recover_missing_words(self, original, doc, current_result):
        """æ¬ è½å˜èªå›å¾©"""
        original_words = set(w.lower() for w in original.split())
        covered_words = set()
        
        for value in current_result.values():
            if value:
                covered_words.update(w.lower() for w in value.split())
        
        missing_words = original_words - covered_words
        
        if missing_words:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šsub-m3ã«è¿½åŠ 
            missing_text = ' '.join(missing_words)
            if current_result['sub-m3']:
                current_result['sub-m3'] += f" {missing_text}"
            else:
                current_result['sub-m3'] = missing_text
        
        return current_result
    
    def _empty_subslots(self):
        """ç©ºã®ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ """
        return {
            'sub-m1': '',
            'sub-s': '',
            'sub-aux': '',
            'sub-m2': '',
            'sub-v': '',
            'sub-c1': '',
            'sub-o1': '',
            'sub-o2': '',
            'sub-c2': '',
            'sub-m3': ''
        }
    
    def generate_excel_output(self, results, example_id="test"):
        """Excelå‡ºåŠ›å½¢å¼ç”Ÿæˆ"""
        excel_data = []
        
        for slot_name, slot_data in results.items():
            if slot_name in self.single_slots:
                # å˜ä¸€è¦ç´ ã‚¹ãƒ­ãƒƒãƒˆ
                excel_data.append({
                    'ä¾‹æ–‡ID': example_id,
                    'Slot': slot_name,
                    'SubslotID': '',
                    'SlotPhrase': slot_data[slot_name.lower()],
                    'SubslotElement': ''
                })
            else:
                # çµ±ä¸€åˆ†è§£ã‚¹ãƒ­ãƒƒãƒˆ
                # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆè¡Œ
                main_phrase = ' '.join([v for v in slot_data.values() if v])
                excel_data.append({
                    'ä¾‹æ–‡ID': example_id,
                    'Slot': slot_name,
                    'SubslotID': '',
                    'SlotPhrase': main_phrase,
                    'SubslotElement': ''
                })
                
                # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆè¡Œ
                for subslot_id, element in slot_data.items():
                    if element:
                        excel_data.append({
                            'ä¾‹æ–‡ID': example_id,
                            'Slot': slot_name,
                            'SubslotID': subslot_id,
                            'SlotPhrase': '',
                            'SubslotElement': element
                        })
        
        return excel_data


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    system = Step18UnifiedRephraseSystem()
    
    print('ğŸ¯ Step18çµ±ä¸€Rephraseã‚·ã‚¹ãƒ†ãƒ  - 5æ–‡å‹ãƒ•ãƒ«ã‚»ãƒƒãƒˆå…¨ä¾‹æ–‡å‡¦ç†')
    print('=' * 80)
    
    try:
        # 5æ–‡å‹ãƒ•ãƒ«ã‚»ãƒƒãƒˆExcelã‹ã‚‰å…¨ä¾‹æ–‡ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_excel('ï¼ˆå°æ–‡å­—åŒ–ã—ãŸæœ€åˆã®5æ–‡å‹ãƒ•ãƒ«ã‚»ãƒƒãƒˆï¼‰ä¾‹æ–‡å…¥åŠ›å…ƒ.xlsx')
        
        # ä¾‹æ–‡IDåˆ¥ã«åŸæ–‡ã‚’å–å¾—
        sentences = {}
        for _, row in df.iterrows():
            if pd.notna(row['ä¾‹æ–‡ID']) and pd.notna(row['åŸæ–‡']):
                if row['ä¾‹æ–‡ID'] not in sentences:
                    sentences[row['ä¾‹æ–‡ID']] = row['åŸæ–‡']
        
        print(f"ğŸ“‚ 5æ–‡å‹ãƒ•ãƒ«ã‚»ãƒƒãƒˆã‹ã‚‰{len(sentences)}å€‹ã®ä¾‹æ–‡ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
        
        # å„ä¾‹æ–‡ã‚’å‡¦ç†ï¼ˆæœ€åˆã®3ä¾‹æ–‡ã®ã¿ãƒ†ã‚¹ãƒˆï¼‰
        for i, (ex_id, sentence) in enumerate(list(sentences.items())[:3], 1):
            print(f"\n{'=' * 80}")
            print(f"ğŸ“‹ [{i}/3] å‡¦ç†ä¸­: {ex_id}")
            print(f"åŸæ–‡: {sentence}")
            print('=' * 80)
            
            # Step18ã§å‡¦ç†
            results = system.process_sentence(sentence)
            
            # çµæœè¡¨ç¤º
            print(f'\nâœ… {ex_id} å‡¦ç†çµæœ:')
            print('-' * 60)
            
            for slot_name, slot_data in results.items():
                if slot_data:  # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                    print(f'\nğŸ“‹ {slot_name}ã‚¹ãƒ­ãƒƒãƒˆ:')
                    if slot_name in system.single_slots:
                        for key, value in slot_data.items():
                            print(f'  {key}: "{value}"')
                    else:
                        for key, value in slot_data.items():
                            if value:
                                print(f'  {key:10}: "{value}"')
        
        print(f"\n{'=' * 80}")
        print("ğŸ¯ ãƒ†ã‚¹ãƒˆå‡¦ç†å®Œäº† - ã‚ˆã‚Šå¤šãã®ä¾‹æ–‡ã‚’å‡¦ç†ã™ã‚‹ã«ã¯åˆ¶é™ã‚’è§£é™¤ã—ã¦ãã ã•ã„")
        print('=' * 80)
        
    except Exception as e:
        print(f"âŒ Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ä¸€ãƒ†ã‚¹ãƒˆæ–‡ã§å‡¦ç†")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨å›ºå®šæ–‡
        test_sentence = "That afternoon at the crucial point in the presentation, the manager who had recently taken charge of the project had to make the committee responsible for implementation deliver the final proposal flawlessly even though he was under intense pressure so the outcome would reflect their full potential."
        
        print(f"ğŸ¯ Step18å‡¦ç†é–‹å§‹: '{test_sentence[:100]}...'")
        print("=" * 80)
        
        results = system.process_sentence(test_sentence)
        
        # çµæœè¡¨ç¤º
        print('\nâœ… å‡¦ç†çµæœ:')
        print('=' * 80)
    
    for slot_name, slot_data in results.items():
        print(f'\nğŸ“‹ {slot_name}ã‚¹ãƒ­ãƒƒãƒˆ:')
        if slot_name in system.single_slots:
            for key, value in slot_data.items():
                print(f'  {key}: "{value}"')
        else:
            for subslot, value in slot_data.items():
                if value:
                    print(f'  {subslot:10}: "{value}"')
    
    # Excelå‡ºåŠ›ãƒ†ã‚¹ãƒˆ
    print('\nğŸ“Š Excelå‡ºåŠ›å½¢å¼:')
    print('=' * 80)
    
    excel_data = system.generate_excel_output(results, "ex001")
    for row in excel_data[:10]:  # æœ€åˆã®10è¡Œ
        print(f"  {row}")
    
    print(f"\nğŸ“ˆ çµ±è¨ˆ:")
    print(f"  å‡¦ç†ã‚¹ãƒ­ãƒƒãƒˆæ•°: {len(results)}")
    print(f"  Excelå‡ºåŠ›è¡Œæ•°: {len(excel_data)}")
    print(f"  å˜ä¸€è¦ç´ ã‚¹ãƒ­ãƒƒãƒˆ: {len(system.single_slots)}")
    print(f"  åˆ†è§£å¯¾è±¡ã‚¹ãƒ­ãƒƒãƒˆ: {len(system.decomposable_slots)}")
