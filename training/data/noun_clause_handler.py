#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NounClauseHandler: åè©ç¯€å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
thatç¯€ãƒ»wh-ç¯€ãƒ»é–“æ¥ç–‘å•æ–‡ã®å°‚é–€åˆ†è§£
å°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼ˆå“è©åˆ†æ + ä¾å­˜é–¢ä¿‚ï¼‰
"""

import re
import spacy
from typing import Dict, Any, List, Tuple, Optional

class NounClauseHandler:
    """åè©ç¯€å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼‰"""
    
    def __init__(self, nlp_model=None, collaborators=None):
        """
        åˆæœŸåŒ–
        
        Args:
            nlp_model: spaCyãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            collaborators: å”åŠ›è€…ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¾æ›¸
             # åŠ©å‹•è©ã¨å¦å®šã‚’åŒæ™‚æ¤œå‡º
        aux_token = None
        neg_token = None
        for child in main_verb.children:
            if child.dep_ == 'aux':
                aux_token = child
                print(f"   åŠ©å‹•è©å€™è£œ: '{child.text}'")
            elif child.dep_ == 'neg':
                neg_token = child
                print(f"   å¦å®šå€™è£œ: '{child.text}'")
        
        if aux_token:
            # å¦å®šã®å ´åˆã¯çµåˆï¼ˆdoesn't, won'tç­‰ï¼‰
            aux_text = aux_token.text
            if neg_token:
                aux_text += neg_token.text
                print(f"   å¦å®šçµåˆ: '{aux_token.text}' + '{neg_token.text}' = '{aux_text}'")
            main_slots['Aux'] = aux_text
            print(f"   åŠ©å‹•è©æ¤œå‡º: '{aux_text}'")- 'adverb': AdverbHandlerï¼ˆä¿®é£¾èªåˆ†é›¢ï¼‰
                - 'five_pattern': BasicFivePatternHandlerï¼ˆ5æ–‡å‹åˆ†æï¼‰
                - 'passive': PassiveVoiceHandlerï¼ˆå—å‹•æ…‹ç†è§£ï¼‰
                - 'modal': ModalHandlerï¼ˆåŠ©å‹•è©å‡¦ç†ï¼‰
        """
        self.name = "NounClauseHandler"
        self.version = "v1.0"
        self.nlp = nlp_model if nlp_model is not None else spacy.load('en_core_web_sm')
        
        # å”åŠ›è€…ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŸã¡
        if collaborators:
            self.adverb_handler = collaborators.get('adverb')
            self.five_pattern_handler = collaborators.get('five_pattern')
            self.passive_handler = collaborators.get('passive')
            self.modal_handler = collaborators.get('modal')
        else:
            self.adverb_handler = None
            self.five_pattern_handler = None
            self.passive_handler = None
            self.modal_handler = None
        
        # åè©ç¯€æ¥ç¶šè©ãƒ»ç–‘å•è©ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.noun_clause_connectors = {
            'that_clause': ['that'],
            'wh_clause': ['what', 'who', 'whom', 'whose', 'which', 'where', 'when', 'why', 'how'],
            'whether_clause': ['whether'],
            'if_clause': ['if']
        }
    
    def _extract_full_phrase(self, token, doc):
        """
        Extract complete phrase including modifiers for a token
        
        Args:
            token: Main token
            doc: spaCy parsed document
            
        Returns:
            str: Complete phrase including modifiers
        """
        # List to collect phrase tokens
        phrase_tokens = []
        
        # Collect children of main token (modifiers, determiners, etc.)
        for child in token.children:
            if child.dep_ in ['amod', 'det', 'compound', 'nummod']:
                phrase_tokens.append((child.i, child.text))
        
        # Add main token
        phrase_tokens.append((token.i, token.text))
        
        # Sort by index to maintain natural word order
        phrase_tokens.sort(key=lambda x: x[0])
        
        # Build phrase
        phrase = ' '.join([text for _, text in phrase_tokens])
        
        return phrase
    
    def process(self, text: str, original_text: str = None) -> Dict[str, Any]:
        """
        åè©ç¯€å‡¦ç†ãƒ¡ã‚¤ãƒ³
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            original_text: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‚è€ƒç”¨ï¼‰
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ” NounClauseHandler.process: '{text}'")
        
        try:
            # Step 1: spaCyè§£æ
            doc = self.nlp(text)
            
            # Step 2: åè©ç¯€æ¤œå‡º
            noun_clause_info = self._detect_noun_clauses(doc, text)
            
            if not noun_clause_info:
                print(f"â„¹ï¸ åè©ç¯€æœªæ¤œå‡º: '{text}'")
                return self._create_failure_result(text, "åè©ç¯€æœªæ¤œå‡º")
            
            # Step 3: åè©ç¯€ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
            result = self._process_noun_clause(doc, text, noun_clause_info)
            
            if result['success']:
                print(f"âœ… NounClauseHandleræˆåŠŸ: {result['main_slots']}")
                print(f"ğŸ“‹ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result['sub_slots']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ NounClauseHandler.process ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_failure_result(text, f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def detect_noun_clauses(self, text: str) -> List[Dict[str, Any]]:
        """
        åè©ç¯€æ¤œå‡ºï¼ˆCentralControllerç”¨ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
        
        Args:
            text: åˆ†æå¯¾è±¡æ–‡
            
        Returns:
            List[Dict]: æ¤œå‡ºã•ã‚ŒãŸåè©ç¯€æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            doc = self.nlp(text)
            noun_clause_info = self._detect_noun_clauses(doc, text)
            return [noun_clause_info] if noun_clause_info else []
        except Exception:
            return []
    
    def _detect_noun_clauses(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        åè©ç¯€æ¤œå‡ºï¼ˆå°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ± or None
        """
        print(f"ğŸ” åè©ç¯€æ¤œå‡ºé–‹å§‹: '{sentence}'")
        
        # ğŸ¯ Wishæ–‡å°‚ç”¨æ¤œå‡ºï¼ˆæœ€å„ªå…ˆï¼‰
        wish_result = self._detect_wish_clause(doc, sentence)
        if wish_result:
            return wish_result
        
        # spaCyä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹åè©ç¯€æ¤œå‡º
        for token in doc:
            print(f"   {token.text}: dep={token.dep_}, pos={token.pos_}, tag={token.tag_}")
            
            # ccomp: è£œèªç¯€ï¼ˆthatç¯€ãƒ»wh-ç¯€ï¼‰
            if token.dep_ == 'ccomp':
                print(f"ğŸ¯ ccompæ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: åè©ç¯€æ§‹é€ ã®ãŸã‚)")
                return self._analyze_ccomp_clause(doc, token, sentence)
                
            # csubj: ç¯€ä¸»èªï¼ˆThatç¯€ãƒ»wh-ç¯€ãŒä¸»èªï¼‰
            elif token.dep_ == 'csubj':
                print(f"ğŸ¯ csubjæ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: ç¯€ä¸»èªã®ãŸã‚)")
                return self._analyze_csubj_clause(doc, token, sentence)
        
        # å“è©åˆ†æã«ã‚ˆã‚‹è£œå®Œæ¤œå‡º
        return self._detect_by_pos_analysis(doc, sentence)
    
    def _analyze_ccomp_clause(self, doc, ccomp_token, sentence: str) -> Dict[str, Any]:
        """
        ccompç¯€ï¼ˆè£œèªç¯€ï¼‰ã®åˆ†æ
        
        Args:
            doc: spaCyè§£æçµæœ
            ccomp_token: ccompè¦ç´ ã®ãƒˆãƒ¼ã‚¯ãƒ³
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ±
        """
        print(f"ğŸ“‹ ccompç¯€åˆ†æ: '{ccomp_token.text}'")
        
        # æ¥ç¶šè©æ¤œå‡ºï¼ˆmarkãƒ©ã‚¤ã‚¯ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
        connector = None
        for child in ccomp_token.children:
            if child.dep_ == 'mark' or child.text.lower() in ['that', 'whether', 'if']:
                connector = child.text.lower()
                print(f"   æ¥ç¶šè©æ¤œå‡º: '{connector}'")
                break
        
        # wh-ç¯€ã®å ´åˆï¼ˆæ¥ç¶šè©ãªã—ï¼‰
        if not connector:
            for token in doc:
                if (token.pos_ in ['PRON', 'ADV'] and 
                    token.text.lower() in self.noun_clause_connectors['wh_clause']):
                    connector = token.text.lower()
                    print(f"   wh-è¦ç´ æ¤œå‡º: '{connector}'")
                    break
                # è¿½åŠ : where, how, whenç­‰ã®å‰¯è©ç³»wh-èª
                elif (token.pos_ in ['SCONJ', 'ADV'] and 
                      token.text.lower() in ['where', 'when', 'how', 'why']):
                    connector = token.text.lower()
                    print(f"   wh-å‰¯è©æ¤œå‡º: '{connector}'")
                    break
        
        return {
            'type': self._determine_clause_type(connector),
            'position': 'object',  # ccompã¯é€šå¸¸ç›®çš„èªä½ç½®
            'connector': connector,
            'main_verb': ccomp_token.text,
            'clause_range': self._get_clause_range(doc, ccomp_token)
        }
    
    def _analyze_csubj_clause(self, doc, csubj_token, sentence: str) -> Dict[str, Any]:
        """
        csubjç¯€ï¼ˆç¯€ä¸»èªï¼‰ã®åˆ†æ
        
        Args:
            doc: spaCyè§£æçµæœ
            csubj_token: csubjè¦ç´ ã®ãƒˆãƒ¼ã‚¯ãƒ³
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ±
        """
        print(f"ğŸ“‹ csubjç¯€åˆ†æ: '{csubj_token.text}'")
        
        # æ¥ç¶šè©æ¤œå‡º
        connector = None
        for token in doc:
            if (token.i < csubj_token.i and 
                token.text.lower() in ['that', 'whether', 'if'] + self.noun_clause_connectors['wh_clause']):
                connector = token.text.lower()
                print(f"   æ¥ç¶šè©æ¤œå‡º: '{connector}'")
                break
        
        return {
            'type': self._determine_clause_type(connector),
            'position': 'subject',  # csubjã¯ä¸»èªä½ç½®
            'connector': connector,
            'main_verb': csubj_token.text,
            'clause_range': self._get_clause_range(doc, csubj_token)
        }
    
    def _detect_by_pos_analysis(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        å“è©åˆ†æã«ã‚ˆã‚‹åè©ç¯€æ¤œå‡ºï¼ˆè£œå®Œï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ± or None
        """
        print(f"ğŸ” å“è©åˆ†æè£œå®Œæ¤œå‡º: '{sentence}'")
        
        # ç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for i, token in enumerate(doc):
            if token.text.lower() in ['that', 'whether', 'if']:
                # å‰ç½®è©å¥å†…ã®ifç¯€æ¤œå‡º
                if i > 0 and doc[i-1].pos_ == 'ADP':  # å‰ç½®è©
                    print(f"   å‰ç½®è©+åè©ç¯€æ¤œå‡º: '{doc[i-1].text} {token.text}' (å“è©ä½¿ç”¨: å˜ç´”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãŸã‚)")
                    return {
                        'type': 'if_clause_noun',
                        'position': 'prepositional_object',
                        'connector': token.text.lower(),
                        'preposition': doc[i-1].text,
                        'clause_range': (i, len(doc))
                    }
        
        return None
    
    def _detect_wish_clause(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        Wishæ–‡å°‚ç”¨æ¤œå‡º
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: Wishç¯€æƒ…å ± or None
        """
        import re
        
        # Wishãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        wish_pattern = r'\b(?:wish|wishes|wished)\s+'
        if not re.search(wish_pattern, sentence, re.IGNORECASE):
            return None
        
        print(f"ğŸ¯ Wishæ–‡æ¤œå‡º: '{sentence}'")
        
        # Wishå‹•è©ã‚’ç‰¹å®š
        wish_verb = None
        wish_token = None
        for token in doc:
            if token.text.lower() in ['wish', 'wishes', 'wished']:
                wish_verb = token.text
                wish_token = token
                print(f"   Wishå‹•è©: '{wish_verb}' (ä½ç½®: {token.i})")
                break
        
        if not wish_token:
            return None
        
        # Wishæ–‡ã®ccompç¯€ã‚’ç‰¹å®š
        ccomp_token = None
        for child in wish_token.children:
            if child.dep_ == 'ccomp':
                ccomp_token = child
                print(f"   Wishç¯€æ¤œå‡º: '{child.text}' (ccomp)")
                break
        
        if not ccomp_token:
            return None
        
        return {
            'type': 'wish_clause',
            'position': 'object',
            'connector': None,  # æš—é»™ã®[that]
            'main_verb': wish_verb,
            'wish_token': wish_token,
            'ccomp_token': ccomp_token,
            'clause_range': (ccomp_token.i, len(doc))
        }
    
    def _detect_by_pos_analysis(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        å“è©åˆ†æã«ã‚ˆã‚‹è£œå®Œæ¤œå‡º
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ± or None
        """
        print(f"ğŸ” å“è©åˆ†æã«ã‚ˆã‚‹è£œå®Œæ¤œå‡º: '{sentence}'")
        
        # ç¾åœ¨ã®å®Ÿè£…ã§ã¯è¿½åŠ æ¤œå‡ºãªã—
        return None
    
    def _determine_clause_type(self, connector: str) -> str:
        """
        æ¥ç¶šè©ã‹ã‚‰åè©ç¯€ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
        
        Args:
            connector: æ¥ç¶šè©
            
        Returns:
            str: ç¯€ã‚¿ã‚¤ãƒ—
        """
        if not connector:
            return 'unknown_clause'
        
        if connector == 'that':
            return 'that_clause'
        elif connector in self.noun_clause_connectors['wh_clause']:
            return 'wh_clause'
        elif connector in ['where', 'when', 'how', 'why']:
            return 'wh_clause'  # where, howç­‰ã‚‚åè©ç¯€ã¨ã—ã¦å‡¦ç†
        elif connector == 'whether':
            return 'whether_clause'
        elif connector == 'if':
            return 'if_clause'
        else:
            return 'unknown_clause'
    
    def _get_clause_range(self, doc, main_token) -> Tuple[int, int]:
        """
        ç¯€ã®ç¯„å›²ã‚’å–å¾—
        
        Args:
            doc: spaCyè§£æçµæœ
            main_token: ç¯€ã®ä¸»è¦ãƒˆãƒ¼ã‚¯ãƒ³
            
        Returns:
            Tuple: (é–‹å§‹ä½ç½®, çµ‚äº†ä½ç½®)
        """
        # ç°¡å˜ãªå®Ÿè£…: ä¸»è¦ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰æ–‡æœ«ã¾ã§
        start_pos = main_token.i
        end_pos = len(doc)
        
        # ã‚ˆã‚Šæ­£ç¢ºãªç¯„å›²æ¤œå‡ºã¯ä»Šå¾Œã®æ‹¡å¼µã§
        return (start_pos, end_pos)
    
    def _process_noun_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åè©ç¯€ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        clause_type = noun_clause_info['type']
        position = noun_clause_info['position']
        
        print(f"ğŸ“‹ åè©ç¯€å‡¦ç†: type={clause_type}, position={position}")
        
        if clause_type == 'wish_clause':
            return self._process_wish_clause(doc, sentence, noun_clause_info)
        elif clause_type == 'that_clause':
            return self._process_that_clause(doc, sentence, noun_clause_info)
        elif clause_type == 'wh_clause':
            return self._process_wh_clause(doc, sentence, noun_clause_info)
        elif clause_type == 'whether_clause':
            return self._process_whether_clause(doc, sentence, noun_clause_info)
        elif clause_type in ['if_clause', 'if_clause_noun']:
            return self._process_if_clause(doc, sentence, noun_clause_info)
        else:
            return self._create_failure_result(sentence, f"æœªå¯¾å¿œã®ç¯€ã‚¿ã‚¤ãƒ—: {clause_type}")
    
    def _process_wish_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Wishæ–‡å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: Wishç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ Wishæ–‡å‡¦ç†é–‹å§‹")
        
        wish_token = noun_clause_info['wish_token']
        ccomp_token = noun_clause_info['ccomp_token']
        
        # ä¸»ç¯€æ§‹é€ ï¼ˆI wishï¼‰
        main_subject = None
        for token in doc:
            if token.dep_ == 'nsubj' and token.head == wish_token:
                main_subject = token.text
                print(f"   ä¸»ç¯€ä¸»èª: '{main_subject}'")
                break
        
        # å¾“ç¯€ã¯ç©ºã®O1ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦è¡¨ç¾
        main_slots = {
            'S': main_subject or '',
            'V': wish_token.text,
            'O1': ''  # Wishæ–‡ã®å¾“ç¯€ã¯æš—é»™çš„
        }
        
        # å¾“ç¯€æ§‹é€ åˆ†æ (I were taller â†’ sub-s: "I", sub-v: "were", sub-c1: "taller")
        sub_slots = {'_parent_slot': 'O1'}
        
        # å¾“ç¯€å†…ã®è¦ç´ ã‚’åˆ†æ - ccompã®ç¯„å›²å…¨ä½“ã‚’ãƒã‚§ãƒƒã‚¯
        clause_start = ccomp_token.i
        for i in range(clause_start, len(doc)):
            token = doc[i]
            
            # å‹•è©æ¤œå‡º: ccompè‡ªä½“
            if token == ccomp_token:
                sub_slots['sub-v'] = token.text
                print(f"      å¾“ç¯€å‹•è©æ¤œå‡º: {token.text} (dep: {token.dep_})")
                
                # ã“ã®å‹•è©ã®ä¸»èªã‚’æ¤œå‡º
                for child in token.children:
                    if child.dep_ == 'nsubj':
                        sub_slots['sub-s'] = child.text
                        print(f"      å¾“ç¯€ä¸»èªæ¤œå‡º: {child.text} (dep: {child.dep_}, head: {child.head.text})")
                
                # ã“ã®å‹•è©ã®è£œèªã‚’æ¤œå‡º
                for child in token.children:
                    if child.dep_ in ['acomp', 'attr', 'dobj']:
                        if child.pos_ == 'ADJ':
                            sub_slots['sub-c1'] = child.text
                            print(f"      å¾“ç¯€è£œèªæ¤œå‡º: {child.text} (dep: {child.dep_})")
                        else:
                            # Extract full phrase including modifiers for objects
                            obj_phrase = self._extract_full_phrase(child, doc)
                            sub_slots['sub-o1'] = obj_phrase
                            print(f"      å¾“ç¯€ç›®çš„èªæ¤œå‡º: {obj_phrase} (dep: {child.dep_})")
        
        print(f"   ä¸»ç¯€: {main_slots}")
        print(f"   å¾“ç¯€: {sub_slots}")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['noun_clause', 'basic_five_pattern'],
            'primary_handler': 'noun_clause',
            'metadata': {
                'handler': 'wish_clause',
                'clause_type': 'wish_clause',
                'confidence': 0.95
            }
        }
    
    def _process_that_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        thatç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ thatç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # thatç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        # _parent_slotè¨­å®šï¼ˆthatç¯€ã¯é€šå¸¸ç›®çš„èªä½ç½®ï¼‰
        position = noun_clause_info.get('position', 'object')
        if position == 'subject':
            sub_slots['_parent_slot'] = 'S'
        elif position == 'object':
            sub_slots['_parent_slot'] = 'O1'
        else:
            sub_slots['_parent_slot'] = 'O1'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'that_clause'
        }
    
    def _process_wh_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        wh-ç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ wh-ç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # wh-ç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # wh-è¦ç´ ã®é©åˆ‡ãªé…ç½®
        connector = noun_clause_info.get('connector', '')
        if connector in ['what']:
            clause_structure['sub-o1'] = connector
        elif connector in ['who', 'whom']:
            clause_structure['sub-s'] = connector
        elif connector in ['where', 'when', 'why', 'how']:
            # howã®å ´åˆã€å½¢å®¹è©ã¨çµåˆã—ã¦å‡¦ç†
            if connector == 'how' and 'sub-c1' in clause_structure:
                clause_structure['sub-m2'] = f"{connector} {clause_structure['sub-c1']}"
                # sub-c1ã¯æ—¢ã«sub-m2ã«å«ã¾ã‚ŒãŸã®ã§å‰Šé™¤
                del clause_structure['sub-c1']
                print(f"   how+å½¢å®¹è©çµåˆ: sub-m2='{clause_structure['sub-m2']}'")
            else:
                clause_structure['sub-m2'] = connector
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        # _parent_slotè¨­å®š
        position = noun_clause_info.get('position', 'object')
        if position == 'subject':
            sub_slots['_parent_slot'] = 'S'
        elif position == 'object':
            sub_slots['_parent_slot'] = 'O1'
        else:
            sub_slots['_parent_slot'] = 'O1'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'wh_clause'
        }
    
    def _process_whether_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        whetherç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ whetherç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # whetherç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        # _parent_slotè¨­å®š
        position = noun_clause_info.get('position', 'object')
        if position == 'subject':
            sub_slots['_parent_slot'] = 'S'
        elif position == 'object':
            sub_slots['_parent_slot'] = 'O1'
        else:
            sub_slots['_parent_slot'] = 'O1'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'whether_clause'
        }
    
    def _process_if_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        ifç¯€ï¼ˆåè©ç”¨æ³•ï¼‰å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ ifç¯€ï¼ˆåè©ç”¨æ³•ï¼‰å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # ifç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # å‰ç½®è©å¥ã®å ´åˆã®ç‰¹åˆ¥å‡¦ç†
        if noun_clause_info.get('preposition'):
            preposition = noun_clause_info['preposition']
            connector = noun_clause_info.get('connector', 'if')
            # "on if you" ã®å½¢å¼ï¼ˆé‡è¤‡å›é¿ï¼‰
            subject_part = clause_structure.get('sub-s', '').replace(f'{connector} ', '')
            clause_structure['sub-s'] = f"{preposition} {connector} {subject_part}"
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        # _parent_slotè¨­å®š
        position = noun_clause_info.get('position', 'object')
        if position == 'subject':
            sub_slots['_parent_slot'] = 'S'
        elif position == 'object':
            sub_slots['_parent_slot'] = 'O1'
        elif position == 'prepositional_object':
            sub_slots['_parent_slot'] = 'M2'
            # å‰ç½®è©+ifç¯€ã®å ´åˆã€M2ã‚’ç©ºã«ã™ã‚‹
            main_slots['M2'] = ""
            print(f"   å‰ç½®è©+ifç¯€æ¤œå‡º: M2ç©ºåŒ–")
        else:
            sub_slots['_parent_slot'] = 'O1'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'if_clause_noun'
        }
    
    def _extract_basic_structure(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Tuple[Dict[str, str], Dict[str, str]]:
        """
        åŸºæœ¬æ§‹é€ ï¼ˆä¸»æ–‡ï¼‰ã®æŠ½å‡º
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Tuple: (main_slots, sub_slots)
        """
        print(f"ğŸ“‹ åŸºæœ¬æ§‹é€ æŠ½å‡ºé–‹å§‹")
        
        main_slots = {}
        sub_slots = {}
        
        # ROOTå‹•è©æ¤œå‡ºï¼ˆä¸»æ–‡ã®å‹•è©ï¼‰
        main_verb = None
        for token in doc:
            if token.dep_ == 'ROOT':
                main_verb = token
                print(f"   ä¸»å‹•è©æ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: è¤‡æ–‡æ§‹é€ ã®ãŸã‚)")
                break
        
        if not main_verb:
            print("âŒ ä¸»å‹•è©æœªæ¤œå‡º")
            return main_slots, sub_slots
        
        main_slots['V'] = main_verb.text
        
        # åŠ©å‹•è©æ¤œå‡ºï¼ˆä¸»å‹•è©ã®å­ã¨ã—ã¦ï¼‰
        for child in main_verb.children:
            if child.dep_ == 'aux':
                # å¦å®šã®å ´åˆã¯çµåˆï¼ˆdoesn't, won'tç­‰ï¼‰
                aux_text = child.text
                for grandchild in child.children:
                    if grandchild.dep_ == 'neg':
                        aux_text += grandchild.text
                main_slots['Aux'] = aux_text
                print(f"   åŠ©å‹•è©æ¤œå‡º: '{aux_text}'")
                break
        
        # ä¸»èªæ¤œå‡º
        for child in main_verb.children:
            if child.dep_ in ['nsubj', 'csubj']:
                if child.dep_ == 'csubj':
                    # ç¯€ä¸»èªã®å ´åˆã¯ç©ºã«ã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
                    main_slots['S'] = ""
                    print(f"   ç¯€ä¸»èªæ¤œå‡º: Sç©ºåŒ–")
                else:
                    main_slots['S'] = child.text
                    print(f"   ä¸»èªæ¤œå‡º: '{child.text}'")
                break
        
        # ç›®çš„èªãƒ»è£œèªæ¤œå‡º
        for child in main_verb.children:
            if child.dep_ == 'dobj':
                main_slots['O1'] = child.text
                print(f"   ç›®çš„èªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'iobj':
                main_slots['O1'] = child.text  # é–“æ¥ç›®çš„èªã¯é€šå¸¸O1
                print(f"   é–“æ¥ç›®çš„èªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'acomp':
                main_slots['C1'] = child.text
                print(f"   è£œèªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'ccomp':
                # è£œèªç¯€ã®å ´åˆã¯ç©ºã«ã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
                if not main_slots.get('O1'):
                    main_slots['O1'] = ""
                    print(f"   è£œèªç¯€æ¤œå‡º: O1ç©ºåŒ–")
                else:
                    main_slots['O2'] = ""
                    print(f"   è£œèªç¯€æ¤œå‡º: O2ç©ºåŒ–")
            elif child.dep_ == 'prep':
                # å‰ç½®è©å¥æ¤œå‡ºï¼ˆåè©ç¯€ãŒã‚ã‚‹å ´åˆã®M2å¯¾å¿œï¼‰
                prep_phrase_text = self._extract_prep_phrase(child, noun_clause_info)
                if prep_phrase_text and 'if' in prep_phrase_text.lower():
                    # ifç¯€ã‚’å«ã‚€å‰ç½®è©å¥ã®å ´åˆã¯M2ç©ºåŒ–
                    main_slots['M2'] = ""
                    print(f"   å‰ç½®è©å¥ç¯€æ¤œå‡º: M2ç©ºåŒ–")
                elif prep_phrase_text:
                    main_slots['M2'] = prep_phrase_text
                    print(f"   å‰ç½®è©å¥æ¤œå‡º: '{prep_phrase_text}'")
        
        return main_slots, sub_slots
    
    def _extract_prep_phrase(self, prep_token, noun_clause_info: Dict[str, Any]) -> str:
        """
        å‰ç½®è©å¥ã®æŠ½å‡ºï¼ˆåè©ç¯€å¯¾å¿œï¼‰
        
        Args:
            prep_token: spaCyå‰ç½®è©ãƒˆãƒ¼ã‚¯ãƒ³
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            str: å‰ç½®è©å¥ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç¯€ã‚’å«ã‚€å ´åˆã¯ç©ºæ–‡å­—ï¼‰
        """
        prep_phrase_parts = [prep_token.text]
        
        # å‰ç½®è©ã®å­è¦ç´ ï¼ˆç›®çš„èªç­‰ï¼‰ã‚’åé›†
        for child in prep_token.children:
            if child.dep_ == 'pobj':
                # å‰ç½®è©ã®ç›®çš„èªãŒåè©ç¯€ã®å ´åˆã¯ç©ºã«ã™ã‚‹
                connector = noun_clause_info.get('connector', '')
                if connector in child.subtree:
                    # åè©ç¯€ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™
                    return ""
                else:
                    prep_phrase_parts.append(child.text)
        
        return ' '.join(prep_phrase_parts) if len(prep_phrase_parts) > 1 else ""
    
    def _analyze_clause_internal_structure(self, doc, noun_clause_info: Dict[str, Any]) -> Dict[str, str]:
        """
        ç¯€å†…éƒ¨æ§‹é€ ã®è§£æ
        
        Args:
            doc: spaCyè§£æçµæœ
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: ç¯€å†…éƒ¨ã®ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ 
        """
        print(f"ğŸ“‹ ç¯€å†…éƒ¨æ§‹é€ è§£æé–‹å§‹")
        
        clause_structure = {}
        
        # ç°¡å˜ãªå®Ÿè£…: æ¥ç¶šè©ä»¥é™ã®åŸºæœ¬è¦ç´ ã‚’æŠ½å‡º
        connector = noun_clause_info.get('connector', '')
        position = noun_clause_info.get('position', 'object')  # ä½ç½®æƒ…å ±ã‚’å–å¾—
        
        # ç¯€å†…ã®ä¸»èªãƒ»å‹•è©ãƒ»è£œèªæ¤œå‡º
        clause_tokens = []
        start_collecting = False
        
        for token in doc:
            # æ¥ç¶šè©ä»¥é™ã‹ã‚‰åé›†é–‹å§‹
            if token.text.lower() == connector.lower():
                start_collecting = True
                continue
            
            if start_collecting:
                clause_tokens.append(token)
        
        # ç¯€å†…éƒ¨ã®5æ–‡å‹åˆ†æï¼ˆç°¡å˜ç‰ˆï¼‰
        clause_subject = None
        clause_verb = None
        clause_complement = None
        clause_aux = None
        
        for token in clause_tokens:
            # ä¸»æ–‡ã®è¦ç´ ã¯ç¯€å†…ã«å«ã‚ãªã„ï¼ˆä¸»èªç¯€ã®å ´åˆã® 'wonderful' ç­‰ï¼‰
            if token.dep_ in ['acomp', 'attr'] and token.head.dep_ == 'ROOT':
                continue  # ä¸»æ–‡ã®è£œèªã¯ã‚¹ã‚­ãƒƒãƒ—
                
            if token.dep_ in ['nsubj', 'nsubjpass'] and not clause_subject:
                # wh-èªãŒä¸»èªã®å ´åˆã¯é™¤å¤–ã€ç›®çš„èªwh-èªï¼ˆwhatï¼‰ã®å ´åˆã¯ä¸»èªã¨ã—ã¦å‡¦ç†
                if connector not in ['who', 'whom']:
                    clause_structure['sub-s'] = token.text
                    clause_subject = token
                    print(f"   ç¯€å†…ä¸»èª: '{token.text}'")
            elif token.pos_ in ['VERB'] and not clause_verb:
                clause_structure['sub-v'] = token.text
                clause_verb = token
                print(f"   ç¯€å†…å‹•è©: '{token.text}'")
            elif token.pos_ in ['AUX'] and not clause_verb:
                # beå‹•è©ç­‰ã¯å‹•è©ã¨ã—ã¦å„ªå…ˆå‡¦ç†
                if token.text.lower() in ['is', 'are', 'was', 'were', 'am']:
                    clause_structure['sub-v'] = token.text
                    clause_verb = token
                    print(f"   ç¯€å†…å‹•è©(be): '{token.text}'")
                elif not clause_aux:
                    # åŠ©å‹•è©ã¨ã—ã¦å‡¦ç†ï¼ˆwill, canç­‰ï¼‰
                    clause_structure['sub-aux'] = token.text
                    clause_aux = token
                    print(f"   ç¯€å†…åŠ©å‹•è©: '{token.text}'")
            elif token.dep_ in ['acomp', 'attr'] and not clause_complement:
                clause_structure['sub-c1'] = token.text
                clause_complement = token
                print(f"   ç¯€å†…è£œèª: '{token.text}'")
            elif token.dep_ in ['advmod'] and token.pos_ in ['ADV']:
                clause_structure['sub-m2'] = token.text
                print(f"   ç¯€å†…å‰¯è©: '{token.text}'")
            elif token.dep_ in ['prep'] and token.pos_ in ['ADP']:
                # å‰ç½®è©å¥ã®æ¤œå‡ºï¼ˆ"to the party"ç­‰ï¼‰
                prep_phrase = token.text
                for child in token.children:
                    if child.dep_ == 'pobj':
                        prep_phrase += f" {child.text}"
                        # ã•ã‚‰ã«ãã®ä¿®é£¾èªã‚‚è¿½åŠ 
                        for grandchild in child.children:
                            if grandchild.dep_ == 'det':
                                prep_phrase = token.text + f" {grandchild.text} {child.text}"
                clause_structure['sub-m2'] = prep_phrase
                print(f"   ç¯€å†…å‰ç½®è©å¥: '{prep_phrase}'")
        
        # æ¥ç¶šè©ã®ã¿ãŒä¸»èªã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ä¿®æ­£ï¼ˆthatç¯€ç­‰ï¼‰
        if connector in ['that', 'whether'] and clause_subject and 'sub-s' in clause_structure:
            # ä¸»èªç¯€ã®å ´åˆã¯å¤§æ–‡å­—åŒ–ã€ç›®çš„èªç¯€ã®å ´åˆã¯å°æ–‡å­—
            if position == 'subject':
                clause_structure['sub-s'] = f"{connector.capitalize()} {clause_structure['sub-s']}"
            else:
                clause_structure['sub-s'] = f"{connector.lower()} {clause_structure['sub-s']}"
        
        # ifç¯€ã®å ´åˆã¯å‰ç½®è©å¥ã§å‡¦ç†æ¸ˆã¿ãªã®ã§é‡è¤‡å›é¿
        if connector == 'if' and clause_subject and 'sub-s' in clause_structure:
            # æ—¢ã«å‰ç½®è©å¥ã¨ã—ã¦å‡¦ç†æ¸ˆã¿ã®å ´åˆã¯ãã®ã¾ã¾
            pass
        
        return clause_structure
    
    def _create_failure_result(self, text: str, reason: str) -> Dict[str, Any]:
        """
        å¤±æ•—çµæœã®ä½œæˆ
        
        Args:
            text: å‡¦ç†å¯¾è±¡æ–‡
            reason: å¤±æ•—ç†ç”±
            
        Returns:
            Dict: å¤±æ•—çµæœ
        """
        return {
            'success': False,
            'text': text,
            'main_slots': {},
            'sub_slots': {},
            'handler': self.name,
            'reason': reason
        }
