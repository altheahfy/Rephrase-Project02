#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NounClauseHandler: åè©ç¯€å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
thatç¯€ãƒ»wh-ç¯€ãƒ»é–“æ¥ç–‘å•æ–‡ã®å°‚é–€åˆ†è§£
å°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼ˆå“è©åˆ†æ + ä¾å­˜é–¢ä¿‚ï¼‰
"""

import re
import spacy
from typing import Dict, Any, List, Tuple, Optional

class NounClauseHandler:
    """åè©ç¯€å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼‰"""
    
    def __init__(self, nlp_model=None, collaborators=None):
        """
        åˆæœŸåŒ–
        
        Args:
            nlp_model: spaCyãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            collaborators: å”åŠ›è€…ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¾æ›¸
                - 'adverb': AdverbHandlerï¼ˆä¿®é£¾èªåˆ†é›¢ï¼‰
                - 'five_pattern': BasicFivePatternHandlerï¼ˆ5æ–‡å‹åˆ†æï¼‰
                - 'passive': PassiveVoiceHandlerï¼ˆå—å‹•æ…‹ç†è§£ï¼‰
                - 'modal': ModalHandlerï¼ˆåŠ©å‹•è©å‡¦ç†ï¼‰
        """
        self.name = "NounClauseHandler"
        self.version = "v1.0"
        self.nlp = nlp_model if nlp_model is not None else spacy.load('en_core_web_sm')
        
        # å”åŠ›è€…ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŸã¡
        if collaborators:
            self.adverb_handler = collaborators.get('adverb')
            self.five_pattern_handler = collaborators.get('five_pattern')
            self.passive_handler = collaborators.get('passive')
            self.modal_handler = collaborators.get('modal')
        else:
            self.adverb_handler = None
            self.five_pattern_handler = None
            self.passive_handler = None
            self.modal_handler = None
        
        # åè©ç¯€æ¥ç¶šè©ãƒ»ç–‘å•è©ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.noun_clause_connectors = {
            'that_clause': ['that'],
            'wh_clause': ['what', 'who', 'whom', 'whose', 'which', 'where', 'when', 'why', 'how'],
            'whether_clause': ['whether'],
            'if_clause': ['if']
        }
    
    def process(self, text: str, original_text: str = None) -> Dict[str, Any]:
        """
        åè©ç¯€å‡¦ç†ãƒ¡ã‚¤ãƒ³
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±èªæ–‡
            original_text: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‚è€ƒç”¨ï¼‰
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ” NounClauseHandler.process: '{text}'")
        
        try:
            # Step 1: spaCyè§£æ
            doc = self.nlp(text)
            
            # Step 2: åè©ç¯€æ¤œå‡º
            noun_clause_info = self._detect_noun_clauses(doc, text)
            
            if not noun_clause_info:
                print(f"â„¹ï¸ åè©ç¯€æœªæ¤œå‡º: '{text}'")
                return self._create_failure_result(text, "åè©ç¯€æœªæ¤œå‡º")
            
            # Step 3: åè©ç¯€ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
            result = self._process_noun_clause(doc, text, noun_clause_info)
            
            if result['success']:
                print(f"âœ… NounClauseHandleræˆåŠŸ: {result['main_slots']}")
                print(f"ğŸ“‹ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result['sub_slots']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ NounClauseHandler.process ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_failure_result(text, f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def detect_noun_clauses(self, text: str) -> List[Dict[str, Any]]:
        """
        åè©ç¯€æ¤œå‡ºï¼ˆCentralControllerç”¨ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
        
        Args:
            text: åˆ†æå¯¾è±¡æ–‡
            
        Returns:
            List[Dict]: æ¤œå‡ºã•ã‚ŒãŸåè©ç¯€æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            doc = self.nlp(text)
            noun_clause_info = self._detect_noun_clauses(doc, text)
            return [noun_clause_info] if noun_clause_info else []
        except Exception:
            return []
    
    def _detect_noun_clauses(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        åè©ç¯€æ¤œå‡ºï¼ˆå°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ± or None
        """
        print(f"ğŸ” åè©ç¯€æ¤œå‡ºé–‹å§‹: '{sentence}'")
        
        # spaCyä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹åè©ç¯€æ¤œå‡º
        for token in doc:
            print(f"   {token.text}: dep={token.dep_}, pos={token.pos_}, tag={token.tag_}")
            
            # ccomp: è£œèªç¯€ï¼ˆthatç¯€ãƒ»wh-ç¯€ï¼‰
            if token.dep_ == 'ccomp':
                print(f"ğŸ¯ ccompæ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: åè©ç¯€æ§‹é€ ã®ãŸã‚)")
                return self._analyze_ccomp_clause(doc, token, sentence)
                
            # csubj: ç¯€ä¸»èªï¼ˆThatç¯€ãƒ»wh-ç¯€ãŒä¸»èªï¼‰
            elif token.dep_ == 'csubj':
                print(f"ğŸ¯ csubjæ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: ç¯€ä¸»èªã®ãŸã‚)")
                return self._analyze_csubj_clause(doc, token, sentence)
        
        # å“è©åˆ†æã«ã‚ˆã‚‹è£œå®Œæ¤œå‡º
        return self._detect_by_pos_analysis(doc, sentence)
    
    def _analyze_ccomp_clause(self, doc, ccomp_token, sentence: str) -> Dict[str, Any]:
        """
        ccompç¯€ï¼ˆè£œèªç¯€ï¼‰ã®åˆ†æ
        
        Args:
            doc: spaCyè§£æçµæœ
            ccomp_token: ccompè¦ç´ ã®ãƒˆãƒ¼ã‚¯ãƒ³
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ±
        """
        print(f"ğŸ“‹ ccompç¯€åˆ†æ: '{ccomp_token.text}'")
        
        # æ¥ç¶šè©æ¤œå‡ºï¼ˆmarkãƒ©ã‚¤ã‚¯ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
        connector = None
        for child in ccomp_token.children:
            if child.dep_ == 'mark' or child.text.lower() in ['that', 'whether', 'if']:
                connector = child.text.lower()
                print(f"   æ¥ç¶šè©æ¤œå‡º: '{connector}'")
                break
        
        # wh-ç¯€ã®å ´åˆï¼ˆæ¥ç¶šè©ãªã—ï¼‰
        if not connector:
            for token in doc:
                if (token.pos_ in ['PRON', 'ADV'] and 
                    token.text.lower() in self.noun_clause_connectors['wh_clause']):
                    connector = token.text.lower()
                    print(f"   wh-è¦ç´ æ¤œå‡º: '{connector}'")
                    break
        
        return {
            'type': self._determine_clause_type(connector),
            'position': 'object',  # ccompã¯é€šå¸¸ç›®çš„èªä½ç½®
            'connector': connector,
            'main_verb': ccomp_token.text,
            'clause_range': self._get_clause_range(doc, ccomp_token)
        }
    
    def _analyze_csubj_clause(self, doc, csubj_token, sentence: str) -> Dict[str, Any]:
        """
        csubjç¯€ï¼ˆç¯€ä¸»èªï¼‰ã®åˆ†æ
        
        Args:
            doc: spaCyè§£æçµæœ
            csubj_token: csubjè¦ç´ ã®ãƒˆãƒ¼ã‚¯ãƒ³
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ±
        """
        print(f"ğŸ“‹ csubjç¯€åˆ†æ: '{csubj_token.text}'")
        
        # æ¥ç¶šè©æ¤œå‡º
        connector = None
        for token in doc:
            if (token.i < csubj_token.i and 
                token.text.lower() in ['that', 'whether', 'if'] + self.noun_clause_connectors['wh_clause']):
                connector = token.text.lower()
                print(f"   æ¥ç¶šè©æ¤œå‡º: '{connector}'")
                break
        
        return {
            'type': self._determine_clause_type(connector),
            'position': 'subject',  # csubjã¯ä¸»èªä½ç½®
            'connector': connector,
            'main_verb': csubj_token.text,
            'clause_range': self._get_clause_range(doc, csubj_token)
        }
    
    def _detect_by_pos_analysis(self, doc, sentence: str) -> Optional[Dict[str, Any]]:
        """
        å“è©åˆ†æã«ã‚ˆã‚‹åè©ç¯€æ¤œå‡ºï¼ˆè£œå®Œï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: åè©ç¯€æƒ…å ± or None
        """
        print(f"ğŸ” å“è©åˆ†æè£œå®Œæ¤œå‡º: '{sentence}'")
        
        # ç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for i, token in enumerate(doc):
            if token.text.lower() in ['that', 'whether', 'if']:
                # å‰ç½®è©å¥å†…ã®ifç¯€æ¤œå‡º
                if i > 0 and doc[i-1].pos_ == 'ADP':  # å‰ç½®è©
                    print(f"   å‰ç½®è©+åè©ç¯€æ¤œå‡º: '{doc[i-1].text} {token.text}' (å“è©ä½¿ç”¨: å˜ç´”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãŸã‚)")
                    return {
                        'type': 'if_clause_noun',
                        'position': 'prepositional_object',
                        'connector': token.text.lower(),
                        'preposition': doc[i-1].text,
                        'clause_range': (i, len(doc))
                    }
        
        return None
    
    def _determine_clause_type(self, connector: str) -> str:
        """
        æ¥ç¶šè©ã‹ã‚‰åè©ç¯€ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
        
        Args:
            connector: æ¥ç¶šè©
            
        Returns:
            str: ç¯€ã‚¿ã‚¤ãƒ—
        """
        if not connector:
            return 'unknown_clause'
        
        if connector == 'that':
            return 'that_clause'
        elif connector in self.noun_clause_connectors['wh_clause']:
            return 'wh_clause'
        elif connector == 'whether':
            return 'whether_clause'
        elif connector == 'if':
            return 'if_clause'
        else:
            return 'unknown_clause'
    
    def _get_clause_range(self, doc, main_token) -> Tuple[int, int]:
        """
        ç¯€ã®ç¯„å›²ã‚’å–å¾—
        
        Args:
            doc: spaCyè§£æçµæœ
            main_token: ç¯€ã®ä¸»è¦ãƒˆãƒ¼ã‚¯ãƒ³
            
        Returns:
            Tuple: (é–‹å§‹ä½ç½®, çµ‚äº†ä½ç½®)
        """
        # ç°¡å˜ãªå®Ÿè£…: ä¸»è¦ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰æ–‡æœ«ã¾ã§
        start_pos = main_token.i
        end_pos = len(doc)
        
        # ã‚ˆã‚Šæ­£ç¢ºãªç¯„å›²æ¤œå‡ºã¯ä»Šå¾Œã®æ‹¡å¼µã§
        return (start_pos, end_pos)
    
    def _process_noun_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åè©ç¯€ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        clause_type = noun_clause_info['type']
        position = noun_clause_info['position']
        
        print(f"ğŸ“‹ åè©ç¯€å‡¦ç†: type={clause_type}, position={position}")
        
        if clause_type == 'that_clause':
            return self._process_that_clause(doc, sentence, noun_clause_info)
        elif clause_type == 'wh_clause':
            return self._process_wh_clause(doc, sentence, noun_clause_info)
        elif clause_type == 'whether_clause':
            return self._process_whether_clause(doc, sentence, noun_clause_info)
        elif clause_type in ['if_clause', 'if_clause_noun']:
            return self._process_if_clause(doc, sentence, noun_clause_info)
        else:
            return self._create_failure_result(sentence, f"æœªå¯¾å¿œã®ç¯€ã‚¿ã‚¤ãƒ—: {clause_type}")
    
    def _process_that_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        thatç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ thatç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # thatç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'that_clause'
        }
    
    def _process_wh_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        wh-ç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ wh-ç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # wh-ç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # wh-è¦ç´ ã®é©åˆ‡ãªé…ç½®
        connector = noun_clause_info.get('connector', '')
        if connector in ['what']:
            clause_structure['sub-o1'] = connector
        elif connector in ['where', 'when', 'why', 'how']:
            clause_structure['sub-m2'] = connector
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'wh_clause'
        }
    
    def _process_whether_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        whetherç¯€å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ whetherç¯€å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # whetherç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'whether_clause'
        }
    
    def _process_if_clause(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        ifç¯€ï¼ˆåè©ç”¨æ³•ï¼‰å‡¦ç†
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        print(f"ğŸ“‹ ifç¯€ï¼ˆåè©ç”¨æ³•ï¼‰å‡¦ç†é–‹å§‹")
        
        # åŸºæœ¬æ§‹é€ è§£æ
        main_slots, sub_slots = self._extract_basic_structure(doc, sentence, noun_clause_info)
        
        # ifç¯€ã®å†…éƒ¨æ§‹é€ è§£æ
        clause_structure = self._analyze_clause_internal_structure(doc, noun_clause_info)
        
        # å‰ç½®è©å¥ã®å ´åˆã®ç‰¹åˆ¥å‡¦ç†
        if noun_clause_info.get('preposition'):
            preposition = noun_clause_info['preposition']
            connector = noun_clause_info.get('connector', 'if')
            # "on if you" ã®å½¢å¼
            clause_structure['sub-s'] = f"{preposition} {connector} " + clause_structure.get('sub-s', '')
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«çµ±åˆ
        sub_slots.update(clause_structure)
        
        return {
            'success': True,
            'text': sentence,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'handler': self.name,
            'clause_type': 'if_clause_noun'
        }
    
    def _extract_basic_structure(self, doc, sentence: str, noun_clause_info: Dict[str, Any]) -> Tuple[Dict[str, str], Dict[str, str]]:
        """
        åŸºæœ¬æ§‹é€ ï¼ˆä¸»æ–‡ï¼‰ã®æŠ½å‡º
        
        Args:
            doc: spaCyè§£æçµæœ
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Tuple: (main_slots, sub_slots)
        """
        print(f"ğŸ“‹ åŸºæœ¬æ§‹é€ æŠ½å‡ºé–‹å§‹")
        
        main_slots = {}
        sub_slots = {}
        
        # ROOTå‹•è©æ¤œå‡ºï¼ˆä¸»æ–‡ã®å‹•è©ï¼‰
        main_verb = None
        for token in doc:
            if token.dep_ == 'ROOT':
                main_verb = token
                print(f"   ä¸»å‹•è©æ¤œå‡º: '{token.text}' (ä¾å­˜é–¢ä¿‚ä½¿ç”¨: è¤‡æ–‡æ§‹é€ ã®ãŸã‚)")
                break
        
        if not main_verb:
            print("âŒ ä¸»å‹•è©æœªæ¤œå‡º")
            return main_slots, sub_slots
        
        main_slots['V'] = main_verb.text
        
        # ä¸»èªæ¤œå‡º
        for child in main_verb.children:
            if child.dep_ in ['nsubj', 'csubj']:
                if child.dep_ == 'csubj':
                    # ç¯€ä¸»èªã®å ´åˆã¯ç©ºã«ã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
                    main_slots['S'] = ""
                    print(f"   ç¯€ä¸»èªæ¤œå‡º: Sç©ºåŒ–")
                else:
                    main_slots['S'] = child.text
                    print(f"   ä¸»èªæ¤œå‡º: '{child.text}'")
                break
        
        # ç›®çš„èªãƒ»è£œèªæ¤œå‡º
        for child in main_verb.children:
            if child.dep_ == 'dobj':
                main_slots['O1'] = child.text
                print(f"   ç›®çš„èªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'iobj':
                main_slots['O1'] = child.text  # é–“æ¥ç›®çš„èªã¯é€šå¸¸O1
                print(f"   é–“æ¥ç›®çš„èªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'acomp':
                main_slots['C1'] = child.text
                print(f"   è£œèªæ¤œå‡º: '{child.text}'")
            elif child.dep_ == 'ccomp':
                # è£œèªç¯€ã®å ´åˆã¯ç©ºã«ã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
                if not main_slots.get('O1'):
                    main_slots['O1'] = ""
                    print(f"   è£œèªç¯€æ¤œå‡º: O1ç©ºåŒ–")
                else:
                    main_slots['O2'] = ""
                    print(f"   è£œèªç¯€æ¤œå‡º: O2ç©ºåŒ–")
        
        return main_slots, sub_slots
    
    def _analyze_clause_internal_structure(self, doc, noun_clause_info: Dict[str, Any]) -> Dict[str, str]:
        """
        ç¯€å†…éƒ¨æ§‹é€ ã®è§£æ
        
        Args:
            doc: spaCyè§£æçµæœ
            noun_clause_info: åè©ç¯€æƒ…å ±
            
        Returns:
            Dict: ç¯€å†…éƒ¨ã®ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ 
        """
        print(f"ğŸ“‹ ç¯€å†…éƒ¨æ§‹é€ è§£æé–‹å§‹")
        
        clause_structure = {}
        
        # ç°¡å˜ãªå®Ÿè£…: æ¥ç¶šè©ä»¥é™ã®åŸºæœ¬è¦ç´ ã‚’æŠ½å‡º
        connector = noun_clause_info.get('connector', '')
        
        # ç¯€å†…ã®ä¸»èªãƒ»å‹•è©ãƒ»è£œèªæ¤œå‡º
        clause_tokens = []
        start_collecting = False
        
        for token in doc:
            # æ¥ç¶šè©ä»¥é™ã‹ã‚‰åé›†é–‹å§‹
            if token.text.lower() == connector.lower():
                start_collecting = True
                continue
            
            if start_collecting:
                clause_tokens.append(token)
        
        # ç¯€å†…éƒ¨ã®5æ–‡å‹åˆ†æï¼ˆç°¡å˜ç‰ˆï¼‰
        clause_subject = None
        clause_verb = None
        clause_complement = None
        
        for token in clause_tokens:
            if token.dep_ in ['nsubj', 'nsubjpass'] and not clause_subject:
                if connector and connector not in ['what', 'who', 'whom']:
                    clause_structure['sub-s'] = f"{connector} {token.text}"
                else:
                    clause_structure['sub-s'] = token.text
                clause_subject = token
                print(f"   ç¯€å†…ä¸»èª: '{token.text}'")
            elif token.pos_ in ['VERB', 'AUX'] and not clause_verb:
                clause_structure['sub-v'] = token.text
                clause_verb = token
                print(f"   ç¯€å†…å‹•è©: '{token.text}'")
            elif token.dep_ in ['acomp', 'attr'] and not clause_complement:
                clause_structure['sub-c1'] = token.text
                clause_complement = token
                print(f"   ç¯€å†…è£œèª: '{token.text}'")
        
        # æ¥ç¶šè©ã®ã¿ãŒä¸»èªã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ä¿®æ­£
        if connector and clause_subject and 'sub-s' in clause_structure:
            if connector not in clause_structure['sub-s']:
                clause_structure['sub-s'] = f"{connector} {clause_structure['sub-s']}"
        
        return clause_structure
    
    def _create_failure_result(self, text: str, reason: str) -> Dict[str, Any]:
        """
        å¤±æ•—çµæœã®ä½œæˆ
        
        Args:
            text: å‡¦ç†å¯¾è±¡æ–‡
            reason: å¤±æ•—ç†ç”±
            
        Returns:
            Dict: å¤±æ•—çµæœ
        """
        return {
            'success': False,
            'text': text,
            'main_slots': {},
            'sub_slots': {},
            'handler': self.name,
            'reason': reason
        }
