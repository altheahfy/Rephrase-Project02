#!/usr/bin/env python3
"""
å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®åˆ†æã‚·ã‚¹ãƒ†ãƒ 
Mè¦ç´ ã‚’ã‚¹ãƒ­ãƒƒãƒˆIDã§ã¯ãªãå˜èªãã®ã‚‚ã®ã§ãƒ¡ã‚¿ã‚»ãƒ«é…ç½®
"""

import json
from pathlib import Path
import sys

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from central_controller import CentralController

class WordBasedAdverbAnalyzer:
    def __init__(self):
        self.controller = CentralController()
        
    def analyze_adverb_positions_by_word(self, sentences):
        """å˜èªãƒ™ãƒ¼ã‚¹ã§å‰¯è©ä½ç½®ã‚’åˆ†æ"""
        print("ğŸš€ å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®åˆ†æé–‹å§‹")
        
        # 1. å…¨ä¾‹æ–‡ã‹ã‚‰è¦ç´ ã‚’æŠ½å‡º
        all_elements = {}
        word_positions = {}  # å˜èªåˆ¥ã®ä½ç½®æƒ…å ±
        
        for i, sentence in enumerate(sentences):
            print(f"  ğŸ“ ä¾‹æ–‡{i+1}: {sentence}")
            
            # ã‚¹ãƒ­ãƒƒãƒˆè§£æ
            try:
                slots = self.controller.parse_sentence_to_slots(sentence, "action")
                print(f"     ã‚¹ãƒ­ãƒƒãƒˆ: {slots}")
            except Exception as e:
                print(f"     âŒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
                continue
            
            # å®Ÿéš›ã®å˜èªä½ç½®ã‚’å–å¾—ï¼ˆæ–‡ä¸­ã§ã®å‡ºç¾é †åºï¼‰
            words = sentence.replace(',', '').replace('.', '').split()
            
            # å„ã‚¹ãƒ­ãƒƒãƒˆã®å˜èªã‚’ä½ç½®ã¨å…±ã«è¨˜éŒ²
            for slot_type, slot_value in slots.items():
                slot_words = slot_value.split()
                
                # å˜èªã®æ–‡ä¸­ä½ç½®ã‚’ç‰¹å®š
                for word in slot_words:
                    if word in words:
                        word_position = words.index(word) + 1
                        
                        # Mè¦ç´ ã¯å˜èªãƒ™ãƒ¼ã‚¹ã§è¨˜éŒ²
                        if slot_type.startswith('M'):
                            if slot_value not in word_positions:
                                word_positions[slot_value] = []
                            word_positions[slot_value].append({
                                'sentence': sentence,
                                'position': word_position,
                                'context': self._get_word_context(slot_value, sentence)
                            })
                        else:
                            # éMè¦ç´ ã¯å¾“æ¥é€šã‚Šã‚¹ãƒ­ãƒƒãƒˆãƒ™ãƒ¼ã‚¹
                            element_key = f"{slot_type}_normal"
                            if element_key not in all_elements:
                                all_elements[element_key] = []
                            all_elements[element_key].append({
                                'value': slot_value,
                                'sentence': sentence,
                                'position': word_position
                            })
        
        print(f"\nğŸ” å‰¯è©å˜èªã®ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        for word, positions in word_positions.items():
            print(f"  ğŸ“ '{word}':")
            for pos_info in positions:
                print(f"    â†’ {pos_info['context']} (ä½ç½®: {pos_info['position']})")
        
        # 2. å‰¯è©ã®æ–‡æ³•çš„ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        adverb_patterns = self._analyze_adverb_patterns(word_positions)
        
        # 3. éMè¦ç´ ã®å¹³å‡ä½ç½®è¨ˆç®—
        element_avg_positions = {}
        for element_type, elements in all_elements.items():
            positions = [elem['position'] for elem in elements]
            avg_pos = sum(positions) / len(positions)
            element_avg_positions[element_type] = avg_pos
            print(f"  âœ… {element_type}: å¹³å‡ä½ç½®={avg_pos:.2f}")
        
        # 4. çµ±åˆé †åºã®æ§‹ç¯‰
        final_order = self._build_integrated_order(element_avg_positions, adverb_patterns)
        
        return final_order, word_positions, adverb_patterns
    
    def _get_word_context(self, word_phrase, sentence):
        """å˜èªã®æ–‡è„ˆæƒ…å ±ã‚’å–å¾—"""
        words = sentence.replace(',', '').replace('.', '').split()
        phrase_words = word_phrase.split()
        
        try:
            start_idx = words.index(phrase_words[0])
            if start_idx == 0:
                return f"æ–‡é ­: {sentence}"
            elif start_idx == len(words) - len(phrase_words):
                return f"æ–‡æœ«: {sentence}"
            else:
                return f"æ–‡ä¸­: {sentence}"
        except ValueError:
            return f"ä¸æ˜: {sentence}"
    
    def _analyze_adverb_patterns(self, word_positions):
        """å‰¯è©ã®æ–‡æ³•çš„ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        patterns = {}
        
        for word, positions in word_positions.items():
            # ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
            position_list = [pos['position'] for pos in positions]
            avg_position = sum(position_list) / len(position_list)
            
            # æ–‡æ³•çš„å½¹å‰²ã®æ¨å®š
            contexts = [pos['context'] for pos in positions]
            
            if any('æ–‡é ­' in ctx for ctx in contexts):
                role = 'sentence_initial'
                order_position = 1
            elif any('æ–‡æœ«' in ctx for ctx in contexts):
                role = 'sentence_final'
                order_position = 10  # å¾Œã«èª¿æ•´
            elif avg_position < 3:
                role = 'pre_verb'
                order_position = 3
            else:
                role = 'post_verb'
                order_position = 5
            
            patterns[word] = {
                'role': role,
                'avg_position': avg_position,
                'order_position': order_position,
                'contexts': contexts
            }
            
            print(f"  ğŸ¯ '{word}' â†’ {role} (é †åºä½ç½®: {order_position})")
        
        return patterns
    
    def _build_integrated_order(self, element_positions, adverb_patterns):
        """çµ±åˆé †åºã‚’æ§‹ç¯‰"""
        all_order_elements = {}
        
        # éMè¦ç´ ã‚’è¿½åŠ 
        for element_type, avg_pos in element_positions.items():
            all_order_elements[element_type] = avg_pos
        
        # Mè¦ç´ ï¼ˆå‰¯è©ï¼‰ã‚’å˜èªãƒ™ãƒ¼ã‚¹ã§è¿½åŠ 
        for word, pattern in adverb_patterns.items():
            all_order_elements[f"word_{word}"] = pattern['order_position']
        
        # é †åºã§ã‚½ãƒ¼ãƒˆ
        sorted_elements = sorted(all_order_elements.items(), key=lambda x: x[1])
        
        print(f"\nğŸ“Š çµ±åˆæœ€çµ‚é †åº:")
        for i, (element, position) in enumerate(sorted_elements, 1):
            print(f"  {i}. {element} (ä½ç½®: {position:.2f})")
        
        # ç•ªå·ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        order_mapping = {}
        for i, (element, _) in enumerate(sorted_elements, 1):
            order_mapping[element] = i
        
        return order_mapping
    
    def apply_word_based_ordering(self, sentences, order_mapping, adverb_patterns):
        """å˜èªãƒ™ãƒ¼ã‚¹é †åºã‚’é©ç”¨"""
        results = []
        
        for sentence in sentences:
            try:
                slots = self.controller.parse_sentence_to_slots(sentence, "action")
                ordered_slots = {}
                
                for slot_type, slot_value in slots.items():
                    if slot_type.startswith('M'):
                        # Mè¦ç´ ã¯å˜èªãƒ™ãƒ¼ã‚¹ã§å‡¦ç†
                        word_key = f"word_{slot_value}"
                        if word_key in order_mapping:
                            order_num = order_mapping[word_key]
                            ordered_slots[str(order_num)] = slot_value
                    else:
                        # éMè¦ç´ ã¯å¾“æ¥é€šã‚Š
                        element_key = f"{slot_type}_normal"
                        if element_key in order_mapping:
                            order_num = order_mapping[element_key]
                            ordered_slots[str(order_num)] = slot_value
                
                results.append({
                    'sentence': sentence,
                    'original_slots': slots,
                    'ordered_slots': ordered_slots
                })
                
                print(f"âœ… {sentence}")
                print(f"  ğŸ¯ å˜èªãƒ™ãƒ¼ã‚¹çµæœ: {ordered_slots}")
                
            except Exception as e:
                print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {sentence} - {e}")
        
        return results

def test_word_based_approach():
    """å˜èªãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ å˜èªãƒ™ãƒ¼ã‚¹å‰¯è©ä½ç½®åˆ†æãƒ†ã‚¹ãƒˆ")
    
    # actionã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    action_sentences = [
        "She sings beautifully.",
        "We always eat breakfast together.", 
        "The cat quietly sat on the mat.",
        "She carefully reads books.",
        "They run fast.",
        "Actually, she works very hard.",
        "Every morning, he jogs slowly in the park."
    ]
    
    analyzer = WordBasedAdverbAnalyzer()
    
    # åˆ†æå®Ÿè¡Œ
    order_mapping, word_positions, adverb_patterns = analyzer.analyze_adverb_positions_by_word(action_sentences)
    
    # çµæœé©ç”¨
    results = analyzer.apply_word_based_ordering(action_sentences, order_mapping, adverb_patterns)
    
    # çµæœä¿å­˜
    output_file = "word_based_action_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å˜èªãƒ™ãƒ¼ã‚¹çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    return results

if __name__ == "__main__":
    test_word_based_approach()
