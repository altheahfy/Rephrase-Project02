#!/usr/bin/env python3
"""
äººé–“çš„åˆ¤æ–­ã«ã‚ˆã‚‹èªé †ãƒãƒƒãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
å…ƒã®ä¾‹æ–‡èªé †ã‚’å°Šé‡ã—ã€è¦–è¦šçš„ç•°å¸¸ã‚’æ¤œå‡ºã—ã¦èª¿æ•´
"""

import json
from pathlib import Path
from collections import defaultdict

class HumanLikeOrderMapper:
    def __init__(self):
        # actionã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚¹ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        self.action_data = [
            {
                "sentence": "She sings beautifully.",
                "slots": {"S": "She", "V": "sings", "M2": "beautifully"}
            },
            {
                "sentence": "We always eat breakfast together.",
                "slots": {"S": "We", "V": "eat", "O1": "breakfast", "M1": "always", "M2": "together"}
            },
            {
                "sentence": "The cat quietly sat on the mat.",
                "slots": {"S": "The cat", "V": "sat", "M1": "quietly", "M2": "on the mat"}
            },
            {
                "sentence": "She carefully reads books.",
                "slots": {"S": "She", "V": "reads", "O1": "books", "M2": "carefully"}
            },
            {
                "sentence": "They run fast.",
                "slots": {"S": "They", "V": "run", "M2": "fast"}
            },
            {
                "sentence": "Actually, she works very hard.",
                "slots": {"S": "she", "V": "works", "M1": "Actually", "M2": "very hard"}
            },
            {
                "sentence": "Every morning, he jogs slowly in the park.",
                "slots": {"S": "he", "V": "jogs", "M1": "Every morning", "M2": "slowly", "M3": "in the park"}
            }
        ]
    
    def get_word_position_in_sentence(self, sentence, word_or_phrase):
        """å…ƒã®ä¾‹æ–‡ä¸­ã§ã®å˜èª/å¥ã®å®Ÿéš›ã®ä½ç½®ã‚’å–å¾—"""
        normalized_sentence = sentence.replace(",", "").replace(".", "")
        words = normalized_sentence.split()
        
        # å¥ã®å ´åˆï¼ˆè¤‡æ•°å˜èªï¼‰
        if " " in word_or_phrase:
            phrase_words = word_or_phrase.split()
            for i in range(len(words) - len(phrase_words) + 1):
                if words[i:i+len(phrase_words)] == phrase_words:
                    return i + 1  # 1-based indexing
        else:
            # å˜èªã®å ´åˆ
            for i, word in enumerate(words):
                if word == word_or_phrase:
                    return i + 1  # 1-based indexing
        return None
    
    def create_initial_grid(self):
        """åˆæœŸã‚°ãƒªãƒƒãƒ‰ä½œæˆï¼šå„ä¾‹æ–‡ã®å®Ÿéš›ã®èªé †ã§é…ç½®"""
        print("ğŸš€ äººé–“çš„åˆ¤æ–­ã«ã‚ˆã‚‹èªé †ãƒãƒƒãƒ”ãƒ³ã‚°é–‹å§‹")
        print("=" * 60)
        
        # æœ€å¤§ä½ç½®æ•°ã‚’ç¢ºèª
        max_positions = 0
        sentence_positions = []
        
        for sentence_data in self.action_data:
            sentence = sentence_data["sentence"]
            slots = sentence_data["slots"]
            
            positions = {}
            for slot_type, element in slots.items():
                pos = self.get_word_position_in_sentence(sentence, element)
                if pos:
                    positions[pos] = element
                    max_positions = max(max_positions, pos)
            
            sentence_positions.append({
                "sentence": sentence,
                "positions": positions,
                "slots": slots
            })
        
        print(f"ğŸ“Š æœ€å¤§ä½ç½®æ•°: {max_positions}")
        
        # ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º
        print("\nğŸ“‹ åˆæœŸã‚°ãƒªãƒƒãƒ‰ï¼ˆå®Ÿéš›ã®èªé †ï¼‰:")
        print("=" * 60)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        header = "ä¾‹æ–‡\t\t\t"
        for i in range(1, max_positions + 1):
            header += f"{i}\t"
        print(header)
        print("-" * 80)
        
        # å„ä¾‹æ–‡ã®ä½ç½®ã‚’è¡¨ç¤º
        grid_data = []
        for i, sp in enumerate(sentence_positions):
            row_data = {"sentence_num": i+1, "sentence": sp["sentence"], "positions": {}}
            
            row = f"{i+1}. {sp['sentence'][:20]}...\t"
            for pos in range(1, max_positions + 1):
                element = sp["positions"].get(pos, "")
                row += f"{element}\t"
                if element:
                    row_data["positions"][pos] = element
            
            print(row)
            grid_data.append(row_data)
        
        return grid_data, max_positions
    
    def analyze_column_conflicts(self, grid_data, max_positions):
        """åˆ—å†…ã®è¡çªãƒ»ç•°å¸¸ã‚’åˆ†æ"""
        print("\nğŸ” åˆ—åˆ†æï¼šåŒã˜ä½ç½®ã®è¦ç´ ã‚’ç¢ºèª")
        print("=" * 60)
        
        column_analysis = {}
        conflict_elements = []
        
        for pos in range(1, max_positions + 1):
            elements_in_column = []
            for row in grid_data:
                element = row["positions"].get(pos)
                if element:
                    elements_in_column.append({
                        "element": element,
                        "sentence_num": row["sentence_num"],
                        "sentence": row["sentence"]
                    })
            
            column_analysis[pos] = elements_in_column
            
            print(f"\nä½ç½®{pos}:")
            if not elements_in_column:
                print("  (ç©º)")
            else:
                for item in elements_in_column:
                    print(f"  - {item['element']} (ä¾‹æ–‡{item['sentence_num']})")
                
                # è¡çªæ¤œå‡ºï¼šåŒã˜ä½ç½®ã«è¤‡æ•°ã®ç•°ãªã‚‹è¦ç´ 
                if len(elements_in_column) > 1:
                    print(f"  âš ï¸ è¡çªæ¤œå‡ºï¼åŒã˜ä½ç½®ã«{len(elements_in_column)}å€‹ã®è¦ç´ ")
                    
                    # ç‰¹æ®Šä½ç½®ã®è¦ç´ ã‚’ç‰¹å®šï¼ˆç§»å‹•å€™è£œï¼‰
                    for item in elements_in_column:
                        if item['element'] in ['together', 'carefully']:
                            conflict_elements.append({
                                'element': item['element'],
                                'current_pos': pos,
                                'sentence_num': item['sentence_num'],
                                'sentence': item['sentence']
                            })
                            print(f"    ğŸ¯ ç§»å‹•å€™è£œ: {item['element']}")
        
        return column_analysis, conflict_elements
    
    def apply_human_adjustments(self, grid_data, conflict_elements, max_positions):
        """äººé–“çš„åˆ¤æ–­ã«ã‚ˆã‚‹èª¿æ•´ã‚’é©ç”¨"""
        print("\nğŸ¯ äººé–“çš„åˆ¤æ–­ã«ã‚ˆã‚‹èª¿æ•´é©ç”¨")
        print("=" * 60)
        
        # èª¿æ•´ãƒ«ãƒ¼ãƒ«
        adjustments = {
            'together': 7,    # 7åˆ—ç›®ã«ç§»å‹•ï¼ˆæ–‡æœ«ä½ç½®ï¼‰
            'carefully': 3,   # 3åˆ—ç›®ã«ç§»å‹•ï¼ˆå‹•è©ç›´å‰ï¼‰
            'in the park': 8  # 8åˆ—ç›®ã«ç§»å‹•
        }
        
        # èª¿æ•´ã‚’é©ç”¨
        adjusted_grid = []
        for row in grid_data:
            new_row = {
                "sentence_num": row["sentence_num"],
                "sentence": row["sentence"],
                "positions": row["positions"].copy()
            }
            
            # ç§»å‹•ãŒå¿…è¦ãªè¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            elements_to_move = []
            for pos, element in list(new_row["positions"].items()):
                if element in adjustments:
                    elements_to_move.append((pos, element, adjustments[element]))
            
            # ç§»å‹•å®Ÿè¡Œ
            for old_pos, element, new_pos in elements_to_move:
                del new_row["positions"][old_pos]
                new_row["positions"][new_pos] = element
                print(f"  ğŸ“ ä¾‹æ–‡{new_row['sentence_num']}: {element} ã‚’ä½ç½®{old_pos}â†’{new_pos}ã«ç§»å‹•")
            
            # ç©ºãã‚¹ãƒ­ãƒƒãƒˆã‚’è©°ã‚ã‚‹å‡¦ç†
            self._fill_gaps(new_row)
            
            adjusted_grid.append(new_row)
        
        return adjusted_grid
    
    def _fill_gaps(self, row):
        """ç©ºãã‚¹ãƒ­ãƒƒãƒˆã‚’è©°ã‚ã‚‹"""
        positions = row["positions"]
        if not positions:
            return
        
        # ç¾åœ¨ã®ä½ç½®ã‚’ã‚½ãƒ¼ãƒˆ
        sorted_positions = sorted(positions.keys())
        
        # é€£ç¶šã—ãŸä½ç½®ã«å†é…ç½®
        new_positions = {}
        new_pos = 1
        
        for old_pos in sorted_positions:
            element = positions[old_pos]
            new_positions[new_pos] = element
            
            # ä½ç½®ãŒå¤‰ã‚ã£ãŸå ´åˆã®ãƒ­ã‚°
            if new_pos != old_pos:
                print(f"    ğŸ”§ ä¾‹æ–‡{row['sentence_num']}: {element} ã‚’ä½ç½®{old_pos}â†’{new_pos}ã«è©°ã‚ã‚‹")
            
            new_pos += 1
        
        row["positions"] = new_positions
    
    def display_final_grid(self, adjusted_grid):
        """æœ€çµ‚èª¿æ•´æ¸ˆã¿ã‚°ãƒªãƒƒãƒ‰ã‚’è¡¨ç¤º"""
        print("\nğŸ“Š æœ€çµ‚èª¿æ•´æ¸ˆã¿ã‚°ãƒªãƒƒãƒ‰:")
        print("=" * 60)
        
        # æœ€å¤§ä½ç½®ã‚’å†è¨ˆç®—
        max_pos = 0
        for row in adjusted_grid:
            if row["positions"]:
                max_pos = max(max_pos, max(row["positions"].keys()))
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        header = "ä¾‹æ–‡\t\t\t"
        for i in range(1, max_pos + 1):
            header += f"{i}\t"
        print(header)
        print("-" * 80)
        
        # å„ä¾‹æ–‡ã®èª¿æ•´å¾Œä½ç½®ã‚’è¡¨ç¤º
        results = []
        for row in adjusted_grid:
            display_row = f"{row['sentence_num']}. {row['sentence'][:20]}...\t"
            ordered_slots = {}
            
            for pos in range(1, max_pos + 1):
                element = row["positions"].get(pos, "")
                display_row += f"{element}\t"
                if element:
                    ordered_slots[str(pos)] = element
            
            print(display_row)
            
            results.append({
                "sentence": row["sentence"],
                "adjusted_ordered_slots": ordered_slots
            })
        
        return results
    
    def generate_final_mapping(self):
        """å®Œå…¨ãªäººé–“çš„åˆ¤æ–­ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç”Ÿæˆ"""
        # Step 1: åˆæœŸã‚°ãƒªãƒƒãƒ‰ä½œæˆ
        grid_data, max_positions = self.create_initial_grid()
        
        # Step 2: è¡çªåˆ†æ
        column_analysis, conflict_elements = self.analyze_column_conflicts(grid_data, max_positions)
        
        # Step 3: äººé–“çš„èª¿æ•´é©ç”¨
        adjusted_grid = self.apply_human_adjustments(grid_data, conflict_elements, max_positions)
        
        # Step 4: æœ€çµ‚ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º
        results = self.display_final_grid(adjusted_grid)
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_file = Path("human_like_order_results.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ äººé–“çš„åˆ¤æ–­çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        return results

def main():
    mapper = HumanLikeOrderMapper()
    results = mapper.generate_final_mapping()
    
    print("\nğŸ¯ æœ€çµ‚çµæœ:")
    for i, result in enumerate(results, 1):
        print(f"ä¾‹æ–‡{i}: {result['sentence']}")
        print(f"èª¿æ•´æ¸ˆã¿é †åº: {result['adjusted_ordered_slots']}")
        print()

if __name__ == "__main__":
    main()
