#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆè‡ªå‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
advmodï¼ˆå‰¯è©ä¿®é£¾èªï¼‰ã¨ç¯€æ§‹é€ ã®å‡¦ç†ã‚’çµ±ä¸€çš„ã«ä¿®æ­£
"""

import os
import re
import json
import spacy
from collections import defaultdict
import shutil
from datetime import datetime

# spaCyãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆè­¦å‘Šã‚’æŠ‘åˆ¶ï¼‰
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="torch")

try:
    nlp = spacy.load("en_core_web_sm")
except OSError:
    print("âŒ spaCyè‹±èªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("python -m spacy download en_core_web_sm")
    exit(1)

def analyze_sentence(sentence):
    """æ–‡ã®æ§‹é€ ã‚’è§£æã—ã¦advmodã¨ç¯€æ§‹é€ ã‚’æ¤œå‡º"""
    doc = nlp(sentence)
    
    advmod_tokens = []
    clause_structure = {
        'has_subject': False,
        'has_verb': False,
        'subjects': [],
        'verbs': []
    }
    
    for token in doc:
        # advmodï¼ˆå‰¯è©ä¿®é£¾èªï¼‰ã‚’æ¤œå‡º
        if token.dep_ == "advmod":
            advmod_tokens.append(token.text)
        
        # ç¯€æ§‹é€ ã®è¦ç´ ã‚’æ¤œå‡º
        if token.dep_ in ["nsubj", "nsubjpass", "csubj"]:
            clause_structure['has_subject'] = True
            clause_structure['subjects'].append(token.text)
        
        if token.pos_ == "VERB":
            clause_structure['has_verb'] = True
            clause_structure['verbs'].append(token.text)
    
    return {
        'advmod_tokens': advmod_tokens,
        'clause_structure': clause_structure,
        'has_clause': clause_structure['has_subject'] and clause_structure['has_verb']
    }

def backup_file(filepath):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
    backup_path = f"{filepath}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    shutil.copy2(filepath, backup_path)
    return backup_path

def apply_advmod_fix(filepath):
    """advmodå‡¦ç†ä¿®æ­£ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # advmodãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
    advmod_fix = '''
        # advmodï¼ˆå‰¯è©ä¿®é£¾èªï¼‰ã¯ä¿®é£¾å­ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
        if token.dep_ == "advmod":
            continue
'''
    
    # process_tokenãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†éƒ¨åˆ†ã‚’æ¢ã—ã¦ä¿®æ­£
    pattern = r'(\s+)def process_token\(self, token\):[^}]+?(\s+)for token in doc:'
    
    # ã‚ˆã‚Šå…·ä½“çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§advmodå‡¦ç†ã‚’è¿½åŠ 
    if 'def process_token(self, token):' in content:
        # process_tokenãƒ¡ã‚½ãƒƒãƒ‰ã®æœ€åˆã«advmodãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
        old_pattern = r'(def process_token\(self, token\):\s*"""[^"]*"""\s*)'
        new_replacement = r'\1' + advmod_fix.strip() + '\n        '
        
        content = re.sub(old_pattern, new_replacement, content, flags=re.DOTALL)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return True

def apply_clause_detection_fix(filepath):
    """ç¯€æ§‹é€ æ¤œå‡ºä¿®æ­£ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç¯€æ§‹é€ æ¤œå‡ºã®æ”¹å–„
    clause_fix = '''
        # ç¯€æ§‹é€ ï¼ˆSVï¼‰ã‚’æŒã¤å ´åˆã¯è©³ç´°åˆ†æ
        analysis = self.analyze_clause_structure(phrase)
        if analysis['has_clause']:
            self.handle_clause_structure(phrase, analysis)
            continue
'''
    
    # analyze_clause_structure ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
    clause_analysis_method = '''
    
    def analyze_clause_structure(self, phrase):
        """ç¯€æ§‹é€ ã‚’åˆ†æ"""
        doc = self.nlp(phrase)
        analysis = {
            'has_subject': False,
            'has_verb': False,
            'subjects': [],
            'verbs': [],
            'objects': []
        }
        
        for token in doc:
            if token.dep_ in ["nsubj", "nsubjpass", "csubj"]:
                analysis['has_subject'] = True
                analysis['subjects'].append(token.text)
            elif token.pos_ == "VERB":
                analysis['has_verb'] = True
                analysis['verbs'].append(token.text)
            elif token.dep_ in ["dobj", "iobj"]:
                analysis['objects'].append(token.text)
        
        analysis['has_clause'] = analysis['has_subject'] and analysis['has_verb']
        return analysis
    
    def handle_clause_structure(self, phrase, analysis):
        """ç¯€æ§‹é€ ã‚’é©åˆ‡ãªã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«æŒ¯ã‚Šåˆ†ã‘"""
        print(f"ğŸ”„ ç¯€æ§‹é€ æ¤œå‡º: '{phrase}' â†’ S:{analysis['subjects']}, V:{analysis['verbs']}, O:{analysis['objects']}")
'''
    
    # ã‚¯ãƒ©ã‚¹ã®æœ€å¾Œã«ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
    if 'class ' in content and 'SubSlot' in content:
        # ã‚¯ãƒ©ã‚¹ã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã¦ã€ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
        content += clause_analysis_method
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”§ å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆè‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹")
    
    # ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    subslot_files = []
    for filename in os.listdir('.'):
        if filename.startswith('step') and 'subslot' in filename and filename.endswith('.py'):
            subslot_files.append(filename)
    
    print(f"ğŸ“ ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(subslot_files)}")
    
    fixed_count = 0
    for filepath in subslot_files:
        print(f"\nğŸ”§ ä¿®æ­£ä¸­: {filepath}")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_path = backup_file(filepath)
            print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
            
            # advmodä¿®æ­£é©ç”¨
            if apply_advmod_fix(filepath):
                print("âœ… advmodå‡¦ç†ä¿®æ­£é©ç”¨å®Œäº†")
            
            # ç¯€æ§‹é€ æ¤œå‡ºä¿®æ­£é©ç”¨
            if apply_clause_detection_fix(filepath):
                print("âœ… ç¯€æ§‹é€ æ¤œå‡ºä¿®æ­£é©ç”¨å®Œäº†")
            
            fixed_count += 1
            
        except Exception as e:
            print(f"âŒ ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"\nğŸ‰ ä¿®æ­£å®Œäº†: {fixed_count}/{len(subslot_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
    print("\nğŸ“ ä¿®æ­£å†…å®¹:")
    print("  1. advmodï¼ˆå‰¯è©ä¿®é£¾èªï¼‰ã¯ä¿®é£¾å­ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†ã™ã‚‹ã‚ˆã†å¤‰æ›´")
    print("  2. ç¯€æ§‹é€ ï¼ˆSVï¼‰æ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ ")
    print("  3. å„ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§ã®é©åˆ‡ãªæŒ¯ã‚Šåˆ†ã‘å‡¦ç†ã‚’è¿½åŠ ")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã®ææ¡ˆ
    print("\nğŸ§ª ä¿®æ­£å¾Œãƒ†ã‚¹ãƒˆæ¨å¥¨:")
    print("python step12_s_subslot.py")
    print("python step13_o1_subslot_new.py")

if __name__ == "__main__":
    main()
