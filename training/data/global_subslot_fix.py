#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rule Dictionary v2.0 - å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå…±é€šä¿®æ­£ãƒ‘ãƒƒãƒ
å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ã™ã‚‹çµ±ä¸€ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 

ä¿®æ­£å¯¾è±¡:
1. advmod(å‰¯è©ä¿®é£¾èª)ã®èª¤åˆ†é¡é˜²æ­¢ - "home"ã¯ä¿®é£¾å­ã¨ã—ã¦æ‰±ã†
2. ç¯€æ§‹é€ ã®é©åˆ‡ãªåˆ†è§£ - "what you said"ã®ã‚ˆã†ãªå®Œå…¨SVæ§‹é€ 
3. æœªåˆ†é¡ãƒˆãƒ¼ã‚¯ãƒ³ã®é©åˆ‡ãªå‡¦ç†
"""

import spacy
import os
import glob
from typing import Dict, List, Tuple, Any

class GlobalSubslotFixer:
    """å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå…±é€šä¿®æ­£ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")
        
    def apply_common_fixes_to_all_subslots(self):
        """å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å…±é€šä¿®æ­£ã‚’é©ç”¨"""
        
        # å¯¾è±¡ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        subslot_files = glob.glob("step*_*subslot*.py")
        
        print("ğŸ”§ å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå…±é€šä¿®æ­£é–‹å§‹")
        print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(subslot_files)}")
        
        for file_path in subslot_files:
            print(f"\nğŸ“ ä¿®æ­£ä¸­: {file_path}")
            self._apply_fixes_to_file(file_path)
            
        print("\nâœ… å…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå…±é€šä¿®æ­£å®Œäº†")
    
    def _apply_fixes_to_file(self, file_path: str):
        """å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿®æ­£ã‚’é©ç”¨"""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ä¿®æ­£1: advmodé™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¿½åŠ 
            fixed_content = self._add_advmod_filter(content)
            
            # ä¿®æ­£2: ç¯€æ§‹é€ æ¤œå‡ºã®æ”¹å–„
            fixed_content = self._improve_clause_detection(fixed_content)
            
            # ä¿®æ­£3: æœªåˆ†é¡ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ã®è¿½åŠ 
            fixed_content = self._add_unassigned_token_handling(fixed_content)
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_path = file_path.replace('.py', '_backup.py')
            with open(backup_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            # ä¿®æ­£ç‰ˆã‚’ä¿å­˜
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(fixed_content)
                
            print(f"  âœ… ä¿®æ­£å®Œäº†: {file_path}")
            print(f"  ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")
            
        except Exception as e:
            print(f"  âŒ ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
    
    def _add_advmod_filter(self, content: str) -> str:
        """advmodé™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¿½åŠ """
        
        # æ—¢å­˜ã®åˆ†é¡ãƒ­ã‚¸ãƒƒã‚¯ã«advmodé™¤å¤–ã‚’è¿½åŠ 
        advmod_filter_code = '''        
        # advmod(å‰¯è©ä¿®é£¾èª)ã¯ä¿®é£¾å­ã¨ã—ã¦æ‰±ã„ã€å½“ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§ã¯é™¤å¤–
        if token.dep_ == "advmod":
            continue  # homeãªã©ã®å‰¯è©ä¿®é£¾èªã¯ä¿®é£¾å­ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†
        '''
        
        # é©åˆ‡ãªä½ç½®ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æŒ¿å…¥
        if "for token in doc:" in content and "advmod" not in content:
            content = content.replace(
                "for token in doc:",
                f"for token in doc:{advmod_filter_code}\n        "
            )
            
        return content
    
    def _improve_clause_detection(self, content: str) -> str:
        """ç¯€æ§‹é€ æ¤œå‡ºã®æ”¹å–„"""
        
        clause_improvement = '''
        # å®Œå…¨SVæ§‹é€ ã®ç¯€æ¤œå‡ºæ”¹å–„
        def _is_complete_clause(self, doc):
            """å®Œå…¨ãªç¯€æ§‹é€ ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
            has_subject = any(token.dep_ == "nsubj" for token in doc)
            has_verb = any(token.pos_ == "VERB" and token.dep_ == "ROOT" for token in doc)
            return has_subject and has_verb
        '''
        
        # ã‚¯ãƒ©ã‚¹å®šç¾©ã®å¾Œã«æ–°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
        if "class " in content and "_is_complete_clause" not in content:
            class_end = content.find("\n    def ")
            if class_end != -1:
                content = content[:class_end] + clause_improvement + content[class_end:]
                
        return content
    
    def _add_unassigned_token_handling(self, content: str) -> str:
        """æœªåˆ†é¡ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ã®è¿½åŠ """
        
        unassigned_handler = '''
        # æœªåˆ†é¡ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆnsubjç­‰ï¼‰ã®é©åˆ‡ãªå‡¦ç†
        unassigned_tokens = []
        for token in doc:
            if token.dep_ in ["nsubj", "nsubjpass"] and not self._is_processed_token(token):
                unassigned_tokens.append(token)
        
        if unassigned_tokens:
            # ä¸»èªãƒˆãƒ¼ã‚¯ãƒ³ã¯åˆ¥ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆï¼ˆSï¼‰ã§å‡¦ç†ã™ã‚‹ãŸã‚è¨˜éŒ²ã®ã¿
            subslots["_unassigned_subjects"] = [token.text for token in unassigned_tokens]
        '''
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã®æœ€å¾Œã«è¿½åŠ 
        if "return subslots" in content and "_unassigned" not in content:
            return_pos = content.rfind("return subslots")
            if return_pos != -1:
                content = content[:return_pos] + unassigned_handler + "\n        " + content[return_pos:]
                
        return content
    
    def test_common_fixes(self):
        """å…±é€šä¿®æ­£ã®å‹•ä½œãƒ†ã‚¹ãƒˆ"""
        
        test_cases = [
            ("to go home", "phrase"),           # homeã¯advmod
            ("what you said", "clause"),        # å®Œå…¨SVæ§‹é€ 
            ("eager to go home", "phrase"),     # homeã¯advmod
            ("To learn English", "phrase"),     # Englishã¯dobj
        ]
        
        print("ğŸ§ª å…±é€šä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        for phrase, phrase_type in test_cases:
            print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆ: '{phrase}' ({phrase_type})")
            
            doc = self.nlp(phrase)
            
            # advmodæ¤œå‡º
            advmod_tokens = [token.text for token in doc if token.dep_ == "advmod"]
            if advmod_tokens:
                print(f"  ğŸ¯ advmodæ¤œå‡º: {advmod_tokens} â†’ ä¿®é£¾å­ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†")
            
            # ç¯€æ§‹é€ æ¤œå‡º
            has_subject = any(token.dep_ == "nsubj" for token in doc)
            has_verb = any(token.pos_ == "VERB" and token.dep_ == "ROOT" for token in doc)
            if has_subject and has_verb:
                print(f"  ğŸ¯ å®Œå…¨ç¯€æ§‹é€ æ¤œå‡º: SVæ§‹é€ ã‚ã‚Š")
            
            # æœªåˆ†é¡ãƒˆãƒ¼ã‚¯ãƒ³æ¤œå‡º
            unassigned = [token.text for token in doc if token.dep_ in ["nsubj", "nsubjpass"]]
            if unassigned:
                print(f"  ğŸ¯ æœªåˆ†é¡ä¸»èª: {unassigned} â†’ Sã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã§å‡¦ç†")

if __name__ == "__main__":
    fixer = GlobalSubslotFixer()
    
    # ã¾ãšãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    fixer.test_common_fixes()
    
    print("\n" + "="*60)
    
    # å®Ÿéš›ã®ä¿®æ­£é©ç”¨
    user_input = input("\nå…¨ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿®æ­£ã‚’é©ç”¨ã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
    if user_input.lower() == 'y':
        fixer.apply_common_fixes_to_all_subslots()
    else:
        print("ä¿®æ­£ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
