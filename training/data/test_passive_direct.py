#!/usr/bin/env python3
"""
å—å‹•æ…‹æ¤œå‡ºãƒ†ã‚¹ãƒˆï¼ˆç›´æ¥å®Ÿè£…ï¼‰
"""

import spacy

def test_passive_detection():
    """å—å‹•æ…‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç›´æ¥æ¤œå‡º"""
    
    # spaCyåˆæœŸåŒ–
    nlp = spacy.load("en_core_web_sm")
    
    test_sentences = [
        'The book was written.',
        'The book was written by John.',
        'The car is repaired.',
        'She was surprised by the news.',
        'The project will be completed.'
    ]
    
    print('ğŸ”¥ å—å‹•æ…‹æ¤œå‡ºãƒ†ã‚¹ãƒˆ')
    print('='*50)
    
    for sentence in test_sentences:
        print(f'\nğŸ“ ãƒ†ã‚¹ãƒˆæ–‡: {sentence}')
        doc = nlp(sentence)
        
        # åŸºæœ¬çš„ãªå—å‹•æ…‹æ¤œå‡º
        passive_found = False
        be_verb = ""
        past_participle = ""
        
        tokens = list(doc)
        for i in range(len(tokens) - 1):
            current = tokens[i]
            next_token = tokens[i + 1] if i + 1 < len(tokens) else None
            
            # beå‹•è© + éå»åˆ†è©ãƒ‘ã‚¿ãƒ¼ãƒ³
            if (current.lemma_.lower() == 'be' and 
                current.pos_ in ['AUX', 'VERB'] and
                next_token and next_token.tag_ == 'VBN'):
                
                passive_found = True
                be_verb = current.text
                past_participle = next_token.text
                break
            
            # modal + be + éå»åˆ†è©ãƒ‘ã‚¿ãƒ¼ãƒ³
            if (current.pos_ == 'AUX' and 
                current.text.lower() in ['will', 'would', 'can', 'could', 'should'] and
                i + 2 < len(tokens)):
                
                be_token = tokens[i + 1]
                pp_token = tokens[i + 2]
                
                if (be_token.lemma_.lower() == 'be' and 
                    pp_token.tag_ == 'VBN'):
                    
                    passive_found = True
                    be_verb = f"{current.text} {be_token.text}"
                    past_participle = pp_token.text
                    break
        
        # byå¥ã®æ¤œå‡º
        by_phrase = ""
        for token in tokens:
            if token.text.lower() == 'by' and token.pos_ == 'ADP':
                # byä»¥é™ã®åè©å¥ã‚’ç°¡å˜ã«æŠ½å‡º
                idx = token.i
                phrase_parts = ['by']
                for j in range(idx + 1, min(idx + 4, len(tokens))):
                    next_tok = tokens[j]
                    if next_tok.pos_ in ['NOUN', 'PROPN', 'DET']:
                        phrase_parts.append(next_tok.text)
                    else:
                        break
                if len(phrase_parts) > 1:
                    by_phrase = ' '.join(phrase_parts)
                break
        
        # çµæœè¡¨ç¤º
        if passive_found:
            print(f'âœ… å—å‹•æ…‹æ¤œå‡º: {be_verb} + {past_participle}')
            if by_phrase:
                print(f'ğŸ“ byå¥: {by_phrase}')
            print(f'ğŸ¯ V ã‚¹ãƒ­ãƒƒãƒˆå€™è£œ: {be_verb} {past_participle}')
        else:
            print('âŒ å—å‹•æ…‹æœªæ¤œå‡º')
        
        print('-' * 30)

if __name__ == '__main__':
    test_passive_detection()
