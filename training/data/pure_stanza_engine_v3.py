#!/usr/bin/env python3
"""
Pure Stanza Engine v3 - ã‚¼ãƒ­ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰ˆ
ä½“ç³»çš„ãªä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°ã«ã‚ˆã‚‹æ±ç”¨çš„æ–‡åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³
"""

import stanza
import spacy
import json
from typing import Dict, List, Optional, Tuple, Any

class PureStanzaEngineV3:
    """
    Pure Stanza Engine v3 - å®Œå…¨è¨­å®šé§†å‹•å‹
    
    è¨­è¨ˆåŸå‰‡:
    1. ã‚¼ãƒ­ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° - ç‰¹å®šã®èªå½™ãƒ»æ§‹é€ ã«ä¾å­˜ã—ãªã„
    2. ãƒ‘ã‚¿ãƒ¼ãƒ³é§†å‹• - Stanzaä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰Rephraseã‚¹ãƒ­ãƒƒãƒˆã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    3. æ‹¡å¼µå¯èƒ½ - æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯è¨­å®šè¿½åŠ ã®ã¿ã§å¯¾å¿œ
    """
    
    def __init__(self):
        """ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–"""
        print("ğŸ¯ PureStanzaEngine v3 åˆæœŸåŒ–ä¸­...")
        
        # Stanza NLP ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        self.nlp = stanza.Pipeline('en', verbose=False)
        print("âœ… Stanzaæº–å‚™å®Œäº†")
        
        # spaCyï¼ˆå¢ƒç•Œèª¿æ•´ç”¨ï¼‰
        self.spacy_nlp = spacy.load("en_core_web_sm")
        print("âœ… spaCyæº–å‚™å®Œäº†")
        
        # æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ«
        self.sentence_patterns = self._load_sentence_patterns()
        
        # ä¿®é£¾èªãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«
        self.modifier_mappings = self._load_modifier_mappings()
        
        print("ğŸ—ï¸ è¨­å®šé§†å‹•å‹ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº† (v3)")
        
    def _load_sentence_patterns(self) -> Dict[str, Any]:
        """æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        return {
            # ç¬¬1æ–‡å‹ (SV): nsubj -> root(VERB)
            "SV": {
                "required_relations": ["nsubj", "root"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "root": "V"
                }
            },
            
            # åŠ©å‹•è©æ§‹æ–‡: nsubj -> aux -> root(VERB)
            "S_AUX_V": {
                "required_relations": ["nsubj", "aux", "root"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "aux": "Aux",
                    "root": "V"
                }
            },
            
            # åŠ©å‹•è© + ç›®çš„èª: nsubj -> aux -> root(VERB) -> obj
            "S_AUX_V_O": {
                "required_relations": ["nsubj", "aux", "root", "obj"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "aux": "Aux",
                    "root": "V",
                    "obj": "O1"
                }
            },
            
            # å—å‹•æ…‹: nsubj:pass -> aux:pass -> root(VERB)
            "PASSIVE": {
                "required_relations": ["nsubj:pass", "aux:pass", "root"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj:pass": "S",
                    "aux:pass": "Aux",
                    "root": "V"
                }
            },
            
            # å—å‹•æ…‹ + åŠ©å‹•è©: nsubj:pass -> aux -> aux:pass -> root(VERB)
            "PASSIVE_AUX": {
                "required_relations": ["nsubj:pass", "aux", "aux:pass", "root"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj:pass": "S",
                    "aux": "Aux",
                    "aux:pass": "Aux",  # è¤‡æ•°ã®Auxã¯çµ±åˆå‡¦ç†
                    "root": "V"
                }
            },
            
            # Thereæ§‹æ–‡: expl -> root(VERB) -> nsubj
            "THERE_BE": {
                "required_relations": ["expl", "nsubj", "root"],
                "root_pos": ["VERB"],
                "expl_check": True,
                "mapping": {
                    "expl": "M1",  # "There" ã‚’ M1 ã«é…ç½®
                    "root": "V",
                    "nsubj": "O1"  # çœŸã®ä¸»èªã¯ O1 ã«é…ç½®
                }
            },
            
            # ç–‘å•æ–‡ï¼ˆç–‘å•è©ãŒROOTï¼‰: root(PRON) -> cop -> nsubj
            "WH_BE": {
                "required_relations": ["nsubj", "cop", "root"],
                "root_pos": ["PRON"],
                "mapping": {
                    "root": "O1",  # ç–‘å•è©ã‚’ O1 ã«é…ç½®
                    "cop": "V",
                    "nsubj": "S"
                }
            },
            
            # ç¬¬2æ–‡å‹ (SVC): nsubj -> cop -> root(ADJ/NOUN)  
            "SVC_BE": {
                "required_relations": ["nsubj", "cop", "root"],
                "root_pos": ["ADJ", "NOUN"],
                "mapping": {
                    "nsubj": "S",
                    "cop": "V", 
                    "root": "C1"
                }
            },
            
            # ç¬¬2æ–‡å‹å¤‰å½¢: nsubj -> root(VERB) -> xcomp(ADJ)
            "SVC_LOOKS": {
                "required_relations": ["nsubj", "root", "xcomp"],
                "root_pos": ["VERB"],
                "xcomp_pos": ["ADJ"],
                "mapping": {
                    "nsubj": "S",
                    "root": "V",
                    "xcomp": "C1"
                }
            },
            
            # ç¬¬3æ–‡å‹ (SVO): nsubj -> root(VERB) -> obj
            "SVO": {
                "required_relations": ["nsubj", "root", "obj"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "root": "V",
                    "obj": "O1"
                }
            },
            
            # ç¬¬4æ–‡å‹ (SVOO): nsubj -> root(VERB) -> obj + iobj
            "SVOO": {
                "required_relations": ["nsubj", "root", "obj", "iobj"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "root": "V",
                    "iobj": "O1",  # é–“æ¥ç›®çš„èªãŒå…ˆ
                    "obj": "O2"    # ç›´æ¥ç›®çš„èªãŒå¾Œ
                }
            },
            
            # ç¬¬5æ–‡å‹ (SVOC): nsubj -> root(VERB) -> obj -> xcomp
            "SVOC": {
                "required_relations": ["nsubj", "root", "obj", "xcomp"],
                "root_pos": ["VERB"],
                "mapping": {
                    "nsubj": "S",
                    "root": "V",
                    "obj": "O1",
                    "xcomp": "C2"
                }
            }
        }
        
    def _load_modifier_mappings(self) -> Dict[str, str]:
        """ä¿®é£¾èªãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«"""
        return {
            "advmod": "M2",      # å‰¯è©ä¿®é£¾èªãƒ»å¦å®šè¾ â†’ M2
            "amod": "subslot",   # å½¢å®¹è©ä¿®é£¾èª â†’ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå†…å‡¦ç†
            "det": "subslot",    # é™å®šè© â†’ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå†…å‡¦ç†
            "case": "subslot",   # å‰ç½®è© â†’ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå†…å‡¦ç†
            "nmod": "M1",        # åè©ä¿®é£¾èª â†’ M1 (æ–‡è„ˆã«ã‚ˆã‚Šå¤‰æ›´å¯èƒ½)
            "mark": "subslot",   # å¾“å±ç¯€ãƒãƒ¼ã‚«ãƒ¼ â†’ ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå†…å‡¦ç†
            "csubj": "O1",       # ç¯€ä¸»èª â†’ O1
        }
    
    def decompose(self, text: str) -> Dict[str, Any]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã«åˆ†è§£
        
        Args:
            text: å…¥åŠ›æ–‡
            
        Returns:
            Rephraseã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ è¾æ›¸
        """
        print(f"\nğŸ¯ StanzaåŸºæœ¬åˆ†è§£é–‹å§‹: '{text}...'")
        
        # Stanzaè§£æ
        doc = self.nlp(text)
        sent = doc.sentences[0]
        
        # ROOTå‹•è©ç‰¹å®š
        root_verb = self._find_root_verb(sent)
        if not root_verb:
            print("âŒ ROOTå‹•è©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
            
        print(f"ğŸ“Œ ROOT: '{root_verb.text}' (POS: {root_verb.upos})")
        
        # æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
        sentence_pattern = self._identify_sentence_pattern(sent, root_verb)
        if not sentence_pattern:
            print("âŒ å¯¾å¿œã™ã‚‹æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
            
        print(f"ğŸ” æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³: {sentence_pattern}")
        
        # åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        basic_slots = self._extract_basic_slots(sent, root_verb, sentence_pattern)
        
        # ä¿®é£¾èªã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        modifier_slots = self._extract_modifier_slots(sent, root_verb)
        
        # çµ±åˆ
        all_slots = {**basic_slots, **modifier_slots}
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†
        result_slots = self._extract_all_subslots(sent, all_slots)
        
        return result_slots
        
    def _find_root_verb(self, sent) -> Optional[Any]:
        """ROOTå‹•è©ã‚’ç‰¹å®š"""
        for word in sent.words:
            if word.deprel == 'root':
                return word
        return None
        
    def _identify_sentence_pattern(self, sent, root_verb) -> Optional[str]:
        """æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è­˜åˆ¥"""
        
        # æ–‡ä¸­ã®ä¾å­˜é–¢ä¿‚ã‚’åé›†
        present_relations = set()
        pos_info = {}
        
        for word in sent.words:
            present_relations.add(word.deprel)
            if word.deprel == 'root':
                pos_info['root'] = word.upos
            elif word.deprel == 'xcomp':
                pos_info['xcomp'] = word.upos
                
        print(f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸé–¢ä¿‚: {sorted(present_relations)}")
                
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å„ªå…ˆé †ä½ä»˜ãæ¤œæŸ»ï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªã‚‚ã®ã‹ã‚‰ï¼‰
        pattern_priority = [
            # ç‰¹æ®Šæ§‹æ–‡
            "PASSIVE_AUX", "PASSIVE", "THERE_BE", "WH_BE",
            # åŠ©å‹•è©ç³»
            "S_AUX_V_O", "S_AUX_V",
            # åŸºæœ¬æ–‡å‹
            "SVOO", "SVOC", "SVO", "SVC_LOOKS", "SVC_BE", "SV"
        ]
        
        for pattern_name in pattern_priority:
            if pattern_name not in self.sentence_patterns:
                continue
                
            pattern_config = self.sentence_patterns[pattern_name]
            required_relations = set(pattern_config["required_relations"])
            
            # å¿…é ˆé–¢ä¿‚ãŒã™ã¹ã¦å­˜åœ¨ã™ã‚‹ã‹
            if not required_relations.issubset(present_relations):
                continue
                
            # ROOTã®POSåˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            if "root_pos" in pattern_config:
                if pos_info.get('root') not in pattern_config["root_pos"]:
                    continue
                    
            # xcompã®POSåˆ¶ç´„ãƒã‚§ãƒƒã‚¯ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
            if "xcomp_pos" in pattern_config:
                if pos_info.get('xcomp') not in pattern_config["xcomp_pos"]:
                    continue
                    
            # Thereæ§‹æ–‡ã®ç‰¹åˆ¥ãƒã‚§ãƒƒã‚¯
            if "expl_check" in pattern_config:
                if 'expl' not in present_relations:
                    continue
                    
            print(f"âœ… ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern_name}")
            return pattern_name
            
        print("âŒ ãƒãƒƒãƒã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—")
        return None
        
    def _extract_basic_slots(self, sent, root_verb, pattern_name: str) -> Dict[str, Dict[str, str]]:
        """åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³é§†å‹•ï¼‰"""
        pattern_config = self.sentence_patterns[pattern_name]
        mapping = pattern_config["mapping"]
        
        slots = {}
        
        # ä¾å­˜é–¢ä¿‚ã”ã¨ã«ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        aux_words = []  # è¤‡æ•°ã®Auxã‚’çµ±åˆ
        
        for word in sent.words:
            if word.deprel in mapping:
                slot_name = mapping[word.deprel]
                
                # Auxã‚¹ãƒ­ãƒƒãƒˆã®ç‰¹åˆ¥å‡¦ç†ï¼ˆè¤‡æ•°ã®auxã‚’çµ±åˆï¼‰
                if slot_name == "Aux":
                    aux_words.append(word)
                    continue
                
                # ã‚¹ãƒ­ãƒƒãƒˆå¢ƒç•Œã‚’å–å¾—
                slot_range = self._get_slot_boundary(sent, word, word.deprel)
                slot_text = self._extract_text_range(sent, slot_range)
                
                print(f"ğŸ“ {slot_name}æ¤œå‡º: '{slot_text}' (deprel: {word.deprel})")
                
                slots[slot_name] = {'main': slot_text}
        
        # è¤‡æ•°ã®Auxã‚’çµ±åˆå‡¦ç†
        if aux_words:
            aux_texts = [word.text for word in sorted(aux_words, key=lambda w: w.id)]
            aux_combined = " ".join(aux_texts)
            print(f"ğŸ“ Auxæ¤œå‡º: '{aux_combined}' (çµ±åˆ: {len(aux_words)}å€‹)")
            slots["Aux"] = {'main': aux_combined}
                
        return slots
        
    def _extract_modifier_slots(self, sent, root_verb) -> Dict[str, Dict[str, str]]:
        """ä¿®é£¾èªã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º"""
        modifier_slots = {}
        
        for word in sent.words:
            if word.deprel in self.modifier_mappings:
                slot_mapping = self.modifier_mappings[word.deprel]
                
                if slot_mapping == "subslot":
                    # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå†…ã§å‡¦ç†ï¼ˆã“ã“ã§ã¯ç„¡è¦–ï¼‰
                    continue
                elif slot_mapping in ["M1", "M2", "M3"]:
                    # ä¿®é£¾èªã‚¹ãƒ­ãƒƒãƒˆã«é…ç½®
                    slot_text = word.text  # åŸºæœ¬çš„ã«å˜èªãã®ã‚‚ã®
                    print(f"ğŸ“ {slot_mapping}æ¤œå‡º: '{slot_text}' (ä¿®é£¾èª: {word.deprel})")
                    modifier_slots[slot_mapping] = {'main': slot_text}
                    
        return modifier_slots
        
    def _get_slot_boundary(self, sent, word, deprel: str) -> Tuple[int, int]:
        """ã‚¹ãƒ­ãƒƒãƒˆå¢ƒç•Œã‚’æ±ºå®šï¼ˆé–¢ä¿‚ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ï¼‰"""
        
        if deprel in ["cop", "aux", "aux:pass"]:
            # beå‹•è©ãƒ»åŠ©å‹•è©ã¯å˜èªãã®ã‚‚ã®
            return (word.start_char, word.end_char)
        elif deprel == "root" and word.upos == "VERB":
            # å‹•è©ROOTã¯å‹•è©å˜ä½“ã®ã¿
            return (word.start_char, word.end_char)
        elif deprel in ["nsubj", "nsubj:pass", "obj", "iobj"]:
            # ä¸»èªãƒ»ç›®çš„èªã¯é™å®šè©ãƒ»ä¿®é£¾èªã‚’å«ã‚€
            return self._find_noun_phrase_boundary(sent, word)
        elif deprel == "root" and word.upos in ["ADJ", "NOUN", "PRON"]:
            # beå‹•è©æ§‹æ–‡ã®è£œèªãƒ»ç–‘å•è©
            return self._find_complement_boundary(sent, word)
        elif deprel == "xcomp":
            # è£œèªã¯ä¿®é£¾èªã‚’å«ã‚€
            return self._find_complement_boundary(sent, word)
        elif deprel == "expl":
            # "There"ã¯å˜èªãã®ã‚‚ã®
            return (word.start_char, word.end_char)
        elif deprel == "csubj":
            # ç¯€ä¸»èªã¯å®Œå…¨ãªä¸‹ä½ãƒ„ãƒªãƒ¼
            return self._find_complete_subtree_range(sent, word)
        else:
            # ãã®ä»–ã¯å®Œå…¨ãªä¸‹ä½ãƒ„ãƒªãƒ¼
            return self._find_complete_subtree_range(sent, word)
            
    def _find_noun_phrase_boundary(self, sent, noun_word) -> Tuple[int, int]:
        """åè©å¥å¢ƒç•Œæ¤œå‡ºï¼ˆé™å®šè©ãƒ»å½¢å®¹è©ä¿®é£¾èªã‚’å«ã‚€ï¼‰"""
        min_idx = noun_word.id
        max_idx = noun_word.id
        
        # ä¿®é£¾è¦ç´ ã‚’åé›†
        for word in sent.words:
            if word.head == noun_word.id and word.deprel in ['det', 'amod', 'compound']:
                min_idx = min(min_idx, word.id)
                max_idx = max(max_idx, word.id)
                
        # æ–‡å­—ä½ç½®ã«å¤‰æ›
        start_char = sent.words[min_idx-1].start_char
        end_char = sent.words[max_idx-1].end_char
        return (start_char, end_char)
        
    def _find_complement_boundary(self, sent, comp_word) -> Tuple[int, int]:
        """è£œèªå¢ƒç•Œæ¤œå‡ºï¼ˆbeå‹•è©æ§‹æ–‡ç”¨ï¼‰"""
        complement_words = {comp_word.id}
        
        # è£œèªã®ä¿®é£¾èªã‚’åé›†ï¼ˆä¸»èªãƒ»beå‹•è©ã¯é™¤å¤–ï¼‰
        for word in sent.words:
            if word.head == comp_word.id and word.deprel in ['det', 'amod', 'case']:
                complement_words.add(word.id)
                # ä¸‹ä½ãƒ„ãƒªãƒ¼ã‚‚è¿½åŠ 
                descendants = self._collect_descendants(sent, word)
                complement_words.update(descendants)
                
        # å¥èª­ç‚¹ã‚’é™¤å¤–
        complement_words = {word_id for word_id in complement_words 
                          if sent.words[word_id-1].upos != 'PUNCT'}
        
        if not complement_words:
            return (comp_word.start_char, comp_word.end_char)
            
        min_idx = min(complement_words)
        max_idx = max(complement_words)
        
        start_char = sent.words[min_idx-1].start_char
        end_char = sent.words[max_idx-1].end_char
        return (start_char, end_char)
        
    def _collect_descendants(self, sent, root_word) -> set:
        """å˜èªã®ä¸‹ä½ãƒ„ãƒªãƒ¼ã®IDã‚’åé›†"""
        descendants = set()
        for word in sent.words:
            if word.head == root_word.id:
                descendants.add(word.id)
                descendants.update(self._collect_descendants(sent, word))
        return descendants
        
    def _find_complete_subtree_range(self, sent, word) -> Tuple[int, int]:
        """å®Œå…¨ãªä¸‹ä½ãƒ„ãƒªãƒ¼ã®ç¯„å›²ã‚’å–å¾—"""
        subtree_ids = {word.id}
        subtree_ids.update(self._collect_descendants(sent, word))
        
        # å¥èª­ç‚¹ã‚’é™¤å¤–
        subtree_ids = {word_id for word_id in subtree_ids 
                      if sent.words[word_id-1].upos != 'PUNCT'}
        
        if not subtree_ids:
            return (word.start_char, word.end_char)
            
        min_idx = min(subtree_ids)
        max_idx = max(subtree_ids)
        
        start_char = sent.words[min_idx-1].start_char
        end_char = sent.words[max_idx-1].end_char
        return (start_char, end_char)
        
    def _extract_text_range(self, sent, char_range: Tuple[int, int]) -> str:
        """æ–‡å­—ç¯„å›²ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        full_text = sent.text
        start_char, end_char = char_range
        return full_text[start_char:end_char].strip()
        
    def _extract_all_subslots(self, sent, slots: Dict[str, Dict[str, str]]) -> Dict[str, Dict[str, str]]:
        """å…¨ã‚¹ãƒ­ãƒƒãƒˆã«å¯¾ã—ã¦ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†ã‚’å®Ÿè¡Œ"""
        result = {}
        
        for slot_name, slot_data in slots.items():
            if 'main' in slot_data and slot_data['main']:
                # ç¾åœ¨ã¯mainã®ã¿ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†ã¯å°†æ¥å®Ÿè£…ï¼‰
                result[slot_name] = {'main': slot_data['main']}
            else:
                result[slot_name] = slot_data
                
        return result
