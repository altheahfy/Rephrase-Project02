#!/usr/bin/env python3
"""
å­¦ç¿’å‹54ä¾‹æ–‡ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Ÿéš›ã®custom_test.pyä½¿ç”¨ç‰ˆï¼‰
AIæ¨æ¸¬ â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨‚æ­£ â†’ å­¦ç¿’æ”¹å–„ã®ã‚µã‚¤ã‚¯ãƒ«
"""

import json
import re
import ast
from unified_stanza_rephrase_mapper import UnifiedStanzaRephraseMapper

class RealCustomLearningValidator:
    """å­¦ç¿’å‹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Ÿéš›ã®custom_test.pyä¾‹æ–‡ç‰ˆï¼‰"""
    
    def __init__(self):
        self.mapper = UnifiedStanzaRephraseMapper(log_level='INFO')
        self.mapper.add_handler('basic_five_pattern')
        self.mapper.add_handler('relative_clause')
        self.mapper.add_handler('adverbial_modifier')
        
        # custom_test.pyã‹ã‚‰å®Ÿéš›ã®54ä¾‹æ–‡ã‚’èª­ã¿è¾¼ã¿
        self.test_sentences = self._load_custom_test_sentences()
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.learning_db = {
            "correction_patterns": [],
            "confidence_scores": {},
            "confirmed_results": {}
        }
    
    def _load_custom_test_sentences(self):
        """custom_test.pyã‹ã‚‰å®Ÿéš›ã®ä¾‹æ–‡ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open('custom_test.py', 'r', encoding='utf-8') as f:
                content = f.read()
            
            # your_test_sentencesé…åˆ—ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            sentences = []
            in_array = False
            bracket_count = 0
            
            lines = content.split('\n')
            for line in lines:
                if 'your_test_sentences = [' in line:
                    in_array = True
                    bracket_count = line.count('[') - line.count(']')
                    continue
                
                if in_array:
                    bracket_count += line.count('[') - line.count(']')
                    
                    # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’æŠ½å‡º
                    string_matches = re.findall(r'"([^"]*)"', line)
                    for match in string_matches:
                        sentence = match.strip()
                        if sentence and not sentence.startswith('#') and len(sentence) > 5:
                            sentences.append(sentence)
                    
                    if bracket_count <= 0:
                        break
            
            print(f"âœ… custom_test.pyã‹ã‚‰{len(sentences)}ä¾‹æ–‡ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return sentences
            
        except Exception as e:
            print(f"âš ï¸  custom_test.pyèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¾‹æ–‡ã‚’ä½¿ç”¨ã—ã¾ã™")
            return [
                "The man who runs fast is strong.",
                "The book which I bought is expensive.",
                "The car which was crashed is red.",
                "The place where we met is beautiful.",
                "The book I read yesterday was boring."
            ]
    
    def generate_initial_expectation(self, sentence_id, sentence):
        """AIåˆæœŸæ¨æ¸¬ç”Ÿæˆ"""
        
        print(f"\nğŸ“ ä¾‹æ–‡{sentence_id}: {sentence}")
        
        try:
            # å®Ÿéš›ã®ãƒãƒƒãƒ‘ãƒ¼å‡¦ç†
            result = self.mapper.process(sentence)
            
            main_slots = result.get('slots', {})
            sub_slots = result.get('sub_slots', {})
            
            # ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ï¼‰
            confidence = self._calculate_confidence(sentence, main_slots, sub_slots)
            
            ai_expectation = {
                "sentence": sentence,
                "main_slots": main_slots,
                "sub_slots": sub_slots,
                "confidence": confidence,
                "ai_expectation": {
                    "main_slots": main_slots,
                    "sub_slots": sub_slots
                }
            }
            
            print(f"ğŸ¤– AIæ¨æ¸¬çµæœ:")
            print(f"   Main slots: {main_slots}")
            print(f"   Sub slots: {sub_slots}")
            print(f"   ä¿¡é ¼åº¦: {confidence:.1f}%")
            
            return ai_expectation
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _calculate_confidence(self, sentence, main_slots, sub_slots):
        """ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆå­¦ç¿’å±¥æ­´ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # åŸºæœ¬ä¿¡é ¼åº¦
        base_confidence = 50.0
        
        # å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern in self.learning_db["correction_patterns"]:
            if self._pattern_matches(sentence, pattern):
                # éå»ã®è¨‚æ­£é »åº¦ã§ä¿¡é ¼åº¦èª¿æ•´
                correction_rate = pattern.get("correction_rate", 0.5)
                base_confidence *= (1 - correction_rate)
        
        # ã‚¹ãƒ­ãƒƒãƒˆæ•°ã«ã‚ˆã‚‹ä¿¡é ¼åº¦èª¿æ•´
        total_slots = len(main_slots) + len(sub_slots)
        if total_slots > 4:
            base_confidence *= 0.8  # è¤‡é›‘æ–‡ã¯ä¿¡é ¼åº¦ä¸‹é™
        
        # ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        special_patterns = ["who", "which", "where", "whose", "that"]
        for pattern in special_patterns:
            if pattern in sentence.lower():
                base_confidence *= 0.7  # é–¢ä¿‚è©ã¯é›£ã—ã„
                break
        
        return min(95.0, max(20.0, base_confidence))
    
    def _pattern_matches(self, sentence, pattern):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ç°¡æ˜“ç‰ˆ"""
        # ç°¡æ˜“çš„ãªå®Ÿè£…ï¼ˆå¾Œã§æ”¹å–„ï¼‰
        trigger_words = pattern.get("trigger_words", [])
        for word in trigger_words:
            if word in sentence.lower():
                return True
        return False
    
    def process_user_correction(self, sentence_id, user_correction):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨‚æ­£ã®å‡¦ç†ã¨å­¦ç¿’"""
        
        if sentence_id not in self.learning_db["confirmed_results"]:
            print(f"âŒ ä¾‹æ–‡{sentence_id}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # è¨‚æ­£å‰ã®æ¨æ¸¬
        ai_expectation = self.learning_db["confirmed_results"][sentence_id]["ai_expectation"]
        
        print(f"\nğŸ“š å­¦ç¿’å‡¦ç†: ä¾‹æ–‡{sentence_id}")
        print(f"ğŸ¤– AIæ¨æ¸¬: {ai_expectation}")
        print(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨‚æ­£: {user_correction}")
        
        # è¨‚æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºãƒ»å­¦ç¿’
        correction_pattern = self._extract_correction_pattern(
            self.test_sentences[sentence_id-1], 
            ai_expectation, 
            user_correction
        )
        
        if correction_pattern:
            self.learning_db["correction_patterns"].append(correction_pattern)
            print(f"ğŸ§  æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’: {correction_pattern['pattern_name']}")
        
        # ç¢ºèªæ¸ˆã¿ãƒãƒ¼ã‚¯
        self.learning_db["confirmed_results"][sentence_id]["user_confirmed"] = True
        self.learning_db["confirmed_results"][sentence_id]["user_correction"] = user_correction
        
        print("âœ… å­¦ç¿’å®Œäº†")
    
    def _extract_correction_pattern(self, sentence, ai_result, user_result):
        """è¨‚æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        
        pattern = {
            "pattern_name": f"correction_{len(self.learning_db['correction_patterns'])+1}",
            "sentence_example": sentence,
            "trigger_words": [],
            "main_slots": {},
            "sub_slots": {},
            "rules": []
        }
        
        # ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        words = sentence.lower().split()
        for word in words:
            if word in ["who", "which", "where", "whose", "that"]:
                pattern["trigger_words"].append(word)
        
        # ã‚¹ãƒ­ãƒƒãƒˆè¨‚æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
        ai_main = ai_result.get("main_slots", {})
        user_main = user_result.get("main_slots", {})
        
        for slot in user_main:
            if slot not in ai_main or ai_main[slot] != user_main[slot]:
                pattern["main_slots"][slot] = user_main[slot]
                pattern["rules"].append(f"{slot} should be '{user_main[slot]}'")
        
        return pattern
    
    def batch_process_with_learning(self, start_idx=1, end_idx=5):
        """å­¦ç¿’å‹ãƒãƒƒãƒå‡¦ç†"""
        
        print(f"ğŸš€ 54ä¾‹æ–‡å­¦ç¿’å‹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆä¾‹æ–‡{start_idx}-{end_idx}ï¼‰")
        print("="*60)
        
        for i in range(start_idx-1, min(end_idx, len(self.test_sentences))):
            sentence_id = i + 1
            sentence = self.test_sentences[i]
            
            # AIæ¨æ¸¬ç”Ÿæˆ
            result = self.generate_initial_expectation(sentence_id, sentence)
            if result:
                self.learning_db["confirmed_results"][sentence_id] = result
                
                print(f"\nâ³ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªå¾…ã¡...")
                print(f"ğŸ’¡ ã“ã®æ¨æ¸¬ã¯æ­£ã—ã„ã§ã™ã‹ï¼Ÿä¿®æ­£ç‚¹ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚")
                print(f"   æ­£ã—ã„å ´åˆ: 'OK' ã¾ãŸã¯ 'ok'")
                print(f"   ä¿®æ­£ãŒã‚ã‚‹å ´åˆ: ä¿®æ­£å†…å®¹ã‚’å…·ä½“çš„ã«")
                print("-" * 40)
        
        # å­¦ç¿’çŠ¶æ³ã‚µãƒãƒªãƒ¼
        confirmed = len([r for r in self.learning_db["confirmed_results"].values() if "user_confirmed" in r])
        total = len(self.learning_db["confirmed_results"])
        
        print(f"\nğŸ“Š å­¦ç¿’çŠ¶æ³: {confirmed}/{total} ä¾‹æ–‡ç¢ºèªæ¸ˆã¿")
        
        return self.learning_db["confirmed_results"]
    
    def get_learning_stats(self):
        """å­¦ç¿’çµ±è¨ˆæƒ…å ±"""
        return {
            "total_patterns": len(self.learning_db["correction_patterns"]),
            "confirmed_sentences": len([r for r in self.learning_db["confirmed_results"].values() if "user_confirmed" in r]),
            "total_sentences": len(self.test_sentences),
            "patterns": self.learning_db["correction_patterns"]
        }

def demo_real_custom_system():
    """å­¦ç¿’å‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ï¼ˆå®Ÿéš›ã®custom_test.pyä½¿ç”¨ï¼‰"""
    
    validator = RealCustomLearningValidator()
    
    print("ğŸ“ å­¦ç¿’å‹54ä¾‹æ–‡ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Ÿéš›ã®custom_test.pyç‰ˆï¼‰")
    print("="*60)
    print("ğŸ’¡ ã‚³ãƒ³ã‚»ãƒ—ãƒˆ:")
    print("   1. custom_test.pyã®å®Ÿéš›ã®54ä¾‹æ–‡ã‚’ä½¿ç”¨")
    print("   2. AIãŒæœŸå¾…çµæœã‚’æ¨æ¸¬")
    print("   3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç¢ºèªãƒ»è¨‚æ­£")
    print("   4. AIãŒè¨‚æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’")
    print("   5. å¾ŒåŠã«ãªã‚‹ã»ã©ç²¾åº¦å‘ä¸Š")
    print("="*60)
    
    # å®Ÿéš›ã®ä¾‹æ–‡ç¢ºèª
    print(f"\nğŸ“– èª­ã¿è¾¼ã¿ä¾‹æ–‡æ•°: {len(validator.test_sentences)}")
    print("æœ€åˆã®5ä¾‹æ–‡:")
    for i, sentence in enumerate(validator.test_sentences[:5], 1):
        print(f"  {i}. {sentence}")
    
    print("\n" + "="*60)
    
    # æœ€åˆã®3ä¾‹æ–‡ã§ãƒ‡ãƒ¢
    results = validator.batch_process_with_learning(1, 3)
    
    return validator

if __name__ == "__main__":
    demo_real_custom_system()
