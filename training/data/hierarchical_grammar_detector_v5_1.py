#!/usr/bin/env python3
"""
Hierarchical Grammar Detector v5.1 - Universal Clause Detection
æ±ç”¨çš„éšå±¤æ–‡æ³•æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  (Stanza/spaCyæ§‹æ–‡è§£æãƒ™ãƒ¼ã‚¹)

è¨­è¨ˆæ€æƒ³:
1. Type phrase(VæŒã¤)/clause(SVæŒã¤)è‡ªå‹•ç‰¹å®š - Stanza/spaCyä¾å­˜æ§‹é€ æ´»ç”¨
2. ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆé«˜ç²¾åº¦åˆ¤å®šæ´»ç”¨ - æ—¢å­˜83.3%ã‚·ã‚¹ãƒ†ãƒ å†åˆ©ç”¨
3. æ§‹é€ ã‚¿ã‚¤ãƒ—åˆ¤å®š - åˆ†è©æ§‹æ–‡ã€æ¥ç¶šç¯€ã€é–¢ä¿‚ä»£åè©ç­‰ã®æ±ç”¨æ¤œå‡º
4. å†å¸°çš„æ–‡æ³•åˆ¤å®š - phrase/clauseå†…éƒ¨ã®éšå±¤çš„è§£æ
"""

import stanza
import spacy
import time
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from advanced_grammar_detector import GrammarPattern
from hierarchical_grammar_detector_v4 import HierarchicalGrammarDetectorV4

@dataclass
class UniversalClauseInfo:
    """æ±ç”¨çš„ç¯€æƒ…å ± - ã‚ã‚‰ã‚†ã‚‹æ–‡æ³•æ§‹é€ ã«å¯¾å¿œ"""
    text: str                           # ç¯€ã®ãƒ†ã‚­ã‚¹ãƒˆ
    clause_type: str                   # spaCyä¾å­˜é–¢ä¿‚ (ccomp, advcl, relclç­‰)
    has_subject: bool                  # Type clauseåˆ¤å®š (SVæ§‹é€ )
    has_verb: bool                     # Type phraseåˆ¤å®š (Væ§‹é€ )
    root_token: str                    # ç¯€ã®ä¸­å¿ƒèª
    placeholder: str                   # ç½®æ›ç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    start_idx: int                     # æ–‡ä¸­ã®é–‹å§‹ä½ç½®
    end_idx: int                      # æ–‡ä¸­ã®çµ‚äº†ä½ç½®
    grammatical_pattern: Optional[GrammarPattern] = None  # å†…éƒ¨æ–‡æ³•ãƒ‘ã‚¿ãƒ¼ãƒ³
    confidence: float = 0.0           # è§£æä¿¡é ¼åº¦

@dataclass
class UniversalHierarchicalResult:
    """æ±ç”¨çš„éšå±¤è§£æçµæœ"""
    sentence: str
    main_result: Any                                      # ä¸»æ§‹é€ ã®è§£æçµæœ
    clause_results: List[UniversalClauseInfo] = field(default_factory=list)
    processing_method: str = "universal_hierarchical"
    total_confidence: float = 0.0
    processing_time: float = 0.0

class UniversalHierarchicalDetector:
    """æ±ç”¨çš„éšå±¤æ–‡æ³•æ¤œå‡ºå™¨ - ã‚ã‚‰ã‚†ã‚‹æ–‡æ³•æ§‹é€ ã«å¯¾å¿œ"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # V4ã®é«˜ç²¾åº¦ã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨
        self.v4_detector = HierarchicalGrammarDetectorV4()
        
        # NLPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        self._initialize_nlp()
        
        # ç¯€ã‚¿ã‚¤ãƒ—åˆ¥ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®šç¾©
        self.placeholder_map = {
            'ccomp': 'something',      # è£œæ–‡ç¯€
            'xcomp': 'something',      # å‹•è©è£œæ–‡
            'advcl': 'somehow',        # å‰¯è©ç¯€
            'acl': 'something',        # å½¢å®¹è©ç¯€
            'relcl': 'something',      # é–¢ä¿‚ç¯€
            'pcomp': 'something',      # å‰ç½®è©è£œæ–‡
        }
        
    def _initialize_nlp(self):
        """NLPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–"""
        try:
            self.nlp_stanza = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse', verbose=False)
            self.nlp_spacy = spacy.load("en_core_web_sm")
            self.logger.info("âœ… Universal NLP pipelines initialized")
        except Exception as e:
            self.logger.error(f"âŒ NLP initialization failed: {e}")
            raise
    
    def detect_universal_hierarchical_grammar(self, sentence: str) -> UniversalHierarchicalResult:
        """æ±ç”¨çš„éšå±¤æ–‡æ³•æ¤œå‡º - 4æ®µéšå‡¦ç†"""
        start_time = time.time()
        
        print(f"ğŸŒ Universal Processing: {sentence}")
        
        # Stage 1: Type phrase/clauseç‰¹å®š
        clauses = self._detect_clause_structures(sentence)
        print(f"    ğŸ“Š Stage 1: Detected {len(clauses)} clause structures")
        
        # Stage 2: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ› + ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆæ–‡æ³•åˆ¤å®š
        main_sentence, main_result = self._analyze_main_structure(sentence, clauses)
        print(f"    ğŸ“Š Stage 2: Main structure = {main_result.main_clause.grammatical_pattern.value if main_result.main_clause else 'Unknown'}")
        
        # Stage 3: æ§‹é€ ã‚¿ã‚¤ãƒ—åˆ¤å®š
        for clause in clauses:
            clause.grammatical_pattern = self._classify_clause_type(clause)
        print(f"    ğŸ“Š Stage 3: Clause types classified")
            
        # Stage 4: å†å¸°çš„å†…éƒ¨è§£æ
        self._analyze_clause_internals(clauses)
        print(f"    ğŸ“Š Stage 4: Internal analysis completed")
        
        # çµæœçµ±åˆ
        total_confidence = self._calculate_total_confidence(main_result, clauses)
        
        result = UniversalHierarchicalResult(
            sentence=sentence,
            main_result=main_result,
            clause_results=clauses,
            total_confidence=total_confidence,
            processing_time=time.time() - start_time
        )
        
        print(f"âœ… Universal Complete: {len(clauses)} clauses processed")
        return result
    
    def _detect_clause_structures(self, sentence: str) -> List[UniversalClauseInfo]:
        """Stage 1: Type phrase/clauseæ§‹é€ ã®æ±ç”¨çš„æ¤œå‡º"""
        
        # spaCyè§£æ
        doc = self.nlp_spacy(sentence)
        
        clauses = []
        clause_deps = ['ccomp', 'xcomp', 'advcl', 'acl', 'relcl', 'pcomp']
        
        for token in doc:
            if token.dep_ in clause_deps:
                # ç¯€ç¯„å›²ç‰¹å®š
                clause_tokens = list(token.subtree)
                clause_text = ' '.join([t.text for t in clause_tokens])
                
                # SVæ§‹é€ åˆ¤å®š
                has_subject = any(t.dep_ == 'nsubj' for t in clause_tokens)
                has_verb = any(t.pos_ == 'VERB' for t in clause_tokens)
                
                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ
                placeholder = self.placeholder_map.get(token.dep_, 'something')
                
                clause_info = UniversalClauseInfo(
                    text=clause_text,
                    clause_type=token.dep_,
                    has_subject=has_subject,
                    has_verb=has_verb,
                    root_token=token.text,
                    placeholder=placeholder,
                    start_idx=clause_tokens[0].idx,
                    end_idx=clause_tokens[-1].idx + len(clause_tokens[-1].text)
                )
                
                clauses.append(clause_info)
                print(f"      ğŸ” {token.dep_}: '{clause_text}' ({'SV' if has_subject and has_verb else 'phrase'})")
        
        return clauses
    
    def _analyze_main_structure(self, sentence: str, clauses: List[UniversalClauseInfo]) -> Tuple[str, Any]:
        """Stage 2: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ› + é«˜ç²¾åº¦æ–‡æ³•åˆ¤å®š"""
        
        # æ–‡å­—åˆ—ç½®æ›ã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ
        main_sentence = sentence
        for clause in sorted(clauses, key=lambda x: x.start_idx, reverse=True):  # å¾Œã‚ã‹ã‚‰ç½®æ›
            main_sentence = (
                main_sentence[:clause.start_idx] + 
                clause.placeholder + 
                main_sentence[clause.end_idx:]
            )
        
        print(f"    ğŸ”„ Modified: '{main_sentence}'")
        
        # æ—¢å­˜é«˜ç²¾åº¦ã‚·ã‚¹ãƒ†ãƒ ã§è§£æ
        main_result = self.v4_detector.detect_hierarchical_grammar(main_sentence)
        
        return main_sentence, main_result
    
    def _classify_clause_type(self, clause: UniversalClauseInfo) -> GrammarPattern:
        """Stage 3: æ§‹é€ ã‚¿ã‚¤ãƒ—ã®æ±ç”¨çš„åˆ¤å®š"""
        
        # spaCyä¾å­˜é–¢ä¿‚ã«åŸºã¥ãåˆ†é¡
        type_mapping = {
            'ccomp': GrammarPattern.NOUN_CLAUSE,          # thatç¯€ç­‰
            'xcomp': GrammarPattern.INFINITIVE_PATTERN,   # ä¸å®šè©å¥
            'advcl': GrammarPattern.CONJUNCTION_PATTERN,  # å‰¯è©ç¯€
            'acl': GrammarPattern.PARTICIPLE_PATTERN,     # åˆ†è©å¥
            'relcl': GrammarPattern.RELATIVE_PATTERN,     # é–¢ä¿‚ç¯€
            'pcomp': GrammarPattern.GERUND_PATTERN        # å‹•åè©å¥
        }
        
        return type_mapping.get(clause.clause_type, GrammarPattern.SV_PATTERN)
    
    def _analyze_clause_internals(self, clauses: List[UniversalClauseInfo]):
        """Stage 4: ç¯€å†…éƒ¨ã®å†å¸°çš„æ–‡æ³•è§£æ"""
        
        for clause in clauses:
            if clause.has_subject and clause.has_verb:  # Type clause
                # å†å¸°çš„ã«æ–‡æ³•åˆ¤å®š
                internal_result = self.v4_detector.detect_hierarchical_grammar(clause.text)
                clause.confidence = getattr(internal_result, 'confidence_breakdown', {}).get('overall', 0.7)
                print(f"      ğŸ“ Internal '{clause.text}' = {internal_result.main_clause.grammatical_pattern.value if internal_result.main_clause else 'Unknown'}")
            else:  # Type phrase
                clause.confidence = 0.6  # phraseå›ºå®šä¿¡é ¼åº¦
                print(f"      ğŸ“ Phrase '{clause.text}' = {clause.grammatical_pattern.value}")
    
    def _calculate_total_confidence(self, main_result: Any, clauses: List[UniversalClauseInfo]) -> float:
        """ç·åˆä¿¡é ¼åº¦è¨ˆç®—"""
        main_confidence = getattr(main_result, 'confidence_breakdown', {}).get('overall', 0.8)
        clause_confidences = [clause.confidence for clause in clauses]
        
        if not clause_confidences:
            return main_confidence
        
        # é‡ã¿ä»˜ã‘å¹³å‡
        total_confidence = (main_confidence * 0.7 + sum(clause_confidences) / len(clause_confidences) * 0.3)
        return min(total_confidence, 1.0)

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    detector = UniversalHierarchicalDetector()
    
    test_cases = [
        "I think that he is smart.",
        "Being a teacher, she knows students well.",
        "The book that I read yesterday was interesting.",
        "Having finished the work, she went home.",
        "If I were rich, I would travel around the world."
    ]
    
    print("ğŸŒ Universal Hierarchical Grammar Detection Test")
    print("=" * 60)
    
    for sentence in test_cases:
        print(f"\nğŸ“ Testing: \"{sentence}\"")
        print("-" * 50)
        
        try:
            result = detector.detect_universal_hierarchical_grammar(sentence)
            
            print(f"ğŸ—ï¸ Main: {result.main_result.main_clause.grammatical_pattern.value if result.main_result.main_clause else 'Unknown'}")
            print(f"ğŸ“Š Clauses: {len(result.clause_results)}")
            for clause in result.clause_results:
                sv_type = "SV-clause" if clause.has_subject and clause.has_verb else "phrase"
                print(f"  ğŸ“ {clause.clause_type}: '{clause.text}' ({sv_type}) -> {clause.grammatical_pattern.value}")
            print(f"ğŸ¯ Total Confidence: {result.total_confidence:.3f}")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
