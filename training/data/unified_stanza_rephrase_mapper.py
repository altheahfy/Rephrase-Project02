#!/usr/bin/env python3
"""
Unified Stanza-Rephrase Mapper v1.0
===================================

çµ±åˆå‹æ–‡æ³•åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³ - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼
- 15å€‹åˆ¥ã‚¨ãƒ³ã‚¸ãƒ³ã®çŸ¥è­˜ã‚’çµ±åˆ
- é¸æŠå•é¡Œã‚’æ’é™¤ï¼ˆå…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åŒæ™‚å®Ÿè¡Œï¼‰
- Stanza dependency parsing â†’ Rephrase slot mapping

ä½œæˆæ—¥: 2025å¹´8æœˆ15æ—¥
Phase 0: åŸºç›¤æ§‹ç¯‰
"""

import stanza
from typing import Dict, List, Optional, Any, Tuple
import json
import logging
from dataclasses import dataclass
from datetime import datetime

@dataclass
class RephraseSlot:
    """Rephraseã‚¹ãƒ­ãƒƒãƒˆè¡¨ç¾"""
    slot_name: str
    content: str
    sub_slots: Dict[str, Any] = None
    confidence: float = 1.0
    source_handler: str = ""

class UnifiedStanzaRephraseMapper:
    """
    çµ±åˆå‹Stanzaâ†’Rephraseãƒãƒƒãƒ‘ãƒ¼
    
    æ ¸å¿ƒæ€æƒ³:
    - å…¨æ–‡æ³•ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåŒæ™‚å®Ÿè¡Œï¼ˆé¸æŠå•é¡Œæ’é™¤ï¼‰
    - å˜ä¸€Stanzaè§£æçµæœã®å¤šè§’çš„åˆ†æ
    - å€‹åˆ¥ã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…çŸ¥è­˜ç¶™æ‰¿
    """
    
    def __init__(self, 
                 language='en', 
                 enable_gpu=False,
                 log_level='INFO'):
        """
        çµ±åˆãƒãƒƒãƒ‘ãƒ¼åˆæœŸåŒ–
        
        Args:
            language: å‡¦ç†è¨€èªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'en'ï¼‰
            enable_gpu: GPUä½¿ç”¨ãƒ•ãƒ©ã‚°
            log_level: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
        """
        self.language = language
        self.enable_gpu = enable_gpu
        
        # ãƒ­ã‚°è¨­å®š
        self._setup_logging(log_level)
        
        # Stanzaãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        self.nlp = None
        self._initialize_stanza_pipeline()
        
        # çµ±è¨ˆæƒ…å ±
        self.processing_count = 0
        self.total_processing_time = 0.0
        self.handler_success_count = {}
        
        # æ®µéšçš„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ç®¡ç†ï¼ˆPhaseåˆ¥è¿½åŠ ï¼‰
        self.active_handlers = []
        
        self.logger.info("ğŸš€ Unified Stanza-Rephrase Mapper v1.0 åˆæœŸåŒ–å®Œäº†")
    
    def _setup_logging(self, level: str):
        """ãƒ­ã‚°è¨­å®š"""
        self.logger = logging.getLogger(f"{__name__}.UnifiedMapper")
        self.logger.setLevel(getattr(logging, level.upper()))
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def _initialize_stanza_pipeline(self):
        """Stanza NLPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–"""
        try:
            self.logger.info("ğŸ”§ Stanza pipeline åˆæœŸåŒ–ä¸­...")
            
            # åŸºæœ¬çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹æˆ
            processors = 'tokenize,pos,lemma,depparse'
            
            self.nlp = stanza.Pipeline(
                lang=self.language,
                processors=processors,
                download_method=None,  # äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‚’æƒ³å®š
                use_gpu=self.enable_gpu,
                verbose=False
            )
            
            self.logger.info("âœ… Stanza pipeline åˆæœŸåŒ–æˆåŠŸ")
            
            # å‹•ä½œç¢ºèª
            test_result = self.nlp("Hello world.")
            self.logger.info(f"ğŸ§ª Pipeline å‹•ä½œç¢ºèª: {len(test_result.sentences)} sentences processed")
            
        except Exception as e:
            self.logger.error(f"âŒ Stanza pipeline åˆæœŸåŒ–å¤±æ•—: {e}")
            self.logger.error("ğŸ’¡ è§£æ±ºæ–¹æ³•: python -c 'import stanza; stanza.download(\"en\")'")
            raise RuntimeError(f"Stanza initialization failed: {e}")
    
    def process(self, sentence: str) -> Dict[str, Any]:
        """
        çµ±åˆå‡¦ç†ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
        
        Args:
            sentence: å‡¦ç†å¯¾è±¡æ–‡
            
        Returns:
            Dict: Rephraseå½¢å¼å‡¦ç†çµæœ
        """
        start_time = datetime.now()
        self.processing_count += 1
        
        try:
            self.logger.debug(f"ğŸ” Processing: {sentence}")
            
            # Phase 1: Stanzaè§£æ
            doc = self._analyze_with_stanza(sentence)
            if not doc or not doc.sentences:
                self.logger.warning(f"âš ï¸ Stanzaè§£æå¤±æ•—: {sentence}")
                return self._create_empty_result(sentence)
            
            # Phase 2: çµ±åˆå‡¦ç†ï¼ˆå…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åŒæ™‚å®Ÿè¡Œï¼‰
            result = self._unified_mapping(sentence, doc)
            
            # Phase 3: å¾Œå‡¦ç†ãƒ»æ¤œè¨¼
            result = self._post_process_result(result, sentence)
            
            # å‡¦ç†æ™‚é–“è¨˜éŒ²
            processing_time = (datetime.now() - start_time).total_seconds()
            self.total_processing_time += processing_time
            
            result['meta'] = {
                'processing_time': processing_time,
                'sentence_id': self.processing_count,
                'active_handlers': len(self.active_handlers),
                'stanza_info': {
                    'sentences': len(doc.sentences),
                    'tokens': len(doc.sentences[0].words) if doc.sentences else 0
                }
            }
            
            self.logger.info(f"âœ… Processingå®Œäº† ({processing_time:.3f}s): {len(result.get('slots', {}))} slots detected")
            return result
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            self.logger.error(f"âŒ Processing error: {e}")
            
            return {
                'sentence': sentence,
                'slots': {},
                'error': str(e),
                'meta': {
                    'processing_time': processing_time,
                    'sentence_id': self.processing_count,
                    'error_occurred': True
                }
            }
    
    def _analyze_with_stanza(self, sentence: str):
        """Stanzaè§£æå®Ÿè¡Œ"""
        try:
            doc = self.nlp(sentence)
            return doc
        except Exception as e:
            self.logger.error(f"âŒ Stanza analysis failed: {e}")
            return None
    
    def _unified_mapping(self, sentence: str, doc) -> Dict[str, Any]:
        """
        çµ±åˆãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†
        
        å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåŒæ™‚å®Ÿè¡Œ
        å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ç‹¬ç«‹ã—ã¦Stanzaè§£æçµæœã‚’å‡¦ç†
        """
        result = {
            'sentence': sentence,
            'slots': {},
            'sub_slots': {},
            'grammar_info': {
                'detected_patterns': [],
                'handler_contributions': {}
            }
        }
        
        # ãƒ¡ã‚¤ãƒ³æ–‡ï¼ˆæœ€åˆã®sentenceï¼‰ã‚’å¯¾è±¡ã¨ã™ã‚‹
        main_sentence = doc.sentences[0] if doc.sentences else None
        if not main_sentence:
            return result
        
        self.logger.debug(f"ğŸ”§ Unified mappingé–‹å§‹: {len(self.active_handlers)} handlers active")
        
        # å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®åŒæ™‚å®Ÿè¡Œ
        for handler_name in self.active_handlers:
            try:
                self.logger.debug(f"ğŸ¯ Handlerå®Ÿè¡Œ: {handler_name}")
                handler_method = getattr(self, f'_handle_{handler_name}')
                handler_result = handler_method(main_sentence, result.copy())
                
                # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼çµæœã‚’ãƒãƒ¼ã‚¸
                if handler_result:
                    result = self._merge_handler_results(result, handler_result, handler_name)
                    
                    # æˆåŠŸã‚«ã‚¦ãƒ³ãƒˆ
                    self.handler_success_count[handler_name] = \
                        self.handler_success_count.get(handler_name, 0) + 1
                        
            except Exception as e:
                self.logger.warning(f"âš ï¸ Handler error ({handler_name}): {e}")
                continue
        
        return result
    
    def _merge_handler_results(self, base_result: Dict, handler_result: Dict, handler_name: str) -> Dict:
        """
        ãƒãƒ³ãƒ‰ãƒ©ãƒ¼çµæœã‚’ãƒ™ãƒ¼ã‚¹çµæœã«ãƒãƒ¼ã‚¸
        
        Args:
            base_result: ãƒ™ãƒ¼ã‚¹çµæœ
            handler_result: ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å‡¦ç†çµæœ  
            handler_name: ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å
        """
        # ã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ãƒãƒ¼ã‚¸
        if 'slots' in handler_result:
            for slot_name, slot_data in handler_result['slots'].items():
                if slot_name not in base_result['slots']:
                    base_result['slots'][slot_name] = slot_data
                else:
                    # ç«¶åˆè§£æ±ºï¼ˆå˜ç´”ä¸Šæ›¸ã - æ–‡å­—åˆ—ã®å ´åˆã‚‚å¯¾å¿œï¼‰
                    base_result['slots'][slot_name] = slot_data
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ãƒãƒ¼ã‚¸
        if 'sub_slots' in handler_result:
            for sub_slot_name, sub_slot_data in handler_result['sub_slots'].items():
                base_result['sub_slots'][sub_slot_name] = sub_slot_data
        
        # æ–‡æ³•æƒ…å ±è¨˜éŒ²
        if 'grammar_info' in handler_result:
            grammar_info = handler_result['grammar_info']
            base_result['grammar_info']['handler_contributions'][handler_name] = grammar_info
            
            # æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ 
            if 'patterns' in grammar_info:
                base_result['grammar_info']['detected_patterns'].extend(grammar_info['patterns'])
        
        return base_result
    
    def _post_process_result(self, result: Dict, sentence: str) -> Dict:
        """å¾Œå‡¦ç†ãƒ»çµæœæ¤œè¨¼"""
        # é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³é™¤å»
        if 'detected_patterns' in result.get('grammar_info', {}):
            result['grammar_info']['detected_patterns'] = \
                list(set(result['grammar_info']['detected_patterns']))
        
        # ã‚¹ãƒ­ãƒƒãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
        # TODO: rephrase_slot_validator.py ã¨ã®é€£æº
        
        return result
    
    def _create_empty_result(self, sentence: str) -> Dict[str, Any]:
        """ç©ºçµæœã®ä½œæˆ"""
        return {
            'sentence': sentence,
            'slots': {},
            'sub_slots': {},
            'grammar_info': {
                'detected_patterns': [],
                'handler_contributions': {}
            },
            'meta': {
                'processing_time': 0.0,
                'sentence_id': self.processing_count,
                'empty_result': True
            }
        }
    
    # =============================================================================
    # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ç®¡ç†ï¼ˆPhaseåˆ¥æ©Ÿèƒ½è¿½åŠ ç”¨ï¼‰
    # =============================================================================
    
    def add_handler(self, handler_name: str):
        """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¿½åŠ ï¼ˆPhaseåˆ¥é–‹ç™ºç”¨ï¼‰"""
        if handler_name not in self.active_handlers:
            self.active_handlers.append(handler_name)
            self.logger.info(f"â• Handlerè¿½åŠ : {handler_name}")
        else:
            self.logger.warning(f"âš ï¸ Handler already active: {handler_name}")
    
    def remove_handler(self, handler_name: str):
        """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‰Šé™¤"""
        if handler_name in self.active_handlers:
            self.active_handlers.remove(handler_name)
            self.logger.info(f"â– Handlerå‰Šé™¤: {handler_name}")
    
    def list_active_handlers(self) -> List[str]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ä¸€è¦§"""
        return self.active_handlers.copy()
    
    # =============================================================================
    # çµ±è¨ˆãƒ»ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    # =============================================================================
    
    def get_stats(self) -> Dict[str, Any]:
        """å‡¦ç†çµ±è¨ˆæƒ…å ±å–å¾—"""
        avg_processing_time = (
            self.total_processing_time / self.processing_count 
            if self.processing_count > 0 else 0.0
        )
        
        return {
            'processing_count': self.processing_count,
            'total_processing_time': self.total_processing_time,
            'average_processing_time': avg_processing_time,
            'active_handlers': self.active_handlers.copy(),
            'handler_success_count': self.handler_success_count.copy(),
            'stanza_pipeline_status': 'active' if self.nlp else 'inactive'
        }
    
    def reset_stats(self):
        """çµ±è¨ˆæƒ…å ±ãƒªã‚»ãƒƒãƒˆ"""
        self.processing_count = 0
        self.total_processing_time = 0.0
        self.handler_success_count.clear()
        self.logger.info("ğŸ“Š Statistics reset")
    
    # =============================================================================
    # æ–‡æ³•ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å®Ÿè£…ï¼ˆPhase 1+: æ®µéšçš„è¿½åŠ ï¼‰
    # =============================================================================
    
    def _handle_relative_clause(self, sentence, base_result: Dict) -> Optional[Dict]:
        """
        é–¢ä¿‚ç¯€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆPhase 1å®Ÿè£…ï¼‰
        
        simple_relative_engine.py ã®æ©Ÿèƒ½ã‚’çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ç§»æ¤
        Stanza dependency parsing ã«ã‚ˆã‚‹ç›´æ¥çš„ãªé–¢ä¿‚ç¯€æ¤œå‡ºãƒ»åˆ†è§£
        
        Args:
            sentence: Stanzaè§£ææ¸ˆã¿sentence object
            base_result: ãƒ™ãƒ¼ã‚¹çµæœï¼ˆã‚³ãƒ”ãƒ¼ï¼‰
            
        Returns:
            Dict: é–¢ä¿‚ç¯€åˆ†è§£çµæœ or None
        """
        try:
            self.logger.debug("ğŸ” é–¢ä¿‚ç¯€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å®Ÿè¡Œä¸­...")
            
            # é–¢ä¿‚ç¯€å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if not self._has_relative_clause(sentence):
                self.logger.debug("  é–¢ä¿‚ç¯€ãªã— - ã‚¹ã‚­ãƒƒãƒ—")
                return None
            
            self.logger.debug("  âœ… é–¢ä¿‚ç¯€æ¤œå‡º")
            return self._process_relative_clause_structure(sentence, base_result)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ é–¢ä¿‚ç¯€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _has_relative_clause(self, sentence) -> bool:
        """é–¢ä¿‚ç¯€ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯"""
        return any(w.deprel in ['acl:relcl', 'acl'] for w in sentence.words)
    
    def _process_relative_clause_structure(self, sentence, base_result: Dict) -> Dict:
        """é–¢ä¿‚ç¯€æ§‹é€ ã®åˆ†è§£å‡¦ç†"""
        
        # === 1. è¦ç´ ç‰¹å®š ===
        # é–¢ä¿‚ç¯€å‹•è©ï¼ˆé–¢ä¿‚ç¯€ã®æ ¸ï¼‰
        rel_verb = self._find_word_by_deprel(sentence, 'acl:relcl')
        if not rel_verb:
            rel_verb = self._find_word_by_deprel(sentence, 'acl')
        if not rel_verb:
            return base_result
        
        # å…ˆè¡Œè©ï¼ˆé–¢ä¿‚ç¯€å‹•è©ã®é ­ï¼‰
        antecedent = self._find_word_by_id(sentence, rel_verb.head)
        if not antecedent:
            return base_result
        
        self.logger.debug(f"  å…ˆè¡Œè©: {antecedent.text}, é–¢ä¿‚å‹•è©: {rel_verb.text}")
        
        # === 2. é–¢ä¿‚ä»£åè©/é–¢ä¿‚å‰¯è©ç‰¹å®š ===
        rel_pronoun, rel_type = self._identify_relative_pronoun(sentence, rel_verb)
        
        # === 3. é–¢ä¿‚ç¯€å†…è¦ç´ ç‰¹å®š ===
        rel_subject = None
        if rel_type in ['obj', 'advmod']:  # ç›®çš„èªãƒ»é–¢ä¿‚å‰¯è©ã®å ´åˆã¯åˆ¥é€”ä¸»èªæ¤œç´¢
            rel_subject = self._find_word_by_head_and_deprel(sentence, rel_verb.id, 'nsubj')
        
        # æ‰€æœ‰æ ¼é–¢ä¿‚ä»£åè©ã®ç‰¹åˆ¥å‡¦ç†
        possessed_noun = None
        if rel_type == 'poss':
            possessed_noun = self._find_word_by_id(sentence, rel_pronoun.head)
        
        self.logger.debug(f"  é–¢ä¿‚ä»£åè©: {rel_pronoun.text if rel_pronoun else 'None'} ({rel_type})")
        if rel_subject:
            self.logger.debug(f"  é–¢ä¿‚ç¯€ä¸»èª: {rel_subject.text}")
        if possessed_noun:
            self.logger.debug(f"  æ‰€æœ‰ã•ã‚Œã‚‹åè©: {possessed_noun.text}")
        
        # === 4. å…ˆè¡Œè©å¥æ§‹ç¯‰ ===
        noun_phrase = self._build_antecedent_phrase(sentence, antecedent, rel_pronoun, possessed_noun)
        self.logger.debug(f"  æ§‹ç¯‰å…ˆè¡Œè©å¥: '{noun_phrase}'")
        
        # === 5. Rephraseã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ ===
        result = base_result.copy()
        rephrase_slots = self._generate_relative_clause_slots(
            rel_type, noun_phrase, rel_subject, rel_verb, sentence
        )
        
        # çµæœãƒãƒ¼ã‚¸
        if 'slots' not in result:
            result['slots'] = {}
        if 'sub_slots' not in result:
            result['sub_slots'] = {}
        
        result['slots'].update(rephrase_slots.get('slots', {}))
        result['sub_slots'].update(rephrase_slots.get('sub_slots', {}))
        
        # æ–‡æ³•æƒ…å ±è¨˜éŒ²
        result['grammar_info'] = {
            'patterns': ['relative_clause'],
            'rel_type': rel_type,
            'antecedent': antecedent.text,
            'rel_pronoun': rel_pronoun.text if rel_pronoun else None,
            'rel_verb': rel_verb.text
        }
        
        self.logger.debug(f"  âœ… é–¢ä¿‚ç¯€å‡¦ç†å®Œäº†: {len(rephrase_slots.get('slots', {}))} main slots, {len(rephrase_slots.get('sub_slots', {}))} sub slots")
        return result
    
    def _identify_relative_pronoun(self, sentence, rel_verb) -> Tuple[Optional[Any], str]:
        """é–¢ä¿‚ä»£åè©/é–¢ä¿‚å‰¯è©ã®ç‰¹å®šã¨åˆ†é¡"""
        
        # 1. é–¢ä¿‚å‰¯è©æ¤œå‡ºï¼ˆæœ€å„ªå…ˆï¼‰
        advmod_word = self._find_word_by_head_and_deprel(sentence, rel_verb.id, 'advmod')
        if advmod_word and advmod_word.text.lower() in ['where', 'when', 'why', 'how']:
            return advmod_word, 'advmod'
        
        # 2. æ‰€æœ‰æ ¼é–¢ä¿‚ä»£åè©æ¤œå‡º
        for word in sentence.words:
            if word.text.lower() == 'whose' and word.deprel == 'nmod:poss':
                return word, 'poss'
        
        # 3. ç›®çš„èªé–¢ä¿‚ä»£åè©
        obj_pronoun = self._find_word_by_head_and_deprel(sentence, rel_verb.id, 'obj')
        if obj_pronoun:
            return obj_pronoun, 'obj'
        
        # 4. ä¸»èªé–¢ä¿‚ä»£åè©
        subj_pronoun = self._find_word_by_head_and_deprel(sentence, rel_verb.id, 'nsubj')
        if subj_pronoun:
            return subj_pronoun, 'nsubj'
        
        return None, 'unknown'
    
    def _build_antecedent_phrase(self, sentence, antecedent, rel_pronoun, possessed_noun=None) -> str:
        """å…ˆè¡Œè©å¥æ§‹ç¯‰ï¼ˆä¿®é£¾èªå«ã‚€ï¼‰- é–¢ä¿‚ç¯€å…¨ä½“ã‚’å«ã‚€å®Œå…¨ãªå¥ã‚’æ§‹ç¯‰"""
        if not antecedent:
            return rel_pronoun.text if rel_pronoun else ""
        
        # å…ˆè¡Œè©ã®ä¿®é£¾èªåé›†
        modifiers = []
        for word in sentence.words:
            if word.head == antecedent.id and word.deprel in ['det', 'amod', 'compound']:
                modifiers.append(word)
        
        # é–¢ä¿‚ç¯€å†…ã®å…¨å˜èªã‚’åé›†ï¼ˆé–¢ä¿‚ç¯€å‹•è©ã¨ãã®ä¾å­˜èªï¼‰
        rel_clause_words = []
        if rel_pronoun:
            # é–¢ä¿‚ä»£åè©ã‚’è¿½åŠ 
            rel_clause_words.append(rel_pronoun)
            
            # é–¢ä¿‚ç¯€å‹•è©ã‚’ç‰¹å®š
            rel_verb = None
            for word in sentence.words:
                if (word.deprel in ['acl:relcl', 'acl'] and 
                    word.head == antecedent.id):
                    rel_verb = word
                    break
            
            if rel_verb:
                # é–¢ä¿‚ç¯€å‹•è©ã‚’è¿½åŠ 
                rel_clause_words.append(rel_verb)
                
                # é–¢ä¿‚ç¯€å‹•è©ã®ä¾å­˜èªã‚’è¿½åŠ 
                for word in sentence.words:
                    if (word.head == rel_verb.id and 
                        word.id != rel_pronoun.id):  # é–¢ä¿‚ä»£åè©ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿
                        rel_clause_words.append(word)
        
        # èªé †æ§‹ç¯‰
        phrase_words = modifiers + [antecedent] + rel_clause_words
        
        # æ‰€æœ‰æ ¼ã®ç‰¹åˆ¥å‡¦ç†
        if possessed_noun and rel_pronoun:
            if possessed_noun not in phrase_words:
                phrase_words.append(possessed_noun)
        
        # IDé †ã‚½ãƒ¼ãƒˆï¼ˆèªé †ä¿æŒï¼‰
        phrase_words.sort(key=lambda w: w.id)
        return ' '.join(w.text for w in phrase_words)
    
    def _generate_relative_clause_slots(self, rel_type: str, noun_phrase: str, rel_subject, rel_verb, sentence) -> Dict:
        """é–¢ä¿‚ç¯€ã‚¿ã‚¤ãƒ—åˆ¥ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆ"""
        
        slots = {}
        sub_slots = {}
        
        if rel_type == 'obj':
            # ç›®çš„èªé–¢ä¿‚ä»£åè©: "The book that he bought"
            slots["O1"] = ""  # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆç©º
            sub_slots["sub-o1"] = noun_phrase
            if rel_subject:
                sub_slots["sub-s"] = rel_subject.text
            sub_slots["sub-v"] = rel_verb.text
            
        elif rel_type == 'nsubj':
            # ä¸»èªé–¢ä¿‚ä»£åè©: "The man who runs"
            slots["S"] = ""  # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆç©º
            sub_slots["sub-s"] = noun_phrase
            sub_slots["sub-v"] = rel_verb.text
            
        elif rel_type == 'poss':
            # æ‰€æœ‰æ ¼é–¢ä¿‚ä»£åè©: "The man whose car is red"
            slots["S"] = ""  # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆç©º
            sub_slots["sub-s"] = noun_phrase
            
            # beå‹•è©ç¢ºèª
            cop_verb = self._find_word_by_head_and_deprel(sentence, rel_verb.id, 'cop')
            if cop_verb:
                if rel_verb.pos == 'ADJ':
                    sub_slots["sub-aux"] = cop_verb.text
                    sub_slots["sub-c1"] = rel_verb.text
                else:
                    sub_slots["sub-aux"] = cop_verb.text
                    sub_slots["sub-v"] = rel_verb.text
            else:
                sub_slots["sub-v"] = rel_verb.text
                
        elif rel_type == 'advmod':
            # é–¢ä¿‚å‰¯è©: "The place where he lives"
            slots["M3"] = ""  # ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆç©ºï¼ˆå‰¯è©å¥æ‰±ã„ï¼‰
            sub_slots["sub-m3"] = noun_phrase
            if rel_subject:
                sub_slots["sub-s"] = rel_subject.text
            sub_slots["sub-v"] = rel_verb.text
            
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆç›®çš„èªæ‰±ã„ï¼‰
            slots["O1"] = ""
            sub_slots["sub-o1"] = noun_phrase
            if rel_subject:
                sub_slots["sub-s"] = rel_subject.text
            sub_slots["sub-v"] = rel_verb.text
        
        return {'slots': slots, 'sub_slots': sub_slots}
    
    # === Stanzaè§£æãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _find_word_by_deprel(self, sentence, deprel: str):
        """ä¾å­˜é–¢ä¿‚ã§èªã‚’æ¤œç´¢"""
        return next((w for w in sentence.words if w.deprel == deprel), None)
    
    def _find_word_by_id(self, sentence, word_id: int):
        """IDã§èªã‚’æ¤œç´¢"""
        return next((w for w in sentence.words if w.id == word_id), None)
    
    def _find_word_by_head_and_deprel(self, sentence, head_id: int, deprel: str):
        """é ­IDã¨ä¾å­˜é–¢ä¿‚ã§èªã‚’æ¤œç´¢"""
        return next((w for w in sentence.words if w.head == head_id and w.deprel == deprel), None)

# =============================================================================
# Phase 0 ãƒ†ã‚¹ãƒˆç”¨ åŸºæœ¬ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒã‚¹
# =============================================================================

def test_phase0_basic():
    """Phase 0 åŸºæœ¬å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Phase 0 åŸºæœ¬ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        # åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        mapper = UnifiedStanzaRephraseMapper(log_level='DEBUG')
        print("âœ… åˆæœŸåŒ–æˆåŠŸ")
        
        # åŸºæœ¬å‡¦ç†ãƒ†ã‚¹ãƒˆ
        test_sentence = "The car is red."
        result = mapper.process(test_sentence)
        
        print(f"âœ… åŸºæœ¬å‡¦ç†æˆåŠŸ: {result['sentence']}")
        print(f"ğŸ“Š å‡¦ç†æ™‚é–“: {result['meta']['processing_time']:.3f}s")
        print(f"ğŸ”§ Stanzaæƒ…å ±: {result['meta']['stanza_info']}")
        
        # çµ±è¨ˆç¢ºèª
        stats = mapper.get_stats()
        print(f"ğŸ“ˆ å‡¦ç†çµ±è¨ˆ: {stats}")
        
        print("ğŸ‰ Phase 0 åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ Phase 0 ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

# =============================================================================
# Phase 1 ãƒ†ã‚¹ãƒˆç”¨ é–¢ä¿‚ç¯€ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒã‚¹
# =============================================================================

def test_phase1_relative_clause():
    """Phase 1 é–¢ä¿‚ç¯€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Phase 1 é–¢ä¿‚ç¯€ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        # åˆæœŸåŒ–
        mapper = UnifiedStanzaRephraseMapper(log_level='DEBUG')
        
        # Phase 1 ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ 
        mapper.add_handler('relative_clause')
        print("âœ… é–¢ä¿‚ç¯€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ å®Œäº†")
        
        # é‡è¦ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            ("The car which we saw was red.", "ç›®çš„èªé–¢ä¿‚ä»£åè©"),
            ("The man who runs fast is strong.", "ä¸»èªé–¢ä¿‚ä»£åè©"),
            ("The man whose car is red lives here.", "æ‰€æœ‰æ ¼é–¢ä¿‚ä»£åè©"),
            ("The place where he lives is nice.", "é–¢ä¿‚å‰¯è©where")
        ]
        
        success_count = 0
        for i, (test_sentence, pattern_type) in enumerate(test_cases, 1):
            print(f"\nğŸ“– ãƒ†ã‚¹ãƒˆ{i}: '{test_sentence}' ({pattern_type})")
            print("-" * 60)
            
            try:
                result = mapper.process(test_sentence)
                
                print("ğŸ“Š å‡¦ç†çµæœ:")
                print(f"  ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: {result.get('slots', {})}")
                print(f"  ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: {result.get('sub_slots', {})}")
                print(f"  æ–‡æ³•æƒ…å ±: {result.get('grammar_info', {})}")
                print(f"  å‡¦ç†æ™‚é–“: {result['meta']['processing_time']:.3f}s")
                
                # ç¬¬1ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ç‰¹åˆ¥ãƒã‚§ãƒƒã‚¯
                if i == 1:  # "The car which we saw was red."
                    slots = result.get('slots', {})
                    sub_slots = result.get('sub_slots', {})
                    
                    print(f"\nğŸ¯ é‡è¦ãƒã‚§ãƒƒã‚¯:")
                    expected_sub_o1 = "The car which we saw"
                    actual_sub_o1 = sub_slots.get('sub-o1', '')
                    print(f"  æœŸå¾… sub-o1: '{expected_sub_o1}'")
                    print(f"  å®Ÿéš› sub-o1: '{actual_sub_o1}'")
                    
                    if expected_sub_o1.lower() in actual_sub_o1.lower():
                        print("  âœ… åŸºæœ¬è¦æ±‚é”æˆï¼")
                        success_count += 1
                    else:
                        print("  âŒ åŸºæœ¬è¦æ±‚æœªé”æˆ")
                else:
                    success_count += 1
                    
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆ{i}ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµ±è¨ˆç¢ºèª
        stats = mapper.get_stats()
        print(f"\nğŸ“ˆ Phase 1 çµ±è¨ˆ:")
        print(f"  å‡¦ç†æ•°: {stats['processing_count']}")
        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {stats['average_processing_time']:.3f}s")
        print(f"  ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æˆåŠŸæ•°: {stats['handler_success_count']}")
        
        print(f"\nğŸ‰ Phase 1 ãƒ†ã‚¹ãƒˆå®Œäº†! æˆåŠŸ: {success_count}/{len(test_cases)}")
        return success_count == len(test_cases)
        
    except Exception as e:
        print(f"âŒ Phase 1 ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    # Phase 0 åŸºæœ¬ãƒ†ã‚¹ãƒˆ
    if test_phase0_basic():
        print("\n" + "="*60)
        # Phase 1 é–¢ä¿‚ç¯€ãƒ†ã‚¹ãƒˆ
        test_phase1_relative_clause()
    else:
        print("âŒ Phase 0å¤±æ•—ã®ãŸã‚ Phase 1ã‚’ã‚¹ã‚­ãƒƒãƒ—")
