"""
Step18: éšå±¤çš„ä¾å­˜é–¢ä¿‚å‡¦ç†ã®æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ 
ex007ã®C2/M2/M3ã‚¹ãƒ­ãƒƒãƒˆæ­£ç¢ºåˆ†é›¢ã®ãŸã‚ã®å®Œå…¨ä¿®æ­£ç‰ˆ
"""

import spacy
import pandas as pd
from collections import defaultdict

class Step18HierarchicalFixSystem:
    def __init__(self):
        """éšå±¤çš„å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ¯ Step18éšå±¤çš„ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        self.nlp = spacy.load('en_core_web_sm')
        
        # ä¾å­˜é–¢ä¿‚-ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Œå…¨ç‰ˆï¼‰
        self.dependency_mapping = {
            # Core grammatical relationships
            'nsubj': 'sub-s',
            'nsubjpass': 'sub-s', 
            'aux': 'sub-aux',
            'auxpass': 'sub-aux',
            'dobj': 'sub-o1',
            'iobj': 'sub-o2',
            'attr': 'sub-c1',
            'ccomp': 'sub-c2',
            'xcomp': 'sub-c2',
            
            # Modifier relationships
            'advmod': 'sub-m2',
            'amod': 'sub-m3',
            'prep': 'sub-m3',
            'pobj': 'sub-o1',
            'pcomp': 'sub-c2',
            'mark': 'sub-m1',
            
            # Clausal relationships
            'advcl': 'M2',  # è¦éšå±¤å‡¦ç†
            'relcl': 'sub-m3',
            'acl': 'sub-m3',
            'conj': 'C2',   # è¦éšå±¤å‡¦ç†
            
            # Determiner relationships
            'det': 'EXTEND',
            'poss': 'EXTEND',
            'compound': 'EXTEND'
        }
        
    def decompose_sentence(self, sentence):
        """éšå±¤çš„æ–‡åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³"""
        print(f"\nğŸ¯ Step18éšå±¤çš„å‡¦ç†é–‹å§‹: '{sentence}'")
        
        # spaCyè§£æ
        doc = self.nlp(sentence)
        
        # ROOTå‹•è©ç‰¹å®š
        root_verb = None
        for token in doc:
            if token.dep_ == 'ROOT' and token.pos_ in ['VERB', 'AUX']:
                root_verb = token
                break
        
        if not root_verb:
            return {}
            
        print(f"ğŸ¯ ROOTå‹•è©ç‰¹å®š: '{root_verb.text}' (pos={root_verb.pos_})")
        
        # éšå±¤çš„ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        all_slots = self._extract_hierarchical_slots(doc, root_verb)
        
        return all_slots
    
    def _extract_hierarchical_slots(self, doc, root_verb):
        """éšå±¤çš„ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰"""
        print(f"\nğŸ” éšå±¤çš„ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºé–‹å§‹: ROOT='{root_verb.text}'")
        
        all_slots = {}
        
        # 1. åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆï¼ˆS/V/O1/Aux/C1ï¼‰æŠ½å‡º
        base_slots = self._extract_base_slots(doc, root_verb)
        if base_slots:
            all_slots.update(base_slots)
        
        # 2. C2ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºï¼ˆconjé–¢ä¿‚ï¼‰
        c2_slots = self._extract_c2_slots(doc, root_verb)
        if c2_slots:
            all_slots.update(c2_slots)
            
        # 3. M2/M3ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºï¼ˆadvcléšå±¤å‡¦ç†ï¼‰
        m_slots = self._extract_advcl_slots(doc, root_verb)
        if m_slots:
            all_slots.update(m_slots)
            
        return all_slots
    
    def _extract_base_slots(self, doc, root_verb):
        """åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º"""
        print(f"ğŸ” åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º: ROOT='{root_verb.text}'")
        
        # ROOTç›´çµã®å­è¦ç´ ã®ã¿å‡¦ç†
        base_children = [child for child in root_verb.children]
        
        base_tokens = defaultdict(list)
        
        for child in base_children:
            dep = child.dep_
            
            # conj/advclã¯åŸºæœ¬ã‚¹ãƒ­ãƒƒãƒˆã‹ã‚‰é™¤å¤–ï¼ˆéšå±¤å‡¦ç†ï¼‰
            if dep in ['conj', 'advcl']:
                continue
                
            # ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒ”ãƒ³ã‚°
            if dep in self.dependency_mapping:
                subslot = self.dependency_mapping[dep]
                if subslot != 'EXTEND':
                    base_tokens[subslot].append(child)
        
        # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹ç¯‰
        base_slots = {}
        if base_tokens:
            base_slots['S'] = self._build_subslots(base_tokens, doc)
            
        return base_slots
    
    def _extract_c2_slots(self, doc, root_verb):
        """C2ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡ºï¼ˆconjé–¢ä¿‚ï¼‰"""
        print(f"ğŸ” C2ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º: ROOT='{root_verb.text}'")
        
        c2_slots = {}
        
        # ROOTç›´çµã®conjæ¤œç´¢
        for child in root_verb.children:
            if child.dep_ == 'conj':
                print(f"ğŸ“Œ C2ç™ºè¦‹: '{child.text}' (dep={child.dep_})")
                
                # C2å‹•è©ã®å­è¦ç´ åé›†
                c2_tokens = defaultdict(list)
                
                for c2_child in child.children:
                    dep = c2_child.dep_
                    
                    # advcl ã¯ M2 ã¨ã—ã¦åˆ¥å‡¦ç†
                    if dep == 'advcl':
                        continue
                        
                    if dep in self.dependency_mapping:
                        subslot = self.dependency_mapping[dep]
                        if subslot != 'EXTEND':
                            c2_tokens[subslot].append(c2_child)
                
                # C2å‹•è©è‡ªä½“ã‚’è¿½åŠ 
                c2_tokens['sub-v'].append(child)
                
                if c2_tokens:
                    c2_slots['C2'] = self._build_subslots(c2_tokens, doc)
                    
        return c2_slots
    
    def _extract_advcl_slots(self, doc, root_verb):
        """advcléšå±¤å‡¦ç†ï¼ˆM2/M3åˆ†é›¢ï¼‰"""
        print(f"ğŸ” advcléšå±¤å‡¦ç†: ROOT='{root_verb.text}'")
        
        m_slots = {}
        
        # ROOTç›´çµã®advcl â†’ M3
        for child in root_verb.children:
            if child.dep_ == 'advcl':
                print(f"ğŸ“Œ M3ç™ºè¦‹: '{child.text}' (advcl:ROOT)")
                
                m3_tokens = defaultdict(list)
                
                for m3_child in child.children:
                    dep = m3_child.dep_
                    if dep in self.dependency_mapping:
                        subslot = self.dependency_mapping[dep]
                        if subslot != 'EXTEND':
                            m3_tokens[subslot].append(m3_child)
                
                # M3å‹•è©è‡ªä½“
                m3_tokens['sub-v'].append(child)
                
                if m3_tokens:
                    m_slots['M3'] = self._build_subslots(m3_tokens, doc)
        
        # C2é…ä¸‹ã®advcl â†’ M2
        for child in root_verb.children:
            if child.dep_ == 'conj':  # C2å‹•è©
                for c2_child in child.children:
                    if c2_child.dep_ == 'advcl':
                        print(f"ğŸ“Œ M2ç™ºè¦‹: '{c2_child.text}' (advcl:C2)")
                        
                        m2_tokens = defaultdict(list)
                        
                        for m2_child in c2_child.children:
                            dep = m2_child.dep_
                            if dep in self.dependency_mapping:
                                subslot = self.dependency_mapping[dep]
                                if subslot != 'EXTEND':
                                    m2_tokens[subslot].append(m2_child)
                        
                        # M2å‹•è©è‡ªä½“
                        m2_tokens['sub-v'].append(c2_child)
                        
                        if m2_tokens:
                            m_slots['M2'] = self._build_subslots(m2_tokens, doc)
        
        return m_slots
    
    def _build_subslots(self, slot_tokens, doc):
        """ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹ç¯‰ï¼ˆå‰ç½®è©çµ±åˆå¯¾å¿œï¼‰"""
        subslots = {}
        
        for subslot_name, tokens in slot_tokens.items():
            if not tokens:
                continue
                
            if len(tokens) == 1:
                # å˜ä¸€ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†
                token = tokens[0]
                
                # å‰ç½®è©çµ±åˆãƒã‚§ãƒƒã‚¯
                final_text = self._integrate_prepositions(token, doc)
                
                # ã‚¹ãƒ‘ãƒ³æ‹¡å¼µé©ç”¨
                if not final_text:
                    final_text = self._expand_span(token, doc)
                    
                subslots[subslot_name] = final_text
            else:
                # è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ - çµåˆ
                combined_text = ' '.join([t.text for t in sorted(tokens, key=lambda x: x.i)])
                subslots[subslot_name] = combined_text
        
        return subslots
        
    def _integrate_prepositions(self, token, doc):
        """å‰ç½®è©çµ±åˆå‡¦ç†"""
        # å‹•è© + å‰ç½®è©ã®çµ±åˆ
        if token.pos_ in ['VERB', 'AUX']:
            prep_children = [child for child in token.children if child.dep_ == 'prep']
            if prep_children:
                prep_texts = []
                for prep in prep_children:
                    # å‰ç½®è© + ãã®ç›®çš„èª
                    pobj_children = [child for child in prep.children if child.dep_ == 'pobj']
                    if pobj_children:
                        pobj = pobj_children[0]
                        pobj_span = self._expand_span(pobj, doc)
                        prep_texts.append(f"{prep.text} {pobj_span}")
                    else:
                        prep_texts.append(prep.text)
                
                if prep_texts:
                    return f"{token.text} {' '.join(prep_texts)}"
        
        # mark + å¾“å±æ¥ç¶šè©ã®çµ±åˆ (even thoughå‡¦ç†)
        if token.dep_ == 'mark':
            # å‰æ–¹ã®advmodã‚’ãƒã‚§ãƒƒã‚¯
            for i in range(token.i - 1, -1, -1):
                prev_token = doc[i]
                if prev_token.dep_ == 'advmod' and prev_token.head == token.head:
                    return f"{prev_token.text} {token.text}"
                if prev_token.i < token.i - 2:  # 2èªä»¥å†…ã§ãƒã‚§ãƒƒã‚¯
                    break
        
        return None
    
    def _expand_span(self, token, doc):
        """ã‚¹ãƒ‘ãƒ³æ‹¡å¼µå‡¦ç†"""
        # æ‹¡å¼µå¯¾è±¡ã®ä¾å­˜é–¢ä¿‚
        expand_deps = ['det', 'poss', 'compound', 'amod', 'prep', 'pobj']
        
        # å·¦å³æ‹¡å¼µ
        start_idx = token.i
        end_idx = token.i
        
        # å·¦æ‹¡å¼µ
        for i in range(token.i - 1, -1, -1):
            if doc[i].head.i == token.i and doc[i].dep_ in expand_deps:
                start_idx = i
            else:
                break
        
        # å³æ‹¡å¼µ
        for i in range(token.i + 1, len(doc)):
            if doc[i].head.i == token.i and doc[i].dep_ in expand_deps:
                end_idx = i
            else:
                break
        
        # ã‚¹ãƒ‘ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        span_text = ' '.join([doc[i].text for i in range(start_idx, end_idx + 1)])
        
        return span_text

def test_ex007_hierarchical():
    """ex007éšå±¤çš„å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    system = Step18HierarchicalFixSystem()
    
    ex007 = "That afternoon at the crucial point in the presentation, the manager who had recently taken charge of the project had to make the committee responsible for implementation deliver the final proposal flawlessly even though he was under intense pressure so the outcome would reflect their full potential."
    
    result = system.decompose_sentence(ex007)
    
    print(f"\n=== éšå±¤çš„å‡¦ç†çµæœ ===")
    for slot_name, subslots in result.items():
        print(f"\nğŸ“‹ {slot_name}ã‚¹ãƒ­ãƒƒãƒˆ:")
        for sub_name, sub_value in subslots.items():
            print(f"  {sub_name:<10}: \"{sub_value}\"")

if __name__ == "__main__":
    test_ex007_hierarchical()
