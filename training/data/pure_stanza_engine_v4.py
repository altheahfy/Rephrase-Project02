#!/usr/bin/env python3
"""
è¤‡æ–‡å¯¾å¿œPure Stanza Engine v4 - éšå±¤çš„clauseåˆ†è§£ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
"""

import stanza
import spacy
from typing import Dict, List, Optional, Any, Tuple
import json

class PureStanzaEngine_v4:
    """è¤‡æ–‡å¯¾å¿œPure Stanza Engine v4"""
    
    def __init__(self):
        self.nlp = None
        self.spacy_nlp = None
        self.sentence_patterns = {}
        self.modifier_mappings = {
            'advmod': 'M2',
            'amod': 'subslot',
            'det': 'subslot',
            'case': 'subslot',
            'nmod': 'M1'
        }
        self.subordinate_relations = ['advcl', 'ccomp', 'xcomp', 'acl:relcl', 'csubj']
        
    def initialize(self):
        """ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–"""
        print("ğŸ¯ PureStanzaEngine v4 åˆæœŸåŒ–ä¸­...")
        
        # StanzaåˆæœŸåŒ–
        try:
            self.nlp = stanza.Pipeline(
                lang='en', 
                processors='tokenize,pos,lemma,depparse',
                download_method=None
            )
            print("âœ… Stanzaæº–å‚™å®Œäº†")
        except Exception as e:
            print(f"âŒ StanzaåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
        # spaCyåˆæœŸåŒ–
        try:
            self.spacy_nlp = spacy.load("en_core_web_sm")
            print("âœ… spaCyæº–å‚™å®Œäº†")
        except Exception as e:
            print(f"âŒ spaCyåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
        # ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šèª­ã¿è¾¼ã¿
        self._load_sentence_patterns()
        print("ğŸ—ï¸ éšå±¤çš„åˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº† (v4)")
        return True
        
    def _load_sentence_patterns(self):
        """æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šèª­ã¿è¾¼ã¿"""
        self.sentence_patterns = {
            "SV": {
                "required": ["nsubj", "root"],
                "mapping": {"nsubj": "S", "root": "V"}
            },
            "SVC_BE": {
                "required": ["nsubj", "cop", "root"],
                "mapping": {"nsubj": "S", "cop": "V", "root": "C1"}
            },
            "SVC_LOOKS": {
                "required": ["nsubj", "root"],
                "optional": ["xcomp"],
                "mapping": {"nsubj": "S", "root": "V", "xcomp": "C1"}
            },
            "SVO": {
                "required": ["nsubj", "root", "obj"],
                "mapping": {"nsubj": "S", "root": "V", "obj": "O1"}
            },
            "SVOO": {
                "required": ["nsubj", "root", "obj", "iobj"],
                "mapping": {"nsubj": "S", "root": "V", "obj": "O1", "iobj": "O2"}
            },
            "SVOC": {
                "required": ["nsubj", "root", "obj", "xcomp"],
                "mapping": {"nsubj": "S", "root": "V", "obj": "O1", "xcomp": "C2"}
            },
            "S_AUX_V": {
                "required": ["nsubj", "root", "aux"],
                "mapping": {"nsubj": "S", "root": "V", "aux": "Aux"}
            },
            "S_AUX_V_O": {
                "required": ["nsubj", "root", "aux", "obj"],
                "mapping": {"nsubj": "S", "root": "V", "aux": "Aux", "obj": "O1"}
            },
            "PASSIVE": {
                "required": ["nsubj:pass", "root"],
                "mapping": {"nsubj:pass": "S", "root": "V"}
            },
            "PASSIVE_AUX": {
                "required": ["nsubj:pass", "root", "aux:pass"],
                "mapping": {"nsubj:pass": "S", "root": "V", "aux:pass": "Aux"}
            },
            "THERE_BE": {
                "required": ["expl", "root"],
                "mapping": {"expl": "S", "root": "V"}
            },
            "WH_BE": {
                "required": ["nsubj", "cop", "root"],
                "mapping": {"nsubj": "S", "cop": "V", "root": "C1"}
            }
        }
    
    def analyze_complex_sentence(self, text: str) -> Dict[str, Any]:
        """è¤‡æ–‡ã®éšå±¤çš„åˆ†æ"""
        print(f"\nğŸ¯ è¤‡æ–‡åˆ†æé–‹å§‹: '{text}'")
        
        # Stanzaè§£æ
        doc = self.nlp(text)
        sent = doc.sentences[0]
        
        # ä¸»ç¯€åˆ†æ
        main_clause_result = self._analyze_main_clause(sent)
        
        # å¾“å±ç¯€åˆ†æ
        subordinate_clauses = self._extract_subordinate_clauses(sent)
        subordinate_results = []
        
        for clause_info in subordinate_clauses:
            clause_result = self._analyze_subordinate_clause(sent, clause_info)
            subordinate_results.append(clause_result)
        
        # çµ±åˆçµæœ
        complex_result = {
            "sentence_type": "complex" if subordinate_clauses else "simple",
            "main_clause": main_clause_result,
            "subordinate_clauses": subordinate_results,
            "total_clauses": 1 + len(subordinate_clauses)
        }
        
        return complex_result
    
    def _analyze_main_clause(self, sent) -> Dict[str, Any]:
        """ä¸»ç¯€ã®åˆ†æ"""
        print("\nğŸ“‹ ä¸»ç¯€åˆ†æ:")
        
        # ROOTå‹•è©ç‰¹å®š
        root_verb = self._find_root_verb(sent)
        if not root_verb:
            print("âŒ ROOTå‹•è©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        print(f"ğŸ“Œ ä¸»ç¯€ROOT: '{root_verb.text}' (POS: {root_verb.upos})")
        
        # ä¸»ç¯€ã®è¦ç´ ã®ã¿æŠ½å‡ºï¼ˆå¾“å±ç¯€ã®è¦ç´ ã‚’é™¤å¤–ï¼‰
        main_clause_words = self._extract_main_clause_words(sent, root_verb)
        
        # æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
        sentence_pattern = self._identify_sentence_pattern_for_words(main_clause_words, root_verb)
        if not sentence_pattern:
            print("âŒ ä¸»ç¯€ã®æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        print(f"ğŸ” ä¸»ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³: {sentence_pattern}")
        
        # ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        slots = self._extract_slots_for_words(main_clause_words, root_verb, sentence_pattern)
        
        return {
            "clause_type": "main",
            "pattern": sentence_pattern,
            "root_verb": root_verb.text,
            "slots": slots
        }
    
    def _extract_subordinate_clauses(self, sent) -> List[Dict[str, Any]]:
        """å¾“å±ç¯€ã®æŠ½å‡º"""
        subordinate_clauses = []
        
        for word in sent.words:
            if word.deprel in self.subordinate_relations:
                # å¾“å±ç¯€ã®æ§‹æˆè¦ç´ ã‚’åé›†
                clause_words = self._collect_clause_words(sent, word)
                
                # å¾“å±æ¥ç¶šè©ã®ç‰¹å®š
                connector = self._find_connector(clause_words)
                
                clause_info = {
                    "head_word": word,
                    "relation": word.deprel,
                    "words": clause_words,
                    "connector": connector
                }
                subordinate_clauses.append(clause_info)
                print(f"ğŸ” å¾“å±ç¯€æ¤œå‡º: {word.text} ({word.deprel}) - æ¥ç¶šè©: {connector}")
        
        return subordinate_clauses
    
    def _analyze_subordinate_clause(self, sent, clause_info: Dict[str, Any]) -> Dict[str, Any]:
        """å€‹åˆ¥ã®å¾“å±ç¯€åˆ†æ"""
        head_word = clause_info["head_word"]
        clause_words = clause_info["words"]
        
        print(f"\nğŸ“‹ å¾“å±ç¯€åˆ†æ: {head_word.text} ({clause_info['relation']})")
        
        # å¾“å±ç¯€å†…ã§ã®æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
        pattern = self._identify_sentence_pattern_for_words(clause_words, head_word)
        if not pattern:
            print("âŒ å¾“å±ç¯€ã®æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        print(f"ğŸ” å¾“å±ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}")
        
        # ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º
        slots = self._extract_slots_for_words(clause_words, head_word, pattern)
        
        return {
            "clause_type": "subordinate",
            "relation": clause_info["relation"],
            "connector": clause_info["connector"],
            "pattern": pattern,
            "root_verb": head_word.text,
            "slots": slots
        }
    
    def _extract_main_clause_words(self, sent, root_verb) -> List[Any]:
        """ä¸»ç¯€ã®å˜èªã®ã¿æŠ½å‡ºï¼ˆå¾“å±ç¯€ã‚’é™¤å¤–ï¼‰"""
        main_words = []
        subordinate_heads = [w for w in sent.words if w.deprel in self.subordinate_relations]
        subordinate_word_ids = set()
        
        # å¾“å±ç¯€ã«å±ã™ã‚‹å˜èªIDã‚’åé›†
        for sub_head in subordinate_heads:
            subordinate_word_ids.update(self._get_subtree_word_ids(sent, sub_head))
        
        # ä¸»ç¯€ã®å˜èªã®ã¿æŠ½å‡º
        for word in sent.words:
            if word.id not in subordinate_word_ids:
                main_words.append(word)
        
        return main_words
    
    def _collect_clause_words(self, sent, head_word) -> List[Any]:
        """å¾“å±ç¯€ã®æ§‹æˆå˜èªã‚’åé›†"""
        clause_words = []
        subtree_ids = self._get_subtree_word_ids(sent, head_word)
        
        for word in sent.words:
            if word.id in subtree_ids:
                clause_words.append(word)
        
        return clause_words
    
    def _get_subtree_word_ids(self, sent, head_word) -> set:
        """æŒ‡å®šã—ãŸèªã‚’é ‚ç‚¹ã¨ã™ã‚‹éƒ¨åˆ†æœ¨ã®å˜èªIDã‚’å–å¾—"""
        subtree_ids = {head_word.id}
        
        # å†å¸°çš„ã«å­ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        def add_children(word_id):
            for word in sent.words:
                if word.head == word_id and word.id not in subtree_ids:
                    subtree_ids.add(word.id)
                    add_children(word.id)
        
        add_children(head_word.id)
        return subtree_ids
    
    def _find_connector(self, clause_words) -> str:
        """å¾“å±æ¥ç¶šè©ã‚’ç‰¹å®š"""
        for word in clause_words:
            if word.deprel == 'mark':
                return word.text
        return ""
    
    # ä»¥ä¸‹ã€æ—¢å­˜ã®v3ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é©ç”¨
    def _find_root_verb(self, sent) -> Optional[Any]:
        """ROOTå‹•è©ã‚’ç‰¹å®š"""
        for word in sent.words:
            if word.deprel == 'root':
                return word
        return None
    
    def _identify_sentence_pattern_for_words(self, words: List[Any], root_verb) -> Optional[str]:
        """æŒ‡å®šã—ãŸå˜èªç¾¤ã§ã®æ–‡å‹ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥"""
        word_relations = [w.deprel for w in words]
        
        for pattern_name, pattern_config in self.sentence_patterns.items():
            required = pattern_config["required"]
            optional = pattern_config.get("optional", [])
            
            # å¿…é ˆè¦ç´ ãƒã‚§ãƒƒã‚¯
            if all(rel in word_relations for rel in required):
                print(f"âœ… ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern_name}")
                return pattern_name
        
        return None
    
    def _extract_slots_for_words(self, words: List[Any], root_verb, pattern_name: str) -> Dict[str, str]:
        """æŒ‡å®šã—ãŸå˜èªç¾¤ã§ã®ã‚¹ãƒ­ãƒƒãƒˆæŠ½å‡º"""
        pattern_config = self.sentence_patterns[pattern_name]
        mapping = pattern_config["mapping"]
        
        slots = {}
        aux_words = []
        
        for word in words:
            if word.deprel in mapping:
                slot_name = mapping[word.deprel]
                
                if slot_name == "Aux":
                    aux_words.append(word)
                    continue
                
                print(f"ğŸ“ {slot_name}æ¤œå‡º: '{word.text}' (deprel: {word.deprel})")
                slots[slot_name] = word.text
        
        # Auxçµ±åˆ
        if aux_words:
            aux_texts = [word.text for word in sorted(aux_words, key=lambda w: w.id)]
            aux_combined = " ".join(aux_texts)
            print(f"ğŸ“ Auxæ¤œå‡º: '{aux_combined}' (çµ±åˆ: {len(aux_words)}å€‹)")
            slots["Aux"] = aux_combined
        
        return slots

def test_complex_analysis():
    """è¤‡æ–‡åˆ†æãƒ†ã‚¹ãƒˆ"""
    engine = PureStanzaEngine_v4()
    if not engine.initialize():
        return
    
    test_sentences = [
        "He succeeded even though he was under intense pressure.",
        "She passed the test because she is very intelligent.",
        "The man who is tall walks quickly.",
        "I know that he is happy."
    ]
    
    for sentence in test_sentences:
        print(f"\n{'='*80}")
        print(f"ãƒ†ã‚¹ãƒˆæ–‡: {sentence}")
        print('='*80)
        
        result = engine.analyze_complex_sentence(sentence)
        
        print(f"\nğŸ“Š åˆ†æçµæœ:")
        print(f"æ–‡å‹: {result.get('sentence_type', 'unknown')}")
        print(f"ç¯€æ•°: {result.get('total_clauses', 0)}")
        
        # ä¸»ç¯€çµæœ
        main_clause = result.get('main_clause', {})
        if main_clause:
            print(f"\nğŸ›ï¸ ä¸»ç¯€:")
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {main_clause.get('pattern', 'N/A')}")
            print(f"  ã‚¹ãƒ­ãƒƒãƒˆ: {main_clause.get('slots', {})}")
        
        # å¾“å±ç¯€çµæœ
        for i, sub_clause in enumerate(result.get('subordinate_clauses', [])):
            print(f"\nğŸ”— å¾“å±ç¯€ {i+1}:")
            print(f"  æ¥ç¶š: {sub_clause.get('connector', 'N/A')} ({sub_clause.get('relation', 'N/A')})")
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {sub_clause.get('pattern', 'N/A')}")
            print(f"  ã‚¹ãƒ­ãƒƒãƒˆ: {sub_clause.get('slots', {})}")

if __name__ == "__main__":
    test_complex_analysis()
