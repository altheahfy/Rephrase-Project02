"""
æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸãƒ«ãƒ¼ãƒ«çµ±åˆç‰ˆ - Step 2æ”¹è‰¯å®Ÿè£…
aux-have vs V-have ã®æ–‡è„ˆåˆ¤å®šã‚’è¿½åŠ 
"""

class ContextAwareRuleEngine:
    """æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸãƒ«ãƒ¼ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.simple_rules = []
        self.init_simple_rules()
    
    def init_simple_rules(self):
        """ç°¡å˜ãƒ«ãƒ¼ãƒ«åˆæœŸåŒ–"""
        self.simple_rules = [
            self.rule_aux_will,
            self.rule_contextual_have,  # æ–‡è„ˆè€ƒæ…®ç‰ˆ
        ]
    
    def rule_aux_will(self, word, context):
        """ãƒ«ãƒ¼ãƒ«: aux-will"""
        if word.lower() == 'will':
            return ('Aux', 'word')
        return None
    
    def rule_contextual_have(self, word, context):
        """ãƒ«ãƒ¼ãƒ«: æ–‡è„ˆè€ƒæ…®ç‰ˆhaveåˆ¤å®š"""
        if word.lower() not in ['has', 'have', 'had']:
            return None
        
        # æ–‡è„ˆåˆ†æ
        word_index = context['word_index']
        words = context['words']
        
        # åŠ©å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¤å®š
        if self.is_auxiliary_have(word, word_index, words):
            return ('Aux', 'word')
        else:
            return ('V', 'word')
    
    def is_auxiliary_have(self, word, word_index, words):
        """haveãŒåŠ©å‹•è©ã‹ã©ã†ã‹ã‚’æ–‡è„ˆã‹ã‚‰åˆ¤å®š"""
        
        # 1. æ¬¡ã®å˜èªãŒéå»åˆ†è©å½¢ã‹ãƒã‚§ãƒƒã‚¯
        if word_index + 1 < len(words):
            next_word = words[word_index + 1].lower()
            
            # æ˜ã‚‰ã‹ãªéå»åˆ†è©ãƒ‘ã‚¿ãƒ¼ãƒ³
            past_participle_patterns = [
                'been', 'done', 'seen', 'gone', 'taken', 'given', 'made', 
                'eaten', 'written', 'spoken', 'broken', 'chosen', 'driven',
                'found', 'bought', 'thought', 'brought', 'taught', 'caught',
                'finished', 'started', 'decided', 'arrived', 'studied'
            ]
            
            # -ed ã§çµ‚ã‚ã‚‹è¦å‰‡å‹•è©ã®éå»åˆ†è©
            if next_word.endswith('ed') and len(next_word) > 3:
                return True
                
            # ä¸è¦å‰‡å‹•è©ã®éå»åˆ†è©
            if next_word in past_participle_patterns:
                return True
        
        # 2. ä¸€èˆ¬å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¤å®š
        if word_index + 1 < len(words):
            next_word = words[word_index + 1].lower()
            
            # æ˜ã‚‰ã‹ã«ç›®çš„èªã«ãªã‚‹å˜èªï¼ˆå† è©ã€åè©ãªã©ï¼‰
            direct_object_indicators = [
                'a', 'an', 'the', 'my', 'your', 'his', 'her', 'our', 'their',
                'some', 'many', 'much', 'apple', 'book', 'car', 'house', 'dog',
                'cat', 'money', 'time', 'problem', 'idea', 'question'
            ]
            
            if next_word in direct_object_indicators:
                return False  # ä¸€èˆ¬å‹•è©
        
        # 3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¤å®šï¼ˆæ–‡è„ˆãŒä¸æ˜ç¢ºãªå ´åˆï¼‰
        # ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚±ãƒ¼ã‚¹ã‚’è€ƒæ…®ã—ã¦ä¸€èˆ¬å‹•è©ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
        return False
    
    def apply_simple_rules(self, word, context):
        """ç°¡å˜ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ï¼ˆæ–‡è„ˆä»˜ãï¼‰"""
        for rule_func in self.simple_rules:
            result = rule_func(word, context)
            if result:
                return result
        return None
    
    def enhanced_sentence_analysis(self, sentence):
        """ãƒ«ãƒ¼ãƒ«çµ±åˆç‰ˆæ–‡åˆ†æ"""
        words = sentence.replace('.', '').replace('?', '').replace('!', '').split()
        results = []
        
        for i, word in enumerate(words):
            # æ–‡è„ˆæƒ…å ±ã‚’ä½œæˆ
            context = {
                'word_index': i,
                'words': words,
                'sentence': sentence
            }
            
            # ã¾ãšç°¡å˜ãƒ«ãƒ¼ãƒ«ã‚’è©¦è¡Œ
            rule_result = self.apply_simple_rules(word, context)
            if rule_result:
                slot, phrase_type = rule_result
                results.append((slot, word, phrase_type))
                print(f"   ğŸ¯ æ–‡è„ˆãƒ«ãƒ¼ãƒ«é©ç”¨: '{word}' â†’ {slot}({phrase_type})")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®åˆ†æ
                slot, phrase_type = self.fallback_analysis(word)
                results.append((slot, word, phrase_type))
                print(f"   ğŸ§  å¾“æ¥åˆ†æ: '{word}' â†’ {slot}({phrase_type})")
        
        return results
    
    def fallback_analysis(self, word):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æï¼ˆå¾“æ¥ã®æ–¹æ³•ï¼‰"""
        # ä»£åè©åˆ¤å®š
        pronouns_s = ['i', 'you', 'he', 'she', 'it', 'we', 'they']
        pronouns_o = ['me', 'him', 'her', 'us', 'them']
        
        if word.lower() in pronouns_s:
            return 'S', 'word'
        elif word.lower() in pronouns_o:
            return 'O1', 'word'
        elif word.lower() in ['where', 'when', 'why', 'how']:
            return 'M3', 'word'
        else:
            return 'O1', 'word'


def test_contextual_have():
    """æ–‡è„ˆè€ƒæ…®ç‰ˆhaveãƒ†ã‚¹ãƒˆ"""
    engine = ContextAwareRuleEngine()
    
    test_sentences = [
        "I have an apple.",          # V (ä¸€èˆ¬å‹•è©) 
        "I have eaten breakfast.",   # Aux (åŠ©å‹•è©)
        "She has finished her work.", # Aux (åŠ©å‹•è©)
        "They have a car.",          # V (ä¸€èˆ¬å‹•è©)
        "We have been to Tokyo.",    # Aux (åŠ©å‹•è©)
        "He will go to school.",     # Aux (will)
    ]
    
    print("ğŸ§ª æ–‡è„ˆè€ƒæ…®ç‰ˆhaveãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    for sentence in test_sentences:
        print(f"\nğŸ“ ä¾‹æ–‡: {sentence}")
        results = engine.enhanced_sentence_analysis(sentence)
        
        # have/has/had/willã®çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        for slot, word, phrase_type in results:
            if word.lower() in ['have', 'has', 'had', 'will']:
                if slot == 'Aux':
                    print(f"   âœ… æ­£è§£: '{word}' ã¯åŠ©å‹•è© â†’ {slot}")
                elif slot == 'V':
                    print(f"   âœ… æ­£è§£: '{word}' ã¯ä¸€èˆ¬å‹•è© â†’ {slot}")


if __name__ == "__main__":
    test_contextual_have()
