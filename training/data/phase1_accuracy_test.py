#!/usr/bin/env python3
"""
Phase 1 Universal System Accuracy Test
=====================================

Phase 1çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¨æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ç²¾åº¦æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆUnifiedStanzaRephraseMapperï¼‰ã¨ã®å®Œå…¨äº’æ›æ€§ç¢ºèª
- äººé–“æ–‡æ³•èªè­˜ã®ç²¾åº¦æ¤œè¨¼
- Universal Slot Position Systemã®æ­£ç¢ºæ€§æ¤œè¨¼

ä½¿ç”¨æ³•:
    python phase1_accuracy_test.py
    python phase1_accuracy_test.py --detailed
"""

import json
import sys
import os
import argparse
from typing import Dict, List, Any, Tuple
from datetime import datetime
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from universal_slot_system import UniversalSlotPositionManager
from universal_slot_system.patterns.whose_pattern import WhosePattern
from universal_slot_system.patterns.passive_pattern import PassivePattern
from unified_stanza_rephrase_mapper import UnifiedStanzaRephraseMapper

import stanza


class Phase1AccuracyTest:
    """Phase 1çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self, detailed=False):
        self.detailed = detailed
        self.logger = logging.getLogger("Phase1AccuracyTest")
        
        # ãƒ­ã‚°è¨­å®š
        log_level = logging.DEBUG if detailed else logging.INFO
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # StanzaåˆæœŸåŒ–
        try:
            self.nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse')
            self.logger.info("âœ… StanzaåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            self.logger.error(f"âŒ StanzaåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return
            
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.legacy_system = UnifiedStanzaRephraseMapper()
        self.universal_system = UniversalSlotPositionManager()
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç™»éŒ²
        self._register_patterns()
        
        # ãƒ†ã‚¹ãƒˆæ–‡ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§100%ç²¾åº¦ãŒç¢ºèªæ¸ˆã¿ã®æ–‡ï¼‰
        self.test_sentences = [
            # whoseæ§‹æ–‡ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            "The man whose car is red lives here",
            "The woman whose house looks beautiful works there",
            "The person whose dog runs fast stays nearby",
            
            # å—å‹•æ…‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹  
            "The result was unexpected",
            "The plan was completed",
            "The book was written",
            
            # æ··åˆãƒ»è¤‡é›‘ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            "The teacher whose class was cancelled lives here",
            "The report that was finished yesterday looks good",
            "The student whose homework was completed early goes home",
            
            # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹
            "The man walks",  # å˜ç´”æ–‡
            "She is beautiful",  # å˜ç´”ä¸»èªè¿°èª
            "They were working",  # é€²è¡Œå½¢
        ]
        
        # çµæœæ ¼ç´
        self.comparison_results = []
        self.accuracy_stats = {
            'total_tests': 0,
            'perfect_matches': 0,
            'partial_matches': 0, 
            'complete_mismatches': 0,
            'error_count': 0
        }
        
    def _register_patterns(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ç™»éŒ²"""
        whose_pattern = WhosePattern()
        passive_pattern = PassivePattern()
        
        self.universal_system.register_pattern("whose_ambiguous_verb", whose_pattern, priority=90)
        self.universal_system.register_pattern("passive_voice", passive_pattern, priority=85)
        
        self.logger.info("âœ… Phase 1ãƒ‘ã‚¿ãƒ¼ãƒ³ç™»éŒ²å®Œäº†")
        
    def run_accuracy_test(self):
        """ç²¾åº¦ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("ğŸ§ª Phase 1ç²¾åº¦ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        for sentence in self.test_sentences:
            self.logger.info(f"ğŸ”„ ãƒ†ã‚¹ãƒˆä¸­: '{sentence}'")
            
            # æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            comparison = self._compare_systems(sentence)
            self.comparison_results.append(comparison)
            
            # çµ±è¨ˆæ›´æ–°
            self._update_stats(comparison)
            
        # çµæœåˆ†æ
        self._analyze_results()
        
        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        self._generate_report()
        
        self.logger.info("ğŸ Phase 1ç²¾åº¦ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    def _compare_systems(self, sentence: str) -> Dict:
        """ã‚·ã‚¹ãƒ†ãƒ é–“æ¯”è¼ƒ"""
        comparison = {
            'sentence': sentence,
            'legacy_result': None,
            'universal_result': None,
            'legacy_error': None,
            'universal_error': None,
            'corrections_match': False,
            'processing_match': False,
            'accuracy_score': 0.0
        }
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§ã®å‡¦ç†
        try:
            legacy_result = self.legacy_system.process(sentence)
            comparison['legacy_result'] = {
                'slots': legacy_result.get('slots', {}),
                'sub_slots': legacy_result.get('sub_slots', {}),
                'corrections': self._extract_corrections(legacy_result.get('stanza_doc'))
            }
            self.logger.debug(f"æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ çµæœ: {comparison['legacy_result']}")
        except Exception as e:
            comparison['legacy_error'] = str(e)
            self.logger.error(f"âŒ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
            
        # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã§ã®å‡¦ç†
        try:
            doc = self.nlp(sentence)
            processed_doc, metadata = self.universal_system.process_all_patterns(doc, sentence)
            
            # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¯æ–‡æ³•ä¿®æ­£ã®ã¿ãªã®ã§ã€ã‚¹ãƒ­ãƒƒãƒˆç”Ÿæˆã¯æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            universal_slots_result = self.legacy_system.process(sentence)
            
            comparison['universal_result'] = {
                'slots': universal_slots_result.get('slots', {}),
                'sub_slots': universal_slots_result.get('sub_slots', {}),
                'corrections': self._extract_corrections(processed_doc),
                'metadata': metadata
            }
            self.logger.debug(f"çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ çµæœ: {comparison['universal_result']}")
        except Exception as e:
            comparison['universal_error'] = str(e)
            self.logger.error(f"âŒ çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
            
        # æ¯”è¼ƒåˆ†æ
        self._analyze_comparison(comparison)
        
        return comparison
        
    def _extract_corrections(self, doc) -> Dict:
        """æ–‡æ³•ä¿®æ­£æƒ…å ±æŠ½å‡º"""
        if not doc:
            return {}
            
        corrections = {}
        
        # human_grammar_correctionså±æ€§ãƒã‚§ãƒƒã‚¯
        if hasattr(doc, 'human_grammar_corrections'):
            corrections['human_grammar'] = doc.human_grammar_corrections
            
        # _human_grammar_correctionså±æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ï¼‰
        if hasattr(doc, '_human_grammar_corrections'):
            corrections['legacy_human_grammar'] = doc._human_grammar_corrections
            
        return corrections
        
    def _analyze_comparison(self, comparison: Dict):
        """æ¯”è¼ƒåˆ†æ"""
        if comparison['legacy_error'] or comparison['universal_error']:
            comparison['accuracy_score'] = 0.0
            return
            
        legacy_corrections = comparison['legacy_result']['corrections']
        universal_corrections = comparison['universal_result']['corrections']
        
        # ä¿®æ­£å†…å®¹ã®æ¯”è¼ƒ
        corrections_match = self._compare_corrections(legacy_corrections, universal_corrections)
        comparison['corrections_match'] = corrections_match
        
        # ã‚¹ãƒ­ãƒƒãƒˆçµæœã®æ¯”è¼ƒï¼ˆçµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¯æ–‡æ³•ä¿®æ­£ã®ã¿ãªã®ã§ã€åŸºæœ¬çš„ã«åŒã˜ã¯ãšï¼‰
        legacy_slots = comparison['legacy_result']['slots']
        universal_slots = comparison['universal_result']['slots']
        
        slots_match = legacy_slots == universal_slots
        comparison['processing_match'] = slots_match
        
        # ç²¾åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = 0.0
        if corrections_match:
            score += 0.7  # æ–‡æ³•ä¿®æ­£ä¸€è‡´åº¦
        if slots_match:
            score += 0.3  # ã‚¹ãƒ­ãƒƒãƒˆå‡¦ç†ä¸€è‡´åº¦
            
        comparison['accuracy_score'] = score
        
        if self.detailed:
            self.logger.debug(f"ğŸ“Š æ¯”è¼ƒåˆ†æ: ä¿®æ­£ä¸€è‡´={corrections_match}, ã‚¹ãƒ­ãƒƒãƒˆä¸€è‡´={slots_match}, ã‚¹ã‚³ã‚¢={score:.2f}")
            
    def _compare_corrections(self, legacy_corrections: Dict, universal_corrections: Dict) -> bool:
        """æ–‡æ³•ä¿®æ­£ã®æ¯”è¼ƒ"""
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ä¿®æ­£
        legacy_human = legacy_corrections.get('human_grammar', {})
        legacy_list = legacy_corrections.get('legacy_human_grammar', [])
        
        # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã®ä¿®æ­£
        universal_human = universal_corrections.get('human_grammar', {})
        
        # æ•°å€¤çš„æ¯”è¼ƒ
        legacy_count = len(legacy_human) + len(legacy_list)
        universal_count = len(universal_human)
        
        if self.detailed:
            self.logger.debug(f"ä¿®æ­£æ•°æ¯”è¼ƒ: æ—¢å­˜={legacy_count}, çµ±ä¸€={universal_count}")
            
        # ä¿®æ­£æ•°ãŒåŒã˜ã‹ã€çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ãŒåŒç­‰ä»¥ä¸Šã®ä¿®æ­£ã‚’è¡Œã£ã¦ã„ã‚‹ã‹
        return universal_count >= legacy_count
        
    def _update_stats(self, comparison: Dict):
        """çµ±è¨ˆæ›´æ–°"""
        self.accuracy_stats['total_tests'] += 1
        
        if comparison['legacy_error'] or comparison['universal_error']:
            self.accuracy_stats['error_count'] += 1
            return
            
        score = comparison['accuracy_score']
        
        if score >= 0.9:
            self.accuracy_stats['perfect_matches'] += 1
        elif score >= 0.5:
            self.accuracy_stats['partial_matches'] += 1
        else:
            self.accuracy_stats['complete_mismatches'] += 1
            
    def _analyze_results(self):
        """çµæœåˆ†æ"""
        stats = self.accuracy_stats
        total = stats['total_tests']
        
        if total == 0:
            self.logger.warning("âš ï¸ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãªã—")
            return
            
        perfect_rate = stats['perfect_matches'] / total
        partial_rate = stats['partial_matches'] / total
        error_rate = stats['error_count'] / total
        
        self.logger.info(f"ğŸ“Š ç²¾åº¦åˆ†æçµæœ:")
        self.logger.info(f"  å®Œå…¨ä¸€è‡´: {stats['perfect_matches']}/{total} ({perfect_rate:.1%})")
        self.logger.info(f"  éƒ¨åˆ†ä¸€è‡´: {stats['partial_matches']}/{total} ({partial_rate:.1%})")
        self.logger.info(f"  ä¸ä¸€è‡´: {stats['complete_mismatches']}/{total}")
        self.logger.info(f"  ã‚¨ãƒ©ãƒ¼: {stats['error_count']}/{total} ({error_rate:.1%})")
        
        # å“è³ªåˆ¤å®š
        if perfect_rate >= 0.9:
            quality = "EXCELLENT"
            status = "âœ…"
        elif perfect_rate >= 0.7:
            quality = "GOOD"
            status = "âš ï¸"
        else:
            quality = "NEEDS_IMPROVEMENT"
            status = "âŒ"
            
        self.logger.info(f"{status} ç·åˆå“è³ªè©•ä¾¡: {quality} (å®Œå…¨ä¸€è‡´ç‡: {perfect_rate:.1%})")
        
    def _generate_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.detailed:
            return
            
        report_filename = f"phase1_accuracy_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report_data = {
            'test_info': {
                'timestamp': datetime.now().isoformat(),
                'test_type': 'phase1_universal_system_accuracy',
                'total_sentences': len(self.test_sentences),
                'detailed_mode': self.detailed
            },
            'accuracy_stats': self.accuracy_stats,
            'detailed_results': self.comparison_results
        }
        
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            self.logger.info(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_filename}")
        except Exception as e:
            self.logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            
    def get_summary(self) -> Dict:
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼å–å¾—"""
        total = self.accuracy_stats['total_tests']
        if total == 0:
            return {'status': 'NO_TESTS', 'accuracy': 0.0}
            
        perfect_rate = self.accuracy_stats['perfect_matches'] / total
        
        return {
            'status': 'EXCELLENT' if perfect_rate >= 0.9 else 'GOOD' if perfect_rate >= 0.7 else 'NEEDS_IMPROVEMENT',
            'accuracy': perfect_rate,
            'total_tests': total,
            'perfect_matches': self.accuracy_stats['perfect_matches'],
            'errors': self.accuracy_stats['error_count']
        }


def main():
    parser = argparse.ArgumentParser(description='Phase 1 Universal System Accuracy Test')
    parser.add_argument('--detailed', action='store_true', help='è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ')
    
    args = parser.parse_args()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test = Phase1AccuracyTest(detailed=args.detailed)
    test.run_accuracy_test()
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = test.get_summary()
    print(f"\nğŸ¯ Phase 1çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç²¾åº¦ãƒ†ã‚¹ãƒˆçµæœ")
    print(f"Status: {summary['status']}")
    print(f"Accuracy: {summary['accuracy']:.1%}")
    print(f"Tests: {summary['perfect_matches']}/{summary['total_tests']} perfect")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    if summary['status'] == 'EXCELLENT':
        exit(0)
    elif summary['status'] == 'GOOD':
        exit(1)
    else:
        exit(2)


if __name__ == "__main__":
    main()
