#!/usr/bin/env python3
"""
Stanzaæº–æ‹ å¾“å±æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æœ€å°åŒ–ã—ã€Stanzaã®æ§‹é€ è§£æã«ä¾å­˜
"""

import stanza
from typing import Dict, List, Optional, Any

class StanzaBasedConjunctionEngine:
    """Stanzaæ§‹é€ è§£ææº–æ‹ ã®æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        print("ğŸš€ Stanzaæº–æ‹ æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–ä¸­...")
        self.nlp = stanza.Pipeline('en', verbose=False)
        
        # æœ€å°é™ã®æ„å‘³åˆ†é¡ï¼ˆèªå½™çš„çŸ¥è­˜ã¨ã—ã¦å¿…è¦ï¼‰
        self.semantic_mapping = {
            # ç†ç”± -> M1ä½ç½®
            'because': 'M1', 'since': 'M1', 'as': 'M1',
            # æ¡ä»¶ -> M1ä½ç½®  
            'if': 'M1', 'unless': 'M1', 'provided': 'M1',
            # è­²æ­© -> M2ä½ç½®
            'although': 'M2', 'though': 'M2', 'whereas': 'M2',
            # æ™‚é–“ -> M3ä½ç½®
            'when': 'M3', 'while': 'M3', 'after': 'M3', 'before': 'M3', 'until': 'M3'
        }
        print("âœ… åˆæœŸåŒ–å®Œäº†")
    
    def process(self, text: str) -> Dict[str, str]:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç† - Stanzaæ§‹é€ è§£æãƒ™ãƒ¼ã‚¹"""
        print(f"ğŸ” Stanzaæ§‹é€ è§£æ: '{text}'")
        
        doc = self.nlp(text)
        sent = doc.sentences[0]
        
        # Stanzaæ§‹é€ ã«ã‚ˆã‚‹å¾“å±ç¯€æ¤œå‡º
        subordinate_info = self._analyze_subordinate_structure(sent)
        
        if subordinate_info:
            return self._process_by_stanza_structure(sent, subordinate_info)
        else:
            return self._process_simple_sentence(sent)
    
    def _analyze_subordinate_structure(self, sent) -> Optional[Dict]:
        """Stanzaæ§‹é€ ã«ã‚ˆã‚‹å¾“å±ç¯€åˆ†æ"""
        structure_info = {
            'mark_word': None,      # marké–¢ä¿‚ã®æ¥ç¶šè©
            'advcl_word': None,     # advclé–¢ä¿‚ã®å‹•è©
            'main_verb': None,      # ä¸»ç¯€ã®å‹•è©ï¼ˆrootï¼‰
            'conjunction_type': None # æ„å‘³åˆ†é¡
        }
        
        # 1. æ§‹é€ è¦ç´ ã‚’ç‰¹å®š
        for word in sent.words:
            if word.deprel == 'mark' and word.upos == 'SCONJ':
                structure_info['mark_word'] = word
                # æ„å‘³åˆ†é¡ã‚’èªå½™ã‹ã‚‰åˆ¤å®š
                lemma = word.lemma.lower()
                structure_info['conjunction_type'] = self.semantic_mapping.get(lemma, 'M1')
                
            elif word.deprel == 'advcl':
                structure_info['advcl_word'] = word
                
            elif word.deprel == 'root':
                structure_info['main_verb'] = word
        
        # 2. å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        if structure_info['mark_word'] or structure_info['advcl_word']:
            print(f"  ğŸ“‹ å¾“å±æ§‹é€ æ¤œå‡º:")
            print(f"    æ¥ç¶šè©: {structure_info['mark_word'].text if structure_info['mark_word'] else '?'}")
            print(f"    å¾“å±å‹•è©: {structure_info['advcl_word'].text if structure_info['advcl_word'] else '?'}")
            print(f"    ä¸»å‹•è©: {structure_info['main_verb'].text if structure_info['main_verb'] else '?'}")
            return structure_info
        
        return None
    
    def _process_by_stanza_structure(self, sent, structure_info) -> Dict[str, str]:
        """Stanzaæ§‹é€ ã«åŸºã¥ãåˆ†è§£å‡¦ç†"""
        mark_word = structure_info['mark_word']
        advcl_word = structure_info['advcl_word']
        main_verb = structure_info['main_verb']
        conjunction_type = structure_info['conjunction_type']
        
        result = {}
        
        # å˜ç‹¬å¾“å±ç¯€ã®å ´åˆï¼ˆä¸»ç¯€ãªã—ã€ã¾ãŸã¯ advclæ¤œå‡ºãªã—ï¼‰
        if mark_word and (not main_verb or not advcl_word):
            print("  ğŸ“ å˜ç‹¬å¾“å±ç¯€å‡¦ç†")
            return self._process_single_subordinate_clause(sent, mark_word)
        
        # è¤‡åˆæ–‡ã®å ´åˆ
        if mark_word and advcl_word and main_verb:
            print(f"  ğŸ“ è¤‡åˆæ–‡å‡¦ç† (æ¥ç¶šè©ä½ç½®: {conjunction_type})")
            
            # å¾“å±ç¯€è¦ç´ ã®æŠ½å‡º
            sub_elements = self._extract_subordinate_elements(sent, advcl_word, mark_word)
            # ä¸»ç¯€è¦ç´ ã®æŠ½å‡º  
            main_elements = self._extract_main_elements(sent, main_verb)
            
            # Rephraseåˆ†è§£çµæœã®æ§‹ç¯‰
            result.update(sub_elements)
            result.update(main_elements)
            
            return result
        
        return {"error": "æ§‹é€ è§£æå¤±æ•—"}
    
    def _process_single_subordinate_clause(self, sent, mark_word) -> Dict[str, str]:
        """å˜ç‹¬å¾“å±ç¯€ã®å‡¦ç†"""
        result = {}
        
        # æ¥ç¶šè©
        conjunction_type = self.semantic_mapping.get(mark_word.lemma.lower(), 'M1')
        result[f"sub-{conjunction_type.lower()}"] = mark_word.text.lower()
        
        # å¾“å±ç¯€ã®å‹•è©ã‚’æ¢ã™
        subordinate_verb = None
        for word in sent.words:
            if word.upos in ['VERB', 'AUX'] and word.id > mark_word.id:
                subordinate_verb = word
                break
        
        if subordinate_verb:
            # å¾“å±ç¯€ã®è¦ç´ ã‚’æŠ½å‡º
            sub_elements = self._extract_clause_elements(sent, subordinate_verb, "sub-")
            result.update(sub_elements)
        
        print(f"  âœ… å˜ç‹¬å¾“å±ç¯€çµæœ: {result}")
        return result
    
    def _extract_subordinate_elements(self, sent, advcl_verb, mark_word) -> Dict[str, str]:
        """å¾“å±ç¯€è¦ç´ ã®æŠ½å‡º"""
        elements = {}
        
        # æ¥ç¶šè©ã®ä½ç½®åˆ†é¡
        conjunction_type = self.semantic_mapping.get(mark_word.lemma.lower(), 'M1')
        elements[f"sub-{conjunction_type.lower()}"] = mark_word.text.lower()
        
        # å¾“å±ç¯€ã®æ–‡æ³•è¦ç´ 
        clause_elements = self._extract_clause_elements(sent, advcl_verb, "sub-")
        elements.update(clause_elements)
        
        return elements
    
    def _extract_main_elements(self, sent, main_verb) -> Dict[str, str]:
        """ä¸»ç¯€è¦ç´ ã®æŠ½å‡º"""
        return self._extract_clause_elements(sent, main_verb, "")
    
    def _extract_clause_elements(self, sent, verb, prefix="") -> Dict[str, str]:
        """ç¯€ã®æ–‡æ³•è¦ç´ æŠ½å‡º"""
        elements = {}
        
        # å‹•è©å‘¨è¾ºã®ä¾å­˜é–¢ä¿‚ã‚’åˆ†æ
        for word in sent.words:
            if word.head == verb.id:
                if word.deprel == 'nsubj':
                    elements[f"{prefix}s"] = word.text
                elif word.deprel == 'obj':
                    elements[f"{prefix}o1"] = word.text
                elif word.deprel == 'iobj':
                    elements[f"{prefix}o2"] = word.text
                elif word.deprel == 'advmod':
                    elements[f"{prefix}m1"] = word.text
            elif word.id == verb.id:
                if word.upos == 'AUX':
                    elements[f"{prefix}aux"] = word.text
                elif word.upos == 'VERB':
                    elements[f"{prefix}v"] = word.text
                elif word.upos == 'ADJ':
                    elements[f"{prefix}c1"] = word.text
        
        return elements
    
    def _process_simple_sentence(self, sent) -> Dict[str, str]:
        """å˜ç´”æ–‡ã®å‡¦ç†"""
        print("  ğŸ“ å˜ç´”æ–‡å‡¦ç†")
        
        # rootå‹•è©ã‚’æ¢ã™
        main_verb = None
        for word in sent.words:
            if word.deprel == 'root':
                main_verb = word
                break
        
        if main_verb:
            return self._extract_clause_elements(sent, main_verb)
        
        return {"error": "å‹•è©æœªæ¤œå‡º"}

def test_stanza_based_engine():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    engine = StanzaBasedConjunctionEngine()
    
    test_cases = [
        "Because he is tired",
        "If you come tomorrow",
        "Although she tried hard",
        "When the bell rings",
        "Because he is tired, he went home",
        "If it rains, we stay inside"
    ]
    
    print("\n" + "="*50)
    print("ğŸ§ª Stanzaæº–æ‹ æ¥ç¶šè©ã‚¨ãƒ³ã‚¸ãƒ³ ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nã€Test {i}ã€‘ '{test}'")
        result = engine.process(test)
        
        print("ğŸ“Š çµæœ:")
        for key, value in result.items():
            print(f"  {key}: {value}")

if __name__ == "__main__":
    test_stanza_based_engine()
