"""
æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  (Phase 6a)
çœŸã®ä¸­å¤®ç®¡ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚‹æ–‡æ³•è§£æã‚·ã‚¹ãƒ†ãƒ 

è¨­è¨ˆåŸå‰‡:
1. ç›£ç£çš„ç«‹å ´: CentralControllerãŒå…¨ã¦ã‚’æŠŠæ¡ãƒ»çµ±åˆ¶
2. æƒ…å ±åé›†: å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ä¸¦è¡Œã—ã¦æƒ…å ±åé›†
3. çµ±åˆåˆ¤æ–­: ä¸­å¤®ã§ã®æœ€çµ‚åˆ¤æ–­ã«ã‚ˆã‚‹å‡¦ç†æ±ºå®š
4. å”åŠ›èª¿æ•´: å¿…è¦æ™‚ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–“å”åŠ›ã®èª¿æ•´
5. å“è³ªä¿è¨¼: ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ»æ¬ è½ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯
"""

import spacy
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ®µéšçš„ç§»è¡Œã®ãŸã‚ï¼‰
from basic_five_pattern_handler import BasicFivePatternHandler
from modal_handler import ModalHandler
from relative_clause_handler import RelativeClauseHandler


class AnalysisConfidence(Enum):
    """åˆ†æä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«"""
    HIGH = "high"
    MEDIUM = "medium" 
    LOW = "low"
    UNKNOWN = "unknown"


@dataclass
class HandlerReport:
    """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã®æƒ…å ±ãƒ¬ãƒãƒ¼ãƒˆ"""
    handler_name: str
    confidence: float  # 0.0-1.0
    detected_patterns: List[str]
    boundary_info: Optional[Dict[str, Any]] = None
    cooperation_needs: List[str] = None
    metadata: Dict[str, Any] = None
    processing_notes: List[str] = None

    def __post_init__(self):
        if self.cooperation_needs is None:
            self.cooperation_needs = []
        if self.metadata is None:
            self.metadata = {}
        if self.processing_notes is None:
            self.processing_notes = []


@dataclass 
class IntegratedAnalysis:
    """çµ±åˆåˆ†æçµæœ"""
    primary_grammar: str
    secondary_grammars: List[str]
    confidence_score: float
    handler_reports: Dict[str, HandlerReport]
    cooperation_plan: Dict[str, Any]
    quality_checks: Dict[str, bool]


class CentralControllerV2:
    """
    æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - çœŸã®ä¸­å¤®ç®¡ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ä¸¦è¡Œé‹ç”¨ã‚’å‰æã¨ã—ãŸæ®µéšçš„ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, config_file: str = 'central_controller_config.json'):
        """åˆæœŸåŒ–: æ–°ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®è¨­å®š"""
        self.nlp = spacy.load('en_core_web_sm')
        self.config = self._load_config(config_file)
        
        # Phase 6a: æœ€å°ã‚»ãƒƒãƒˆã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã§é–‹å§‹ï¼ˆæ¦‚å¿µå®Ÿè¨¼ï¼‰
        self.active_handlers = self._initialize_poc_handlers()
        
        # çµ±åˆãƒ«ãƒ¼ãƒ«è¨­å®š
        self.integration_rules = self.config.get('central_management', {})
        
        print("ğŸ¯ Central Controller V2 åˆæœŸåŒ–å®Œäº† - æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
        print(f"ğŸ“Š ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æ•°: {len(self.active_handlers)}")
        
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨å…±é€šï¼‰"""
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                return {}
        return {}
    
    def _initialize_poc_handlers(self) -> Dict[str, Any]:
        """Phase 6a: æ¦‚å¿µå®Ÿè¨¼ç”¨ã®æœ€å°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚»ãƒƒãƒˆ"""
        handlers = {}
        
        # åŸºæœ¬çš„ãªãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰é–‹å§‹ï¼ˆæ—¢å­˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«åˆã‚ã›ã¦ï¼‰
        try:
            # BasicFivePatternHandlerã¯å¼•æ•°ãªã—ã§åˆæœŸåŒ–
            handlers['basic_five_pattern'] = BasicFivePatternHandler()
            print("âœ… BasicFivePatternHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ BasicFivePatternHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # ModalHandlerã¯nlpã‚’å¼•æ•°ã«å–ã‚‹
            handlers['modal'] = ModalHandler(self.nlp)
            print("âœ… ModalHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ ModalHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # RelativeClauseHandlerã¯ç©ºè¾æ›¸ã‚’å¼•æ•°ã«å–ã‚‹
            handlers['relative_clause'] = RelativeClauseHandler({})
            print("âœ… RelativeClauseHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ RelativeClauseHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        print(f"âœ… POC ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–å®Œäº†: {len(handlers)}å€‹")
        return handlers

    def analyze_grammar_structure_v2(self, text: str) -> Dict[str, Any]:
        """
        æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹æ–‡æ³•è§£æ
        
        Returns:
            åˆ†æçµæœ + æ¯”è¼ƒç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        print(f"\nğŸ”¬ æ–°ã‚·ã‚¹ãƒ†ãƒ åˆ†æé–‹å§‹: '{text}'")
        
        # Step 1: å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰æƒ…å ±åé›†
        handler_reports = self._collect_all_handler_reports(text)
        
        # Step 2: ä¸­å¤®ã§ã®çµ±åˆåˆ¤æ–­
        integrated_analysis = self._integrate_handler_reports(handler_reports, text)
        
        # Step 3: å”åŠ›èª¿æ•´ï¼ˆå¿…è¦æ™‚ï¼‰
        if self._requires_collaboration(integrated_analysis):
            collaborative_result = self._coordinate_handlers(integrated_analysis, text)
            integrated_analysis = collaborative_result
        
        # Step 4: å“è³ªä¿è¨¼ãƒã‚§ãƒƒã‚¯
        validated_result = self._validate_final_result(integrated_analysis, text)
        
        # Step 5: æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›å½¢å¼ã«å¤‰æ›
        legacy_format_result = self._convert_to_legacy_format(validated_result)
        
        return {
            'v2_result': validated_result,
            'legacy_format': legacy_format_result,
            'analysis_metadata': {
                'system_version': 'v2',
                'handler_count': len(handler_reports),
                'confidence_score': validated_result.confidence_score,
                'processing_time': None  # å¾Œã§å®Ÿè£…
            }
        }
    
    def _collect_all_handler_reports(self, text: str) -> Dict[str, HandlerReport]:
        """å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ä¸¦è¡Œæƒ…å ±åé›†"""
        reports = {}
        
        for handler_name, handler in self.active_handlers.items():
            try:
                # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰æƒ…å ±ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ï¼ˆåˆ¤æ–­ã¯ã•ã›ãªã„ï¼‰
                report = self._get_handler_report(handler_name, handler, text)
                reports[handler_name] = report
                
                print(f"ğŸ“‹ {handler_name}: ä¿¡é ¼åº¦={report.confidence:.2f}, ãƒ‘ã‚¿ãƒ¼ãƒ³={report.detected_patterns}")
                
            except Exception as e:
                print(f"âš ï¸ {handler_name} ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                reports[handler_name] = HandlerReport(
                    handler_name=handler_name,
                    confidence=0.0,
                    detected_patterns=[],
                    processing_notes=[f"Error: {str(e)}"]
                )
        
        return reports
    
    def _get_handler_report(self, handler_name: str, handler: Any, text: str) -> HandlerReport:
        """å€‹åˆ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰æƒ…å ±ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        
        # æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®æƒ…å ±ã‚’æ–°å½¢å¼ã«å¤‰æ›
        if handler_name == 'basic_five_pattern':
            # BasicFivePatternHandlerã®å ´åˆ
            confidence = 0.8 if self._has_basic_structure(text) else 0.3
            patterns = ['five_pattern'] if confidence > 0.5 else []
            
        elif handler_name == 'modal':
            # ModalHandlerã®å ´åˆ
            modal_info = handler.detect_modal_structure(text)
            confidence = 0.9 if modal_info.get('has_modal', False) else 0.1
            patterns = ['modal'] if modal_info.get('has_modal', False) else []
            
        elif handler_name == 'relative_clause':
            # RelativeClauseHandlerã®å ´åˆ
            doc = self.nlp(text)
            has_relative = any(token.text.lower() in ['who', 'which', 'that', 'whose', 'whom'] 
                             for token in doc)
            confidence = 0.7 if has_relative else 0.2
            patterns = ['relative_clause'] if has_relative else []
            
        else:
            # æœªçŸ¥ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            confidence = 0.0
            patterns = []
        
        return HandlerReport(
            handler_name=handler_name,
            confidence=confidence,
            detected_patterns=patterns,
            metadata={'text_length': len(text)}
        )
    
    def _has_basic_structure(self, text: str) -> bool:
        """åŸºæœ¬æ§‹é€ ã®å­˜åœ¨ç¢ºèªï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        doc = self.nlp(text)
        has_verb = any(token.pos_ in ['VERB', 'AUX'] for token in doc)
        has_noun = any(token.pos_ in ['NOUN', 'PRON', 'PROPN'] for token in doc)
        return has_verb and has_noun
    
    def _integrate_handler_reports(self, reports: Dict[str, HandlerReport], text: str) -> IntegratedAnalysis:
        """ä¸­å¤®ã§ã®çµ±åˆåˆ¤æ–­"""
        
        # ä¿¡é ¼åº¦ã«åŸºã¥ã„ã¦ä¸»è¦æ–‡æ³•é …ç›®ã‚’æ±ºå®š
        valid_reports = {name: report for name, report in reports.items() 
                        if report.confidence > 0.5}
        
        if not valid_reports:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ
            if reports:
                best_report = max(reports.values(), key=lambda r: r.confidence)
                primary_grammar = best_report.handler_name
                confidence_score = best_report.confidence
            else:
                primary_grammar = 'unknown'
                confidence_score = 0.0
            secondary_grammars = []
        else:
            # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã‚’ä¸»è¦æ–‡æ³•ã«
            best_report = max(valid_reports.values(), key=lambda r: r.confidence)
            primary_grammar = best_report.handler_name
            confidence_score = best_report.confidence
            
            # æ®‹ã‚Šã‚’å‰¯æ¬¡æ–‡æ³•ã«
            secondary_grammars = [name for name, report in valid_reports.items() 
                                if name != primary_grammar]
        
        print(f"ğŸ¯ çµ±åˆåˆ¤æ–­: ä¸»è¦={primary_grammar} (ä¿¡é ¼åº¦={confidence_score:.2f}), å‰¯æ¬¡={secondary_grammars}")
        
        return IntegratedAnalysis(
            primary_grammar=primary_grammar,
            secondary_grammars=secondary_grammars,
            confidence_score=confidence_score,
            handler_reports=reports,
            cooperation_plan={},
            quality_checks={'basic_validation': True}
        )
    
    def _requires_collaboration(self, analysis: IntegratedAnalysis) -> bool:
        """å”åŠ›ãŒå¿…è¦ã‹ã©ã†ã‹ã®åˆ¤æ–­"""
        # Phase 6a: ç°¡æ˜“ç‰ˆï¼ˆå¾Œã§æ‹¡å¼µï¼‰
        return len(analysis.secondary_grammars) > 1
    
    def _coordinate_handlers(self, analysis: IntegratedAnalysis, text: str) -> IntegratedAnalysis:
        """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–“å”åŠ›ã®èª¿æ•´"""
        # Phase 6a: åŸºæœ¬å®Ÿè£…ï¼ˆå¾Œã§æ‹¡å¼µï¼‰
        print(f"ğŸ¤ å”åŠ›èª¿æ•´å®Ÿè¡Œ: {analysis.primary_grammar} + {analysis.secondary_grammars}")
        
        # å”åŠ›è¨ˆç”»ã‚’æ›´æ–°
        analysis.cooperation_plan = {
            'strategy': 'parallel_processing',
            'involved_handlers': [analysis.primary_grammar] + analysis.secondary_grammars,
            'coordination_notes': ['Phase 6a basic coordination']
        }
        
        return analysis
    
    def _validate_final_result(self, analysis: IntegratedAnalysis, text: str) -> IntegratedAnalysis:
        """æœ€çµ‚å“è³ªä¿è¨¼"""
        
        # åŸºæœ¬çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
        quality_checks = {
            'has_primary_grammar': bool(analysis.primary_grammar),
            'confidence_acceptable': analysis.confidence_score > 0.3,
            'no_critical_conflicts': True,  # å¾Œã§å®Ÿè£…
            'text_coverage_adequate': True   # å¾Œã§å®Ÿè£…
        }
        
        analysis.quality_checks = quality_checks
        
        all_passed = all(quality_checks.values())
        print(f"âœ… å“è³ªä¿è¨¼: {'åˆæ ¼' if all_passed else 'è¦æ³¨æ„'} - {quality_checks}")
        
        return analysis
    
    def _convert_to_legacy_format(self, analysis: IntegratedAnalysis) -> List[str]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›å½¢å¼ã«å¤‰æ›"""
        result = []
        
        if analysis.primary_grammar and analysis.primary_grammar != 'unknown':
            result.append(analysis.primary_grammar)
        
        result.extend(analysis.secondary_grammars)
        
        return result
    
    def compare_with_legacy_system(self, text: str, legacy_controller) -> Dict[str, Any]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®æ¯”è¼ƒåˆ†æ"""
        
        # æ–°ã‚·ã‚¹ãƒ†ãƒ ã§åˆ†æ
        v2_result = self.analyze_grammar_structure_v2(text)
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§åˆ†æ
        try:
            legacy_result = legacy_controller.analyze_grammar_structure(text)
        except Exception as e:
            legacy_result = []
            print(f"âš ï¸ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ¯”è¼ƒåˆ†æ
        comparison = {
            'text': text,
            'v2_system': {
                'result': v2_result['legacy_format'],
                'confidence': v2_result['v2_result'].confidence_score,
                'handlers_used': len(v2_result['v2_result'].handler_reports)
            },
            'legacy_system': {
                'result': legacy_result,
                'confidence': None,  # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ä¿¡é ¼åº¦ãªã—
                'handlers_used': None
            },
            'differences': {
                'result_match': v2_result['legacy_format'] == legacy_result,
                'v2_extra': set(v2_result['legacy_format']) - set(legacy_result),
                'legacy_extra': set(legacy_result) - set(v2_result['legacy_format'])
            }
        }
        
        print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒçµæœ:")
        print(f"   æ–°ã‚·ã‚¹ãƒ†ãƒ : {v2_result['legacy_format']}")
        print(f"   æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ : {legacy_result}")
        print(f"   ä¸€è‡´: {comparison['differences']['result_match']}")
        
        return comparison


def test_new_system():
    """æ–°ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # æ–°ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    controller_v2 = CentralControllerV2()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        "I can speak English.",
        "The book that I read was interesting.",
        "What did you see?",
        "I wish I knew the answer."
    ]
    
    for text in test_cases:
        print(f"\n--- ãƒ†ã‚¹ãƒˆ: '{text}' ---")
        result = controller_v2.analyze_grammar_structure_v2(text)
        print(f"çµæœ: {result['legacy_format']}")
        print(f"ä¿¡é ¼åº¦: {result['v2_result'].confidence_score:.2f}")


if __name__ == "__main__":
    test_new_system()
