"""
æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  (Phase 6a)
çœŸã®ä¸­å¤®ç®¡ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚‹æ–‡æ³•è§£æã‚·ã‚¹ãƒ†ãƒ 

è¨­è¨ˆåŸå‰‡:
1. ç›£ç£çš„ç«‹å ´: CentralControllerãŒå…¨ã¦ã‚’æŠŠæ¡ãƒ»çµ±åˆ¶
2. æƒ…å ±åé›†: å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ä¸¦è¡Œã—ã¦æƒ…å ±åé›†
3. çµ±åˆåˆ¤æ–­: ä¸­å¤®ã§ã®æœ€çµ‚åˆ¤æ–­ã«ã‚ˆã‚‹å‡¦ç†æ±ºå®š
4. å”åŠ›èª¿æ•´: å¿…è¦æ™‚ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–“å”åŠ›ã®èª¿æ•´
5. å“è³ªä¿è¨¼: ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ»æ¬ è½ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯
"""

import spacy
import json
import os
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ®µéšçš„ç§»è¡Œã®ãŸã‚ï¼‰
from basic_five_pattern_handler import BasicFivePatternHandler
from modal_handler import ModalHandler
from omitted_relative_pronoun_handler import OmittedRelativePronounHandler
from adverb_handler import AdverbHandler
from passive_voice_handler import PassiveVoiceHandler


class AnalysisConfidence(Enum):
    """åˆ†æä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«"""
    HIGH = "high"
    MEDIUM = "medium" 
    LOW = "low"
    UNKNOWN = "unknown"


@dataclass
class HandlerReport:
    """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã®æƒ…å ±ãƒ¬ãƒãƒ¼ãƒˆ"""
    handler_name: str
    confidence: float  # 0.0-1.0
    detected_patterns: List[str]
    boundary_info: Optional[Dict[str, Any]] = None
    cooperation_needs: List[str] = None
    metadata: Dict[str, Any] = None
    processing_notes: List[str] = None

    def __post_init__(self):
        if self.cooperation_needs is None:
            self.cooperation_needs = []
        if self.metadata is None:
            self.metadata = {}
        if self.processing_notes is None:
            self.processing_notes = []


@dataclass 
class IntegratedAnalysis:
    """çµ±åˆåˆ†æçµæœ"""
    primary_grammar: str
    secondary_grammars: List[str]
    confidence_score: float
    handler_reports: Dict[str, HandlerReport]
    cooperation_plan: Dict[str, Any]
    quality_checks: Dict[str, bool]


class CentralControllerV2:
    """
    æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - çœŸã®ä¸­å¤®ç®¡ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ä¸¦è¡Œé‹ç”¨ã‚’å‰æã¨ã—ãŸæ®µéšçš„ç§»è¡Œã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, config_file: str = 'central_controller_config.json'):
        """åˆæœŸåŒ–: æ–°ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®è¨­å®š"""
        self.nlp = spacy.load('en_core_web_sm')
        self.config = self._load_config(config_file)
        
        # Phase 6a: æœ€å°ã‚»ãƒƒãƒˆã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã§é–‹å§‹ï¼ˆæ¦‚å¿µå®Ÿè¨¼ï¼‰
        self.active_handlers = self._initialize_poc_handlers()
        
        # çµ±åˆãƒ«ãƒ¼ãƒ«è¨­å®š
        self.integration_rules = self.config.get('central_management', {})
        
        print("ğŸ¯ Central Controller V2 åˆæœŸåŒ–å®Œäº† - æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
        print(f"ğŸ“Š ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æ•°: {len(self.active_handlers)}")
        
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨å…±é€šï¼‰"""
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                return {}
        return {}
    
    def _initialize_poc_handlers(self) -> Dict[str, Any]:
        """Phase 6a: æ¦‚å¿µå®Ÿè¨¼ç”¨ã®æœ€å°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚»ãƒƒãƒˆ"""
        handlers = {}
        
        # åŸºæœ¬çš„ãªãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰é–‹å§‹ï¼ˆæ—¢å­˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«åˆã‚ã›ã¦ï¼‰
        try:
            # BasicFivePatternHandlerã¯å¼•æ•°ãªã—ã§åˆæœŸåŒ–
            handlers['basic_five_pattern'] = BasicFivePatternHandler()
            print("âœ… BasicFivePatternHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ BasicFivePatternHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # ModalHandlerã¯nlpã‚’å¼•æ•°ã«å–ã‚‹
            handlers['modal'] = ModalHandler(self.nlp)
            print("âœ… ModalHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ ModalHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # RelativeClauseHandlerã¯ç©ºè¾æ›¸ã‚’å¼•æ•°ã«å–ã‚‹
            handlers['relative_clause'] = OmittedRelativePronounHandler({})
            print("âœ… RelativeClauseHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ RelativeClauseHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # AdverbHandlerã¯å¼•æ•°ãªã—ã§åˆæœŸåŒ–
            handlers['adverb'] = AdverbHandler()
            print("âœ… AdverbHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ AdverbHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        try:
            # PassiveVoiceHandlerã‚’è¿½åŠ 
            handlers['passive_voice'] = PassiveVoiceHandler()
            print("âœ… PassiveVoiceHandler åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ PassiveVoiceHandler åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        print(f"âœ… POC ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–å®Œäº†: {len(handlers)}å€‹")
        return handlers

    def process_sentence(self, sentence):
        """æ–‡ã®ç·åˆåˆ†æã¨åˆ†è§£ã‚’å®Ÿè¡Œï¼ˆunified_test.pyäº’æ›ï¼‰"""
        try:
            start_time = time.time()
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: ä¸¦è¡Œæƒ…å ±åé›†
            handler_reports = self._collect_handler_reports(sentence)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: çµ±åˆåˆ¤æ–­
            primary_handler, cooperation_plan = self._make_integration_decision(handler_reports)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£å®Ÿè¡Œ
            slots_result = self._execute_slot_decomposition(sentence, primary_handler, handler_reports)
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: å“è³ªä¿è¨¼
            quality_result = self._quality_assurance(handler_reports, primary_handler)
            
            processing_time = time.time() - start_time
            
            return {
                'main_slots': slots_result.get('main_slots', {}),
                'sub_slots': slots_result.get('sub_slots', {}),
                'detected_grammar': cooperation_plan.get('active_handlers', []),
                'confidence': max([handler_reports[h]['confidence'] for h in cooperation_plan.get('active_handlers', [])], default=0.0),
                'v2_metadata': {
                    'handler_reports': len(handler_reports),
                    'cooperation_plan': cooperation_plan,
                    'quality_checks': quality_result,
                    'processing_time': processing_time
                }
            }
            
        except Exception as e:
            print(f"âŒ CentralControllerV2ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'main_slots': {},
                'sub_slots': {},
                'detected_grammar': [],
                'confidence': 0.0,
                'v2_metadata': {
                    'error': str(e)
                }
            }
    
    def _collect_handler_reports(self, sentence):
        """ä¸¦è¡Œæƒ…å ±åé›†ï¼ˆæ–°ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        reports = {}
        
        for handler_name, handler in self.active_handlers.items():
            try:
                print(f"ğŸ” {handler_name} ãƒãƒ³ãƒ‰ãƒ©ãƒ¼å‡¦ç†é–‹å§‹")
                report = self._get_handler_report(handler_name, handler, sentence)
                print(f"ğŸ” {handler_name} ãƒ¬ãƒãƒ¼ãƒˆå–å¾—æˆåŠŸ: {report}")
                
                # HandlerReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹è¾æ›¸ã‹ãƒã‚§ãƒƒã‚¯
                if hasattr(report, 'confidence'):
                    # HandlerReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                    reports[handler_name] = {
                        'confidence': report.confidence,
                        'patterns': report.detected_patterns,
                        'metadata': report.metadata
                    }
                else:
                    # è¾æ›¸ã®å ´åˆ
                    reports[handler_name] = {
                        'confidence': report['confidence'],
                        'patterns': report['patterns'],
                        'metadata': report['metadata']
                    }
            except Exception as e:
                print(f"âš ï¸ {handler_name} ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()
                reports[handler_name] = {
                    'confidence': 0.0,
                    'patterns': [],
                    'metadata': {'error': str(e)}
                }
        
        return reports
    
    def _get_handler_report(self, handler_name, handler, sentence):
        """å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        if handler_name == 'basic_five_pattern':
            try:
                result = handler.process(sentence)
                if result and result.get('success', False):
                    confidence = len(result.get('slots', {})) * 0.3  # ã‚¹ãƒ­ãƒƒãƒˆæ•°ã«åŸºã¥ãä¿¡é ¼åº¦
                    patterns = ['basic_five_pattern']
                else:
                    confidence = 0.0
                    patterns = []
                
                return {
                    'confidence': confidence,
                    'patterns': patterns,
                    'metadata': {'result': result}
                }
            except Exception as e:
                return {
                    'confidence': 0.0,
                    'patterns': [],
                    'metadata': {'error': str(e)}
                }
        
        elif handler_name == 'adverb':
            try:
                result = handler.process(sentence)
                if result and result.get('success', False):
                    # å‰¯è©ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ä¿¡é ¼åº¦
                    modifiers = result.get('modifiers', {})
                    modifier_count = len(modifiers)
                    if modifier_count > 0:
                        # å‰¯è©ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã¯é«˜ã„ä¿¡é ¼åº¦ã‚’è¨­å®š
                        confidence = 0.8  # å‰¯è©æ¤œå‡ºæ™‚ã¯æœ€é«˜å„ªå…ˆåº¦
                        patterns = ['adverb_modifier']
                    else:
                        confidence = 0.0
                        patterns = []
                else:
                    confidence = 0.0
                    patterns = []
                
                return {
                    'confidence': confidence,
                    'patterns': patterns,
                    'metadata': {'result': result}
                }
            except Exception as e:
                return {
                    'confidence': 0.0,
                    'patterns': [],
                    'metadata': {'error': str(e)}
                }
        
        elif handler_name == 'modal':
            try:
                # ModalHandlerã®å ´åˆã¯ç°¡æ˜“è©•ä¾¡
                # ç¾åœ¨ã¯POCãªã®ã§åŸºæœ¬çš„ãªè©•ä¾¡
                return {
                    'confidence': 0.1,  # ä½ã„åŸºæº–ä¿¡é ¼åº¦
                    'patterns': [],
                    'metadata': {}
                }
            except Exception as e:
                return {
                    'confidence': 0.0,
                    'patterns': [],
                    'metadata': {'error': str(e)}
                }
        
        elif handler_name == 'passive_voice':
            try:
                result = handler.process(sentence)
                if result and result.get('is_passive', False):
                    # å—å‹•æ…‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ä¿¡é ¼åº¦
                    confidence = 0.9  # å—å‹•æ…‹æ¤œå‡ºæ™‚ã¯é«˜ã„ä¿¡é ¼åº¦
                    patterns = ['passive_voice']
                    
                    # æˆåŠŸãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ã—ã¦Adapterãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨
                    result['success'] = True
                else:
                    confidence = 0.0
                    patterns = []
                
                return {
                    'confidence': confidence,
                    'patterns': patterns,
                    'metadata': {'result': result}
                }
            except Exception as e:
                return {
                    'confidence': 0.0,
                    'patterns': [],
                    'metadata': {'error': str(e)}
                }
        
        # ãã®ä»–ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚‚ä½ã„åŸºæº–ä¿¡é ¼åº¦
        return {
            'confidence': 0.1,
            'patterns': [],
            'metadata': {}
        }
    
    def _make_integration_decision(self, handler_reports):
        """çµ±åˆåˆ¤æ–­ï¼ˆæ–°ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰ - å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼çµæœã®çµ±åˆå‡¦ç†"""
        if not handler_reports:
            return None, {}
        
        # ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ : å„ªå…ˆåº¦ã§ã¯ãªãã€å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®çµæœã‚’çµ±åˆ
        active_handlers = [h for h, report in handler_reports.items() 
                          if report['confidence'] > 0.0]
        
        cooperation_plan = {
            'strategy': 'comprehensive_integration',
            'active_handlers': active_handlers,
            'integration_mode': 'merge_all_results'
        }
        
        # çµ±åˆå‡¦ç†ã®ãŸã‚ã€ç‰¹å®šã®ã€Œprimaryã€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯é¸æŠã—ãªã„
        return 'integrated', cooperation_plan
    
    def _execute_slot_decomposition(self, sentence, primary_handler, handler_reports):
        """ã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£å®Ÿè¡Œï¼ˆRephraseãƒ«ãƒ¼ãƒ«æº–æ‹ ï¼‰ - å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼çµæœçµ±åˆ"""
        if primary_handler != 'integrated' or not handler_reports:
            return {'main_slots': {}, 'sub_slots': {}}
        
        # ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ : å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®çµæœã‚’çµ±åˆ
        integrated_main_slots = {}
        integrated_sub_slots = {}
        
        # ç‰¹æ®Šãƒ«ãƒ¼ãƒ«: å—å‹•æ…‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®å„ªå…ˆçµ±åˆ
        passive_detected = False
        for handler_name in handler_reports:
            if handler_name == 'passive_voice' and handler_reports[handler_name]['confidence'] > 0.0:
                passive_detected = True
                break
        
        # ä¿®é£¾èªç«¶åˆè§£æ±º: AdverbHandlerãŒæ¤œå‡ºã—ãŸä¿®é£¾èªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åé›†
        adverb_modifiers = {}
        if 'adverb' in handler_reports and handler_reports['adverb']['confidence'] > 0.0:
            adverb_handler = self.active_handlers['adverb']
            adverb_result = self._get_handler_slot_result('adverb', adverb_handler, sentence)
            if adverb_result:
                adverb_modifiers = adverb_result.get('main_slots', {})
        
        for handler_name, handler in self.active_handlers.items():
            if handler_name not in handler_reports:
                continue
                
            report = handler_reports[handler_name]
            if report['confidence'] <= 0.0:
                continue
            
            # å—å‹•æ…‹æ¤œå‡ºæ™‚ã¯ã€BasicFivePatternHandlerã®SVCèª¤èªè­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if passive_detected and handler_name == 'basic_five_pattern':
                handler_result = self._get_handler_slot_result(handler_name, handler, sentence)
                if handler_result:
                    handler_main = handler_result.get('main_slots', {})
                    # SVCèª¤èªè­˜ã®å ´åˆã€C1ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦Sã¨Vã®ã¿çµ±åˆ
                    if 'C1' in handler_main and 'V' in handler_main:
                        # å—å‹•æ…‹ã®å ´åˆã€C1ã¯èª¤èªè­˜ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
                        filtered_main = {k: v for k, v in handler_main.items() if k != 'C1'}
                        integrated_main_slots.update(filtered_main)
                        print(f"ğŸ” {handler_name}çµæœçµ±åˆï¼ˆå—å‹•æ…‹å„ªå…ˆï¼‰: main={filtered_main}, sub={{}}")
                    else:
                        integrated_main_slots.update(handler_main)
                        print(f"ğŸ” {handler_name}çµæœçµ±åˆ: main={handler_main}, sub={{}}")
                continue
            
            # ä¿®é£¾èªç«¶åˆè§£æ±º: BasicFivePatternã¨Adverbã®ç«¶åˆãƒã‚§ãƒƒã‚¯
            if handler_name == 'basic_five_pattern' and adverb_modifiers:
                handler_result = self._get_handler_slot_result(handler_name, handler, sentence)
                if handler_result:
                    handler_main = handler_result.get('main_slots', {})
                    handler_sub = handler_result.get('sub_slots', {})
                    
                    # ä¿®é£¾èªã¨ã®ç«¶åˆã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦è§£æ±º
                    filtered_main = self._resolve_modifier_conflicts(handler_main, adverb_modifiers, sentence)
                    
                    integrated_main_slots.update(filtered_main)
                    integrated_sub_slots.update(handler_sub)
                    
                    print(f"ğŸ” {handler_name}çµæœçµ±åˆï¼ˆä¿®é£¾èªç«¶åˆè§£æ±ºå¾Œï¼‰: main={filtered_main}, sub={handler_sub}")
                continue
            
            try:
                # å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®çµæœã‚’å–å¾—ã—ã¦çµ±åˆ
                handler_result = self._get_handler_slot_result(handler_name, handler, sentence)
                
                if handler_result:
                    # main_slotsã¨sub_slotsã‚’çµ±åˆ
                    handler_main = handler_result.get('main_slots', {})
                    handler_sub = handler_result.get('sub_slots', {})
                    
                    # ã‚¹ãƒ­ãƒƒãƒˆã®çµ±åˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
                    integrated_main_slots.update(handler_main)
                    integrated_sub_slots.update(handler_sub)
                    
                    print(f"ğŸ” {handler_name}çµæœçµ±åˆ: main={handler_main}, sub={handler_sub}")
                
            except Exception as e:
                print(f"âš ï¸ {handler_name} çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"ğŸ¯ çµ±åˆçµæœ: main_slots={integrated_main_slots}, sub_slots={integrated_sub_slots}")
        
        return {
            'main_slots': integrated_main_slots,
            'sub_slots': integrated_sub_slots
        }
    
    def _get_handler_slot_result(self, handler_name, handler, sentence):
        """å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã‚¹ãƒ­ãƒƒãƒˆçµæœã‚’å–å¾—"""
        try:
            if handler_name == 'basic_five_pattern':
                result = handler.process(sentence)
                if result and result.get('success', False):
                    all_slots = result.get('slots', {})
                    main_slots = {}
                    sub_slots = {}
                    
                    for key, value in all_slots.items():
                        if key.startswith('sub-'):
                            sub_slots[key] = value
                        else:
                            main_slots[key] = value
                    
                    return {'main_slots': main_slots, 'sub_slots': sub_slots}
                    
            elif handler_name == 'adverb':
                result = handler.process(sentence)
                if result and result.get('success', False):
                    all_slots = result.get('modifier_slots', {})
                    main_slots = {}
                    sub_slots = {}
                    
                    for key, value in all_slots.items():
                        if key.startswith('sub-'):
                            sub_slots[key] = value
                        else:
                            main_slots[key] = value
                    
                    return {'main_slots': main_slots, 'sub_slots': sub_slots}
            
            elif handler_name == 'modal':
                # ç¾åœ¨ã¯POCãªã®ã§åŸºæœ¬å®Ÿè£…
                return {'main_slots': {}, 'sub_slots': {}}
            
            elif handler_name == 'passive_voice':
                result = handler.process(sentence)
                if result and result.get('is_passive', False):
                    # å—å‹•æ…‹æ§‹é€ ã‹ã‚‰ã‚¹ãƒ­ãƒƒãƒˆæƒ…å ±ã‚’æ§‹ç¯‰
                    main_slots = {}
                    sub_slots = {}
                    
                    # ä¸»èªã‚’æŠ½å‡ºï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æï¼‰
                    doc = handler.nlp(sentence)
                    for token in doc:
                        if token.dep_ == 'nsubjpass':  # å—å‹•æ…‹ã®ä¸»èª
                            # è¨˜äº‹è©ã‚‚å«ã‚€ä¸»èªã‚’æŠ½å‡º
                            if token.children:
                                # å† è©ã‚’å«ã‚€ä¸»èªæ§‹ç¯‰
                                subject_tokens = []
                                for child in token.children:
                                    if child.dep_ == 'det':
                                        subject_tokens.append(child.text)
                                subject_tokens.append(token.text)
                                main_slots['S'] = ' '.join(subject_tokens)
                            else:
                                main_slots['S'] = token.text
                            break
                    
                    # åŠ©å‹•è©ã¨å‹•è©ã‚’è¨­å®š
                    main_slots['Aux'] = result.get('aux', '')
                    main_slots['V'] = result.get('verb', '')
                    
                    return {'main_slots': main_slots, 'sub_slots': sub_slots}
                    
                return {'main_slots': {}, 'sub_slots': {}}
            
            # ãã®ä»–ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            return {'main_slots': {}, 'sub_slots': {}}
            
        except Exception as e:
            print(f"âš ï¸ {handler_name} ã‚¹ãƒ­ãƒƒãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'main_slots': {}, 'sub_slots': {}}
    
    def _extract_sub_slots_from_legacy_result(self, legacy_result):
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®çµæœã‹ã‚‰ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã‚’æŠ½å‡º"""
        sub_slots = {}
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®slotsã‹ã‚‰ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆï¼ˆsub-ã§å§‹ã¾ã‚‹ï¼‰ã‚’æŠ½å‡º
        all_slots = legacy_result.get('slots', {})
        for key, value in all_slots.items():
            if key.startswith('sub-') and value:  # sub-ã§å§‹ã¾ã‚‹éç©ºã‚¹ãƒ­ãƒƒãƒˆ
                sub_slots[key] = value
        
        return sub_slots
    
    def _resolve_modifier_conflicts(self, basic_slots, adverb_modifiers, sentence):
        """BasicFivePatternã¨Adverbã®ä¿®é£¾èªç«¶åˆã‚’è§£æ±º"""
        filtered_slots = basic_slots.copy()
        
        # å‰ç½®è©å¥ä¿®é£¾èªï¼ˆM2, M3ãªã©ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
        for modifier_key, modifier_value in adverb_modifiers.items():
            if modifier_key.startswith('M') and modifier_value:
                # å‰ç½®è©å¥ã‹ã‚‰åè©éƒ¨åˆ†ã‚’æŠ½å‡º (ä¾‹: "for exams" â†’ "exams")
                modifier_words = modifier_value.split()
                if len(modifier_words) >= 2:  # å‰ç½®è© + åè©ã®å½¢
                    noun_part = modifier_words[-1]  # æœ€å¾Œã®å˜èªï¼ˆé€šå¸¸åè©ï¼‰
                    
                    # BasicFivePatternã®ç›®çš„èªã‚¹ãƒ­ãƒƒãƒˆã¨ç«¶åˆãƒã‚§ãƒƒã‚¯
                    for basic_key, basic_value in list(filtered_slots.items()):
                        if basic_key in ['O1', 'O2', 'C1', 'C2'] and basic_value:
                            # ç›®çš„èª/è£œèªãŒä¿®é£¾èªå†…ã®åè©ã¨ä¸€è‡´ã™ã‚‹å ´åˆ
                            if basic_value.lower() == noun_part.lower():
                                print(f"ğŸ”§ ä¿®é£¾èªç«¶åˆè§£æ±º: {basic_key}='{basic_value}' ã‚’å‰Šé™¤ï¼ˆ{modifier_key}='{modifier_value}' ã¨é‡è¤‡ï¼‰")
                                del filtered_slots[basic_key]
                                
        return filtered_slots
    
    def _basic_slot_decomposition(self, sentence):
        """åŸºæœ¬çš„ãªã‚¹ãƒ­ãƒƒãƒˆåˆ†è§£ï¼ˆRephraseãƒ«ãƒ¼ãƒ«ç°¡æ˜“ç‰ˆï¼‰"""
        # spaCyã§åŸºæœ¬çš„ãªè§£æ
        doc = self.nlp(sentence)
        
        main_slots = {}
        sub_slots = {}
        
        # ä¸»èªæ¤œå‡º
        subject = None
        verb = None
        objects = []
        modifiers = []
        
        for token in doc:
            if token.dep_ == 'nsubj':  # ä¸»èª
                subject = token.text
            elif token.dep_ == 'ROOT' and token.pos_ in ['VERB', 'AUX']:  # å‹•è©
                verb = token.text
            elif token.dep_ in ['dobj', 'iobj']:  # ç›®çš„èª
                objects.append(token.text)
            elif token.dep_ in ['acomp', 'attr']:  # è£œèª
                if 'C1' not in main_slots:
                    main_slots['C1'] = token.text
            elif token.dep_ == 'advmod':  # å‰¯è©
                modifiers.append(token.text)
        
        # Rephraseãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦é…ç½®
        if subject:
            main_slots['S'] = subject
        if verb:
            main_slots['V'] = verb
        
        # ç›®çš„èªé…ç½®
        if objects:
            if len(objects) >= 1:
                main_slots['O1'] = objects[0]
            if len(objects) >= 2:
                main_slots['O2'] = objects[1]
        
        # ä¿®é£¾èªé…ç½®ï¼ˆå€‹æ•°ãƒ™ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ«ï¼‰
        if modifiers:
            if len(modifiers) == 1:
                main_slots['M2'] = modifiers[0]
            elif len(modifiers) == 2:
                main_slots['M1'] = modifiers[0]
                main_slots['M3'] = modifiers[1]
            elif len(modifiers) >= 3:
                main_slots['M1'] = modifiers[0]
                main_slots['M2'] = modifiers[1]
                main_slots['M3'] = modifiers[2]
        
        return {
            'main_slots': main_slots,
            'sub_slots': sub_slots
        }
    
    def _quality_assurance(self, handler_reports, primary_handler):
        """å“è³ªä¿è¨¼ãƒã‚§ãƒƒã‚¯"""
        active_handlers = [h for h, report in handler_reports.items() 
                          if report['confidence'] > 0.0]
        
        max_confidence = max([report['confidence'] for report in handler_reports.values()], default=0.0)
        
        return {
            'has_active_handlers': len(active_handlers) > 0,
            'confidence_acceptable': max_confidence > 0.3,
            'no_critical_conflicts': True,
            'text_coverage_adequate': True,
            'integrated_processing': primary_handler == 'integrated'
        }

    def analyze_grammar_structure_v2(self, text: str) -> Dict[str, Any]:
        """
        æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹æ–‡æ³•è§£æï¼ˆunified_test.pyäº’æ›ï¼‰
        
        Returns:
            process_sentenceã¨åŒã˜å½¢å¼ã®çµæœ
        """
        print(f"\nğŸ”¬ æ–°ã‚·ã‚¹ãƒ†ãƒ åˆ†æé–‹å§‹: '{text}'")
        
        # process_sentenceãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãã®ã¾ã¾å‘¼ã³å‡ºã—
        return self.process_sentence(text)
    
    def _collect_all_handler_reports(self, text: str) -> Dict[str, HandlerReport]:
        """å…¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ä¸¦è¡Œæƒ…å ±åé›†"""
        reports = {}
        
        for handler_name, handler in self.active_handlers.items():
            try:
                # ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰æƒ…å ±ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ï¼ˆåˆ¤æ–­ã¯ã•ã›ãªã„ï¼‰
                report = self._get_handler_report(handler_name, handler, text)
                reports[handler_name] = report
                
                print(f"ğŸ“‹ {handler_name}: ä¿¡é ¼åº¦={report.confidence:.2f}, ãƒ‘ã‚¿ãƒ¼ãƒ³={report.detected_patterns}")
                
            except Exception as e:
                print(f"âš ï¸ {handler_name} ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                reports[handler_name] = HandlerReport(
                    handler_name=handler_name,
                    confidence=0.0,
                    detected_patterns=[],
                    processing_notes=[f"Error: {str(e)}"]
                )
        
        return reports
    
    def _has_basic_structure(self, text: str) -> bool:
        """åŸºæœ¬æ§‹é€ ã®å­˜åœ¨ç¢ºèªï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        doc = self.nlp(text)
        has_verb = any(token.pos_ in ['VERB', 'AUX'] for token in doc)
        has_noun = any(token.pos_ in ['NOUN', 'PRON', 'PROPN'] for token in doc)
        return has_verb and has_noun
    
    def _integrate_handler_reports(self, reports: Dict[str, HandlerReport], text: str) -> IntegratedAnalysis:
        """ä¸­å¤®ã§ã®çµ±åˆåˆ¤æ–­"""
        
        # ä¿¡é ¼åº¦ã«åŸºã¥ã„ã¦ä¸»è¦æ–‡æ³•é …ç›®ã‚’æ±ºå®š
        valid_reports = {name: report for name, report in reports.items() 
                        if report.confidence > 0.5}
        
        if not valid_reports:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã‚’é¸æŠ
            if reports:
                best_report = max(reports.values(), key=lambda r: r.confidence)
                primary_grammar = best_report.handler_name
                confidence_score = best_report.confidence
            else:
                primary_grammar = 'unknown'
                confidence_score = 0.0
            secondary_grammars = []
        else:
            # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã‚’ä¸»è¦æ–‡æ³•ã«
            best_report = max(valid_reports.values(), key=lambda r: r.confidence)
            primary_grammar = best_report.handler_name
            confidence_score = best_report.confidence
            
            # æ®‹ã‚Šã‚’å‰¯æ¬¡æ–‡æ³•ã«
            secondary_grammars = [name for name, report in valid_reports.items() 
                                if name != primary_grammar]
        
        print(f"ğŸ¯ çµ±åˆåˆ¤æ–­: ä¸»è¦={primary_grammar} (ä¿¡é ¼åº¦={confidence_score:.2f}), å‰¯æ¬¡={secondary_grammars}")
        
        return IntegratedAnalysis(
            primary_grammar=primary_grammar,
            secondary_grammars=secondary_grammars,
            confidence_score=confidence_score,
            handler_reports=reports,
            cooperation_plan={},
            quality_checks={'basic_validation': True}
        )
    
    def _requires_collaboration(self, analysis: IntegratedAnalysis) -> bool:
        """å”åŠ›ãŒå¿…è¦ã‹ã©ã†ã‹ã®åˆ¤æ–­"""
        # Phase 6a: ç°¡æ˜“ç‰ˆï¼ˆå¾Œã§æ‹¡å¼µï¼‰
        return len(analysis.secondary_grammars) > 1
    
    def _coordinate_handlers(self, analysis: IntegratedAnalysis, text: str) -> IntegratedAnalysis:
        """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–“å”åŠ›ã®èª¿æ•´"""
        # Phase 6a: åŸºæœ¬å®Ÿè£…ï¼ˆå¾Œã§æ‹¡å¼µï¼‰
        print(f"ğŸ¤ å”åŠ›èª¿æ•´å®Ÿè¡Œ: {analysis.primary_grammar} + {analysis.secondary_grammars}")
        
        # å”åŠ›è¨ˆç”»ã‚’æ›´æ–°
        analysis.cooperation_plan = {
            'strategy': 'parallel_processing',
            'involved_handlers': [analysis.primary_grammar] + analysis.secondary_grammars,
            'coordination_notes': ['Phase 6a basic coordination']
        }
        
        return analysis
    
    def _validate_final_result(self, analysis: IntegratedAnalysis, text: str) -> IntegratedAnalysis:
        """æœ€çµ‚å“è³ªä¿è¨¼"""
        
        # åŸºæœ¬çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
        quality_checks = {
            'has_primary_grammar': bool(analysis.primary_grammar),
            'confidence_acceptable': analysis.confidence_score > 0.3,
            'no_critical_conflicts': True,  # å¾Œã§å®Ÿè£…
            'text_coverage_adequate': True   # å¾Œã§å®Ÿè£…
        }
        
        analysis.quality_checks = quality_checks
        
        all_passed = all(quality_checks.values())
        print(f"âœ… å“è³ªä¿è¨¼: {'åˆæ ¼' if all_passed else 'è¦æ³¨æ„'} - {quality_checks}")
        
        return analysis
    
    def _convert_to_legacy_format(self, analysis: IntegratedAnalysis) -> List[str]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›å½¢å¼ã«å¤‰æ›"""
        result = []
        
        if analysis.primary_grammar and analysis.primary_grammar != 'unknown':
            result.append(analysis.primary_grammar)
        
        result.extend(analysis.secondary_grammars)
        
        return result
    
    def compare_with_legacy_system(self, text: str, legacy_controller) -> Dict[str, Any]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®æ¯”è¼ƒåˆ†æ"""
        
        # æ–°ã‚·ã‚¹ãƒ†ãƒ ã§åˆ†æ
        v2_result = self.analyze_grammar_structure_v2(text)
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§åˆ†æ
        try:
            legacy_result = legacy_controller.analyze_grammar_structure(text)
        except Exception as e:
            legacy_result = []
            print(f"âš ï¸ æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ¯”è¼ƒåˆ†æ
        comparison = {
            'text': text,
            'v2_system': {
                'result': v2_result['legacy_format'],
                'confidence': v2_result['v2_result'].confidence_score,
                'handlers_used': len(v2_result['v2_result'].handler_reports)
            },
            'legacy_system': {
                'result': legacy_result,
                'confidence': None,  # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ä¿¡é ¼åº¦ãªã—
                'handlers_used': None
            },
            'differences': {
                'result_match': v2_result['legacy_format'] == legacy_result,
                'v2_extra': set(v2_result['legacy_format']) - set(legacy_result),
                'legacy_extra': set(legacy_result) - set(v2_result['legacy_format'])
            }
        }
        
        print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒçµæœ:")
        print(f"   æ–°ã‚·ã‚¹ãƒ†ãƒ : {v2_result['legacy_format']}")
        print(f"   æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ : {legacy_result}")
        print(f"   ä¸€è‡´: {comparison['differences']['result_match']}")
        
        return comparison


def test_new_system():
    """æ–°ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª æ–°ä¸­å¤®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # æ–°ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    controller_v2 = CentralControllerV2()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        "I can speak English.",
        "The book that I read was interesting.",
        "What did you see?",
        "I wish I knew the answer."
    ]
    
    for text in test_cases:
        print(f"\n--- ãƒ†ã‚¹ãƒˆ: '{text}' ---")
        result = controller_v2.analyze_grammar_structure_v2(text)
        print(f"çµæœ: {result['legacy_format']}")
        print(f"ä¿¡é ¼åº¦: {result['v2_result'].confidence_score:.2f}")


if __name__ == "__main__":
    test_new_system()
