#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
InfinitiveHandler: ä¸å®šè©å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
toä¸å®šè©ã®åè©çš„ãƒ»å½¢å®¹è©çš„ãƒ»å‰¯è©çš„ç”¨æ³•ã®å°‚é–€åˆ†è§£
å°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼ˆå“è©åˆ†æ + ä¾å­˜é–¢ä¿‚ï¼‰+ äººé–“çš„            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: xcomp (complement) + aux=to
            if token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'xcomp_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… xcompä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
                        
                        # too...toæ§‹æ–‡ã®ç‰¹åˆ¥åˆ¤å®š
                        if self._is_too_to_pattern(doc, token):
                            infinitive_info['infinitive_tokens'][-1]['pattern'] = 'too_to_pattern'
                            print(f"   ğŸ¯ too...toæ§‹æ–‡æ¤œå‡º: '{child.text} {token.text}'")
                        # enough...toæ§‹æ–‡ã®ç‰¹åˆ¥åˆ¤å®š  
                        elif self._is_enough_to_pattern(doc, token):
                            infinitive_info['infinitive_tokens'][-1]['pattern'] = 'enough_to_pattern'
                            print(f"   ğŸ¯ enough...toæ§‹æ–‡æ¤œå‡º: '{child.text} {token.text}'")
                        else:
                            print(f"   ğŸ“ é€šå¸¸ã®xcompå‡¦ç†: '{child.text} {token.text}'")ãƒ³ã‚°æ¥µåŠ›æ’é™¤ãƒ»æ±ç”¨çš„ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ
"""

import spacy
from typing import Dict, Any, List, Tuple, Optional

class InfinitiveHandler:
    """ä¸å®šè©å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆHuman Grammar Pattern + spaCyè§£æï¼‰"""
    
    def __init__(self, nlp_model=None, collaborators=None):
        """
        åˆæœŸåŒ–
        
        Args:
            nlp_model: spaCyãƒ¢ãƒ‡ãƒ«ï¼ˆå“è©åˆ†æãƒ»ä¾å­˜é–¢ä¿‚è§£æç”¨ï¼‰
            collaborators: ä»–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨ã®å”åŠ›ä½“åˆ¶
        """
        self.nlp = nlp_model or spacy.load('en_core_web_sm')
        self.collaborators = collaborators or {}
        
        print("ğŸ”§ InfinitiveHandleråˆæœŸåŒ–: Human Grammar Pattern + spaCyè§£æ")
    
    def can_handle(self, text: str) -> bool:
        """
        ä¸å®šè©æ§‹æ–‡ã‚’å‡¦ç†å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            bool: å‡¦ç†å¯èƒ½ãªå ´åˆTrue
        """
        try:
            doc = self.nlp(text)
            
            # spaCyä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹ä¸å®šè©æ¤œå‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
            for token in doc:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: to + VERB ã®ç›´æ¥çš„ãªå­é–¢ä¿‚
                if (token.text.lower() == 'to' and 
                    token.pos_ == 'PART' and  # to ã¯ PART (particle) ã¨ã—ã¦åˆ†é¡
                    any(child.pos_ == 'VERB' for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: VERB (advcl/xcomp) + to (aux) ã®é–¢ä¿‚ï¼ˆcase159å¯¾å¿œï¼‰
                if (token.pos_ == 'VERB' and 
                    token.dep_ in ['advcl', 'xcomp'] and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³3: xcomp (open clausal complement) ã§ã®ä¸å®šè©æ¤œå‡º
                if token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                    # xcompã®å‰ã«toãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    for child in token.children:
                        if child.text.lower() == 'to' and child.dep_ == 'aux':
                            return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³4: csubj (clausal subject) ã§ã®ä¸å®šè©æ¤œå‡º - åè©çš„ç”¨æ³•
                if (token.pos_ == 'VERB' and 
                    token.dep_ == 'csubj' and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³5: relcl (relative clause) ã§ã®ä¸å®šè©æ¤œå‡º - å½¢å®¹è©çš„ç”¨æ³•
                if (token.pos_ == 'VERB' and 
                    token.dep_ == 'relcl' and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
            
            # é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆcase164-170å¯¾å¿œï¼‰
            text_lower = text.lower()
            
            # å®Œäº†ä¸å®šè©: to have + éå»åˆ†è©
            if 'to have' in text_lower and any(token.tag_ in ['VBN'] for token in doc):
                return True
            
            # å—å‹•ä¸å®šè©: to be + éå»åˆ†è©
            if 'to be' in text_lower and any(token.tag_ in ['VBN'] for token in doc):
                return True
            
            # ç–‘å•è©+ä¸å®šè©: what/how/when/where to do
            if any(token.text.lower() in ['what', 'how', 'when', 'where', 'which', 'who'] and 
                   token.pos_ in ['PRON', 'ADV'] for token in doc) and 'to ' in text_lower:
                return True
            
            # ä½¿å½¹æ§‹æ–‡: want + äºº + to do
            for token in doc:
                if (token.lemma_.lower() in ['want', 'ask', 'tell', 'expect', 'allow', 'cause'] and
                    'to ' in text_lower):
                    return True
            
            # be about toæ§‹æ–‡
            if 'about to' in text_lower:
                return True
            
            # in order toæ§‹æ–‡
            if 'in order to' in text_lower:
                return True
            
            # so as toæ§‹æ–‡
            if 'so as to' in text_lower:
                return True
            
            return False
            
        except Exception as e:
            print(f"âš ï¸ can_handleè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        ä¸å®šè©æ§‹æ–‡ã®åˆ†è§£å‡¦ç†
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            Dict[str, Any]: åˆ†è§£çµæœ
        """
        print(f"ğŸ”§ InfinitiveHandlerå‡¦ç†é–‹å§‹: '{text}'")
        
        try:
            # spaCyè§£æ
            doc = self.nlp(text)
            
            # ä¸å®šè©ã®æ¤œå‡ºã¨åˆ†é¡
            infinitive_info = self._analyze_infinitive_structure(doc, text)
            
            if infinitive_info['found']:
                # ä¸å®šè©ç”¨æ³•ã«å¿œã˜ãŸå‡¦ç†
                return self._process_by_usage_type(doc, text, infinitive_info)
            else:
                return {
                    'success': False,
                    'error': 'ä¸å®šè©æ§‹æ–‡ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ',
                    'text': text
                }
                
        except Exception as e:
            print(f"âŒ InfinitiveHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'success': False,
                'error': f'InfinitiveHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'text': text
            }
    
    def _analyze_infinitive_structure(self, doc, text: str) -> Dict[str, Any]:
        """
        ä¸å®šè©æ§‹é€ ã®åˆ†æï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            
        Returns:
            Dict[str, Any]: ä¸å®šè©æ§‹é€ æƒ…å ±
        """
        print(f"ğŸ” ä¸å®šè©æ§‹é€ è§£æé–‹å§‹: spaCyä¾å­˜é–¢ä¿‚åˆ†æ")
        
        infinitive_info = {
            'found': False,
            'infinitive_tokens': [],
            'usage_patterns': [],
            'syntactic_role': None,
            'dependency_info': []
        }
        
        # é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆcase164-170å¯¾å¿œï¼‰
        text_lower = text.lower()
        
        # å®Œäº†ä¸å®šè©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: to have + éå»åˆ†è©
        if 'to have' in text_lower:
            for i, token in enumerate(doc):
                if (token.text.lower() == 'to' and i + 1 < len(doc) and 
                    doc[i + 1].text.lower() == 'have'):
                    # éå»åˆ†è©ã‚’æ¢ã™
                    for j in range(i + 2, len(doc)):
                        if doc[j].tag_ == 'VBN':  # éå»åˆ†è©
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[i + 1],  # have
                                'to_token': token,
                                'pattern': 'perfect_infinitive',
                                'head': doc[i + 1].head,
                                'dependency': 'xcomp',
                                'participle': doc[j]
                            })
                            print(f"   âœ… å®Œäº†ä¸å®šè©æ¤œå‡º: 'to have {doc[j].text}'")
                            break
                    break
        
        # å—å‹•ä¸å®šè©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: to be + éå»åˆ†è©
        if 'to be' in text_lower:
            for i, token in enumerate(doc):
                if (token.text.lower() == 'to' and i + 1 < len(doc) and 
                    doc[i + 1].text.lower() == 'be'):
                    # éå»åˆ†è©ã‚’æ¢ã™
                    for j in range(i + 2, len(doc)):
                        if doc[j].tag_ == 'VBN':  # éå»åˆ†è©
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[i + 1],  # be
                                'to_token': token,
                                'pattern': 'passive_infinitive',
                                'head': doc[i + 1].head,
                                'dependency': 'xcomp',
                                'participle': doc[j]
                            })
                            print(f"   âœ… å—å‹•ä¸å®šè©æ¤œå‡º: 'to be {doc[j].text}'")
                            break
                    break
        
        # ç–‘å•è©+ä¸å®šè©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        wh_words = ['what', 'how', 'when', 'where', 'which', 'who']
        for token in doc:
            if (token.text.lower() in wh_words and 
                token.pos_ in ['PRON', 'ADV']):
                # ãã®å¾Œã«to+å‹•è©ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                for next_token in doc[token.i + 1:]:
                    if (next_token.text.lower() == 'to' and 
                        next_token.dep_ == 'aux'):
                        for verb_token in next_token.children:
                            if verb_token.pos_ == 'VERB':
                                infinitive_info['found'] = True
                                infinitive_info['infinitive_tokens'].append({
                                    'main_verb': verb_token,
                                    'to_token': next_token,
                                    'pattern': 'wh_infinitive',
                                    'head': verb_token.head,
                                    'dependency': 'xcomp',
                                    'wh_word': token
                                })
                                print(f"   âœ… ç–‘å•è©+ä¸å®šè©æ¤œå‡º: '{token.text} to {verb_token.text}'")
                                break
                        break
                break
        
        # ä½¿å½¹æ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        causative_verbs = ['want', 'ask', 'tell', 'expect', 'allow', 'cause']
        for token in doc:
            if (token.lemma_.lower() in causative_verbs and 
                token.pos_ == 'VERB'):
                # "I want you to help me" ãƒ‘ã‚¿ãƒ¼ãƒ³
                object_person = None
                infinitive_verb = None
                to_token = None
                
                # ccompæ§‹æ–‡ã§ã®ä¸å®šè©æ¤œå‡º
                for child in token.children:
                    if child.dep_ == 'ccomp' and child.pos_ == 'VERB':
                        infinitive_verb = child
                        # toãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¢ã™
                        for inf_child in child.children:
                            if inf_child.text.lower() == 'to' and inf_child.dep_ == 'aux':
                                to_token = inf_child
                                break
                        
                        # ä¸å®šè©ã®ä¸»èªï¼ˆcausativeã®ç›®çš„èªï¼‰ã‚’æ¢ã™
                        for inf_child in child.children:
                            if inf_child.dep_ == 'nsubj':
                                object_person = inf_child
                                break
                        
                        break
                
                if infinitive_verb and object_person:
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': infinitive_verb,
                        'to_token': to_token,
                        'pattern': 'causative',
                        'head': token,
                        'dependency': 'ccomp',
                        'causative_verb': token,
                        'object': object_person
                    })
                    print(f"   âœ… ä½¿å½¹æ§‹æ–‡æ¤œå‡º: '{token.text} {object_person.text} to {infinitive_verb.text}'")
        
        # be about toæ§‹æ–‡æ¤œå‡º
        if 'about to' in text_lower:
            for i, token in enumerate(doc):
                if (token.text.lower() == 'about' and 
                    i + 1 < len(doc) and doc[i + 1].text.lower() == 'to'):
                    # ãã®å¾Œã®å‹•è©ã‚’æ¢ã™
                    for j in range(i + 2, len(doc)):
                        if doc[j].pos_ == 'VERB':
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[j],
                                'to_token': doc[i + 1],
                                'pattern': 'be_about_to',
                                'head': token.head,
                                'dependency': 'xcomp',
                                'about_token': token
                            })
                            print(f"   âœ… be about toæ§‹æ–‡æ¤œå‡º: 'about to {doc[j].text}'")
                            break
                    break
        
        # in order toæ§‹æ–‡æ¤œå‡º
        if 'in order to' in text_lower:
            for i, token in enumerate(doc):
                if (token.text.lower() == 'in' and 
                    i + 2 < len(doc) and 
                    doc[i + 1].text.lower() == 'order' and 
                    doc[i + 2].text.lower() == 'to'):
                    # ãã®å¾Œã®å‹•è©ã‚’æ¢ã™
                    for j in range(i + 3, len(doc)):
                        if doc[j].pos_ == 'VERB':
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[j],
                                'to_token': doc[i + 2],
                                'pattern': 'in_order_to',
                                'head': doc[j].head,
                                'dependency': 'acl'
                            })
                            print(f"   âœ… in order toæ§‹æ–‡æ¤œå‡º: 'in order to {doc[j].text}'")
                            break
                    break
        
        # so as toæ§‹æ–‡æ¤œå‡º
        if 'so as to' in text_lower:
            for i, token in enumerate(doc):
                if (token.text.lower() == 'so' and 
                    i + 2 < len(doc) and 
                    doc[i + 1].text.lower() == 'as' and 
                    doc[i + 2].text.lower() == 'to'):
                    # ãã®å¾Œã®å‹•è©ã‚’æ¢ã™
                    for j in range(i + 3, len(doc)):
                        if doc[j].pos_ == 'VERB':
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[j],
                                'to_token': doc[i + 2],
                                'pattern': 'so_as_to',
                                'head': doc[j].head,
                                'dependency': 'advcl'
                            })
                            print(f"   âœ… so as toæ§‹æ–‡æ¤œå‡º: 'so as to {doc[j].text}'")
                            break
                    break
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: xcomp (open clausal complement) + aux=to
            if token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'xcomp_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… xcompä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
                        
                        # too...toæ§‹æ–‡ã®ç‰¹åˆ¥åˆ¤å®š
                        if self._is_too_to_pattern(doc, token):
                            infinitive_info['infinitive_tokens'][-1]['pattern'] = 'too_to_pattern'
                            print(f"   ğŸ¯ too...toæ§‹æ–‡æ¤œå‡º: '{child.text} {token.text}'")
                        # enough...toæ§‹æ–‡ã®ç‰¹åˆ¥åˆ¤å®š  
                        elif self._is_enough_to_pattern(doc, token):
                            infinitive_info['infinitive_tokens'][-1]['pattern'] = 'enough_to_pattern'
                            print(f"   ğŸ¯ enough...toæ§‹æ–‡æ¤œå‡º: '{child.text} {token.text}'")
                        else:
                            print(f"   ğŸ“ é€šå¸¸ã®xcompå‡¦ç†: '{child.text} {token.text}'")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: advcl (adverbial clause) + aux/mark=to  
            elif token.dep_ == 'advcl' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ in ['mark', 'aux']:
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'advcl_mark',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… advclä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ccomp (clausal complement) + aux=to
            elif token.dep_ == 'ccomp' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'ccomp_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… ccompä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: csubj (clausal subject) + aux=to - åè©çš„ç”¨æ³•ãƒ»ä¸»èª
            elif token.dep_ == 'csubj' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'csubj_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… csubjä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³5: relcl (relative clause) + aux=to - å½¢å®¹è©çš„ç”¨æ³•
            elif token.dep_ == 'relcl' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'relcl_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… relclä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
        
        # é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆcase164-170ï¼‰
        text_lower = text.lower()
        
        # å®Œäº†ä¸å®šè©æ¤œå‡º: to have + éå»åˆ†è©
        if not infinitive_info['found'] and 'to have' in text_lower:
            for token in doc:
                if (token.text.lower() == 'have' and 
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' for child in token.children) and
                    any(child.tag_ == 'VBN' for child in token.children)):
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': token,
                        'to_token': next((child for child in token.children if child.text.lower() == 'to'), None),
                        'pattern': 'perfect_infinitive',
                        'head': token.head,
                        'dependency': token.dep_
                    })
                    print(f"   âœ… å®Œäº†ä¸å®šè©æ¤œå‡º: 'to have + éå»åˆ†è©' (head: {token.head.text})")
        
        # å—å‹•ä¸å®šè©æ¤œå‡º: to be + éå»åˆ†è©
        if not infinitive_info['found'] and 'to be' in text_lower:
            for token in doc:
                if (token.lemma_ == 'be' and 
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' for child in token.children) and
                    any(child.tag_ == 'VBN' for child in token.children)):
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': token,
                        'to_token': next((child for child in token.children if child.text.lower() == 'to'), None),
                        'pattern': 'passive_infinitive',
                        'head': token.head,
                        'dependency': token.dep_
                    })
                    print(f"   âœ… å—å‹•ä¸å®šè©æ¤œå‡º: 'to be + éå»åˆ†è©' (head: {token.head.text})")
        
        # ç–‘å•è©+ä¸å®šè©æ¤œå‡º: what/how/when/where to do
        if not infinitive_info['found']:
            for token in doc:
                if (token.text.lower() in ['what', 'how', 'when', 'where', 'which', 'who'] and
                    token.pos_ in ['PRON', 'ADV']):
                    # æ¬¡ã®toã‚’æ¢ã™
                    for next_token in doc[token.i+1:]:
                        if (next_token.text.lower() == 'to' and next_token.pos_ == 'PART' and
                            next_token.i < len(doc) - 1 and doc[next_token.i + 1].pos_ == 'VERB'):
                            infinitive_info['found'] = True
                            infinitive_info['infinitive_tokens'].append({
                                'main_verb': doc[next_token.i + 1],
                                'to_token': next_token,
                                'pattern': 'wh_infinitive',
                                'wh_word': token,
                                'head': token.head,
                                'dependency': token.dep_
                            })
                            print(f"   âœ… ç–‘å•è©+ä¸å®šè©æ¤œå‡º: '{token.text} to {doc[next_token.i + 1].text}'")
                            break
        
        # be about toæ§‹æ–‡æ¤œå‡º
        if not infinitive_info['found'] and 'about to' in text_lower:
            for token in doc:
                if (token.text.lower() == 'about' and token.i < len(doc) - 2 and
                    doc[token.i + 1].text.lower() == 'to' and doc[token.i + 2].pos_ == 'VERB'):
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': doc[token.i + 2],
                        'to_token': doc[token.i + 1],
                        'pattern': 'be_about_to',
                        'about_token': token,
                        'head': token.head,
                        'dependency': token.dep_
                    })
                    print(f"   âœ… be about toæ§‹æ–‡æ¤œå‡º: 'about to {doc[token.i + 2].text}'")
        
        # in order toæ§‹æ–‡æ¤œå‡º
        if not infinitive_info['found'] and 'in order to' in text_lower:
            for token in doc:
                if (token.text.lower() == 'order' and token.i < len(doc) - 2 and
                    doc[token.i + 1].text.lower() == 'to' and doc[token.i + 2].pos_ == 'VERB'):
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': doc[token.i + 2],
                        'to_token': doc[token.i + 1],
                        'pattern': 'in_order_to',
                        'order_token': token,
                        'head': token.head,
                        'dependency': token.dep_
                    })
                    print(f"   âœ… in order toæ§‹æ–‡æ¤œå‡º: 'in order to {doc[token.i + 2].text}'")
        
        # so as toæ§‹æ–‡æ¤œå‡º
        if not infinitive_info['found'] and 'so as to' in text_lower:
            for token in doc:
                if (token.text.lower() == 'as' and token.i < len(doc) - 2 and
                    doc[token.i + 1].text.lower() == 'to' and doc[token.i + 2].pos_ == 'VERB' and
                    token.i > 0 and doc[token.i - 1].text.lower() == 'so'):
                    infinitive_info['found'] = True
                    infinitive_info['infinitive_tokens'].append({
                        'main_verb': doc[token.i + 2],
                        'to_token': doc[token.i + 1],
                        'pattern': 'so_as_to',
                        'as_token': token,
                        'head': token.head,
                        'dependency': token.dep_
                    })
                    print(f"   âœ… so as toæ§‹æ–‡æ¤œå‡º: 'so as to {doc[token.i + 2].text}'")
        
        # ä½¿å½¹æ§‹æ–‡æ¤œå‡º: want + äºº + to do
        if not infinitive_info['found']:
            for token in doc:
                if (token.lemma_.lower() in ['want', 'ask', 'tell', 'expect', 'allow', 'cause'] and
                    token.pos_ == 'VERB'):
                    # ç›®çš„èª + to + å‹•è©ã®æ§‹é€ ã‚’æ¢ã™
                    for child in token.children:
                        if child.dep_ == 'dobj':  # ç›´æ¥ç›®çš„èª
                            # æ¬¡ã®toã‚’æ¢ã™
                            for next_token in doc[child.i+1:]:
                                if (next_token.text.lower() == 'to' and next_token.pos_ == 'PART' and
                                    next_token.i < len(doc) - 1 and doc[next_token.i + 1].pos_ == 'VERB'):
                                    infinitive_info['found'] = True
                                    infinitive_info['infinitive_tokens'].append({
                                        'main_verb': doc[next_token.i + 1],
                                        'to_token': next_token,
                                        'pattern': 'causative',
                                        'causative_verb': token,
                                        'object': child,
                                        'head': token,
                                        'dependency': 'causative'
                                    })
                                    print(f"   âœ… ä½¿å½¹æ§‹æ–‡æ¤œå‡º: '{token.text} {child.text} to {doc[next_token.i + 1].text}'")
                                    break
        
        # ç”¨æ³•åˆ†é¡ï¼ˆä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰
        if infinitive_info['found']:
            infinitive_info['syntactic_role'] = self._analyze_syntactic_role(doc, infinitive_info)
        
        return infinitive_info
    
    def _analyze_syntactic_role(self, doc, infinitive_info: Dict) -> str:
        """
        ä¸å®šè©ã®çµ±èªçš„å½¹å‰²åˆ†æï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            infinitive_info: ä¸å®šè©æƒ…å ±
            
        Returns:
            str: çµ±èªçš„å½¹å‰²
        """
        print(f"ğŸ§  çµ±èªçš„å½¹å‰²åˆ†æ: Human Grammar Pattern")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            pattern = inf_token['pattern']
            head = inf_token['head']
            dependency = inf_token['dependency']
            
            # ç‰¹åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡¦ç†
            if pattern == 'too_to_pattern':
                print(f"   ğŸ“ too...toæ§‹æ–‡ â†’ çµæœã®å‰¯è©çš„ç”¨æ³•")
                return 'too_to_adverbial'
            elif pattern == 'enough_to_pattern':
                print(f"   ğŸ“ enough...toæ§‹æ–‡ â†’ çµæœã®å‰¯è©çš„ç”¨æ³•")
                return 'enough_to_adverbial'
            
            # é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡¦ç†ï¼ˆcase164-170ï¼‰
            elif pattern == 'perfect_infinitive':
                print(f"   ğŸ“ å®Œäº†ä¸å®šè© â†’ åŠ©å‹•è©å½¢å¼")
                return 'perfect_infinitive'
            elif pattern == 'passive_infinitive':
                print(f"   ğŸ“ å—å‹•ä¸å®šè© â†’ åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰")
                return 'passive_infinitive'
            elif pattern == 'wh_infinitive':
                print(f"   ğŸ“ ç–‘å•è©+ä¸å®šè© â†’ åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰")
                return 'wh_infinitive'
            elif pattern == 'causative':
                print(f"   ğŸ“ ä½¿å½¹æ§‹æ–‡ â†’ ç›®çš„èªè£œèª")
                return 'causative'
            elif pattern == 'be_about_to':
                print(f"   ğŸ“ be about toæ§‹æ–‡ â†’ åŠ©å‹•è©å½¢å¼")
                return 'be_about_to'
            elif pattern == 'in_order_to':
                print(f"   ğŸ“ in order toæ§‹æ–‡ â†’ ç›®çš„ã®å‰¯è©çš„ç”¨æ³•")
                return 'in_order_to'
            elif pattern == 'so_as_to':
                print(f"   ğŸ“ so as toæ§‹æ–‡ â†’ ç›®çš„ã®å‰¯è©çš„ç”¨æ³•")
                return 'so_as_to'
            
            # xcomp: é€šå¸¸ã¯ç›®çš„èªè£œèªï¼ˆå½¢å®¹è©çš„ãƒ»å‰¯è©çš„ç”¨æ³•ï¼‰
            elif pattern == 'xcomp_aux':
                if head.pos_ == 'VERB':
                    # want to do å½¢å¼ã¯åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰
                    if head.lemma_.lower() in ['want', 'need', 'like', 'love', 'hate', 'prefer', 'decide', 'hope', 'plan', 'try', 'attempt']:
                        print(f"   ğŸ“ xcomp + æ¬²æ±‚ãƒ»æ„æ€å‹•è© â†’ åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰")
                        return 'nominal_object'
                    else:
                        print(f"   ğŸ“ xcomp + å‹•è©head â†’ ç›®çš„èªè£œèªï¼ˆå½¢å®¹è©çš„ç”¨æ³•å€™è£œï¼‰")
                        return 'adjectival_complement'
                    
            # advcl: å‰¯è©ç¯€ï¼ˆå‰¯è©çš„ç”¨æ³•ï¼‰
            # advcl: foræ§‹æ–‡ã®å ´åˆã¯å½¢å¼ä¸»èªæ§‹æ–‡ã€ãã‚Œä»¥å¤–ã¯å‰¯è©çš„ç”¨æ³•
            elif pattern == 'advcl_mark':
                # "It is easy for me to understand" æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯
                tokens = [token.text.lower() for token in doc]
                print(f"   ğŸ“ advclæ¤œè¨¼: tokens={tokens}")
                print(f"   ğŸ“ advclæ¤œè¨¼: head={head.text}, head.lemma={head.lemma_}")
                
                # It is ... for ... to ...æ§‹æ–‡ã®åˆ¤å®š
                has_it = 'it' in tokens
                has_be = head.lemma_.lower() in ['be', 'is', 'are', 'was', 'were']
                has_for = 'for' in tokens
                has_to = 'to' in tokens
                
                print(f"   ğŸ“ formal_subjectåˆ¤å®š: it={has_it}, be={has_be}, for={has_for}, to={has_to}")
                
                if has_it and has_be and has_for and has_to:
                    print(f"   ğŸ“ advcl + foræ§‹æ–‡ â†’ å½¢å¼ä¸»èªæ§‹æ–‡")
                    return 'formal_subject'
                else:
                    print(f"   ğŸ“ advcl + mark â†’ å‰¯è©ç¯€ï¼ˆå‰¯è©çš„ç”¨æ³•ï¼‰")
                    return 'adverbial_clause'
                    
            # ccomp: è£œèªç¯€ï¼ˆåè©çš„ç”¨æ³•å€™è£œï¼‰
            elif pattern == 'ccomp_aux':
                print(f"   ğŸ“ ccomp + è£œèªç¯€ â†’ åè©çš„ç”¨æ³•å€™è£œ")
                return 'nominal_complement'
                
            # csubj: ç¯€ä¸»èªï¼ˆåè©çš„ç”¨æ³•ãƒ»ä¸»èªï¼‰
            elif pattern == 'csubj_aux':
                print(f"   ğŸ“ csubj + ç¯€ä¸»èª â†’ åè©çš„ç”¨æ³•ï¼ˆä¸»èªï¼‰")
                return 'nominal_subject'
                
            # relcl: é–¢ä¿‚ç¯€ãƒ»å½¢å®¹è©çš„ç”¨æ³•
            elif pattern == 'relcl_aux':
                print(f"   ğŸ“ relcl + é–¢ä¿‚ç¯€ â†’ å½¢å®¹è©çš„ç”¨æ³•")
                return 'adjectival_modifier'
        
        return 'unknown'
    
    def _is_too_to_pattern(self, doc, infinitive_verb):
        """too...toæ§‹æ–‡ã®åˆ¤å®š"""
        print(f"   ğŸ” too...toåˆ¤å®šé–‹å§‹: infinitive_verb={infinitive_verb.text}")
        # 'too'ãŒå½¢å®¹è©ã‚’ä¿®é£¾ã—ã¦ã„ã‚‹æ§‹é€ ã‚’æ¢ã™
        for token in doc:
            print(f"      ğŸ” token='{token.text}', dep={token.dep_}, pos={token.pos_}")
            if token.text.lower() == 'too' and token.dep_ == 'advmod':
                print(f"      âœ… tooæ¤œå‡º: head={token.head.text}, head.pos={token.head.pos_}")
                # tooãŒä¿®é£¾ã—ã¦ã„ã‚‹å½¢å®¹è©
                if token.head.pos_ == 'ADJ':
                    print(f"      âœ… too...toæ§‹æ–‡åˆ¤å®šæˆåŠŸ: 'too {token.head.text} to {infinitive_verb.text}'")
                    return True
        print(f"      âŒ too...toæ§‹æ–‡åˆ¤å®šå¤±æ•—")
        return False
    
    def _is_enough_to_pattern(self, doc, infinitive_verb):
        """enough...toæ§‹æ–‡ã®åˆ¤å®š"""
        print(f"   ğŸ” enough...toåˆ¤å®šé–‹å§‹: infinitive_verb={infinitive_verb.text}")
        # 'enough'ãŒå½¢å®¹è©ã¾ãŸã¯å‰¯è©ã‚’ä¿®é£¾ã—ã¦ã„ã‚‹æ§‹é€ ã‚’æ¢ã™
        for token in doc:
            print(f"      ğŸ” token='{token.text}', dep={token.dep_}, pos={token.pos_}")
            if token.text.lower() == 'enough' and token.dep_ == 'advmod':
                print(f"      âœ… enoughæ¤œå‡º: head={token.head.text}, head.pos={token.head.pos_}")
                # enoughãŒä¿®é£¾ã—ã¦ã„ã‚‹å½¢å®¹è©/å‰¯è©
                if token.head.pos_ in ['ADJ', 'ADV']:
                    print(f"      âœ… enough...toæ§‹æ–‡åˆ¤å®šæˆåŠŸ: '{token.head.text} enough to {infinitive_verb.text}'")
                    return True
        print(f"      âŒ enough...toæ§‹æ–‡åˆ¤å®šå¤±æ•—")
        return False
    
    def _process_by_usage_type(self, doc, text: str, infinitive_info: Dict) -> Dict[str, Any]:
        """
        ç”¨æ³•ã‚¿ã‚¤ãƒ—åˆ¥ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ¯ ç”¨æ³•åˆ¥å‡¦ç†é–‹å§‹: {infinitive_info.get('syntactic_role', 'unknown')}")
        
        # ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡ã®å®Ÿè¡Œ
        slots = self._classify_slot_types(doc, infinitive_info)
        
        syntactic_role = infinitive_info.get('syntactic_role', 'unknown')
        
        if syntactic_role == 'nominal_complement':
            return self._process_nominal_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'nominal_subject':
            return self._process_nominal_subject_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'nominal_object':
            return self._process_nominal_object_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adjectival_complement':
            return self._process_adjectival_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adjectival_modifier':
            return self._process_adjectival_modifier_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'formal_subject':
            return self._process_formal_subject_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'too_to_adverbial':
            return self._process_too_to_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'enough_to_adverbial':
            return self._process_enough_to_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adverbial_clause':
            return self._process_adverbial_infinitive(doc, text, infinitive_info, slots)
        
        # é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡¦ç†ï¼ˆcase164-170ï¼‰
        elif syntactic_role == 'perfect_infinitive':
            return self._process_perfect_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'passive_infinitive':
            return self._process_passive_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'wh_infinitive':
            return self._process_wh_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'causative':
            return self._process_causative_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'be_about_to':
            return self._process_be_about_to_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'in_order_to':
            return self._process_in_order_to_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'so_as_to':
            return self._process_so_as_to_infinitive(doc, text, infinitive_info, slots)
        
        else:
            return self._process_basic_infinitive(doc, text, infinitive_info, slots)
    
    def _classify_slot_types(self, doc, infinitive_info: Dict[str, Any]) -> Dict[str, str]:
        """
        ä¸å®šè©æ§‹é€ ã®ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            infinitive_info: ä¸å®šè©æ§‹é€ æƒ…å ±
            
        Returns:
            Dict[str, str]: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡çµæœ
        """
        print(f"ğŸ¯ ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡: spaCyä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹è©³ç´°è§£æ")
        
        slots = {}
        
        for inf_token in infinitive_info['infinitive_tokens']:
            main_verb = inf_token['main_verb']
            to_token = inf_token['to_token']
            head = inf_token['head']
            pattern = inf_token['pattern']
            
            # ä¸å®šè©ãƒãƒ¼ã‚«ãƒ¼åˆ†é¡
            slots[to_token.text] = 'inf-marker'
            print(f"   ğŸ“Œ '{to_token.text}' â†’ inf-marker")
            
            # ä¸å®šè©å‹•è©åˆ†é¡
            slots[main_verb.text] = self._classify_infinitive_verb(main_verb, pattern, head)
            print(f"   ğŸ”§ '{main_verb.text}' â†’ {slots[main_verb.text]}")
            
            # ä¸»å‹•è©åˆ†é¡
            if head.pos_ == 'VERB' and head.text not in slots:
                slots[head.text] = self._classify_main_verb(head, pattern)
                print(f"   âš™ï¸ '{head.text}' â†’ {slots[head.text]}")
            
            # ä¸å®šè©ã®å¼•æ•°åˆ†æ
            self._analyze_infinitive_arguments(main_verb, slots)
        
        return slots
    
    def _classify_infinitive_verb(self, verb_token, pattern: str, head) -> str:
        """
        ä¸å®šè©å‹•è©ã®åˆ†é¡
        
        Args:
            verb_token: ä¸å®šè©å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            pattern: ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³
            head: çµ±èªçš„æ”¯é…èª
            
        Returns:
            str: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
        """
        # xcomp: è£œèªå‹•è©
        if pattern == 'xcomp_aux':
            return 'inf-complement-verb'
        
        # advcl: å‰¯è©å¥å‹•è©
        elif pattern == 'advcl_mark':
            return 'inf-adverbial-verb'
        
        # ccomp: è£œèªç¯€å‹•è©
        elif pattern == 'ccomp_aux':
            return 'inf-clausal-verb'
        
        return 'inf-verb'
    
    def _classify_main_verb(self, verb_token, pattern: str) -> str:
        """
        ä¸»å‹•è©ã®åˆ†é¡
        
        Args:
            verb_token: ä¸»å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            pattern: ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
            str: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
        """
        # ä¸å®šè©ã‚’æ”¯é…ã™ã‚‹ä¸»å‹•è©ã®ç‰¹å¾´åˆ†æ
        if pattern in ['xcomp_aux', 'ccomp_aux']:
            return 'inf-governing-verb'
        elif pattern == 'advcl_mark':
            return 'main-verb'
        
        return 'verb'
    
    def _analyze_infinitive_arguments(self, verb_token, slots: Dict[str, str]):
        """
        ä¸å®šè©ã®å¼•æ•°æ§‹é€ åˆ†æ
        
        Args:
            verb_token: ä¸å®šè©å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            slots: ã‚¹ãƒ­ãƒƒãƒˆè¾æ›¸ï¼ˆæ›´æ–°ã•ã‚Œã‚‹ï¼‰
        """
        print(f"   ï¿½ ä¸å®šè©'{verb_token.text}'ã®å¼•æ•°æ§‹é€ è§£æ")
        
        for child in verb_token.children:
            if child.dep_ == 'dobj':  # ç›´æ¥ç›®çš„èª
                slots[child.text] = 'inf-object'
                print(f"     ğŸ“¦ '{child.text}' â†’ inf-object")
            elif child.dep_ == 'nsubj':  # ä¸»èª
                slots[child.text] = 'inf-subject'
                print(f"     ğŸ‘¤ '{child.text}' â†’ inf-subject")
            elif child.dep_ == 'prep':  # å‰ç½®è©å¥
                slots[child.text] = 'inf-prep'
                print(f"     ğŸ”— '{child.text}' â†’ inf-prep")
                # å‰ç½®è©ã®ç›®çš„èªã‚‚åˆ†æ
                for grandchild in child.children:
                    if grandchild.dep_ == 'pobj':
                        slots[grandchild.text] = 'inf-prep-object'
                        print(f"     ğŸ“ '{grandchild.text}' â†’ inf-prep-object")
    
    def _process_nominal_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¸å®šè©ã‚’ä¸»èªã¨ã—ã¦å‡¦ç†
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            main_slots['S'] = f"{to_token.text} {main_verb.text}"
            
            # æ–‡ã®ä¸»å‹•è©ã‚’æ¤œå‡º
            for token in doc:
                if token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                    main_slots['V'] = token.text
                    break
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal',
                'usage_type': 'nominal',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_nominal_subject_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ãƒ»ä¸»èªã®å‡¦ç†ï¼ˆcsubjæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©ãƒ»ä¸»èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case156: "To study English is important."
        # æœŸå¾…å€¤: main_slots={'S': '', 'V': 'is', 'C1': 'important'}
        #        sub_slots={'sub-v': 'To study', 'sub-o1': 'English', '_parent_slot': 'S'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # study
            head = inf_token['head']  # is
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: æ–‡ã®ä¸»å‹•è©ï¼ˆisï¼‰ã¨ãã®è£œèª
            main_slots['S'] = ''  # ä¸»èªã¯ç©ºï¼ˆä¸å®šè©ãŒã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦å‡¦ç†ï¼‰
            main_slots['V'] = head.text  # is
            
            # è£œèªï¼ˆC1ï¼‰ã‚’æ¤œå‡º
            for child in head.children:
                if child.dep_ in ['acomp', 'attr'] and child.pos_ == 'ADJ':
                    main_slots['C1'] = child.text
                    print(f"   ğŸ“ è£œèªæ¤œå‡º: C1 = '{child.text}'")
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "To study"
            sub_slots['_parent_slot'] = 'S'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj' and child.pos_ in ['NOUN', 'PROPN']:
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal_subject',
                'usage_type': 'nominal_subject',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_nominal_object_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ãƒ»ç›®çš„èªã®å‡¦ç†ï¼ˆxcompæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©ãƒ»ç›®çš„èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case157: "I want to learn programming."
        # æœŸå¾…å€¤: main_slots={'S': 'I', 'V': 'want', 'O1': ''}
        #        sub_slots={'sub-v': 'to learn', 'sub-o1': 'programming', '_parent_slot': 'O1'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # learn
            head = inf_token['head']  # want
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: ä¸»å‹•è©ï¼ˆwantï¼‰ã¨ãã®ä¸»èª
            for token in doc:
                if token.dep_ == 'nsubj' and token.head == head:
                    main_slots['S'] = token.text
                    print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{token.text}'")
            
            main_slots['V'] = head.text  # want
            main_slots['O1'] = ''  # ç›®çš„èªã¯ç©ºï¼ˆä¸å®šè©ãŒã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦å‡¦ç†ï¼‰
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "to learn"
            sub_slots['_parent_slot'] = 'O1'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj' and child.pos_ in ['NOUN', 'PROPN']:
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal_object',
                'usage_type': 'nominal_object',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adjectival_modifier_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å½¢å®¹è©çš„ç”¨æ³•ãƒ»ä¿®é£¾èªã®å‡¦ç†ï¼ˆrelclæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ å½¢å®¹è©çš„ä¸å®šè©ãƒ»ä¿®é£¾èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case158: "She has something to tell you."
        # æœŸå¾…å€¤: main_slots={'S': 'She', 'V': 'has', 'O1': ''}
        #        sub_slots={'sub-v': 'something to tell', 'sub-o1': 'you', '_parent_slot': 'O1'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # tell
            head = inf_token['head']  # something
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: ä¸»å‹•è©ã¨ãã®ä¸»èªãƒ»ç›®çš„èª
            for token in doc:
                if token.dep_ == 'ROOT':
                    main_slots['V'] = token.text  # has
                    # ä¸»èªã‚’æ¢ã™
                    for child in token.children:
                        if child.dep_ == 'nsubj':
                            main_slots['S'] = child.text
                            print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{child.text}'")
                        # ç›®çš„èªã‚’æ¢ã™ï¼ˆhead=somethingã®è¦ªï¼‰
                        elif child.dep_ == 'dobj' and child == head:
                            main_slots['O1'] = ''  # ç›®çš„èªã¯ä¸å®šè©ã§ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåŒ–
                            print(f"   ğŸ“ ç›®çš„èªæ¤œå‡ºï¼ˆä¸å®šè©ä¿®é£¾å¯¾è±¡ï¼‰: '{child.text}' â†’ O1ç©ºæ¬„")
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{head.text} {to_token.text} {main_verb.text}"  # "something to tell"
            sub_slots['_parent_slot'] = 'O1'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adjectival_modifier',
                'usage_type': 'adjectival_modifier',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_formal_subject_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å½¢å¼ä¸»èªæ§‹æ–‡ã®å‡¦ç†ï¼ˆIt is ... for äºº to ...ï¼‰"""
        print(f"ğŸ“ å½¢å¼ä¸»èªä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case161: "It is easy for me to understand this."
        # æœŸå¾…å€¤: main_slots={'S': 'It', 'V': 'is', 'C1': 'easy', 'M2': 'for me', 'M3': ''}
        #        sub_slots={'sub-v': 'to understand', 'sub-o1': 'this', '_parent_slot': 'M3'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # understand
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã‚’æ§‹ç¯‰
            main_slots['S'] = 'It'  # å½¢å¼ä¸»èª
            
            # beå‹•è©ã¨è£œèªã‚’æ¢ã™
            for token in doc:
                if token.dep_ == 'ROOT' and token.lemma_.lower() == 'be':
                    main_slots['V'] = token.text  # is
                    # è£œèªï¼ˆå½¢å®¹è©ï¼‰ã‚’æ¢ã™
                    for child in token.children:
                        if child.dep_ == 'acomp':
                            main_slots['C1'] = child.text  # easy
                            print(f"   ğŸ“ è£œèªæ¤œå‡º: C1 = '{child.text}'")
            
            # forå¥ã‚’æ¢ã™
            for token in doc:
                if token.text.lower() == 'for' and token.dep_ == 'mark':
                    # forå¥ã®å¯¾è±¡ã‚’æ¢ã™
                    for child in token.children:
                        if child.dep_ == 'nsubj':
                            main_slots['M2'] = f"for {child.text}"
                            print(f"   ğŸ“ forå¥æ¤œå‡º: M2 = 'for {child.text}'")
                    # ã¾ãŸã¯è¦ªã®å…„å¼Ÿã‹ã‚‰æ¢ã™
                    if 'M2' not in main_slots:
                        parent = token.head
                        for sibling in parent.children:
                            if sibling.dep_ == 'nsubj' and sibling != token:
                                main_slots['M2'] = f"for {sibling.text}"
                                print(f"   ğŸ“ forå¥æ¤œå‡º: M2 = 'for {sibling.text}'")
                                break
            
            # M2ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€åˆ¥ã®æ–¹æ³•ã§æ¢ã™
            if 'M2' not in main_slots:
                for token in doc:
                    if token.text.lower() == 'me' and token.dep_ == 'nsubj':
                        main_slots['M2'] = 'for me'
                        print(f"   ğŸ“ forå¥æ¤œå‡ºï¼ˆä»£æ›¿ï¼‰: M2 = 'for me'")
                        break
            
            main_slots['M3'] = ''  # ä¸å®šè©éƒ¨åˆ†ã¯ç©ºã§ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåŒ–
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "to understand"
            sub_slots['_parent_slot'] = 'M3'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_formal_subject',
                'usage_type': 'formal_subject',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_too_to_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """too...toæ§‹æ–‡ã®å‡¦ç†"""
        print(f"ğŸ“ too...toæ§‹æ–‡å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case162: "This box is too heavy to carry."
        # æœŸå¾…å€¤: main_slots={'S': 'This box', 'V': 'is', 'C1': 'too heavy', 'M2': ''}
        #        sub_slots={'sub-v': 'to carry', '_parent_slot': 'M2'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # carry
            
            # ãƒ¡ã‚¤ãƒ³æ§‹é€ ã‚’è§£æ
            for token in doc:
                if token.dep_ == 'nsubj':
                    # ä¸»èª: é™å®šè© + åè©
                    if token.i > 0 and doc[token.i-1].pos_ == 'DET':
                        main_slots['S'] = f"{doc[token.i-1].text} {token.text}"
                    else:
                        main_slots['S'] = token.text
                elif token.dep_ == 'ROOT' and token.pos_ in ['AUX', 'VERB']:
                    main_slots['V'] = token.text  # is
                    
                    # è£œèª: too + å½¢å®¹è©
                    for child in token.children:
                        if child.dep_ == 'acomp' and child.pos_ == 'ADJ':
                            # tooãŒä¿®é£¾ã—ã¦ã„ã‚‹å½¢å®¹è©
                            for grandchild in child.children:
                                if grandchild.text.lower() == 'too' and grandchild.dep_ == 'advmod':
                                    main_slots['C1'] = f"too {child.text}"
                                    print(f"   ğŸ“ too+å½¢å®¹è©æ¤œå‡º: C1 = 'too {child.text}'")
                                    break
                            if 'C1' not in main_slots:
                                main_slots['C1'] = child.text
            
            main_slots['M2'] = ''  # ä¸å®šè©éƒ¨åˆ†ã¯ç©ºã§ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåŒ–
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "to carry"
            sub_slots['_parent_slot'] = 'M2'
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_too_to',
                'usage_type': 'too_to_adverbial',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_enough_to_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """enough...toæ§‹æ–‡ã®å‡¦ç†"""
        print(f"ğŸ“ enough...toæ§‹æ–‡å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case163: "She is old enough to drive a car."
        # æœŸå¾…å€¤: main_slots={'S': 'She', 'V': 'is', 'C1': 'old', 'M2': ''}
        #        sub_slots={'sub-v': 'enough to drive', 'sub-o1': 'a car', '_parent_slot': 'M2'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # drive
            
            # ãƒ¡ã‚¤ãƒ³æ§‹é€ ã‚’è§£æ
            for token in doc:
                if token.dep_ == 'nsubj':
                    main_slots['S'] = token.text  # She
                elif token.dep_ == 'ROOT' and token.pos_ in ['AUX', 'VERB']:
                    main_slots['V'] = token.text  # is
                    
                    # è£œèª: å½¢å®¹è©ï¼ˆenoughãŒä¿®é£¾ã—ã¦ã„ã‚‹ï¼‰
                    for child in token.children:
                        if child.dep_ == 'acomp' and child.pos_ == 'ADJ':
                            # enoughãŒä¿®é£¾ã—ã¦ã„ã‚‹å½¢å®¹è©
                            for grandchild in child.children:
                                if grandchild.text.lower() == 'enough' and grandchild.dep_ == 'advmod':
                                    main_slots['C1'] = child.text  # old (enoughã¯é™¤ã)
                                    print(f"   ğŸ“ enough+å½¢å®¹è©æ¤œå‡º: C1 = '{child.text}'")
                                    break
                            if 'C1' not in main_slots:
                                main_slots['C1'] = child.text
            
            main_slots['M2'] = ''  # ä¸å®šè©éƒ¨åˆ†ã¯ç©ºã§ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåŒ–
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: enough + ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"enough {to_token.text} {main_verb.text}"  # "enough to drive"
            sub_slots['_parent_slot'] = 'M2'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    # é™å®šè© + åè©
                    if child.i > 0 and doc[child.i-1].pos_ == 'DET':
                        sub_slots['sub-o1'] = f"{doc[child.i-1].text} {child.text}"
                    else:
                        sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{sub_slots['sub-o1']}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_enough_to',
                'usage_type': 'enough_to_adverbial',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adjectival_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å½¢å®¹è©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ å½¢å®¹è©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¿®é£¾ã•ã‚Œã‚‹åè©ã¨ä¸å®šè©ã®é–¢ä¿‚ã‚’åˆ†æ
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            head = inf_token['head']
            
            # ä¸»æ–‡ã®æ§‹é€ ã‚’æŠ½å‡º
            for token in doc:
                if token.dep_ == 'nsubj':
                    main_slots['S'] = token.text
                elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                    main_slots['V'] = token.text
                elif token.dep_ == 'dobj':
                    main_slots['O1'] = token.text
            
            # ä¸å®šè©ã‚’ä¿®é£¾èªã¨ã—ã¦åˆ†é¡
            main_slots['M2'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adjectival',
                'usage_type': 'adjectival',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adverbial_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å‰¯è©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ å‰¯è©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¸»æ–‡ã®æ§‹é€ ã‚’æŠ½å‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                main_slots['S'] = token.text
            elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                main_slots['V'] = token.text
            elif token.dep_ == 'dobj' and token.head.dep_ == 'ROOT':
                # ãƒ¡ã‚¤ãƒ³å‹•è©ã®ç›´æ¥ç›®çš„èªã®ã¿
                main_slots['O1'] = token.text
        
        # å‰¯è©çš„ä¸å®šè©ã®è©³ç´°åˆ†æã¨å‡ºåŠ›å½¢å¼æ±ºå®š
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            # ä¸å®šè©ã®æ„å‘³çš„åˆ†é¡ï¼ˆç›®çš„ vs çµæœ vs ãã®ä»–ï¼‰
            infinitive_purpose = self._is_purpose_infinitive(doc, inf_token)
            infinitive_result = self._is_result_infinitive(doc, inf_token)
            
            if infinitive_purpose:
                # ç›®çš„ã®å‰¯è©çš„ä¸å®šè©ï¼šã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡ºåŠ›
                print(f"ğŸ¯ ç›®çš„ã®å‰¯è©çš„ä¸å®šè©ï¼šã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡¦ç†")
                main_slots['M3'] = ""  # ç©ºæ–‡å­—åˆ—
                
                # ä¸å®šè©éƒ¨åˆ†ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«åˆ†è§£
                sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"
                sub_slots['_parent_slot'] = "M3"
                
                # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                for token in doc:
                    if (token.head == main_verb and 
                        token.dep_ == 'dobj'):
                        # "his friend" ã®ã‚ˆã†ã«æ‰€æœ‰æ ¼+åè©ã‚’çµåˆ
                        obj_text = self._get_full_noun_phrase(token)
                        sub_slots['sub-o1'] = obj_text
                        break
                        
            elif infinitive_result:
                # çµæœã®å‰¯è©çš„ä¸å®šè©ï¼šAux+Vå½¢å¼ã§å‡ºåŠ›ï¼ˆä¾‹ï¼šgrew up to becomeï¼‰
                print(f"ğŸ¯ çµæœã®å‰¯è©çš„ä¸å®šè©ï¼šAux+Vå½¢å¼ã§å‡¦ç†")
                
                # ãƒ¡ã‚¤ãƒ³å‹•è©ã«ä»˜å±ã™ã‚‹è¦ç´ ã‚’å«ã‚ã¦Auxæ§‹ç¯‰
                main_verb_head = inf_token['head']
                
                # "grew up" ã®ã‚ˆã†ãªå¥å‹•è©ï¼‹toä¸å®šè©ã‚’ä¸€ã¤ã®Auxã¨ã—ã¦æ‰±ã†
                aux_parts = [main_verb_head.text]
                
                # å¥å‹•è©ã®å‰¯è©çš„å°è©ï¼ˆprtï¼‰ã‚’æ¤œç´¢
                for child in main_verb_head.children:
                    if child.dep_ == 'prt':  # particleï¼ˆup, down, etc.ï¼‰
                        aux_parts.append(child.text)
                
                # toä¸å®šè©éƒ¨åˆ†ã‚’è¿½åŠ 
                aux_parts.extend([to_token.text])
                
                main_slots['Aux'] = ' '.join(aux_parts)
                main_slots['V'] = main_verb.text
                
                # ä¸å®šè©ã®è£œèªã‚’æ¤œå‡ºï¼ˆbecome a teacherã®a teacherï¼‰
                for token in doc:
                    if (token.head == main_verb and 
                        token.dep_ in ['attr', 'dobj']):
                        # "a teacher" ã®ã‚ˆã†ãªåè©å¥ã‚’çµåˆ
                        comp_text = self._get_full_noun_phrase(token)
                        main_slots['C1'] = comp_text
                        break
            else:
                # çµæœãƒ»æ–¹æ³•ç­‰ã®å‰¯è©çš„ä¸å®šè©ï¼šãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ 
                print(f"ğŸ¯ çµæœ/æ–¹æ³•ã®å‰¯è©çš„ä¸å®šè©ï¼šãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡¦ç†")
                main_slots['M2'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adverbial',
                'usage_type': 'adverbial',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_basic_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªä¸å®šè©å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ åŸºæœ¬ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # åŸºæœ¬çš„ãªæ–‡æ§‹é€ æŠ½å‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                main_slots['S'] = token.text
            elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                main_slots['V'] = token.text
        
        # ä¸å®šè©ã‚’ç›®çš„èªã¨ã—ã¦åˆ†é¡
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            main_slots['O1'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_basic',
                'usage_type': 'basic',
                'confidence': 0.8,
                'spacy_analysis': True
            }
        }
    
    def _is_purpose_infinitive(self, doc, inf_token: Dict) -> bool:
        """
        ä¸å®šè©ãŒç›®çš„ã®å‰¯è©çš„ç”¨æ³•ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            doc: spaCyè§£æçµæœ
            inf_token: ä¸å®šè©ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±
            
        Returns:
            bool: ç›®çš„ã®å‰¯è©çš„ç”¨æ³•ã®å ´åˆTrue
        """
        # åŸºæœ¬çš„ã« "came to see" ã®ã‚ˆã†ãªç§»å‹•å‹•è©ï¼‹toä¸å®šè©ã¯ç›®çš„ç”¨æ³•
        main_verb_lemma = inf_token['head'].lemma_.lower()
        
        # ç§»å‹•ãƒ»åˆ°ç€ã‚’è¡¨ã™å‹•è© + toä¸å®šè© = ç›®çš„ç”¨æ³•
        purpose_verbs = ['come', 'go', 'run', 'walk', 'drive', 'travel', 'move', 'rush', 'hurry']
        
        if main_verb_lemma in purpose_verbs:
            return True
            
        # ãã®ä»–ã®åˆ¤å®šæ¡ä»¶ï¼ˆå°†æ¥æ‹¡å¼µå¯èƒ½ï¼‰
        return False
    
    def _is_result_infinitive(self, doc, inf_token: Dict) -> bool:
        """
        ä¸å®šè©ãŒçµæœã®å‰¯è©çš„ç”¨æ³•ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            doc: spaCyè§£æçµæœ
            inf_token: ä¸å®šè©ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±
            
        Returns:
            bool: çµæœã®å‰¯è©çš„ç”¨æ³•ã®å ´åˆTrue
        """
        # "grew up to become" ã®ã‚ˆã†ãªæˆé•·ãƒ»å¤‰åŒ–å‹•è© + toä¸å®šè© = çµæœç”¨æ³•
        main_verb_lemma = inf_token['head'].lemma_.lower()
        
        # æˆé•·ãƒ»å¤‰åŒ–ã‚’è¡¨ã™å‹•è© + toä¸å®šè© = çµæœç”¨æ³•
        result_verbs = ['grow', 'rise', 'wake', 'turn', 'come', 'live', 'get']
        
        if main_verb_lemma in result_verbs:
            # å¥å‹•è©ï¼ˆgrow up, wake upç­‰ï¼‰ã®å ´åˆã‚‚çµæœç”¨æ³•
            for child in inf_token['head'].children:
                if child.dep_ == 'prt':  # particle
                    return True
            return True
            
        return False
    
    def _get_full_noun_phrase(self, token) -> str:
        """
        åè©å¥å…¨ä½“ã‚’å–å¾—ï¼ˆæ‰€æœ‰æ ¼ç­‰ã‚’å«ã‚€ï¼‰
        
        Args:
            token: ä¸­å¿ƒã¨ãªã‚‹åè©ãƒˆãƒ¼ã‚¯ãƒ³
            
        Returns:
            str: å®Œå…¨ãªåè©å¥
        """
        # æ‰€æœ‰æ ¼ã‚„å½¢å®¹è©ç­‰ã®ä¿®é£¾èªã‚’å«ã‚€åè©å¥ã‚’æ§‹ç¯‰
        phrase_tokens = []
        
        # å‰ç½®ä¿®é£¾èªã‚’åé›†
        for child in token.children:
            if child.dep_ in ['poss', 'det', 'amod', 'compound']:
                phrase_tokens.append((child.i, child.text))
        
        # ä¸­å¿ƒèªã‚’è¿½åŠ 
        phrase_tokens.append((token.i, token.text))
        
        # ä½ç½®é †ã§ã‚½ãƒ¼ãƒˆã—ã¦çµåˆ
        phrase_tokens.sort(key=lambda x: x[0])
        return ' '.join([t[1] for t in phrase_tokens])

    # ========== é«˜åº¦ãªä¸å®šè©æ§‹æ–‡å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆcase164-170ï¼‰ ==========
    
    def _process_perfect_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        å®Œäº†ä¸å®šè©ã®å‡¦ç†ï¼ˆcase164: He seems to have finished his workï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ å®Œäº†ä¸å®šè©å‡¦ç†: {text}")
        
        # æ–‡æ§‹é€ ã‚’ç‰¹å®š: He seems to have finished his work
        main_subject = None      # He
        governing_verb = None    # seems  
        perfect_verb = None      # finished
        object_part = None       # his work
        
        # spaCyè§£æã§å„è¦ç´ ã‚’æ¤œå‡º
        for token in doc:
            if token.dep_ == 'nsubj' and token.head.pos_ == 'VERB':
                main_subject = token.text
            elif token.lemma_ in ['seem', 'appear', 'happen'] and token.pos_ == 'VERB':
                governing_verb = token.text
            elif token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                perfect_verb = token.text
                # å®Œäº†ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                for child in token.children:
                    if child.dep_ == 'dobj':
                        # æ‰€æœ‰æ ¼ã‚‚å«ã‚ã¦ç›®çš„èªã‚’æ§‹ç¯‰
                        obj_parts = []
                        for obj_child in child.children:
                            if obj_child.dep_ == 'poss':
                                obj_parts.append(obj_child.text)
                        obj_parts.append(child.text)
                        object_part = ' '.join(obj_parts)
        
        print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{main_subject}'")
        print(f"   ğŸ“ å®Œäº†åŠ©å‹•è©çµ±åˆ: Aux = '{governing_verb} to have'")
        print(f"   ğŸ“ éå»åˆ†è©æ¤œå‡º: V = '{perfect_verb}'")
        if object_part:
            print(f"   ğŸ“ ç›®çš„èªæ¤œå‡º: O1 = '{object_part}'")
        
        # æœŸå¾…ã•ã‚Œã‚‹å½¢å¼ã§çµæœã‚’æ§‹ç¯‰
        main_slots = {
            'S': main_subject or '',
            'Aux': f"{governing_verb} to have" if governing_verb else "to have",
            'V': perfect_verb or '',
            'O1': object_part or ''
        }
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': {},
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_perfect',
                'usage_type': 'perfect_infinitive',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_passive_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        å—å‹•ä¸å®šè©ã®å‡¦ç†ï¼ˆcase165: This problem needs to be solved quicklyï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ å—å‹•ä¸å®šè©å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'passive_infinitive':
                be_verb = inf_token['main_verb']  # be
                
                # çœŸã®ä¸»å‹•è©ã‚’æ¢ã™: beã®æ”¯é…èªã®æ”¯é…èªã‚’ãƒã‚§ãƒƒã‚¯
                governing_verb = be_verb.head
                if governing_verb.dep_ == 'xcomp':
                    # xcompã®å ´åˆã¯ã€ãã®æ”¯é…èªãŒçœŸã®ä¸»å‹•è©
                    main_verb = governing_verb.head
                else:
                    main_verb = governing_verb
                
                print(f"   ğŸ” beå‹•è©: {be_verb.text}")
                print(f"   ğŸ” beå‹•è©ã®æ”¯é…èª: {governing_verb.text} (dep: {governing_verb.dep_})")
                print(f"   ğŸ” DEBUG: governing_verb tag = {governing_verb.tag_}")
                print(f"   ğŸ” çœŸã®ä¸»å‹•è©å€™è£œ: {main_verb.text}")
                
                # éå»åˆ†è©ã¨ä¿®é£¾èªã‚’æ¢ã™
                past_participle = None
                
                # governing_verbè‡ªèº«ãŒéå»åˆ†è©ã‹ãƒã‚§ãƒƒã‚¯
                if governing_verb.tag_ == 'VBN':
                    past_participle = governing_verb
                    print(f"   ğŸ” governing_verbè‡ªèº«ãŒéå»åˆ†è©: {governing_verb.text}")
                adverb = None
                
                # beå‹•è©ã®å­è¦ç´ ã‹ã‚‰éå»åˆ†è©ã‚’æ¢ã™
                print(f"   ğŸ” DEBUG: beå‹•è©'{be_verb.text}'ã®å­è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯")
                for child in be_verb.children:
                    print(f"   ğŸ” DEBUG: beå‹•è©ã®å­: {child.text} (tag: {child.tag_}, dep: {child.dep_})")
                    if child.tag_ == 'VBN':  # éå»åˆ†è©
                        past_participle = child
                        print(f"   ğŸ” beå‹•è©ã®å­ã‹ã‚‰éå»åˆ†è©ç™ºè¦‹: {child.text}")
                    elif child.dep_ == 'advmod':  # å‰¯è©ä¿®é£¾èª
                        adverb = child.text
                        print(f"   ğŸ” beå‹•è©ã®å­ã‹ã‚‰å‰¯è©ç™ºè¦‹: {child.text}")
                
                # beå‹•è©ã®å…„å¼Ÿï¼ˆgoverningã®å­è¦ç´ ï¼‰ã‹ã‚‰éå»åˆ†è©ã‚’æ¢ã™
                if not past_participle:
                    print(f"   ğŸ” DEBUG: governing verb '{governing_verb.text}'ã®å­è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯")
                    for child in governing_verb.children:
                        print(f"   ğŸ” DEBUG: governing verbã®å­: {child.text} (tag: {child.tag_}, dep: {child.dep_})")
                        if child.tag_ == 'VBN':
                            past_participle = child
                            print(f"   ğŸ” governing verbã®å­ã‹ã‚‰éå»åˆ†è©ç™ºè¦‹: {child.text}")
                
                # éå»åˆ†è©ã®å­è¦ç´ ã‹ã‚‰å‰¯è©ã‚’æ¢ã™
                if past_participle and not adverb:
                    for child in past_participle.children:
                        if child.dep_ == 'advmod':
                            adverb = child.text
                            print(f"   ğŸ” éå»åˆ†è©ã®å­ã‹ã‚‰å‰¯è©ç™ºè¦‹: {child.text}")
                            break
                
                # æ–‡å…¨ä½“ã‹ã‚‰ 'quickly' ã®ã‚ˆã†ãªå‰¯è©ã‚’æ¢ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                if not adverb:
                    for token in doc:
                        if token.pos_ == 'ADV' and token.dep_ == 'advmod':
                            # éå»åˆ†è©ã«ä¾å­˜ã™ã‚‹å‰¯è©ã‚’å„ªå…ˆ
                            if past_participle and token.head == past_participle:
                                adverb = token.text
                                print(f"   ğŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éå»åˆ†è©ã«ä¾å­˜ã™ã‚‹å‰¯è©ç™ºè¦‹: {token.text}")
                                break
                            # ã¾ãŸã¯å‹•è©ã«ä¾å­˜ã™ã‚‹å‰¯è©
                            elif token.head == governing_verb:
                                adverb = token.text
                                print(f"   ğŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: governing verbã«ä¾å­˜ã™ã‚‹å‰¯è©ç™ºè¦‹: {token.text}")
                                break
                
                # ä¸»èªã‚’æ¤œå‡º: çœŸã®ä¸»å‹•è©ã®ä¸»èªã‚’æ¢ã™
                subject = None
                for token in doc:
                    if token.dep_ == 'nsubj' and token.head == main_verb:
                        subject = self._get_full_noun_phrase(token)
                        break
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                print(f"   ğŸ“ ä¸»å‹•è©æ¤œå‡º: V = '{main_verb.text}'")
                print(f"   ğŸ“ å—å‹•ä¸å®šè©ç›®çš„èª: O1 = ç©ºï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆä½¿ç”¨ï¼‰")
                print(f"   ğŸ“ å—å‹•åŠ©å‹•è©æ¤œå‡º: sub-aux = 'to be'")
                print(f"   ğŸ“ å—å‹•å‹•è©æ¤œå‡º: sub-v = '{past_participle.text if past_participle else 'unknown'}'")
                if adverb:
                    print(f"   ğŸ“ å‰¯è©ä¿®é£¾èªæ¤œå‡º: sub-m2 = '{adverb}'")
                
                result = {
                    'success': True,
                    'main_slots': {
                        'S': subject or '',
                        'V': main_verb.text,
                        'O1': ''
                    },
                    'sub_slots': {
                        'sub-aux': 'to be',
                        'sub-v': past_participle.text if past_participle else '',
                        '_parent_slot': 'O1'
                    },
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_passive',
                        'usage_type': 'passive_infinitive',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
                
                if adverb:
                    result['sub_slots']['sub-m2'] = adverb
                
                return result
        
        return {'success': False, 'error': 'å—å‹•ä¸å®šè©ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
    
    def _process_wh_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        ç–‘å•è©+ä¸å®šè©ã®å‡¦ç†ï¼ˆcase166: I don't know what to doï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ ç–‘å•è©+ä¸å®šè©å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'wh_infinitive':
                main_verb = inf_token['main_verb']
                wh_word = inf_token['wh_word']
                head = inf_token['head']
                
                # ä¸»èªã¨åŠ©å‹•è©ã‚’æ¤œå‡º
                subject = None
                auxiliary = None
                
                # ã‚ˆã‚Šæ­£ç¢ºãªä¸»èªãƒ»åŠ©å‹•è©æ¤œå‡º
                for token in doc:
                    if token.dep_ == 'nsubj' and token.head == head:
                        subject = token.text
                    elif token.dep_ == 'aux' and token.head == head:
                        # åŠ©å‹•è©ã¨å¦å®šã®çµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯
                        neg_token = None
                        for child in token.head.children:
                            if child.dep_ == 'neg':
                                neg_token = child
                                break
                        
                        if neg_token:
                            auxiliary = f"{token.text}{neg_token.text}"
                        else:
                            auxiliary = token.text
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                if auxiliary:
                    print(f"   ğŸ“ åŠ©å‹•è©æ¤œå‡º: Aux = '{auxiliary}'")
                print(f"   ğŸ“ ä¸»å‹•è©æ¤œå‡º: V = '{head.text}'")
                print(f"   ğŸ“ ç–‘å•è©+ä¸å®šè©ç›®çš„èª: O1 = ç©ºï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆä½¿ç”¨ï¼‰")
                print(f"   ğŸ“ ç–‘å•è©æ¤œå‡º: sub-o1 = '{wh_word.text}'")
                print(f"   ğŸ“ ä¸å®šè©å‹•è©æ¤œå‡º: sub-v = 'to {main_verb.text}'")
                
                # main_slotsã«åŠ©å‹•è©ã‚‚å«ã‚ã‚‹
                main_slots = {
                    'S': subject or '',
                    'V': head.text,
                    'O1': ''
                }
                
                if auxiliary:
                    main_slots['Aux'] = auxiliary
                
                result = {
                    'success': True,
                    'main_slots': main_slots,
                    'sub_slots': {
                        'sub-o1': wh_word.text,
                        'sub-v': f'to {main_verb.text}',
                        '_parent_slot': 'O1'
                    },
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_wh_question',
                        'usage_type': 'wh_infinitive',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
                
                if auxiliary:
                    result['main_slots']['Aux'] = auxiliary
                
                return result
        
        return {'success': False, 'error': 'ç–‘å•è©+ä¸å®šè©ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
    
    def _process_causative_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        ä½¿å½¹æ§‹æ–‡ã®å‡¦ç†ï¼ˆcase167: I want you to help meï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ ä½¿å½¹æ§‹æ–‡å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'causative':
                main_verb = inf_token['main_verb']
                causative_verb = inf_token['causative_verb']
                object_person = inf_token.get('object')
                
                # ä¸»èªã‚’æ¤œå‡º
                subject = None
                for token in doc:
                    if token.dep_ == 'nsubj' and token.head == causative_verb:
                        subject = token.text
                        break
                
                # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                infinitive_object = None
                for child in main_verb.children:
                    if child.dep_ == 'dobj':
                        infinitive_object = child.text
                        break
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                print(f"   ğŸ“ ä½¿å½¹å‹•è©æ¤œå‡º: V = '{causative_verb.text}'")
                if object_person:
                    print(f"   ğŸ“ ç›´æ¥ç›®çš„èªæ¤œå‡º: O1 = '{object_person.text}'")
                else:
                    print(f"   âš ï¸ ç›´æ¥ç›®çš„èªæ¤œå‡ºå¤±æ•—")
                print(f"   ğŸ“ ç›®çš„èªè£œèª: C2 = ç©ºï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆä½¿ç”¨ï¼‰")
                print(f"   ğŸ“ ä¸å®šè©å‹•è©æ¤œå‡º: sub-v = 'to {main_verb.text}'")
                if infinitive_object:
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{infinitive_object}'")
                
                result = {
                    'success': True,
                    'main_slots': {
                        'S': subject or '',
                        'V': causative_verb.text,
                        'O1': object_person.text if object_person else '',
                        'C2': ''
                    },
                    'sub_slots': {
                        'sub-v': f'to {main_verb.text}',
                        'sub-o1': infinitive_object or '',
                        '_parent_slot': 'C2'
                    },
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_causative',
                        'usage_type': 'causative',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
                
                if infinitive_object:
                    result['sub_slots']['sub-o1'] = infinitive_object
                
                return result
        
        return {'success': False, 'error': 'ä½¿å½¹æ§‹æ–‡ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
    
    def _process_be_about_to_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        be about toæ§‹æ–‡ã®å‡¦ç†ï¼ˆcase168: The meeting is about to startï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ be about toæ§‹æ–‡å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'be_about_to':
                main_verb = inf_token['main_verb']
                about_token = inf_token['about_token']
                
                # ä¸»èªã¨beå‹•è©ã‚’æ¤œå‡º
                subject = None
                be_verb = None
                
                for token in doc:
                    if token.dep_ == 'nsubj':
                        subject = self._get_full_noun_phrase(token)
                    elif token.lemma_ == 'be' and token.pos_ == 'AUX':
                        be_verb = token.text
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                print(f"   ğŸ“ be about toåŠ©å‹•è©çµ±åˆ: Aux = '{be_verb} about to'")
                print(f"   ğŸ“ ä¸å®šè©å‹•è©æ¤œå‡º: V = '{main_verb.text}'")
                
                return {
                    'success': True,
                    'main_slots': {
                        'S': subject or '',
                        'Aux': f'{be_verb} about to' if be_verb else 'about to',
                        'V': main_verb.text
                    },
                    'sub_slots': {},
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_be_about_to',
                        'usage_type': 'be_about_to',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
        
        return {'success': False, 'error': 'be about toæ§‹æ–‡ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
    
    def _process_in_order_to_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        in order toæ§‹æ–‡ã®å‡¦ç†ï¼ˆcase169: She studies hard in order to pass the examï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ in order toæ§‹æ–‡å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'in_order_to':
                main_verb = inf_token['main_verb']
                
                # ä¸»èªã¨ä¸»å‹•è©ã‚’æ¤œå‡º
                subject = None
                main_verb_word = None
                adverb = None
                
                for token in doc:
                    if token.dep_ == 'nsubj':
                        subject = token.text
                    elif token.dep_ == 'ROOT':
                        main_verb_word = token.text
                    elif token.dep_ == 'advmod' and token.head.dep_ == 'ROOT':
                        adverb = token.text
                
                # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                infinitive_object = None
                for child in main_verb.children:
                    if child.dep_ == 'dobj':
                        infinitive_object = self._get_full_noun_phrase(child)
                        break
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                print(f"   ğŸ“ ä¸»å‹•è©æ¤œå‡º: V = '{main_verb_word}'")
                if adverb:
                    print(f"   ğŸ“ å‰¯è©ä¿®é£¾èªæ¤œå‡º: M2 = '{adverb}'")
                print(f"   ğŸ“ ç›®çš„ã®å‰¯è©å¥: M3 = ç©ºï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆä½¿ç”¨ï¼‰")
                print(f"   ğŸ“ in order toå‹•è©æ¤œå‡º: sub-v = 'in order to {main_verb.text}'")
                if infinitive_object:
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{infinitive_object}'")
                
                result = {
                    'success': True,
                    'main_slots': {
                        'S': subject or '',
                        'V': main_verb_word or '',
                        'M3': ''
                    },
                    'sub_slots': {
                        'sub-v': f'in order to {main_verb.text}',
                        '_parent_slot': 'M3'
                    },
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_in_order_to',
                        'usage_type': 'in_order_to',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
                
                if adverb:
                    result['main_slots']['M2'] = adverb
                if infinitive_object:
                    result['sub_slots']['sub-o1'] = infinitive_object
                
                return result
        
        return {'success': False, 'error': 'in order toæ§‹æ–‡ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
    
    def _process_so_as_to_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """
        so as toæ§‹æ–‡ã®å‡¦ç†ï¼ˆcase170: He left early so as to avoid trafficï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            slots: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ“ so as toæ§‹æ–‡å‡¦ç†: {text}")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            if inf_token['pattern'] == 'so_as_to':
                main_verb = inf_token['main_verb']
                
                # ä¸»èªã¨ä¸»å‹•è©ã‚’æ¤œå‡º
                subject = None
                main_verb_word = None
                adverb = None
                
                for token in doc:
                    if token.dep_ == 'nsubj':
                        subject = token.text
                    elif token.dep_ == 'ROOT':
                        main_verb_word = token.text
                    elif token.dep_ == 'advmod' and token.head.dep_ == 'ROOT':
                        adverb = token.text
                
                # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                infinitive_object = None
                for child in main_verb.children:
                    if child.dep_ == 'dobj':
                        infinitive_object = child.text
                        break
                
                print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{subject}'")
                print(f"   ğŸ“ ä¸»å‹•è©æ¤œå‡º: V = '{main_verb_word}'")
                if adverb:
                    print(f"   ğŸ“ å‰¯è©ä¿®é£¾èªæ¤œå‡º: M2 = '{adverb}'")
                print(f"   ğŸ“ ç›®çš„ã®å‰¯è©å¥: M3 = ç©ºï¼ˆã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆä½¿ç”¨ï¼‰")
                print(f"   ğŸ“ so as toå‹•è©æ¤œå‡º: sub-v = 'so as to {main_verb.text}'")
                if infinitive_object:
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{infinitive_object}'")
                
                result = {
                    'success': True,
                    'main_slots': {
                        'S': subject or '',
                        'V': main_verb_word or '',
                        'M3': ''
                    },
                    'sub_slots': {
                        'sub-v': f'so as to {main_verb.text}',
                        '_parent_slot': 'M3'
                    },
                    'collaboration': ['infinitive'],
                    'primary_handler': 'infinitive',
                    'metadata': {
                        'handler': 'infinitive_so_as_to',
                        'usage_type': 'so_as_to',
                        'confidence': 0.9,
                        'spacy_analysis': True
                    }
                }
                
                if adverb:
                    result['main_slots']['M2'] = adverb
                if infinitive_object:
                    result['sub_slots']['sub-o1'] = infinitive_object
                
                return result
        
        return {'success': False, 'error': 'so as toæ§‹æ–‡ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ'}
