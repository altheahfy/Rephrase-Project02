#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
InfinitiveHandler: ä¸å®šè©å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
toä¸å®šè©ã®åè©çš„ãƒ»å½¢å®¹è©çš„ãƒ»å‰¯è©çš„ç”¨æ³•ã®å°‚é–€åˆ†è§£
å°‚é–€åˆ†æ‹…å‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æï¼ˆå“è©åˆ†æ + ä¾å­˜é–¢ä¿‚ï¼‰+ äººé–“çš„æ–‡æ³•èªè­˜
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¥µåŠ›æ’é™¤ãƒ»æ±ç”¨çš„ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ
"""

import spacy
from typing import Dict, Any, List, Tuple, Optional

class InfinitiveHandler:
    """ä¸å®šè©å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆHuman Grammar Pattern + spaCyè§£æï¼‰"""
    
    def __init__(self, nlp_model=None, collaborators=None):
        """
        åˆæœŸåŒ–
        
        Args:
            nlp_model: spaCyãƒ¢ãƒ‡ãƒ«ï¼ˆå“è©åˆ†æãƒ»ä¾å­˜é–¢ä¿‚è§£æç”¨ï¼‰
            collaborators: ä»–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨ã®å”åŠ›ä½“åˆ¶
        """
        self.nlp = nlp_model or spacy.load('en_core_web_sm')
        self.collaborators = collaborators or {}
        
        print("ğŸ”§ InfinitiveHandleråˆæœŸåŒ–: Human Grammar Pattern + spaCyè§£æ")
    
    def can_handle(self, text: str) -> bool:
        """
        ä¸å®šè©æ§‹æ–‡ã‚’å‡¦ç†å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            bool: å‡¦ç†å¯èƒ½ãªå ´åˆTrue
        """
        try:
            doc = self.nlp(text)
            
            # spaCyä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹ä¸å®šè©æ¤œå‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
            for token in doc:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: to + VERB ã®ç›´æ¥çš„ãªå­é–¢ä¿‚
                if (token.text.lower() == 'to' and 
                    token.pos_ == 'PART' and  # to ã¯ PART (particle) ã¨ã—ã¦åˆ†é¡
                    any(child.pos_ == 'VERB' for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: VERB (advcl/xcomp) + to (aux) ã®é–¢ä¿‚ï¼ˆcase159å¯¾å¿œï¼‰
                if (token.pos_ == 'VERB' and 
                    token.dep_ in ['advcl', 'xcomp'] and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³3: xcomp (open clausal complement) ã§ã®ä¸å®šè©æ¤œå‡º
                if token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                    # xcompã®å‰ã«toãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    for child in token.children:
                        if child.text.lower() == 'to' and child.dep_ == 'aux':
                            return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³4: csubj (clausal subject) ã§ã®ä¸å®šè©æ¤œå‡º - åè©çš„ç”¨æ³•
                if (token.pos_ == 'VERB' and 
                    token.dep_ == 'csubj' and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³5: relcl (relative clause) ã§ã®ä¸å®šè©æ¤œå‡º - å½¢å®¹è©çš„ç”¨æ³•
                if (token.pos_ == 'VERB' and 
                    token.dep_ == 'relcl' and
                    any(child.text.lower() == 'to' and child.dep_ == 'aux' 
                        for child in token.children)):
                    return True
            
            return False
            
        except Exception as e:
            print(f"âš ï¸ can_handleè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process(self, text: str) -> Dict[str, Any]:
        """
        ä¸å®šè©æ§‹æ–‡ã®åˆ†è§£å‡¦ç†
        
        Args:
            text: å‡¦ç†å¯¾è±¡ã®è‹±æ–‡
            
        Returns:
            Dict[str, Any]: åˆ†è§£çµæœ
        """
        print(f"ğŸ”§ InfinitiveHandlerå‡¦ç†é–‹å§‹: '{text}'")
        
        try:
            # spaCyè§£æ
            doc = self.nlp(text)
            
            # ä¸å®šè©ã®æ¤œå‡ºã¨åˆ†é¡
            infinitive_info = self._analyze_infinitive_structure(doc, text)
            
            if infinitive_info['found']:
                # ä¸å®šè©ç”¨æ³•ã«å¿œã˜ãŸå‡¦ç†
                return self._process_by_usage_type(doc, text, infinitive_info)
            else:
                return {
                    'success': False,
                    'error': 'ä¸å®šè©æ§‹æ–‡ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ',
                    'text': text
                }
                
        except Exception as e:
            print(f"âŒ InfinitiveHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'success': False,
                'error': f'InfinitiveHandlerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'text': text
            }
    
    def _analyze_infinitive_structure(self, doc, text: str) -> Dict[str, Any]:
        """
        ä¸å®šè©æ§‹é€ ã®åˆ†æï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            
        Returns:
            Dict[str, Any]: ä¸å®šè©æ§‹é€ æƒ…å ±
        """
        print(f"ğŸ” ä¸å®šè©æ§‹é€ è§£æé–‹å§‹: spaCyä¾å­˜é–¢ä¿‚åˆ†æ")
        
        infinitive_info = {
            'found': False,
            'infinitive_tokens': [],
            'usage_patterns': [],
            'syntactic_role': None,
            'dependency_info': []
        }
        
        # spaCyä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹ä¸å®šè©æ¤œå‡º
        for token in doc:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: xcomp (open clausal complement) + aux=to
            if token.dep_ == 'xcomp' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'xcomp_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… xcompä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: advcl (adverbial clause) + aux/mark=to  
            elif token.dep_ == 'advcl' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ in ['mark', 'aux']:
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'advcl_mark',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… advclä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ccomp (clausal complement) + aux=to
            elif token.dep_ == 'ccomp' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'ccomp_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… ccompä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: csubj (clausal subject) + aux=to - åè©çš„ç”¨æ³•ãƒ»ä¸»èª
            elif token.dep_ == 'csubj' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'csubj_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… csubjä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³5: relcl (relative clause) + aux=to - å½¢å®¹è©çš„ç”¨æ³•
            elif token.dep_ == 'relcl' and token.pos_ == 'VERB':
                for child in token.children:
                    if child.text.lower() == 'to' and child.dep_ == 'aux':
                        infinitive_info['found'] = True
                        infinitive_info['infinitive_tokens'].append({
                            'main_verb': token,
                            'to_token': child,
                            'pattern': 'relcl_aux',
                            'head': token.head,
                            'dependency': token.dep_
                        })
                        print(f"   âœ… relclä¸å®šè©æ¤œå‡º: '{child.text} {token.text}' (head: {token.head.text})")
        
        # ç”¨æ³•åˆ†é¡ï¼ˆä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰
        if infinitive_info['found']:
            infinitive_info['syntactic_role'] = self._analyze_syntactic_role(doc, infinitive_info)
        
        return infinitive_info
    
    def _analyze_syntactic_role(self, doc, infinitive_info: Dict) -> str:
        """
        ä¸å®šè©ã®çµ±èªçš„å½¹å‰²åˆ†æï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            infinitive_info: ä¸å®šè©æƒ…å ±
            
        Returns:
            str: çµ±èªçš„å½¹å‰²
        """
        print(f"ğŸ§  çµ±èªçš„å½¹å‰²åˆ†æ: Human Grammar Pattern")
        
        for inf_token in infinitive_info['infinitive_tokens']:
            pattern = inf_token['pattern']
            head = inf_token['head']
            dependency = inf_token['dependency']
            
            # xcomp: é€šå¸¸ã¯ç›®çš„èªè£œèªï¼ˆå½¢å®¹è©çš„ãƒ»å‰¯è©çš„ç”¨æ³•ï¼‰
            if pattern == 'xcomp_aux':
                if head.pos_ == 'VERB':
                    # want to do å½¢å¼ã¯åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰
                    if head.lemma_.lower() in ['want', 'need', 'like', 'love', 'hate', 'prefer', 'decide', 'hope', 'plan', 'try', 'attempt']:
                        print(f"   ğŸ“ xcomp + æ¬²æ±‚ãƒ»æ„æ€å‹•è© â†’ åè©çš„ç”¨æ³•ï¼ˆç›®çš„èªï¼‰")
                        return 'nominal_object'
                    else:
                        print(f"   ğŸ“ xcomp + å‹•è©head â†’ ç›®çš„èªè£œèªï¼ˆå½¢å®¹è©çš„ç”¨æ³•å€™è£œï¼‰")
                        return 'adjectival_complement'
                    
            # advcl: å‰¯è©ç¯€ï¼ˆå‰¯è©çš„ç”¨æ³•ï¼‰
            elif pattern == 'advcl_mark':
                print(f"   ğŸ“ advcl + mark â†’ å‰¯è©ç¯€ï¼ˆå‰¯è©çš„ç”¨æ³•ï¼‰")
                return 'adverbial_clause'
                
            # ccomp: è£œèªç¯€ï¼ˆåè©çš„ç”¨æ³•å€™è£œï¼‰
            elif pattern == 'ccomp_aux':
                print(f"   ğŸ“ ccomp + è£œèªç¯€ â†’ åè©çš„ç”¨æ³•å€™è£œ")
                return 'nominal_complement'
                
            # csubj: ç¯€ä¸»èªï¼ˆåè©çš„ç”¨æ³•ãƒ»ä¸»èªï¼‰
            elif pattern == 'csubj_aux':
                print(f"   ğŸ“ csubj + ç¯€ä¸»èª â†’ åè©çš„ç”¨æ³•ï¼ˆä¸»èªï¼‰")
                return 'nominal_subject'
                
            # relcl: é–¢ä¿‚ç¯€ãƒ»å½¢å®¹è©çš„ç”¨æ³•
            elif pattern == 'relcl_aux':
                print(f"   ğŸ“ relcl + é–¢ä¿‚ç¯€ â†’ å½¢å®¹è©çš„ç”¨æ³•")
                return 'adjectival_modifier'
        
        return 'unknown'
    
    def _process_by_usage_type(self, doc, text: str, infinitive_info: Dict) -> Dict[str, Any]:
        """
        ç”¨æ³•ã‚¿ã‚¤ãƒ—åˆ¥ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            text: å…ƒã®è‹±æ–‡
            infinitive_info: ä¸å®šè©æƒ…å ±
            
        Returns:
            Dict[str, Any]: å‡¦ç†çµæœ
        """
        print(f"ğŸ¯ ç”¨æ³•åˆ¥å‡¦ç†é–‹å§‹: {infinitive_info.get('syntactic_role', 'unknown')}")
        
        # ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡ã®å®Ÿè¡Œ
        slots = self._classify_slot_types(doc, infinitive_info)
        
        syntactic_role = infinitive_info.get('syntactic_role', 'unknown')
        
        if syntactic_role == 'nominal_complement':
            return self._process_nominal_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'nominal_subject':
            return self._process_nominal_subject_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'nominal_object':
            return self._process_nominal_object_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adjectival_complement':
            return self._process_adjectival_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adjectival_modifier':
            return self._process_adjectival_modifier_infinitive(doc, text, infinitive_info, slots)
        elif syntactic_role == 'adverbial_clause':
            return self._process_adverbial_infinitive(doc, text, infinitive_info, slots)
        else:
            return self._process_basic_infinitive(doc, text, infinitive_info, slots)
    
    def _classify_slot_types(self, doc, infinitive_info: Dict[str, Any]) -> Dict[str, str]:
        """
        ä¸å®šè©æ§‹é€ ã®ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡ï¼ˆspaCyä¾å­˜é–¢ä¿‚è§£æãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            doc: spaCyè§£æçµæœ
            infinitive_info: ä¸å®šè©æ§‹é€ æƒ…å ±
            
        Returns:
            Dict[str, str]: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡çµæœ
        """
        print(f"ğŸ¯ ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡: spaCyä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹è©³ç´°è§£æ")
        
        slots = {}
        
        for inf_token in infinitive_info['infinitive_tokens']:
            main_verb = inf_token['main_verb']
            to_token = inf_token['to_token']
            head = inf_token['head']
            pattern = inf_token['pattern']
            
            # ä¸å®šè©ãƒãƒ¼ã‚«ãƒ¼åˆ†é¡
            slots[to_token.text] = 'inf-marker'
            print(f"   ğŸ“Œ '{to_token.text}' â†’ inf-marker")
            
            # ä¸å®šè©å‹•è©åˆ†é¡
            slots[main_verb.text] = self._classify_infinitive_verb(main_verb, pattern, head)
            print(f"   ğŸ”§ '{main_verb.text}' â†’ {slots[main_verb.text]}")
            
            # ä¸»å‹•è©åˆ†é¡
            if head.pos_ == 'VERB' and head.text not in slots:
                slots[head.text] = self._classify_main_verb(head, pattern)
                print(f"   âš™ï¸ '{head.text}' â†’ {slots[head.text]}")
            
            # ä¸å®šè©ã®å¼•æ•°åˆ†æ
            self._analyze_infinitive_arguments(main_verb, slots)
        
        return slots
    
    def _classify_infinitive_verb(self, verb_token, pattern: str, head) -> str:
        """
        ä¸å®šè©å‹•è©ã®åˆ†é¡
        
        Args:
            verb_token: ä¸å®šè©å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            pattern: ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³
            head: çµ±èªçš„æ”¯é…èª
            
        Returns:
            str: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
        """
        # xcomp: è£œèªå‹•è©
        if pattern == 'xcomp_aux':
            return 'inf-complement-verb'
        
        # advcl: å‰¯è©å¥å‹•è©
        elif pattern == 'advcl_mark':
            return 'inf-adverbial-verb'
        
        # ccomp: è£œèªç¯€å‹•è©
        elif pattern == 'ccomp_aux':
            return 'inf-clausal-verb'
        
        return 'inf-verb'
    
    def _classify_main_verb(self, verb_token, pattern: str) -> str:
        """
        ä¸»å‹•è©ã®åˆ†é¡
        
        Args:
            verb_token: ä¸»å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            pattern: ä¾å­˜é–¢ä¿‚ãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
            str: ã‚¹ãƒ­ãƒƒãƒˆåˆ†é¡
        """
        # ä¸å®šè©ã‚’æ”¯é…ã™ã‚‹ä¸»å‹•è©ã®ç‰¹å¾´åˆ†æ
        if pattern in ['xcomp_aux', 'ccomp_aux']:
            return 'inf-governing-verb'
        elif pattern == 'advcl_mark':
            return 'main-verb'
        
        return 'verb'
    
    def _analyze_infinitive_arguments(self, verb_token, slots: Dict[str, str]):
        """
        ä¸å®šè©ã®å¼•æ•°æ§‹é€ åˆ†æ
        
        Args:
            verb_token: ä¸å®šè©å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³
            slots: ã‚¹ãƒ­ãƒƒãƒˆè¾æ›¸ï¼ˆæ›´æ–°ã•ã‚Œã‚‹ï¼‰
        """
        print(f"   ï¿½ ä¸å®šè©'{verb_token.text}'ã®å¼•æ•°æ§‹é€ è§£æ")
        
        for child in verb_token.children:
            if child.dep_ == 'dobj':  # ç›´æ¥ç›®çš„èª
                slots[child.text] = 'inf-object'
                print(f"     ğŸ“¦ '{child.text}' â†’ inf-object")
            elif child.dep_ == 'nsubj':  # ä¸»èª
                slots[child.text] = 'inf-subject'
                print(f"     ğŸ‘¤ '{child.text}' â†’ inf-subject")
            elif child.dep_ == 'prep':  # å‰ç½®è©å¥
                slots[child.text] = 'inf-prep'
                print(f"     ğŸ”— '{child.text}' â†’ inf-prep")
                # å‰ç½®è©ã®ç›®çš„èªã‚‚åˆ†æ
                for grandchild in child.children:
                    if grandchild.dep_ == 'pobj':
                        slots[grandchild.text] = 'inf-prep-object'
                        print(f"     ğŸ“ '{grandchild.text}' â†’ inf-prep-object")
    
    def _process_nominal_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¸å®šè©ã‚’ä¸»èªã¨ã—ã¦å‡¦ç†
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            main_slots['S'] = f"{to_token.text} {main_verb.text}"
            
            # æ–‡ã®ä¸»å‹•è©ã‚’æ¤œå‡º
            for token in doc:
                if token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                    main_slots['V'] = token.text
                    break
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal',
                'usage_type': 'nominal',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_nominal_subject_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ãƒ»ä¸»èªã®å‡¦ç†ï¼ˆcsubjæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©ãƒ»ä¸»èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case156: "To study English is important."
        # æœŸå¾…å€¤: main_slots={'S': '', 'V': 'is', 'C1': 'important'}
        #        sub_slots={'sub-v': 'To study', 'sub-o1': 'English', '_parent_slot': 'S'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # study
            head = inf_token['head']  # is
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: æ–‡ã®ä¸»å‹•è©ï¼ˆisï¼‰ã¨ãã®è£œèª
            main_slots['S'] = ''  # ä¸»èªã¯ç©ºï¼ˆä¸å®šè©ãŒã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦å‡¦ç†ï¼‰
            main_slots['V'] = head.text  # is
            
            # è£œèªï¼ˆC1ï¼‰ã‚’æ¤œå‡º
            for child in head.children:
                if child.dep_ in ['acomp', 'attr'] and child.pos_ == 'ADJ':
                    main_slots['C1'] = child.text
                    print(f"   ğŸ“ è£œèªæ¤œå‡º: C1 = '{child.text}'")
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "To study"
            sub_slots['_parent_slot'] = 'S'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj' and child.pos_ in ['NOUN', 'PROPN']:
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal_subject',
                'usage_type': 'nominal_subject',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_nominal_object_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åè©çš„ç”¨æ³•ãƒ»ç›®çš„èªã®å‡¦ç†ï¼ˆxcompæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ åè©çš„ä¸å®šè©ãƒ»ç›®çš„èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case157: "I want to learn programming."
        # æœŸå¾…å€¤: main_slots={'S': 'I', 'V': 'want', 'O1': ''}
        #        sub_slots={'sub-v': 'to learn', 'sub-o1': 'programming', '_parent_slot': 'O1'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # learn
            head = inf_token['head']  # want
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: ä¸»å‹•è©ï¼ˆwantï¼‰ã¨ãã®ä¸»èª
            for token in doc:
                if token.dep_ == 'nsubj' and token.head == head:
                    main_slots['S'] = token.text
                    print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{token.text}'")
            
            main_slots['V'] = head.text  # want
            main_slots['O1'] = ''  # ç›®çš„èªã¯ç©ºï¼ˆä¸å®šè©ãŒã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦å‡¦ç†ï¼‰
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"  # "to learn"
            sub_slots['_parent_slot'] = 'O1'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj' and child.pos_ in ['NOUN', 'PROPN']:
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_nominal_object',
                'usage_type': 'nominal_object',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adjectival_modifier_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å½¢å®¹è©çš„ç”¨æ³•ãƒ»ä¿®é£¾èªã®å‡¦ç†ï¼ˆrelclæ§‹é€ å¯¾å¿œï¼‰"""
        print(f"ğŸ“ å½¢å®¹è©çš„ä¸å®šè©ãƒ»ä¿®é£¾èªå‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # case158: "She has something to tell you."
        # æœŸå¾…å€¤: main_slots={'S': 'She', 'V': 'has', 'O1': ''}
        #        sub_slots={'sub-v': 'something to tell', 'sub-o1': 'you', '_parent_slot': 'O1'}
        
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']  # tell
            head = inf_token['head']  # something
            
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆ: ä¸»å‹•è©ã¨ãã®ä¸»èªãƒ»ç›®çš„èª
            for token in doc:
                if token.dep_ == 'ROOT':
                    main_slots['V'] = token.text  # has
                    # ä¸»èªã‚’æ¢ã™
                    for child in token.children:
                        if child.dep_ == 'nsubj':
                            main_slots['S'] = child.text
                            print(f"   ğŸ“ ä¸»èªæ¤œå‡º: S = '{child.text}'")
                        # ç›®çš„èªã‚’æ¢ã™ï¼ˆhead=somethingã®è¦ªï¼‰
                        elif child.dep_ == 'dobj' and child == head:
                            main_slots['O1'] = ''  # ç›®çš„èªã¯ä¸å®šè©ã§ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆåŒ–
                            print(f"   ğŸ“ ç›®çš„èªæ¤œå‡ºï¼ˆä¸å®šè©ä¿®é£¾å¯¾è±¡ï¼‰: '{child.text}' â†’ O1ç©ºæ¬„")
            
            # ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆ: ä¸å®šè©éƒ¨åˆ†
            sub_slots['sub-v'] = f"{head.text} {to_token.text} {main_verb.text}"  # "something to tell"
            sub_slots['_parent_slot'] = 'O1'
            
            # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
            for child in main_verb.children:
                if child.dep_ == 'dobj':
                    sub_slots['sub-o1'] = child.text
                    print(f"   ğŸ“ ä¸å®šè©ç›®çš„èªæ¤œå‡º: sub-o1 = '{child.text}'")
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adjectival_modifier',
                'usage_type': 'adjectival_modifier',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adjectival_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å½¢å®¹è©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ å½¢å®¹è©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¿®é£¾ã•ã‚Œã‚‹åè©ã¨ä¸å®šè©ã®é–¢ä¿‚ã‚’åˆ†æ
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            head = inf_token['head']
            
            # ä¸»æ–‡ã®æ§‹é€ ã‚’æŠ½å‡º
            for token in doc:
                if token.dep_ == 'nsubj':
                    main_slots['S'] = token.text
                elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                    main_slots['V'] = token.text
                elif token.dep_ == 'dobj':
                    main_slots['O1'] = token.text
            
            # ä¸å®šè©ã‚’ä¿®é£¾èªã¨ã—ã¦åˆ†é¡
            main_slots['M2'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adjectival',
                'usage_type': 'adjectival',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_adverbial_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """å‰¯è©çš„ç”¨æ³•ã®å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ å‰¯è©çš„ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # ä¸»æ–‡ã®æ§‹é€ ã‚’æŠ½å‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                main_slots['S'] = token.text
            elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                main_slots['V'] = token.text
            elif token.dep_ == 'dobj' and token.head.dep_ == 'ROOT':
                # ãƒ¡ã‚¤ãƒ³å‹•è©ã®ç›´æ¥ç›®çš„èªã®ã¿
                main_slots['O1'] = token.text
        
        # å‰¯è©çš„ä¸å®šè©ã®è©³ç´°åˆ†æã¨å‡ºåŠ›å½¢å¼æ±ºå®š
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            # ä¸å®šè©ã®æ„å‘³çš„åˆ†é¡ï¼ˆç›®çš„ vs çµæœ vs ãã®ä»–ï¼‰
            infinitive_purpose = self._is_purpose_infinitive(doc, inf_token)
            infinitive_result = self._is_result_infinitive(doc, inf_token)
            
            if infinitive_purpose:
                # ç›®çš„ã®å‰¯è©çš„ä¸å®šè©ï¼šã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡ºåŠ›
                print(f"ğŸ¯ ç›®çš„ã®å‰¯è©çš„ä¸å®šè©ï¼šã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡¦ç†")
                main_slots['M3'] = ""  # ç©ºæ–‡å­—åˆ—
                
                # ä¸å®šè©éƒ¨åˆ†ã‚’ã‚µãƒ–ã‚¹ãƒ­ãƒƒãƒˆã«åˆ†è§£
                sub_slots['sub-v'] = f"{to_token.text} {main_verb.text}"
                sub_slots['_parent_slot'] = "M3"
                
                # ä¸å®šè©ã®ç›®çš„èªã‚’æ¤œå‡º
                for token in doc:
                    if (token.head == main_verb and 
                        token.dep_ == 'dobj'):
                        # "his friend" ã®ã‚ˆã†ã«æ‰€æœ‰æ ¼+åè©ã‚’çµåˆ
                        obj_text = self._get_full_noun_phrase(token)
                        sub_slots['sub-o1'] = obj_text
                        break
                        
            elif infinitive_result:
                # çµæœã®å‰¯è©çš„ä¸å®šè©ï¼šAux+Vå½¢å¼ã§å‡ºåŠ›ï¼ˆä¾‹ï¼šgrew up to becomeï¼‰
                print(f"ğŸ¯ çµæœã®å‰¯è©çš„ä¸å®šè©ï¼šAux+Vå½¢å¼ã§å‡¦ç†")
                
                # ãƒ¡ã‚¤ãƒ³å‹•è©ã«ä»˜å±ã™ã‚‹è¦ç´ ã‚’å«ã‚ã¦Auxæ§‹ç¯‰
                main_verb_head = inf_token['head']
                
                # "grew up" ã®ã‚ˆã†ãªå¥å‹•è©ï¼‹toä¸å®šè©ã‚’ä¸€ã¤ã®Auxã¨ã—ã¦æ‰±ã†
                aux_parts = [main_verb_head.text]
                
                # å¥å‹•è©ã®å‰¯è©çš„å°è©ï¼ˆprtï¼‰ã‚’æ¤œç´¢
                for child in main_verb_head.children:
                    if child.dep_ == 'prt':  # particleï¼ˆup, down, etc.ï¼‰
                        aux_parts.append(child.text)
                
                # toä¸å®šè©éƒ¨åˆ†ã‚’è¿½åŠ 
                aux_parts.extend([to_token.text])
                
                main_slots['Aux'] = ' '.join(aux_parts)
                main_slots['V'] = main_verb.text
                
                # ä¸å®šè©ã®è£œèªã‚’æ¤œå‡ºï¼ˆbecome a teacherã®a teacherï¼‰
                for token in doc:
                    if (token.head == main_verb and 
                        token.dep_ in ['attr', 'dobj']):
                        # "a teacher" ã®ã‚ˆã†ãªåè©å¥ã‚’çµåˆ
                        comp_text = self._get_full_noun_phrase(token)
                        main_slots['C1'] = comp_text
                        break
            else:
                # çµæœãƒ»æ–¹æ³•ç­‰ã®å‰¯è©çš„ä¸å®šè©ï¼šãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ 
                print(f"ğŸ¯ çµæœ/æ–¹æ³•ã®å‰¯è©çš„ä¸å®šè©ï¼šãƒ¡ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆæ§‹é€ ã§å‡¦ç†")
                main_slots['M2'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_adverbial',
                'usage_type': 'adverbial',
                'confidence': 0.9,
                'spacy_analysis': True
            }
        }
    
    def _process_basic_infinitive(self, doc, text: str, infinitive_info: Dict, slots: Dict) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªä¸å®šè©å‡¦ç†ï¼ˆspaCyä¾å­˜é–¢ä¿‚ãƒ™ãƒ¼ã‚¹ï¼‰"""
        print(f"ğŸ“ åŸºæœ¬ä¸å®šè©å‡¦ç†: {text}")
        
        main_slots = {}
        sub_slots = {}
        
        # åŸºæœ¬çš„ãªæ–‡æ§‹é€ æŠ½å‡º
        for token in doc:
            if token.dep_ == 'nsubj':
                main_slots['S'] = token.text
            elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                main_slots['V'] = token.text
        
        # ä¸å®šè©ã‚’ç›®çš„èªã¨ã—ã¦åˆ†é¡
        if infinitive_info['infinitive_tokens']:
            inf_token = infinitive_info['infinitive_tokens'][0]
            to_token = inf_token['to_token']
            main_verb = inf_token['main_verb']
            
            main_slots['O1'] = f"{to_token.text} {main_verb.text}"
        
        return {
            'success': True,
            'main_slots': main_slots,
            'sub_slots': sub_slots,
            'collaboration': ['infinitive'],
            'primary_handler': 'infinitive',
            'metadata': {
                'handler': 'infinitive_basic',
                'usage_type': 'basic',
                'confidence': 0.8,
                'spacy_analysis': True
            }
        }
    
    def _is_purpose_infinitive(self, doc, inf_token: Dict) -> bool:
        """
        ä¸å®šè©ãŒç›®çš„ã®å‰¯è©çš„ç”¨æ³•ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            doc: spaCyè§£æçµæœ
            inf_token: ä¸å®šè©ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±
            
        Returns:
            bool: ç›®çš„ã®å‰¯è©çš„ç”¨æ³•ã®å ´åˆTrue
        """
        # åŸºæœ¬çš„ã« "came to see" ã®ã‚ˆã†ãªç§»å‹•å‹•è©ï¼‹toä¸å®šè©ã¯ç›®çš„ç”¨æ³•
        main_verb_lemma = inf_token['head'].lemma_.lower()
        
        # ç§»å‹•ãƒ»åˆ°ç€ã‚’è¡¨ã™å‹•è© + toä¸å®šè© = ç›®çš„ç”¨æ³•
        purpose_verbs = ['come', 'go', 'run', 'walk', 'drive', 'travel', 'move', 'rush', 'hurry']
        
        if main_verb_lemma in purpose_verbs:
            return True
            
        # ãã®ä»–ã®åˆ¤å®šæ¡ä»¶ï¼ˆå°†æ¥æ‹¡å¼µå¯èƒ½ï¼‰
        return False
    
    def _is_result_infinitive(self, doc, inf_token: Dict) -> bool:
        """
        ä¸å®šè©ãŒçµæœã®å‰¯è©çš„ç”¨æ³•ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            doc: spaCyè§£æçµæœ
            inf_token: ä¸å®šè©ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±
            
        Returns:
            bool: çµæœã®å‰¯è©çš„ç”¨æ³•ã®å ´åˆTrue
        """
        # "grew up to become" ã®ã‚ˆã†ãªæˆé•·ãƒ»å¤‰åŒ–å‹•è© + toä¸å®šè© = çµæœç”¨æ³•
        main_verb_lemma = inf_token['head'].lemma_.lower()
        
        # æˆé•·ãƒ»å¤‰åŒ–ã‚’è¡¨ã™å‹•è© + toä¸å®šè© = çµæœç”¨æ³•
        result_verbs = ['grow', 'rise', 'wake', 'turn', 'come', 'live', 'get']
        
        if main_verb_lemma in result_verbs:
            # å¥å‹•è©ï¼ˆgrow up, wake upç­‰ï¼‰ã®å ´åˆã‚‚çµæœç”¨æ³•
            for child in inf_token['head'].children:
                if child.dep_ == 'prt':  # particle
                    return True
            return True
            
        return False
    
    def _get_full_noun_phrase(self, token) -> str:
        """
        åè©å¥å…¨ä½“ã‚’å–å¾—ï¼ˆæ‰€æœ‰æ ¼ç­‰ã‚’å«ã‚€ï¼‰
        
        Args:
            token: ä¸­å¿ƒã¨ãªã‚‹åè©ãƒˆãƒ¼ã‚¯ãƒ³
            
        Returns:
            str: å®Œå…¨ãªåè©å¥
        """
        # æ‰€æœ‰æ ¼ã‚„å½¢å®¹è©ç­‰ã®ä¿®é£¾èªã‚’å«ã‚€åè©å¥ã‚’æ§‹ç¯‰
        phrase_tokens = []
        
        # å‰ç½®ä¿®é£¾èªã‚’åé›†
        for child in token.children:
            if child.dep_ in ['poss', 'det', 'amod', 'compound']:
                phrase_tokens.append((child.i, child.text))
        
        # ä¸­å¿ƒèªã‚’è¿½åŠ 
        phrase_tokens.append((token.i, token.text))
        
        # ä½ç½®é †ã§ã‚½ãƒ¼ãƒˆã—ã¦çµåˆ
        phrase_tokens.sort(key=lambda x: x[0])
        return ' '.join([t[1] for t in phrase_tokens])
