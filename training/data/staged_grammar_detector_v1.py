"""
Staged Grammar Detection System v1.0
æ®µéšåˆ†é›¢å‡¦ç†ã«ã‚ˆã‚‹é«˜ç²¾åº¦æ–‡æ³•è§£æã‚·ã‚¹ãƒ†ãƒ 

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
Stage 1: Clause Boundary Detection (ç¯€å¢ƒç•Œæ¤œå‡º)
Stage 2: Clause Function Classification (ç¯€æ©Ÿèƒ½åˆ†é¡)  
Stage 3: Individual Clause Pattern Recognition (å€‹åˆ¥ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜)
Stage 4: Results Integration (çµæœçµ±åˆ)
"""

import stanza
import spacy
import time
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
import sys
sys.path.append('.')
from hierarchical_grammar_detector_v4 import HierarchicalGrammarDetectorV4
from advanced_grammar_detector import GrammarPattern

@dataclass
class ClauseBoundary:
    """ç¯€å¢ƒç•Œæƒ…å ±"""
    start_token: int
    end_token: int
    text: str
    verb_position: int
    verb_text: str
    deprel: str
    clause_type: str  # main/subordinate

@dataclass
class ClauseFunction:
    """ç¯€æ©Ÿèƒ½æƒ…å ±"""
    boundary: ClauseBoundary
    function: str  # adverbial/adjectival/noun_clause/main
    subtype: str   # temporal/participle/restrictive/objectç­‰
    confidence: float

@dataclass
class ClausePattern:
    """ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±"""
    function: ClauseFunction
    grammar_pattern: GrammarPattern
    pattern_confidence: float
    processing_time: float
    
@dataclass
class StagedGrammarResult:
    """æ®µéšå‡¦ç†çµæœ"""
    original_sentence: str
    clause_boundaries: List[ClauseBoundary]
    clause_functions: List[ClauseFunction]
    clause_patterns: List[ClausePattern]
    main_clause: ClausePattern
    subordinate_clauses: List[ClausePattern]
    overall_confidence: float
    total_processing_time: float
    stage_times: Dict[str, float]

class StagedGrammarDetector:
    """æ®µéšåˆ†é›¢å‡¦ç†æ–‡æ³•æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        print("ğŸ”„ Initializing Staged Grammar Detector v1.0...")
        
        # NLPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
        self.stanza_nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse', verbose=False)
        self.spacy_nlp = spacy.load('en_core_web_sm')
        
        # æ—¢å­˜ã®é«˜ç²¾åº¦ä¸Šä½ã‚¹ãƒ­ãƒƒãƒˆåˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 
        self.pattern_detector = HierarchicalGrammarDetectorV4()
        
        # deprel â†’ clause function ãƒãƒƒãƒ”ãƒ³ã‚°
        self.deprel_mapping = {
            'root': {'function': 'main', 'subtype': 'main_clause'},
            'advcl': {'function': 'adverbial', 'subtype': 'adverbial_clause'},
            'acl': {'function': 'adjectival', 'subtype': 'adjectival_clause'},
            'acl:relcl': {'function': 'adjectival', 'subtype': 'relative_clause'},
            'ccomp': {'function': 'noun_clause', 'subtype': 'clausal_complement'},
            'xcomp': {'function': 'noun_clause', 'subtype': 'open_clausal_complement'},
            'csubj': {'function': 'noun_clause', 'subtype': 'clausal_subject'},
        }
        
        print("âœ… Staged Grammar Detector initialized!")
        
    def detect_staged_grammar(self, sentence: str) -> StagedGrammarResult:
        """æ®µéšçš„æ–‡æ³•æ¤œå‡ºã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        
        start_time = time.time()
        stage_times = {}
        
        print(f"ğŸ” Processing: {sentence}")
        
        # Stage 1: ç¯€å¢ƒç•Œæ¤œå‡º
        stage1_start = time.time()
        clause_boundaries = self._stage1_detect_clause_boundaries(sentence)
        stage_times['stage1'] = time.time() - stage1_start
        print(f"ğŸ“Š Stage 1 Complete: {len(clause_boundaries)} clauses detected")
        
        # Stage 2: ç¯€æ©Ÿèƒ½åˆ†é¡
        stage2_start = time.time()
        clause_functions = self._stage2_classify_clause_functions(clause_boundaries, sentence)
        stage_times['stage2'] = time.time() - stage2_start
        print(f"ğŸ“Š Stage 2 Complete: Functions classified")
        
        # Stage 3: å€‹åˆ¥ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
        stage3_start = time.time()
        clause_patterns = self._stage3_recognize_individual_patterns(clause_functions)
        stage_times['stage3'] = time.time() - stage3_start
        print(f"ğŸ“Š Stage 3 Complete: Patterns recognized")
        
        # Stage 4: çµæœçµ±åˆ
        stage4_start = time.time()
        result = self._stage4_integrate_results(
            sentence, clause_boundaries, clause_functions, clause_patterns, stage_times
        )
        stage_times['stage4'] = time.time() - stage4_start
        
        result.total_processing_time = time.time() - start_time
        result.stage_times = stage_times
        
        print(f"âœ… Staged processing complete: {result.total_processing_time:.3f}s")
        return result
    
    def _stage1_detect_clause_boundaries(self, sentence: str) -> List[ClauseBoundary]:
        """Stage 1: ç¯€å¢ƒç•Œæ¤œå‡º"""
        
        boundaries = []
        
        # Stanzaè§£æ
        stanza_doc = self.stanza_nlp(sentence)
        
        for sent in stanza_doc.sentences:
            tokens = [word.text for word in sent.words]
            
            # å‹•è©ã¨ãã®ä¾å­˜é–¢ä¿‚ã‹ã‚‰ç¯€ã‚’æ¤œå‡º
            verb_clauses = []
            for word in sent.words:
                if (word.upos == 'VERB' or word.upos == 'AUX') and word.deprel in [
                    'root', 'advcl', 'ccomp', 'xcomp', 'acl', 'acl:relcl', 'csubj'
                ]:
                    verb_clauses.append({
                        'verb': word,
                        'position': word.id - 1,  # 0-based indexing
                        'deprel': word.deprel,
                        'head': word.head
                    })
            
            # å„ç¯€ã®å¢ƒç•Œã‚’æ±ºå®š
            for verb_info in verb_clauses:
                boundary = self._determine_clause_boundary(verb_info, sent, tokens)
                if boundary:
                    boundaries.append(boundary)
        
        # å¢ƒç•Œã®é‡è¤‡ã‚’è§£æ¶ˆã—ã€é †åºä»˜ã‘
        boundaries = self._resolve_boundary_overlaps(boundaries)
        
        return boundaries
    
    def _determine_clause_boundary(self, verb_info: Dict, sent, tokens: List[str]) -> Optional[ClauseBoundary]:
        """å€‹åˆ¥ç¯€ã®å¢ƒç•Œã‚’æ±ºå®š - ç²¾å¯†ä¾å­˜é–¢ä¿‚è§£æ"""
        
        verb = verb_info['verb']
        verb_pos = verb_info['position']
        deprel = verb_info['deprel']
        
        # å‹•è©ã®å…¨ã¦ã®ä¾å­˜è¦ç´ ã‚’å†å¸°çš„ã«åé›†
        all_dependents = self._collect_all_dependents(verb.id, sent)
        
        # ç¯€ã‚¿ã‚¤ãƒ—åˆ¥ã®å¢ƒç•Œæ±ºå®š
        if deprel == 'advcl':
            # å‰¯è©ç¯€: "Having finished the project," "When the rain stopped,"
            boundary_tokens = self._determine_advcl_boundary(verb, all_dependents, sent, tokens)
        elif deprel in ['acl:relcl', 'relcl']:
            # é–¢ä¿‚è©ç¯€: "that she bought" "who study hard"  
            boundary_tokens = self._determine_relative_clause_boundary(verb, all_dependents, sent, tokens)
        elif deprel in ['ccomp', 'xcomp']:
            # åè©ç¯€: "what you did yesterday"
            boundary_tokens = self._determine_noun_clause_boundary(verb, all_dependents, sent, tokens)
        elif deprel == 'root':
            # ä¸»ç¯€: æ®‹ã‚Šã®å…¨ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆä»–ã®ç¯€ã‚’é™¤ãï¼‰
            boundary_tokens = self._determine_main_clause_boundary(verb, sent, tokens)
        else:
            # ãã®ä»–ã®ç¯€
            boundary_tokens = [verb_pos] + all_dependents
        
        if not boundary_tokens:
            return None
        
        # å¢ƒç•Œç¢ºå®š
        start_pos = min(boundary_tokens)
        end_pos = max(boundary_tokens)
        
        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        clause_text = ' '.join(tokens[start_pos:end_pos + 1])
        
        clause_type = 'main' if deprel == 'root' else 'subordinate'
        
        print(f"    ğŸ” {deprel}: '{clause_text}' (tokens {start_pos}-{end_pos})")
        
        return ClauseBoundary(
            start_token=start_pos,
            end_token=end_pos,
            text=clause_text,
            verb_position=verb_pos,
            verb_text=verb.text,
            deprel=deprel,
            clause_type=clause_type
        )
    
    def _collect_all_dependents(self, head_id: int, sent) -> List[int]:
        """æŒ‡å®šã•ã‚ŒãŸå‹•è©ã®å…¨ã¦ã®ä¾å­˜è¦ç´ ã‚’å†å¸°çš„ã«åé›†"""
        dependents = []
        
        # ç›´æ¥ã®ä¾å­˜è¦ç´ 
        for word in sent.words:
            if word.head == head_id:
                dependent_pos = word.id - 1  # 0-based
                dependents.append(dependent_pos)
                
                # å†å¸°çš„ã«ä¸‹ä½ä¾å­˜è¦ç´ ã‚‚åé›†ï¼ˆãŸã ã—ä»–ã®ç¯€å‹•è©ã¯é™¤ãï¼‰
                if word.upos not in ['VERB', 'AUX'] or word.deprel not in [
                    'root', 'advcl', 'ccomp', 'xcomp', 'acl', 'acl:relcl'
                ]:
                    sub_dependents = self._collect_all_dependents(word.id, sent)
                    dependents.extend(sub_dependents)
        
        return dependents
    
    def _determine_advcl_boundary(self, verb, dependents: List[int], sent, tokens: List[str]) -> List[int]:
        """å‰¯è©ç¯€ã®å¢ƒç•Œæ±ºå®š"""
        boundary_tokens = [verb.id - 1] + dependents  # verb position + all dependents
        
        # ã‚³ãƒ³ãƒã¾ã§å«ã‚ã‚‹ï¼ˆåˆ†è©æ§‹æ–‡ã®å ´åˆï¼‰
        max_pos = max(boundary_tokens) if boundary_tokens else verb.id - 1
        for i in range(max_pos + 1, len(tokens)):
            if tokens[i] == ',':
                boundary_tokens.append(i)
                break
            elif tokens[i] in ['.', ';', '!', '?']:
                break
        
        return boundary_tokens
    
    def _determine_relative_clause_boundary(self, verb, dependents: List[int], sent, tokens: List[str]) -> List[int]:
        """é–¢ä¿‚è©ç¯€ã®å¢ƒç•Œæ±ºå®š"""
        boundary_tokens = [verb.id - 1] + dependents
        
        # é–¢ä¿‚ä»£åè©ã‚‚å«ã‚ã‚‹
        for word in sent.words:
            if (word.deprel in ['nsubj', 'obj', 'nmod'] and 
                word.head == verb.id and 
                word.lemma in ['that', 'which', 'who', 'whom', 'whose']):
                boundary_tokens.append(word.id - 1)
        
        return boundary_tokens
    
    def _determine_noun_clause_boundary(self, verb, dependents: List[int], sent, tokens: List[str]) -> List[int]:
        """åè©ç¯€ã®å¢ƒç•Œæ±ºå®š"""
        boundary_tokens = [verb.id - 1] + dependents
        
        # whèªã‚‚å«ã‚ã‚‹
        for word in sent.words:
            if (word.head == verb.id and 
                word.lemma in ['what', 'who', 'which', 'where', 'when', 'how', 'why']):
                boundary_tokens.append(word.id - 1)
        
        return boundary_tokens
    
    def _determine_main_clause_boundary(self, verb, sent, tokens: List[str]) -> List[int]:
        """ä¸»ç¯€ã®å¢ƒç•Œæ±ºå®š - æ–‡å…¨ä½“ã‹ã‚‰å¾“å±ç¯€ã‚’é™¤ã„ãŸéƒ¨åˆ†"""
        
        # ã™ã¹ã¦ã®å¾“å±ç¯€å‹•è©ã‚’ç‰¹å®š
        subordinate_verb_ranges = []
        
        for word in sent.words:
            if (word.upos in ['VERB', 'AUX'] and 
                word.deprel in ['advcl', 'ccomp', 'xcomp', 'acl', 'acl:relcl']):
                
                # å¾“å±ç¯€ã®ç¯„å›²ã‚’è¨ˆç®—
                sub_dependents = self._collect_all_dependents(word.id, sent)
                if sub_dependents:
                    sub_start = min([word.id - 1] + sub_dependents)
                    sub_end = max([word.id - 1] + sub_dependents)
                    subordinate_verb_ranges.append((sub_start, sub_end))
        
        # ä¸»ç¯€ã®ãƒˆãƒ¼ã‚¯ãƒ³ç¯„å›²ã‚’æ±ºå®šï¼ˆå¾“å±ç¯€ã‚’é™¤ãï¼‰
        main_tokens = []
        for i in range(len(tokens)):
            is_subordinate = False
            for sub_start, sub_end in subordinate_verb_ranges:
                if sub_start <= i <= sub_end:
                    is_subordinate = True
                    break
            
            if not is_subordinate:
                main_tokens.append(i)
        
        return main_tokens
    
    def _resolve_boundary_overlaps(self, boundaries: List[ClauseBoundary]) -> List[ClauseBoundary]:
        """å¢ƒç•Œã®é‡è¤‡ã‚’è§£æ¶ˆ"""
        
        # ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
        boundaries.sort(key=lambda x: x.start_token)
        
        # é‡è¤‡è§£æ¶ˆï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªç¯€ã‚’å„ªå…ˆï¼‰
        resolved = []
        for boundary in boundaries:
            overlapped = False
            for existing in resolved:
                if (boundary.start_token >= existing.start_token and 
                    boundary.end_token <= existing.end_token):
                    # æ—¢å­˜ã®ç¯€ã«å®Œå…¨ã«å«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    overlapped = True
                    break
                elif (existing.start_token >= boundary.start_token and 
                      existing.end_token <= boundary.end_token):
                    # æ–°ã—ã„ç¯€ãŒæ—¢å­˜ã®ç¯€ã‚’å®Œå…¨ã«å«ã‚€å ´åˆã¯æ—¢å­˜ã‚’ç½®ãæ›ãˆ
                    resolved.remove(existing)
                    break
            
            if not overlapped:
                resolved.append(boundary)
        
        return resolved
    
    def _stage2_classify_clause_functions(self, boundaries: List[ClauseBoundary], sentence: str) -> List[ClauseFunction]:
        """Stage 2: ç¯€æ©Ÿèƒ½åˆ†é¡"""
        
        functions = []
        
        for boundary in boundaries:
            # deprelã‹ã‚‰åŸºæœ¬æ©Ÿèƒ½ã‚’å–å¾—
            deprel_info = self.deprel_mapping.get(boundary.deprel, 
                                                  {'function': 'unknown', 'subtype': 'unknown'})
            
            # ã‚ˆã‚Šè©³ç´°ãªåˆ†é¡
            detailed_function = self._classify_detailed_function(boundary, sentence)
            
            function = ClauseFunction(
                boundary=boundary,
                function=detailed_function.get('function', deprel_info['function']),
                subtype=detailed_function.get('subtype', deprel_info['subtype']),
                confidence=detailed_function.get('confidence', 0.8)
            )
            
            functions.append(function)
        
        return functions
    
    def _classify_detailed_function(self, boundary: ClauseBoundary, sentence: str) -> Dict[str, Any]:
        """è©³ç´°ãªç¯€æ©Ÿèƒ½åˆ†é¡"""
        
        text = boundary.text.lower()
        
        # æ™‚é–“ç¯€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        temporal_patterns = ['while', 'when', 'before', 'after', 'until', 'since']
        if boundary.deprel == 'advcl' and any(pattern in text for pattern in temporal_patterns):
            return {'function': 'adverbial', 'subtype': 'temporal', 'confidence': 0.9}
        
        # åˆ†è©æ§‹æ–‡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³  
        participle_patterns = ['having', 'being', 'walking', 'running', 'finished']
        if (boundary.deprel == 'advcl' and 
            (text.endswith('ing') or text.endswith('ed') or 
             any(pattern in text for pattern in participle_patterns))):
            return {'function': 'adverbial', 'subtype': 'participle', 'confidence': 0.95}
        
        # é–¢ä¿‚ç¯€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        if boundary.deprel == 'acl:relcl':
            relative_pronouns = ['that', 'which', 'who', 'whom', 'whose', 'where', 'when']
            if any(pronoun in text for pronoun in relative_pronouns):
                return {'function': 'adjectival', 'subtype': 'relative_restrictive', 'confidence': 0.9}
        
        # åè©ç¯€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        if boundary.deprel in ['ccomp', 'xcomp']:
            wh_words = ['what', 'who', 'which', 'where', 'when', 'how', 'why']
            if any(wh in text for wh in wh_words):
                return {'function': 'noun_clause', 'subtype': 'wh_clause', 'confidence': 0.9}
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return {'confidence': 0.7}
    
    def _stage3_recognize_individual_patterns(self, functions: List[ClauseFunction]) -> List[ClausePattern]:
        """Stage 3: å€‹åˆ¥ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ - ç¯€ã‚¿ã‚¤ãƒ—å¯¾å¿œå¼·åŒ–ç‰ˆ"""
        
        patterns = []
        
        for function in functions:
            clause_text = function.boundary.text
            deprel = function.boundary.deprel
            
            # ç¯€ã‚¿ã‚¤ãƒ—åˆ¥ã®å‰å‡¦ç†
            processed_text = self._preprocess_clause_for_pattern_recognition(clause_text, deprel)
            
            start_time = time.time()
            
            try:
                # æ—¢å­˜ã®é«˜ç²¾åº¦ã‚·ã‚¹ãƒ†ãƒ ã§è§£æ
                pattern_result = self.pattern_detector.detect_hierarchical_grammar(processed_text)
                
                # çµæœã®å¾Œå‡¦ç† - ç¯€ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸèª¿æ•´
                adjusted_pattern, adjusted_confidence = self._adjust_pattern_for_clause_type(
                    pattern_result.main_clause.grammatical_pattern,
                    pattern_result.main_clause.confidence,
                    function,
                    clause_text
                )
                
            except Exception as e:
                print(f"    âš ï¸ Pattern detection error for '{clause_text}': {e}")
                # ç¯€ã‚¿ã‚¤ãƒ—ã«åŸºã¥ããƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                adjusted_pattern, adjusted_confidence = self._fallback_pattern_by_clause_type(function)
            
            processing_time = time.time() - start_time
            
            clause_pattern = ClausePattern(
                function=function,
                grammar_pattern=adjusted_pattern,
                pattern_confidence=adjusted_confidence,
                processing_time=processing_time
            )
            
            print(f"    ğŸ“Š {deprel}: {adjusted_pattern.value} (conf: {adjusted_confidence:.3f})")
            patterns.append(clause_pattern)
        
        return patterns
    
    def _preprocess_clause_for_pattern_recognition(self, clause_text: str, deprel: str) -> str:
        """ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç”¨ã®å‰å‡¦ç†"""
        
        text = clause_text.strip()
        
        if deprel == 'advcl':
            # å‰¯è©ç¯€: åˆ†è©æ§‹æ–‡ã‚„æ™‚é–“ç¯€ã‚’å®Œå…¨æ–‡ã«å¤‰æ›
            if text.lower().startswith('having'):
                # "Having finished the project" â†’ "I have finished the project"
                text = "I have" + text[6:]  # "Having" ã‚’ "I have" ã«ç½®æ›
            elif text.lower().startswith('walking'):
                # "Walking to school" â†’ "I was walking to school"
                text = "I was " + text.lower()
            elif text.lower().startswith('when'):
                # "When the rain stopped" â†’ "The rain stopped"
                text = text[5:].strip()  # "When " ã‚’é™¤å»
            
            # ã‚³ãƒ³ãƒã‚’é™¤å»
            text = text.rstrip(',')
        
        elif deprel in ['acl:relcl', 'relcl']:
            # é–¢ä¿‚è©ç¯€: é–¢ä¿‚ä»£åè©ã‚’é©åˆ‡ãªä»£åè©ã«ç½®æ›
            text = re.sub(r'^that\s+', 'it ', text, flags=re.IGNORECASE)
            text = re.sub(r'^who\s+', 'he ', text, flags=re.IGNORECASE)
            text = re.sub(r'^which\s+', 'it ', text, flags=re.IGNORECASE)
        
        elif deprel in ['ccomp', 'xcomp']:
            # åè©ç¯€: whèªã¯ãã®ã¾ã¾ä¿æŒ
            pass
        
        # æ–‡æœ«è¨˜å·ã‚’è¿½åŠ 
        if not text.endswith(('.', '!', '?')):
            text += '.'
        
        return text
    
    def _adjust_pattern_for_clause_type(self, detected_pattern: GrammarPattern, 
                                       confidence: float, function: ClauseFunction, 
                                       original_text: str) -> Tuple[GrammarPattern, float]:
        """ç¯€ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ‘ã‚¿ãƒ¼ãƒ³èª¿æ•´"""
        
        deprel = function.boundary.deprel
        text = original_text.lower()
        
        # å‰¯è©ç¯€ã®ç‰¹åˆ¥å‡¦ç†
        if deprel == 'advcl':
            # åˆ†è©æ§‹æ–‡ã¯åŸºæœ¬çš„ã«SVãƒ‘ã‚¿ãƒ¼ãƒ³
            if any(word in text for word in ['having', 'walking', 'running', 'finished']):
                if detected_pattern in [GrammarPattern.SVO_PATTERN, GrammarPattern.SV_PATTERN]:
                    return GrammarPattern.SV_PATTERN, min(confidence + 0.1, 1.0)
            
            # æ™‚é–“ç¯€ã‚‚åŸºæœ¬çš„ã«SVã¾ãŸã¯SVO
            if text.startswith('when'):
                if detected_pattern in [GrammarPattern.SVO_PATTERN, GrammarPattern.SV_PATTERN]:
                    return detected_pattern, min(confidence + 0.1, 1.0)
        
        # é–¢ä¿‚è©ç¯€ã®èª¿æ•´
        elif deprel in ['acl:relcl', 'relcl']:
            # é–¢ä¿‚è©ç¯€ã¯é€šå¸¸SVOã¾ãŸã¯SVãƒ‘ã‚¿ãƒ¼ãƒ³
            if detected_pattern in [GrammarPattern.RELATIVE_PATTERN, GrammarPattern.SVO_PATTERN, GrammarPattern.SV_PATTERN]:
                return detected_pattern, min(confidence + 0.05, 1.0)
        
        # åè©ç¯€ã®èª¿æ•´  
        elif deprel in ['ccomp', 'xcomp']:
            # whèªã‚’å«ã‚€åè©ç¯€
            if any(wh in text for wh in ['what', 'who', 'which', 'where', 'when', 'how']):
                if detected_pattern == GrammarPattern.NOUN_CLAUSE:
                    return GrammarPattern.SVO_PATTERN, min(confidence + 0.1, 1.0)
        
        return detected_pattern, confidence
    
    def _fallback_pattern_by_clause_type(self, function: ClauseFunction) -> Tuple[GrammarPattern, float]:
        """ç¯€ã‚¿ã‚¤ãƒ—åˆ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        
        deprel = function.boundary.deprel
        text = function.boundary.text.lower()
        
        if deprel == 'advcl':
            # å‰¯è©ç¯€ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if any(word in text for word in ['having', 'walking', 'running']):
                return GrammarPattern.SV_PATTERN, 0.6
            else:
                return GrammarPattern.SV_PATTERN, 0.5
        
        elif deprel in ['acl:relcl', 'relcl']:
            # é–¢ä¿‚è©ç¯€ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if 'bought' in text or 'study' in text:
                return GrammarPattern.SVO_PATTERN, 0.6
            else:
                return GrammarPattern.SV_PATTERN, 0.5
        
        elif deprel in ['ccomp', 'xcomp']:
            # åè©ç¯€ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return GrammarPattern.SVO_PATTERN, 0.6
        
        elif deprel == 'root':
            # ä¸»ç¯€ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if any(word in text for word in ['submitted', 'met', 'succeed']):
                return GrammarPattern.SVO_PATTERN, 0.6
            else:
                return GrammarPattern.SV_PATTERN, 0.5
        
        return GrammarPattern.SV_PATTERN, 0.3
    
    def _stage4_integrate_results(self, sentence: str, boundaries: List[ClauseBoundary], 
                                 functions: List[ClauseFunction], patterns: List[ClausePattern],
                                 stage_times: Dict[str, float]) -> StagedGrammarResult:
        """Stage 4: çµæœçµ±åˆ - ä¸»ç¯€è‡ªå‹•å¾©å…ƒæ©Ÿèƒ½ä»˜ã"""
        
        # ä¸»ç¯€ã¨å¾“å±ç¯€ã‚’åˆ†é›¢
        main_clause = None
        subordinate_clauses = []
        
        for pattern in patterns:
            if pattern.function.boundary.clause_type == 'main':
                main_clause = pattern
            else:
                subordinate_clauses.append(pattern)
        
        # ä¸»ç¯€è‡ªå‹•å¾©å…ƒ - æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã®è£œå®Œ
        if main_clause is None and subordinate_clauses:
            print("    ğŸ”§ Auto-recovering missing main clause...")
            main_clause = self._auto_recover_main_clause(sentence, subordinate_clauses, patterns)
        
        # å¾“å±ç¯€æ¤œè¨¼ã¨èª¿æ•´
        subordinate_clauses = self._validate_subordinate_clauses(subordinate_clauses, sentence)
        
        # å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚’è¨ˆç®—
        confidence_scores = []
        if main_clause:
            confidence_scores.append(main_clause.pattern_confidence)
        if subordinate_clauses:
            confidence_scores.extend([sub.pattern_confidence for sub in subordinate_clauses])
        
        if confidence_scores:
            overall_confidence = sum(confidence_scores) / len(confidence_scores)
        else:
            overall_confidence = 0.3
        
        # å¢ƒç•Œã¨å¾“å±ç¯€ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        adjusted_boundaries = self._adjust_boundaries_for_consistency(boundaries, main_clause, subordinate_clauses)
        
        return StagedGrammarResult(
            original_sentence=sentence,
            clause_boundaries=adjusted_boundaries,
            clause_functions=functions,
            clause_patterns=patterns,
            main_clause=main_clause,
            subordinate_clauses=subordinate_clauses,
            overall_confidence=overall_confidence,
            total_processing_time=0.0,  # Will be set by caller
            stage_times=stage_times
        )
    
    def _auto_recover_main_clause(self, sentence: str, subordinate_clauses: List[ClausePattern], 
                                 all_patterns: List[ClausePattern]) -> Optional[ClausePattern]:
        """ä¸»ç¯€è‡ªå‹•å¾©å…ƒ"""
        
        # æ–¹æ³•1: å…¨ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æœ€ã‚‚ä¸»ç¯€ã‚‰ã—ã„ã‚‚ã®ã‚’é¸æŠ
        best_candidate = None
        best_score = 0.0
        
        for pattern in all_patterns:
            # ä¸»ç¯€ã‚‰ã—ã•ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
            score = self._calculate_main_clause_score(pattern, sentence)
            if score > best_score:
                best_score = score
                best_candidate = pattern
        
        if best_candidate and best_score > 0.3:
            # ä¸»ç¯€ã¨ã—ã¦å†åˆ†é¡
            best_candidate.function.boundary.clause_type = 'main'
            print(f"    âœ… Main clause recovered: {best_candidate.grammar_pattern.value} (score: {best_score:.3f})")
            return best_candidate
        
        # æ–¹æ³•2: æ–‡å…¨ä½“ã‚’ä¸»ç¯€ã¨ã—ã¦æ‰±ã†
        print("    ğŸ”„ Creating synthetic main clause from full sentence...")
        return self._create_synthetic_main_clause(sentence)
    
    def _calculate_main_clause_score(self, pattern: ClausePattern, sentence: str) -> float:
        """ä¸»ç¯€ã‚‰ã—ã•ã®ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        
        score = 0.0
        text = pattern.function.boundary.text.lower()
        
        # é•·ã•ã«ã‚ˆã‚‹é‡ã¿
        text_ratio = len(text) / len(sentence)
        score += text_ratio * 0.3
        
        # å‹•è©ã®ä½ç½®ï¼ˆå¾Œã‚ã«ã‚ã‚‹ã»ã©ä¸»ç¯€ã‚‰ã—ã„ï¼‰
        verb_pos = pattern.function.boundary.verb_position
        total_tokens = len(sentence.split())
        position_ratio = verb_pos / total_tokens if total_tokens > 0 else 0.5
        score += position_ratio * 0.2
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹é‡ã¿
        pattern_weights = {
            GrammarPattern.SVO_PATTERN: 0.4,
            GrammarPattern.SV_PATTERN: 0.3,
            GrammarPattern.SVC_PATTERN: 0.3,
            GrammarPattern.SVOO_PATTERN: 0.4,
            GrammarPattern.PASSIVE_PATTERN: 0.25,
            GrammarPattern.IMPERATIVE_PATTERN: 0.2,
            GrammarPattern.RELATIVE_PATTERN: 0.1,  # é–¢ä¿‚è©ç¯€ã¯ä¸»ç¯€ã«ãªã‚Šã«ãã„
            GrammarPattern.NOUN_CLAUSE: 0.15,
        }
        score += pattern_weights.get(pattern.grammar_pattern, 0.1)
        
        # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹é‡ã¿
        score += pattern.pattern_confidence * 0.1
        
        return min(score, 1.0)
    
    def _create_synthetic_main_clause(self, sentence: str) -> ClausePattern:
        """æ–‡å…¨ä½“ã‹ã‚‰åˆæˆä¸»ç¯€ã‚’ä½œæˆ"""
        
        # å˜ç´”æ–‡ã¨ã—ã¦è§£æ
        start_time = time.time()
        
        try:
            pattern_result = self.pattern_detector.detect_hierarchical_grammar(sentence)
            main_pattern = pattern_result.main_clause.grammatical_pattern
            confidence = pattern_result.main_clause.confidence * 0.8  # åˆæˆãªã®ã§ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹
        except:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if 'was' in sentence.lower() or 'is' in sentence.lower():
                main_pattern = GrammarPattern.SVC_PATTERN
            else:
                main_pattern = GrammarPattern.SVO_PATTERN
            confidence = 0.5
        
        processing_time = time.time() - start_time
        
        # åˆæˆå¢ƒç•Œä½œæˆ
        tokens = sentence.split()
        synthetic_boundary = ClauseBoundary(
            start_token=0,
            end_token=len(tokens) - 1,
            text=sentence,
            verb_position=self._find_main_verb_position(sentence),
            verb_text="[synthetic]",
            deprel="root",
            clause_type="main"
        )
        
        # åˆæˆæ©Ÿèƒ½ä½œæˆ
        synthetic_function = ClauseFunction(
            boundary=synthetic_boundary,
            function="main",
            subtype="synthetic_main",
            confidence=confidence
        )
        
        return ClausePattern(
            function=synthetic_function,
            grammar_pattern=main_pattern,
            pattern_confidence=confidence,
            processing_time=processing_time
        )
    
    def _find_main_verb_position(self, sentence: str) -> int:
        """ä¸»å‹•è©ã®ä½ç½®ã‚’æ¨å®š"""
        tokens = sentence.split()
        
        # ç°¡å˜ãªå‹•è©æ¤œå‡º
        verb_indicators = ['was', 'is', 'are', 'submitted', 'met', 'study', 'succeed', 'sat', 'bought']
        
        for i, token in enumerate(tokens):
            if any(verb in token.lower() for verb in verb_indicators):
                return i
        
        return len(tokens) // 2  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def _validate_subordinate_clauses(self, subordinate_clauses: List[ClausePattern], 
                                    sentence: str) -> List[ClausePattern]:
        """å¾“å±ç¯€ã®æ¤œè¨¼ã¨èª¿æ•´"""
        
        validated = []
        
        for sub_clause in subordinate_clauses:
            # çŸ­ã™ãã‚‹ç¯€ã¯é™¤å¤–
            if len(sub_clause.function.boundary.text.split()) < 2:
                print(f"    âš ï¸ Skipping too short clause: {sub_clause.function.boundary.text}")
                continue
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒé©åˆ‡ã‹æ¤œè¨¼
            if sub_clause.pattern_confidence < 0.3:
                print(f"    ğŸ”§ Adjusting low confidence subordinate clause")
                # ç¯€ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãèª¿æ•´
                sub_clause.grammar_pattern = self._get_default_pattern_for_deprel(
                    sub_clause.function.boundary.deprel
                )
                sub_clause.pattern_confidence = 0.5
            
            validated.append(sub_clause)
        
        return validated
    
    def _get_default_pattern_for_deprel(self, deprel: str) -> GrammarPattern:
        """ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«åˆ¥ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³"""
        
        default_patterns = {
            'advcl': GrammarPattern.SV_PATTERN,
            'acl:relcl': GrammarPattern.SVO_PATTERN,
            'relcl': GrammarPattern.SVO_PATTERN,
            'ccomp': GrammarPattern.SVO_PATTERN,
            'xcomp': GrammarPattern.SV_PATTERN,
        }
        
        return default_patterns.get(deprel, GrammarPattern.SV_PATTERN)
    
    def _adjust_boundaries_for_consistency(self, boundaries: List[ClauseBoundary], 
                                         main_clause: Optional[ClausePattern],
                                         subordinate_clauses: List[ClausePattern]) -> List[ClauseBoundary]:
        """å¢ƒç•Œã®æ•´åˆæ€§èª¿æ•´"""
        
        # æ—¢å­˜ã®å¢ƒç•ŒãŒã‚ã‚‹å ´åˆã¯åŸºæœ¬çš„ã«ãã®ã¾ã¾ä½¿ç”¨
        if boundaries and len(boundaries) >= 1 + len(subordinate_clauses):
            return boundaries
        
        # ä¸è¶³ã—ã¦ã„ã‚‹å¢ƒç•Œã‚’è£œå®Œ
        adjusted = boundaries.copy()
        
        # ä¸»ç¯€å¢ƒç•ŒãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        if main_clause and not any(b.clause_type == 'main' for b in adjusted):
            adjusted.append(main_clause.function.boundary)
        
        return adjusted

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    detector = StagedGrammarDetector()
    
    test_sentence = "Having finished the project, the student submitted it confidently."
    result = detector.detect_staged_grammar(test_sentence)
    
    print("\nğŸ¯ Staged Processing Results:")
    print(f"Main: {result.main_clause.grammar_pattern.value if result.main_clause else 'None'}")
    for i, sub in enumerate(result.subordinate_clauses, 1):
        print(f"Sub {i}: {sub.grammar_pattern.value}")
